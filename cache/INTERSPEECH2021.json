[
    {
        "paper_name": "Interspeech 2021, 22nd Annual Conference of the International Speech Communication Association, Brno, Czechia, 30 August - 3 September 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021",
        "paper_authors": [
            "Hynek Hermansky",
            "Honza Cernock\u00fd",
            "Luk\u00e1s Burget",
            "Lori Lamel",
            "Odette Scharenborg",
            "Petr Motl\u00edcek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conversion of Airborne to Bone-Conducted Speech with Deep Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-473",
        "paper_authors": [
            "Michael Pucher",
            "Thomas Woltron"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-546",
        "paper_authors": [
            "Mark\u00e9ta Rez\u00e1ckov\u00e1",
            "Jan Svec",
            "Daniel Tihelka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating the Extrapolation Capabilities of Neural Vocoders to Extreme Pitch Values",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1547",
        "paper_authors": [
            "Olivier Perrotin",
            "Hussein El Amouri",
            "G\u00e9rard Bailly",
            "Thomas Hueber"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Systematic Review and Analysis of Multilingual Data Strategies in Text-to-Speech for Low-Resource Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1565",
        "paper_authors": [
            "Phat Do",
            "Matt Coler",
            "Jelske Dijkstra",
            "Esther Klabbers"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Indicators of Speech Motor Coordination in Adults With and Without Traumatic Brain Injury",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1581",
        "paper_authors": [
            "Tanya Talkar",
            "Nancy Pearl Solomon",
            "Douglas S. Brungart",
            "Stefanie E. Kuchinsky",
            "Megan M. Eitel",
            "Sara M. Lippa",
            "Tracey A. Brickell",
            "Louis M. French",
            "Rael T. Lange",
            "Thomas F. Quatieri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Modeling Glottal Source Information for Phonation Assessment in Parkinson's Disease",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1084",
        "paper_authors": [
            "Juan Camilo V\u00e1squez-Correa",
            "Julian Fritsch",
            "Juan Rafael Orozco-Arroyave",
            "Elmar N\u00f6th",
            "Mathew Magimai-Doss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distortion of Voiced Obstruents for Differential Diagnosis Between Parkinson's Disease and Multiple System Atrophy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-223",
        "paper_authors": [
            "Khalid Daoudi",
            "Biswajit Das",
            "Solange Milh\u00e9 de Saint Victor",
            "Alexandra Foubert-Samier",
            "Anne Pavy-Le Traon",
            "Olivier Rascol",
            "Wassilios G. Meissner",
            "Virginie Woisard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Study into Pre-Training Strategies for Spoken Language Understanding on Dysarthric Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1720",
        "paper_authors": [
            "Pu Wang",
            "Bagher BabaAli",
            "Hugo Van hamme"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EasyCall Corpus: A Dysarthric Speech Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-549",
        "paper_authors": [
            "Rosanna Turrisi",
            "Arianna Braccia",
            "Marco Emanuele",
            "Simone Giulietti",
            "Maura Pugliatti",
            "Mariachiara Sensi",
            "Luciano Fadiga",
            "Leonardo Badino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Benchmark of Dynamical Variational Autoencoders Applied to Speech Spectrogram Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-256",
        "paper_authors": [
            "Xiaoyu Bie",
            "Laurent Girin",
            "Simon Leglaive",
            "Thomas Hueber",
            "Xavier Alameda-Pineda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fricative Phoneme Detection Using Deep Neural Networks and its Comparison to Traditional Methods",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-645",
        "paper_authors": [
            "Metehan Yurt",
            "Pavan Kantharaju",
            "Sascha Disch",
            "Andreas Niedermeier",
            "Alberto N. Escalante-B.",
            "Veniamin I. Morgenshtern"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identification of F1 and F2 in Speech Using Modified Zero Frequency Filtering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1598",
        "paper_authors": [
            "RaviShankar Prasad",
            "Mathew Magimai-Doss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phoneme-to-Audio Alignment with Recurrent Neural Networks for Speaking and Singing Voice",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1676",
        "paper_authors": [
            "Yann Teytaut",
            "Axel Roebel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Convolutional Neural Network for Text-Independent Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-65",
        "paper_authors": [
            "Seong-Hu Kim",
            "Yong-Hwa Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bidirectional Multiscale Feature Aggregation for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-111",
        "paper_authors": [
            "Jiajun Qi",
            "Wu Guo",
            "Bin Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Time Delay Neural Network Based Speaker Recognition with Convolutional Block and Feature Aggregation Methods",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-356",
        "paper_authors": [
            "Yu-Jia Zhang",
            "Yih-Wen Wang",
            "Chia-Ping Chen",
            "Chung-Li Lu",
            "Bo-Cheng Chan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Deep CNN Architectures with Variable-Length Training Samples for Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-559",
        "paper_authors": [
            "Yanfeng Wu",
            "Junan Zhao",
            "Chenkai Guo",
            "Jing Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Binary Neural Network for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-600",
        "paper_authors": [
            "Tinglong Zhu",
            "Xiaoyi Qin",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mutual Information Enhanced Training for Speaker Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1436",
        "paper_authors": [
            "Youzhi Tu",
            "Man-Wai Mak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Y-Vector: Multiscale Waveform Encoder for Speaker Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1707",
        "paper_authors": [
            "Ge Zhu",
            "Fei Jiang",
            "Zhiyao Duan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phoneme-Aware and Channel-Wise Attentive Learning for Text Dependent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2137",
        "paper_authors": [
            "Yan Liu",
            "Zheng Li",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Serialized Multi-Layer Multi-Head Attention for Neural Speaker Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2210",
        "paper_authors": [
            "Hongning Zhu",
            "Kong Aik Lee",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TacoLPCNet: Fast and Stable TTS by Conditioning LPCNet on Mel Spectrogram Predictions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-852",
        "paper_authors": [
            "Cheng Gong",
            "Longbiao Wang",
            "Ju Zhang",
            "Shaotong Guo",
            "Yuguang Wang",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FastPitchFormant: Source-Filter Based Decomposed Modeling for Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-866",
        "paper_authors": [
            "Taejun Bak",
            "Jae-Sung Bae",
            "Hanbin Bae",
            "Young-Ik Kim",
            "Hoon-Young Cho"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sequence-to-Sequence Learning for Deep Gaussian Process Based Speech Synthesis Using Self-Attention GP Layer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-896",
        "paper_authors": [
            "Taiki Nakamura",
            "Tomoki Koriyama",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic and Prosodic Information Estimation from Texts for Genuine Japanese End-to-End Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-914",
        "paper_authors": [
            "Naoto Kakegawa",
            "Sunao Hara",
            "Masanobu Abe",
            "Yusuke Ijima"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Information Sieve: Content Leakage Reduction in End-to-End Prosody Transfer for Expressive Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1011",
        "paper_authors": [
            "Xudong Dai",
            "Cheng Gong",
            "Longbiao Wang",
            "Kaili Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deliberation-Based Multi-Pass Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1405",
        "paper_authors": [
            "Qingyun Dou",
            "Xixin Wu",
            "Moquan Wan",
            "Yiting Lu",
            "Mark J. F. Gales"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parallel Tacotron 2: A Non-Autoregressive Neural TTS Model with Differentiable Duration Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1461",
        "paper_authors": [
            "Isaac Elias",
            "Heiga Zen",
            "Jonathan Shen",
            "Yu Zhang",
            "Ye Jia",
            "R. J. Skerry-Ryan",
            "Yonghui Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer-Based Acoustic Modeling for Streaming Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1655",
        "paper_authors": [
            "Chunyang Wu",
            "Zhiping Xiu",
            "Yangyang Shi",
            "Ozlem Kalinli",
            "Christian Fuegen",
            "Thilo K\u00f6hler",
            "Qing He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1757",
        "paper_authors": [
            "Ye Jia",
            "Heiga Zen",
            "Jonathan Shen",
            "Yu Zhang",
            "Yonghui Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speed up Training with Variable Length Inputs by Efficient Batching Strategies",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2100",
        "paper_authors": [
            "Zhenhao Ge",
            "Lakshmish Kaushik",
            "Masanori Omote",
            "Saket Kumar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Funnel Deep Complex U-Net for Phase-Aware Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-10",
        "paper_authors": [
            "Yuhang Sun",
            "Linju Yang",
            "Huifeng Zhu",
            "Jie Hao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Temporal Convolutional Network with Frequency Dimension Adaptive Attention for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-46",
        "paper_authors": [
            "Qiquan Zhang",
            "Qi Song",
            "Aaron Nicolson",
            "Tian Lan",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perceptual Contributions of Vowels and Consonant-Vowel Transitions in Understanding Time-Compressed Mandarin Sentences",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-58",
        "paper_authors": [
            "Changjie Pan",
            "Feng Yang",
            "Fei Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning for Speech Intelligibility Improvement in Noisy Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-150",
        "paper_authors": [
            "Ritujoy Biswas",
            "Karan Nathwani",
            "Vinayak Abrol"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison of Remote Experiments Using Crowdsourcing and Laboratory Experiments on Speech Intelligibility",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-174",
        "paper_authors": [
            "Ayako Yamamoto",
            "Toshio Irino",
            "Kenichi Arai",
            "Shoko Araki",
            "Atsunori Ogawa",
            "Keisuke Kinoshita",
            "Tomohiro Nakatani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Know Your Enemy, Know Yourself: A Unified Two-Stage Framework for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-238",
        "paper_authors": [
            "Wenzhe Liu",
            "Andong Li",
            "Yuxuan Ke",
            "Chengshi Zheng",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Enhancement with Weakly Labelled Data from AudioSet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-259",
        "paper_authors": [
            "Qiuqiang Kong",
            "Haohe Liu",
            "Xingjian Du",
            "Li Chen",
            "Rui Xia",
            "Yuxuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Perceptual Quality by Phone-Fortified Perceptual Loss Using Wasserstein Distance for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-582",
        "paper_authors": [
            "Tsun-An Hsieh",
            "Cheng Yu",
            "Szu-Wei Fu",
            "Xugang Lu",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-599",
        "paper_authors": [
            "Szu-Wei Fu",
            "Cheng Yu",
            "Tsun-An Hsieh",
            "Peter Plantinga",
            "Mirco Ravanelli",
            "Xugang Lu",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Spectro-Temporal Glimpsing Index (STGI) for Speech Intelligibility Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-605",
        "paper_authors": [
            "Amin Edraki",
            "Wai-Yip Chan",
            "Jesper Jensen",
            "Daniel Fogerty"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Learning Based Phone-Fortified Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-734",
        "paper_authors": [
            "Yuanhang Qiu",
            "Ruili Wang",
            "Satwinder Singh",
            "Zhizhong Ma",
            "Feng Hou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incorporating Embedding Vectors from a Human Mean-Opinion Score Prediction Model for Monaural Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1844",
        "paper_authors": [
            "Khandokar Md. Nayem",
            "Donald S. Williamson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Restoring Degraded Speech via a Modified Diffusion Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1889",
        "paper_authors": [
            "Jianwei Zhang",
            "Suren Jayasuriya",
            "Visar Berisha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "User-Initiated Repetition-Based Recovery in Multi-Utterance Dialogue Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1536",
        "paper_authors": [
            "Hoang Long Nguyen",
            "Vincent Renkens",
            "Joris Pelemans",
            "Srividya Pranavi Potharaju",
            "Anil Kumar Nalamalapu",
            "Murat Akbacak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Dialogue Learning for Spoken Conversational Question Answering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-120",
        "paper_authors": [
            "Nuo Chen",
            "Chenyu You",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Act-Aware Slot-Value Predicting in Multi-Domain Dialogue State Tracking",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-138",
        "paper_authors": [
            "Ruolin Su",
            "Ting-Wei Wu",
            "Biing-Hwang Juang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dialogue Situation Recognition for Everyday Conversation Using Multimodal Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-171",
        "paper_authors": [
            "Yuya Chiba",
            "Ryuichiro Higashinaka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Spoken-Response Generation Using Prosodic and Linguistic Context for Conversational Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-381",
        "paper_authors": [
            "Yoshihiro Yamazaki",
            "Yuya Chiba",
            "Takashi Nose",
            "Akinori Ito"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantic Transportation Prototypical Network for Few-Shot Intent Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-548",
        "paper_authors": [
            "Weiyuan Xu",
            "Peilin Zhou",
            "Chenyu You",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain-Specific Multi-Agent Dialog Policy Learning in Multi-Domain Task-Oriented Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-887",
        "paper_authors": [
            "Li Tang",
            "Yuke Si",
            "Longbiao Wang",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging ASR N-Best in Deep Entity Retrieval",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1370",
        "paper_authors": [
            "Haoyu Wang",
            "John Chen",
            "Majid Laali",
            "Kevin Durda",
            "Jeff King",
            "William Campbell",
            "Yang Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1242",
        "paper_authors": [
            "Shuai Zhang",
            "Jiangyan Yi",
            "Zhengkun Tian",
            "Ye Bai",
            "Jianhua Tao",
            "Xuefei Liu",
            "Zhengqi Wen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1434",
        "paper_authors": [
            "Kathleen Siminyu",
            "Xinjian Li",
            "Antonios Anastasopoulos",
            "David R. Mortensen",
            "Michael R. Marlo",
            "Graham Neubig"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Acoustic Modelling Using Raw Source and Filter Components",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-53",
        "paper_authors": [
            "Erfan Loweimi",
            "Zoran Cvetkovic",
            "Peter Bell",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Noise Robust Acoustic Modeling for Single-Channel Speech Recognition Based on a Stream-Wise Transformer Architecture",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-225",
        "paper_authors": [
            "Masakiyo Fujimoto",
            "Hisashi Kawai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "IR-GAN: Room Impulse Response Generator for Far-Field Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-230",
        "paper_authors": [
            "Anton Ratnarajah",
            "Zhenyu Tang",
            "Dinesh Manocha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scaling Sparsemax Based Channel Selection for Speech Recognition with ad-hoc Microphone Arrays",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-419",
        "paper_authors": [
            "Junqi Chen",
            "Xiao-Lei Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Channel Transformer Transducer for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-655",
        "paper_authors": [
            "Feng-Ju Chang",
            "Martin Radfar",
            "Athanasios Mouchtaris",
            "Maurizio Omologo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation Methods for End-to-End Speech Recognition on Distant-Talk Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-958",
        "paper_authors": [
            "Emiru Tsunoo",
            "Kentaro Shibata",
            "Chaitanya Narisetty",
            "Yosuke Kashiwagi",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-964",
        "paper_authors": [
            "Guodong Ma",
            "Pengfei Hu",
            "Jian Kang",
            "Shen Huang",
            "Hao Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking Evaluation in ASR: Are Our Models Robust Enough?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1758",
        "paper_authors": [
            "Tatiana Likhomanenko",
            "Qiantong Xu",
            "Vineel Pratap",
            "Paden Tomasello",
            "Jacob Kahn",
            "Gilad Avidov",
            "Ronan Collobert",
            "Gabriel Synnaeve"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2084",
        "paper_authors": [
            "Max W. Y. Lam",
            "Jun Wang",
            "Chao Weng",
            "Dan Su",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention-Based Cross-Modal Fusion for Audio-Visual Voice Activity Detection in Musical Video Streams",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-37",
        "paper_authors": [
            "Yuanbo Hou",
            "Zhesong Yu",
            "Xia Liang",
            "Xingjian Du",
            "Bilei Zhu",
            "Zejun Ma",
            "Dick Botteldooren"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Noise-Tolerant Self-Supervised Learning for Audio-Visual Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-43",
        "paper_authors": [
            "Ui-Hyun Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Noisy Student-Teacher Training for Robust Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-72",
        "paper_authors": [
            "Hyun-Jin Park",
            "Pai Zhu",
            "Ignacio L\u00f3pez-Moreno",
            "Niranjan Subrahmanya"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Channel VAD for Transcription of Group Discussion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-200",
        "paper_authors": [
            "Osamu Ichikawa",
            "Kaito Nakano",
            "Takahiro Nakayama",
            "Hajime Shirouzu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Information Fusion Using Cross-Modal Teacher-Student Learning for Voice Activity Detection in Realistic Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-592",
        "paper_authors": [
            "Hengshun Zhou",
            "Jun Du",
            "Hang Chen",
            "Zijun Jing",
            "Shifu Xiong",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enrollment-Less Training for Personalized Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-731",
        "paper_authors": [
            "Naoki Makishima",
            "Mana Ihori",
            "Tomohiro Tanaka",
            "Akihiko Takashima",
            "Shota Orihashi",
            "Ryo Masumura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Activity Detection for Live Speech of Baseball Game Based on Tandem Connection with Speech/Noise Separation Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-792",
        "paper_authors": [
            "Yuto Nonaka",
            "Chee Siang Leow",
            "Akio Kobayashi",
            "Takehito Utsuro",
            "Hiromitsu Nishizaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FastICARL: Fast Incremental Classifier and Representation Learning with Efficient Budget Allocation in Audio Sensing Applications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1091",
        "paper_authors": [
            "Young D. Kwon",
            "Jagmohan Chauhan",
            "Cecilia Mascolo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Transformer-Based Open-Vocabulary Keyword Spotting with Location-Guided Local Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1335",
        "paper_authors": [
            "Bo Wei",
            "Meirong Yang",
            "Tao Zhang",
            "Xiao Tang",
            "Xing Huang",
            "Kyuhong Kim",
            "Jaeyun Lee",
            "Kiho Cho",
            "Sung-Un Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1874",
        "paper_authors": [
            "Saurabhchand Bhati",
            "Jes\u00fas Villalba",
            "Piotr Zelasko",
            "Laureano Moro-Vel\u00e1zquez",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Lightweight Framework for Online Voice Activity Detection in the Wild",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1977",
        "paper_authors": [
            "Xuenan Xu",
            "Heinrich Dinkel",
            "Mengyue Wu",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "\"See what I mean, huh?\" Evaluating Visual Inspection of F0 Tracking in Nasal Grunts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-129",
        "paper_authors": [
            "Aur\u00e9lie Chl\u00e9bowski",
            "Nicolas Ballier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "System Performance as a Function of Calibration Methods, Sample Size and Sampling Variability in Likelihood Ratio-Based Forensic Voice Comparison",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-267",
        "paper_authors": [
            "Bruce Xiao Wang",
            "Vincent Hughes"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voicing Assimilations by French Speakers of German in Stop-Fricative Sequences",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-601",
        "paper_authors": [
            "Anne Bonneau"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Four-Way Classification of Stops with Voicing and Aspiration for Non-Native Speech Evaluation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-635",
        "paper_authors": [
            "Titas Chakraborty",
            "Vaishali Patil",
            "Preeti Rao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic and Prosodic Correlates of Emotions in Urdu Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-910",
        "paper_authors": [
            "Saba Urooj",
            "Benazir Mumtaz",
            "Sarmad Hussain",
            "Ehsan ul Haq"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voicing Contrasts in the Singleton Stops of Palestinian Arabic: Production and Perception",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1079",
        "paper_authors": [
            "Nour Tamim",
            "Silke Hamann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparison of the Accuracy of Dissen and Keshet's (2016) DeepFormants and Traditional LPC Methods for Semi-Automatic Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1487",
        "paper_authors": [
            "Thomas Coy",
            "Vincent Hughes",
            "Philip Harrison",
            "Amelia Jane Gully"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MAP Adaptation Characteristics in Forensic Long-Term Formant Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1697",
        "paper_authors": [
            "Michael Jessen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Linguistic Speaker Individuality of Long-Term Formant Distributions: Phonetic and Forensic Perspectives",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1699",
        "paper_authors": [
            "Justin J. H. Lo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1754",
        "paper_authors": [
            "Rachel Soo",
            "Khia A. Johnson",
            "Molly Babel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Characterizing Voiced and Voiceless Nasals in Mizo",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2104",
        "paper_authors": [
            "Wendy Lalhminghlui",
            "Priyankoo Sarmah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19 Cough, COVID-19 Speech, Escalation & Primates",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-19",
        "paper_authors": [
            "Bj\u00f6rn W. Schuller",
            "Anton Batliner",
            "Christian Bergler",
            "Cecilia Mascolo",
            "Jing Han",
            "Iulia Lefter",
            "Heysem Kaya",
            "Shahin Amiriparian",
            "Alice Baird",
            "Lukas Stappen",
            "Sandra Ottl",
            "Maurice Gerczuk",
            "Panagiotis Tzirakis",
            "Chlo\u00eb Brown",
            "Jagmohan Chauhan",
            "Andreas Grammenos",
            "Apinan Hasthanasombat",
            "Dimitris Spathis",
            "Tong Xia",
            "Pietro Cicuta",
            "L\u00e9on J. M. Rothkrantz",
            "Joeri A. Zwerts",
            "Jelle Treep",
            "Casper S. Kaandorp"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1702",
        "paper_authors": [
            "Rub\u00e9n Solera-Ure\u00f1a",
            "Catarina Botelho",
            "Francisco Teixeira",
            "Thomas Rolland",
            "Alberto Abad",
            "Isabel Trancoso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Phonetic Footprint of Covid-19?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1488",
        "paper_authors": [
            "Philipp Klumpp",
            "Tobias Bocklet",
            "Tom\u00e1s Arias-Vergara",
            "Juan Camilo V\u00e1squez-Correa",
            "Paula Andrea P\u00e9rez-Toro",
            "Sebastian P. Bayerl",
            "Juan Rafael Orozco-Arroyave",
            "Elmar N\u00f6th"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning and Data Augmentation Techniques to the COVID-19 Identification Tasks in ComParE 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1798",
        "paper_authors": [
            "Edresson Casanova",
            "Arnaldo Candido Jr.",
            "Ricardo Corso Fernandes Junior",
            "Marcelo Finger",
            "Lucas Rafael Stefanel Gris",
            "Moacir Antonelli Ponti",
            "Daniel Peixoto Pinto da Silva"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visual Transformers for Primates Classification and Covid Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-273",
        "paper_authors": [
            "Steffen Illium",
            "Robert M\u00fcller",
            "Andreas Sedlmeier",
            "Claudia Linnhoff-Popien"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep-Learning-Based Central African Primate Species Classification with MixUp and SpecAugment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1911",
        "paper_authors": [
            "Thomas Pellegrini"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep and Recurrent Architecture for Primate Vocalization Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1274",
        "paper_authors": [
            "Robert M\u00fcller",
            "Steffen Illium",
            "Claudia Linnhoff-Popien"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Introducing a Central African Primate Vocalisation Dataset for Automated Species Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-154",
        "paper_authors": [
            "Joeri A. Zwerts",
            "Jelle Treep",
            "Casper S. Kaandorp",
            "Floor Meewis",
            "Amparo C. Koot",
            "Heysem Kaya"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Attentive Detection of the Spider Monkey Whinny in the (Actual) Wild",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1969",
        "paper_authors": [
            "Georgios Rizos",
            "Jenna Lawson",
            "Zhuoda Han",
            "Duncan Butler",
            "James Rosindell",
            "Krystian Mikolajczyk",
            "Cristina Banks-Leite",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identifying Conflict Escalation and Primates by Using Ensemble X-Vectors and Fisher Vector Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1173",
        "paper_authors": [
            "Jos\u00e9 Vicente Egas L\u00f3pez",
            "Mercedes Vetr\u00e1b",
            "L\u00e1szl\u00f3 T\u00f3th",
            "G\u00e1bor Gosztolya"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ensemble-Within-Ensemble Classification for Escalation Prediction from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1821",
        "paper_authors": [
            "Oxana Verkholyak",
            "Denis Dresvyanskiy",
            "Anastasia Dvoynikova",
            "Denis Kotov",
            "Elena Ryumina",
            "Alena Velichko",
            "Danila Mamontov",
            "Wolfgang Minker",
            "Alexey Karpov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis by Synthesis: Using an Expressive TTS Model as Feature Extractor for Paralinguistic Speech Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1587",
        "paper_authors": [
            "Dominik Schiller",
            "Silvan Mertes",
            "Pol van Rijn",
            "Elisabeth Andr\u00e9"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Automatic Speech Recognition for People with Atypical Speech",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/christensen21_interspeech.html",
        "paper_authors": [
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Speaker Attribute Information Using Multi Task Learning for Speaker Verification and Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-622",
        "paper_authors": [
            "Chau Luu",
            "Peter Bell",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spine2Net: SpineNet with Res2Net and Time-Squeeze-and-Excitation Blocks for Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1163",
        "paper_authors": [
            "Magdalena Rybicka",
            "Jes\u00fas Villalba",
            "Piotr Zelasko",
            "Najim Dehak",
            "Konrad Kowalczyk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Embeddings by Modeling Channel-Wise Correlations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1442",
        "paper_authors": [
            "Themos Stafylakis",
            "Johan Rohdin",
            "Luk\u00e1s Burget"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Task Neural Network for Robust Multiple Speaker Embedding Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1769",
        "paper_authors": [
            "Weipeng He",
            "Petr Motl\u00edcek",
            "Jean-Marc Odobez"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ICSpk: Interpretable Complex Speaker Embedding Extractor from Raw Waveform",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2016",
        "paper_authors": [
            "Junyi Peng",
            "Xiaoyang Qu",
            "Jianzong Wang",
            "Rongzhi Gu",
            "Jing Xiao",
            "Luk\u00e1s Burget",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosodic Disambiguation Using Chironomic Stylization of Intonation with Native and Non-Native Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-182",
        "paper_authors": [
            "Xiao Xiao",
            "Nicolas Audibert",
            "Gr\u00e9goire Locqueville",
            "Christophe d'Alessandro",
            "Barbara Kuhnert",
            "Claire Pillot-Loiseau"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variation in Perceptual Sensitivity and Compensation for Coarticulation Across Adult and Child Naturally-Produced and TTS Voices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-228",
        "paper_authors": [
            "Aleese Block",
            "Michelle Cohn",
            "Georgia Zellou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extracting Different Levels of Speech Information from EEG Using an LSTM-Based Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-336",
        "paper_authors": [
            "Mohammad Jalilpour-Monesi",
            "Bernd Accou",
            "Tom Francart",
            "Hugo Van hamme"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Word Competition: An Entropy-Based Approach in the DIANA Model of Human Word Comprehension",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1394",
        "paper_authors": [
            "Louis ten Bosch",
            "Lou Boves"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Time-to-Event Models for Analyzing Reaction Time Sequences",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1408",
        "paper_authors": [
            "Louis ten Bosch",
            "Lou Boves"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Models of Reaction Times in Auditory Lexical Decision: RTonset versus RToffset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1700",
        "paper_authors": [
            "Sophie Brand",
            "Kimberley Mulder",
            "Louis ten Bosch",
            "Lou Boves"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpecMix : A Mixed Sample Data Augmentation Method for Training with Time-Frequency Domain Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-103",
        "paper_authors": [
            "Gwantae Kim",
            "David K. Han",
            "Hanseok Ko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-140",
        "paper_authors": [
            "Helin Wang",
            "Yuexian Zou",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Effective Mutual Mean Teaching Based Domain Adaptation Method for Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-281",
        "paper_authors": [
            "Xu Zheng",
            "Yan Song",
            "Li-Rong Dai",
            "Ian McLoughlin",
            "Lin Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Scene Classification Using Kervolution-Based SubSpectralNet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-656",
        "paper_authors": [
            "Ritika Nandi",
            "Shashank Shekhar",
            "Manjunath Mulimani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Event Specific Attention for Polyphonic Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-684",
        "paper_authors": [
            "Harshavardhan Sundar",
            "Ming Sun",
            "Chao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AST: Audio Spectrogram Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-698",
        "paper_authors": [
            "Yuan Gong",
            "Yu-An Chung",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Shallow Convolution-Augmented Transformer with Differentiable Neural Computer for Low-Complexity Classification of Variable-Length Acoustic Scene",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1308",
        "paper_authors": [
            "Soonshin Seo",
            "Donghyun Lee",
            "Ji-Hwan Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Evaluation of Data Augmentation Methods for Sound Scene Geotagging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1837",
        "paper_authors": [
            "Helen L. Bear",
            "Veronica Morfi",
            "Emmanouil Benetos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimizing Latency for Online Video Captioning Using Audio-Visual Transformers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1975",
        "paper_authors": [
            "Chiori Hori",
            "Takaaki Hori",
            "Jonathan Le Roux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variational Information Bottleneck for Effective Low-Resource Audio Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2028",
        "paper_authors": [
            "Shijing Si",
            "Jianzong Wang",
            "Huiming Sun",
            "Jianhan Wu",
            "Chuanyao Zhang",
            "Xiaoyang Qu",
            "Ning Cheng",
            "Lei Chen",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Weakly Supervised Sound Event Detection with Self-Supervised Auxiliary Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2079",
        "paper_authors": [
            "Soham Deshmukh",
            "Bhiksha Raj",
            "Rita Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Event Detection with Classifier Chains",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2218",
        "paper_authors": [
            "Tatsuya Komatsu",
            "Shinji Watanabe",
            "Koichi Miyazaki",
            "Tomoki Hayashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Segment and Tone Production in Continuous Speech of Hearing and Hearing-Impaired Children",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-757",
        "paper_authors": [
            "Shu-Chuan Tseng",
            "Yi-Fen Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effect of Carrier Bandwidth on Understanding Mandarin Sentences in Simulated Electric-Acoustic Hearing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-24",
        "paper_authors": [
            "Feng Wang",
            "Jing Chen",
            "Fei Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparative Study of Different EMG Features for Acoustics-to-EMG Mapping",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2240",
        "paper_authors": [
            "Manthan Sharma",
            "Navaneetha Gaddam",
            "Tejas Umesh",
            "Aditya Murthy",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Image-Based Assessment of Jaw Parameters and Jaw Kinematics for Articulatory Simulation: Preliminary Results",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1155",
        "paper_authors": [
            "Ajish K. Abraham",
            "V. Sivaramakrishnan",
            "N. Swapna",
            "N. Manohar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Attention Self-Supervised Contrastive Learning Based Three-Stage Model for Hand Shape Feature Representation in Cued Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-440",
        "paper_authors": [
            "Jianrong Wang",
            "Nan Gu",
            "Mei Yu",
            "Xuewei Li",
            "Qiang Fang",
            "Li Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Remote Smartphone-Based Speech Collection: Acceptance and Barriers in Individuals with Major Depressive Disorder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1240",
        "paper_authors": [
            "Judith Dineley",
            "Grace Lavelle",
            "Daniel Leightley",
            "Faith Matcham",
            "Sara Siddi",
            "Maria Teresa Pe\u00f1arrubia-Mar\u00eda",
            "Katie M. White",
            "Alina Ivan",
            "Carolin Oetzmann",
            "Sara Simblett",
            "Erin Dawe-Lane",
            "Stuart Bruce",
            "Daniel Stahl",
            "Yatharth Ranjan",
            "Zulqarnain Rashid",
            "Pauline Conde",
            "Amos A. Folarin",
            "Josep Maria Haro",
            "Til Wykes",
            "Richard J. B. Dobson",
            "Vaibhav A. Narayan",
            "Matthew Hotopf",
            "Bj\u00f6rn W. Schuller",
            "Nicholas Cummins",
            "RADAR-CNS Consortium"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Automatic, Simple Ultrasound Biofeedback Parameter for Distinguishing Accurate and Misarticulated Rhotic Syllables",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1749",
        "paper_authors": [
            "Sarah R. Li",
            "Colin T. Annand",
            "Sarah Dugan",
            "Sarah M. Schwab",
            "Kathryn J. Eary",
            "Michael Swearengen",
            "Sarah Stack",
            "Suzanne Boyce",
            "Michael A. Riley",
            "T. Douglas Mast"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Silent versus Modal Multi-Speaker Speech Recognition from Ultrasound and Video",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-23",
        "paper_authors": [
            "Manuel Sam Ribeiro",
            "Aciel Eshky",
            "Korin Richmond",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RaSSpeR: Radar-Based Silent Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1413",
        "paper_authors": [
            "David Ferreira",
            "Samuel S. Silva",
            "Francisco Curado",
            "Ant\u00f3nio J. S. Teixeira"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Speech Reconstruction for Laryngectomees for Silent Speech Interfaces",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1842",
        "paper_authors": [
            "Beiming Cao",
            "Nordine Sebkhi",
            "Arpan Bhavsar",
            "Omer T. Inan",
            "Robin Samlan",
            "Ted Mau",
            "Jun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LACOPE: Latency-Constrained Pitch Estimation for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-633",
        "paper_authors": [
            "Hendrik Schr\u00f6ter",
            "Tobias Rosenkranz",
            "Alberto N. Escalante-B.",
            "Andreas K. Maier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alpha-Stable Autoregressive Fast Multichannel Nonnegative Matrix Factorization for Joint Speech Enhancement and Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-742",
        "paper_authors": [
            "Mathieu Fontaine",
            "Kouhei Sekiguchi",
            "Aditya Arie Nugraha",
            "Yoshiaki Bando",
            "Kazuyoshi Yoshii"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Microphone Array Generalization for Multichannel Narrowband Deep Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-944",
        "paper_authors": [
            "Siyuan Zhang",
            "Xiaofei Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multiple Sound Source Localization Based on Interchannel Phase Differences in All Frequencies with Spectral Masks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1178",
        "paper_authors": [
            "Hyungchan Song",
            "Jong Won Shin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cancellation of Local Competing Speaker with Near-Field Localization for Distributed ad-hoc Sensor Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1329",
        "paper_authors": [
            "Pablo P\u00e9rez Zarazaga",
            "Mariem Bouafif Mansali",
            "Tom B\u00e4ckstr\u00f6m",
            "Zied Lachiri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep Learning Method to Multi-Channel Active Noise Control",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1512",
        "paper_authors": [
            "Hao Zhang",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Clarity-2021 Challenges: Machine Learning Challenges for Advancing Hearing Aid Processing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1574",
        "paper_authors": [
            "Simone Graetzer",
            "Jon Barker",
            "Trevor J. Cox",
            "Michael Akeroyd",
            "John F. Culling",
            "Graham Naylor",
            "Eszter Porter",
            "Rhoddy Viveros Mu\u00f1oz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimising Hearing Aid Fittings for Speech in Noise with a Differentiable Hearing Loss Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1613",
        "paper_authors": [
            "Zehai Tu",
            "Ning Ma",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Explaining Deep Learning Models for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1764",
        "paper_authors": [
            "Sunit Sivasankaran",
            "Emmanuel Vincent",
            "Dominique Fohr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Minimum-Norm Differential Beamforming for Linear Array with Directional Microphones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1989",
        "paper_authors": [
            "Weilong Huang",
            "Jinwei Feng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Streaming Transformer Based ASR Under a Framework of Self-Supervised Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1454",
        "paper_authors": [
            "Songjun Cao",
            "Yueteng Kang",
            "Yanzhe Fu",
            "Xiaoshuo Xu",
            "Sining Sun",
            "Yike Zhang",
            "Long Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "wav2vec-C: A Self-Supervised Model for Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-717",
        "paper_authors": [
            "Samik Sadhu",
            "Di He",
            "Che-Wei Huang",
            "Sri Harish Mallidi",
            "Minhua Wu",
            "Ariya Rastrow",
            "Andreas Stolcke",
            "Jasha Droppo",
            "Roland Maas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Learning Dynamics of Semi-Supervised Training for ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1777",
        "paper_authors": [
            "Electra Wallington",
            "Benji Kershenbaum",
            "Ondrej Klejch",
            "Peter Bell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-236",
        "paper_authors": [
            "Wei-Ning Hsu",
            "Anuroop Sriram",
            "Alexei Baevski",
            "Tatiana Likhomanenko",
            "Qiantong Xu",
            "Vineel Pratap",
            "Jacob Kahn",
            "Ann Lee",
            "Ronan Collobert",
            "Gabriel Synnaeve",
            "Michael Auli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-571",
        "paper_authors": [
            "Yosuke Higuchi",
            "Niko Moritz",
            "Jonathan Le Roux",
            "Takaaki Hori"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparison of Supervised and Unsupervised Pre-Training of End-to-End Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-654",
        "paper_authors": [
            "Ananya Misra",
            "Dongseong Hwang",
            "Zhouyuan Huo",
            "Shefali Garg",
            "Nikhil Siddhartha",
            "Arun Narayanan",
            "Khe Chai Sim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervision in ASR: Sequential MixMatch and Factorized TTS-Based Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-677",
        "paper_authors": [
            "Zhehuai Chen",
            "Andrew Rosenberg",
            "Yu Zhang",
            "Heiga Zen",
            "Mohammadreza Ghodsi",
            "Yinghui Huang",
            "Jesse Emond",
            "Gary Wang",
            "Bhuvana Ramabhadran",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "slimIPL: Language-Model-Free Iterative Pseudo-Labeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-740",
        "paper_authors": [
            "Tatiana Likhomanenko",
            "Qiantong Xu",
            "Jacob Kahn",
            "Gabriel Synnaeve",
            "Ronan Collobert"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetically Motivated Self-Supervised Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-905",
        "paper_authors": [
            "Xianghu Yue",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving RNN-T for Domain Scaling Using Semi-Supervised Training with Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1017",
        "paper_authors": [
            "Yan Deng",
            "Rui Zhao",
            "Zhong Meng",
            "Xie Chen",
            "Bing Liu",
            "Jinyu Li",
            "Yifan Gong",
            "Lei He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Conversation Factorial Designs for Diarization Error Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1864",
        "paper_authors": [
            "Scott Seyfarth",
            "Sundararajan Srinivasan",
            "Katrin Kirchhoff"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SmallER: Scaling Neural Entity Resolution for Edge Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-98",
        "paper_authors": [
            "Ross McGowan",
            "Jinru Su",
            "Vince DiCocco",
            "Thejaswi Muniyappa",
            "Grant P. Strimel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Disfluency Detection with Unlabeled Data and Small BERT Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-351",
        "paper_authors": [
            "Johann C. Rocholl",
            "Vicky Zayats",
            "Daniel D. Walker",
            "Noah B. Murad",
            "Aaron Schneider",
            "Daniel J. Liebling"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discriminative Self-Training for Punctuation Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-246",
        "paper_authors": [
            "Qian Chen",
            "Wen Wang",
            "Mengzhe Chen",
            "Qinglin Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Joint Modeling of Multiple Spoken-Text-Style Conversion Tasks Using Switching Tokens",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1607",
        "paper_authors": [
            "Mana Ihori",
            "Naoki Makishima",
            "Tomohiro Tanaka",
            "Akihiko Takashima",
            "Shota Orihashi",
            "Ryo Masumura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Noise Robust Method for Word-Level Pronunciation Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1005",
        "paper_authors": [
            "Binghuai Lin",
            "Liyuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Targeted Keyword Filtering for Accelerated Spoken Topic Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1670",
        "paper_authors": [
            "Jonathan Wintrode"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Speech Summarization Through Semantic Concept Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1923",
        "paper_authors": [
            "Shruti Palaskar",
            "Ruslan Salakhutdinov",
            "Alan W. Black",
            "Florian Metze"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Semantic Understanding with Self-Supervised Methods for Abstractive Dialogue Summarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1270",
        "paper_authors": [
            "Hyunjae Lee",
            "Jaewoong Yun",
            "Hyunjin Choi",
            "Seongho Joe",
            "Youngjune L. Gwon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Transition Patterns in Three-Party Conversation: Evidence from English, Estonian and Swedish",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-199",
        "paper_authors": [
            "Marcin Wlodarczak",
            "Emer Gilmartin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Deep Neural Structures and their Interpretability in the Domain of Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1730",
        "paper_authors": [
            "Samuel J. Broughton",
            "Md. Asif Jalal",
            "Roger K. Moore"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-Stage Sequence-to-Sequence Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-781",
        "paper_authors": [
            "Kun Zhou",
            "Berrak Sisman",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Voice Conversion Against Neural Spoofing Detectors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-948",
        "paper_authors": [
            "Yi-Yang Ding",
            "Li-Juan Liu",
            "Yu Hu",
            "Zhen-Hua Ling"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Improved StarGAN for Emotional Voice Conversion: Enhancing Voice Quality and Data Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1253",
        "paper_authors": [
            "Xiangheng He",
            "Junjie Chen",
            "Georgios Rizos",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TVQVC: Transformer Based Vector Quantized Variational Autoencoder with CTC Loss for Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1301",
        "paper_authors": [
            "Ziyi Chen",
            "Pengyuan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enriching Source Style Transfer in Recognition-Synthesis Based Non-Parallel Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1351",
        "paper_authors": [
            "Zhichao Wang",
            "Xinyong Zhou",
            "Fengyu Yang",
            "Tao Li",
            "Hongqiang Du",
            "Lei Xie",
            "Wendong Gan",
            "Haitao Chen",
            "Hai Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1356",
        "paper_authors": [
            "Jheng-Hao Lin",
            "Yist Y. Lin",
            "Chung-Ming Chien",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Exemplar Selection Algorithm for Native-Nonnative Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1740",
        "paper_authors": [
            "Christopher Liberatore",
            "Ricardo Gutierrez-Osuna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarially Learning Disentangled Speech Representations for Robust Multi-Factor Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1990",
        "paper_authors": [
            "Jie Wang",
            "Jingbei Li",
            "Xintao Zhao",
            "Zhiyong Wu",
            "Shiyin Kang",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Many-to-Many Voice Conversion Based Feature Disentanglement Using Variational Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2086",
        "paper_authors": [
            "Manh Luong",
            "Viet-Anh Tran"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Privacy-Preserving Voice Anti-Spoofing Using Secure Multi-Party Computation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-983",
        "paper_authors": [
            "Ouba\u00efda Chouchane",
            "Baptiste Brossier",
            "Jorge Esteban Gamboa Gamboa",
            "Thomas Lardy",
            "Hemlata Tak",
            "Orhan Ermis",
            "Madhu R. Kamble",
            "Jose Patino",
            "Nicholas W. D. Evans",
            "Melek \u00d6nen",
            "Massimiliano Todisco"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Configurable Privacy-Preserving Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1783",
        "paper_authors": [
            "Ranya Aloufi",
            "Hamed Haddadi",
            "David Boyle"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adjunct-Emeritus Distillation for Semi-Supervised Language Model Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-27",
        "paper_authors": [
            "Scott Novotney",
            "Yile Gu",
            "Ivan Bulyko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Communication-Efficient Agnostic Federated Averaging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-153",
        "paper_authors": [
            "Jae Ro",
            "Mingqing Chen",
            "Rajiv Mathews",
            "Mehryar Mohri",
            "Ananda Theertha Suresh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Privacy-Preserving Feature Extraction for Cloud-Based Wake Word Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-262",
        "paper_authors": [
            "Timm Koppelmann",
            "Alexandru Nelus",
            "Lea Sch\u00f6nherr",
            "Dorothea Kolossa",
            "Rainer Martin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-640",
        "paper_authors": [
            "Chao-Han Huck Yang",
            "Sabato Marco Siniscalchi",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continual Learning for Fake Audio Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-794",
        "paper_authors": [
            "Haoxin Ma",
            "Jiangyan Yi",
            "Jianhua Tao",
            "Ye Bai",
            "Zhengkun Tian",
            "Chenglong Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating the Vulnerability of End-to-End Automatic Speech Recognition Models to Membership Inference Attacks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1188",
        "paper_authors": [
            "Muhammad A. Shah",
            "Joseph Szurley",
            "Markus M\u00fcller",
            "Athanasios Mouchtaris",
            "Jasha Droppo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SynthASR: Unlocking Synthetic Data for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1882",
        "paper_authors": [
            "Amin Fazel",
            "Wei Yang",
            "Yulan Liu",
            "Roberto Barra-Chicote",
            "Yixiong Meng",
            "Roland Maas",
            "Jasha Droppo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DiCOVA Challenge: Dataset, Task, and Baseline System for COVID-19 Diagnosis Using Acoustics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-74",
        "paper_authors": [
            "Ananya Muguli",
            "Lancelot Pinto",
            "Nirmala R.",
            "Neeraj Kumar Sharma",
            "Prashant Krishnan V",
            "Prasanta Kumar Ghosh",
            "Rohit Kumar",
            "Shrirama Bhat",
            "Srikanth Raj Chetupalli",
            "Sriram Ganapathy",
            "Shreyas Ramoji",
            "Viral Nanda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PANACEA Cough Sound-Based Diagnosis of COVID-19 for the DiCOVA 2021 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1062",
        "paper_authors": [
            "Madhu R. Kamble",
            "Jos\u00e9 Andr\u00e9s Gonz\u00e1lez L\u00f3pez",
            "Teresa Grau",
            "Juan M. Esp\u00edn",
            "Lorenzo Cascioli",
            "Yiqing Huang",
            "Alejandro Gomez-Alanis",
            "Jose Patino",
            "Roberto Font",
            "Antonio M. Peinado",
            "Angel M. Gomez",
            "Nicholas W. D. Evans",
            "Maria A. Zuluaga",
            "Massimiliano Todisco"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recognising Covid-19 from Coughing Using Ensembles of SVMs and LSTMs with Handcrafted and Deep Audio Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1267",
        "paper_authors": [
            "Vincent Karas",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting COVID-19 from Audio Recording of Coughs Using Random Forests and Support Vector Machines",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2191",
        "paper_authors": [
            "Isabella S\u00f6dergren",
            "Maryam Pahlavan Nodeh",
            "Prakash Chandra Chhipa",
            "Konstantina Nikolaidou",
            "Gy\u00f6rgy Kov\u00e1cs"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Diagnosis of COVID-19 Using Auditory Acoustic Cues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-497",
        "paper_authors": [
            "Rohan Kumar Das",
            "Maulik C. Madhavi",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Classification of COVID-19 from Cough Using Autoregressive Predictive Coding Pretraining and Spectral Data Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-799",
        "paper_authors": [
            "John B. Harvill",
            "Yash R. Wani",
            "Mark Hasegawa-Johnson",
            "Narendra Ahuja",
            "David G. Beiser",
            "David Chestek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The DiCOVA 2021 Challenge - An Encoder-Decoder Approach for COVID-19 Recognition from Coughing Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-811",
        "paper_authors": [
            "Gauri Deshpande",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "COVID-19 Detection from Spectral Features on the DiCOVA Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1031",
        "paper_authors": [
            "Kotra Venkata Sai Ritwik",
            "Shareef Babu Kalluri",
            "Deepu Vijayasenan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cough-Based COVID-19 Detection with Contextual Attention Convolutional Neural Networks and Gender Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1052",
        "paper_authors": [
            "Adria Mallol-Ragolta",
            "Helena Cuesta",
            "Emilia G\u00f3mez",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contrastive Learning of Cough Descriptors for Automatic COVID-19 Preliminary Diagnosis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1249",
        "paper_authors": [
            "Swapnil Bhosale",
            "Upasana Tiwari",
            "Rupayan Chakraborty",
            "Sunil Kumar Kopparapu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Feature Selection and Explainability for COVID-19 Diagnostics from Cough Sounds",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2197",
        "paper_authors": [
            "Fl\u00e1vio \u00c1vila",
            "Amir H. Poorjam",
            "Deepak Mittal",
            "Charles Dognin",
            "Ananya Muguli",
            "Rohit Kumar",
            "Srikanth Raj Chetupalli",
            "Sriram Ganapathy",
            "Maneesh Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Application for Detecting Depression, Parkinson's Disease and Dysphonic Speech",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/kiss21_interspeech.html",
        "paper_authors": [
            "G\u00e1bor Kiss",
            "D\u00e1vid Sztah\u00f3",
            "Mikl\u00f3s G\u00e1briel Tulics"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Beey: More Than a Speech-to-Text Editor",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/weingartova21_interspeech.html",
        "paper_authors": [
            "Lenka Weingartov\u00e1",
            "Veronika Volna",
            "Ewa Balejov\u00e1"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Downsizing of Vocal-Tract Models to Line up Variations and Reduce Manufacturing Costs",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/arai21_interspeech.html",
        "paper_authors": [
            "Takayuki Arai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ROXANNE Research Platform: Automate Criminal Investigations",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/fabien21_interspeech.html",
        "paper_authors": [
            "Ma\u00ebl Fabien",
            "Shantipriya Parida",
            "Petr Motl\u00edcek",
            "Dawei Zhu",
            "Aravind Krishnan",
            "Hoang H. Nguyen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The LIUM Human Active Correction Platform for Speaker Diarization",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/flucha21_interspeech.html",
        "paper_authors": [
            "Alexandre Flucha",
            "Anthony Larcher",
            "Ambuj Mehrish",
            "Sylvain Meignier",
            "Florian Plaut",
            "Nicolas Poupon",
            "Yevhenii Prokopalo",
            "Adrien Puertolas",
            "Meysam Shamsi",
            "Marie Tahon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On-Device Streaming Transformer-Based End-to-End Speech Recognition",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/oh21_interspeech.html",
        "paper_authors": [
            "Yoo Rhee Oh",
            "Kiyoung Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Advanced Semi-Blind Speaker Extraction and Tracking Implemented in Experimental Device with Revolving Dense Microphone Array",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/cmejla21_interspeech.html",
        "paper_authors": [
            "Jaroslav Cmejla",
            "Tom\u00e1s Kounovsk\u00fd",
            "Jakub Jansk\u00fd",
            "Jir\u00ed M\u00e1lek",
            "M. Rozkovec",
            "Zbynek Koldovsk\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Forty Years of Speech and Language Processing: From Bayes Decision Rule to Deep Learning",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/ney21_interspeech.html",
        "paper_authors": [
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Information Retrieval for ZeroSpeech 2021: The Submission by University of Wroclaw",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1465",
        "paper_authors": [
            "Jan Chorowski",
            "Grzegorz Ciesielski",
            "Jaroslaw Dzikowski",
            "Adrian Lancucki",
            "Ricard Marxer",
            "Mateusz Opala",
            "Piotr Pusz",
            "Pawel Rychlikowski",
            "Michal Stypulkowski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Aligned Contrastive Predictive Coding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1544",
        "paper_authors": [
            "Jan Chorowski",
            "Grzegorz Ciesielski",
            "Jaroslaw Dzikowski",
            "Adrian Lancucki",
            "Ricard Marxer",
            "Mateusz Opala",
            "Piotr Pusz",
            "Pawel Rychlikowski",
            "Michal Stypulkowski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Text Denormalization for Speech Transcripts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1814",
        "paper_authors": [
            "Benjamin Suter",
            "Josef Nov\u00e1k"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fearless Steps Challenge Phase-3 (FSC P3): Advancing SLT for Unseen Channel and Mission Data Across NASA Apollo Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2011",
        "paper_authors": [
            "Aditya Joglekar",
            "Seyed Omid Sadjadi",
            "Meena Chandra Shekar",
            "Christopher Cieri",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Quality in Verbal Irony: Electroglottographic Analyses of Ironic Utterances in Standard Austrian German",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-452",
        "paper_authors": [
            "Hannah Leykum"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Synchronic Fortition in Five Romance Languages? A Large Corpus-Based Study of Word-Initial Devoicing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-939",
        "paper_authors": [
            "Mathilde Hutin",
            "Yaru Wu",
            "Ad\u00e8le Jatteau",
            "Ioana Vasilescu",
            "Lori Lamel",
            "Martine Adda-Decker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Glottal Stops in Upper Sorbian: A Data-Driven Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1101",
        "paper_authors": [
            "Ivan Kraljevski",
            "Maria Paola Bissiri",
            "Frank Duckhorn",
            "Constanze Tsch\u00f6pe",
            "Matthias Wolff"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cue Interaction in the Perception of Prosodic Prominence: The Role of Voice Quality",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1357",
        "paper_authors": [
            "Bogdan Ludusan",
            "Petra Wagner",
            "Marcin Wlodarczak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Glottal Sounds in Korebaju",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1417",
        "paper_authors": [
            "Jenifer Vega Rodr\u00edguez",
            "Nathalie Vall\u00e9e"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Classification of Phonation Types in Spontaneous Speech: Towards a New Workflow for the Characterization of Speakers' Voice Quality",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1765",
        "paper_authors": [
            "Ana\u00efs Chanclu",
            "Imen Ben Amor",
            "C\u00e9dric Gendrot",
            "Emmanuel Ferragne",
            "Jean-Fran\u00e7ois Bonastre"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Measuring Voice Quality Parameters After Speaker Pseudonymization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-26",
        "paper_authors": [
            "Rob J. J. H. van Son"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Recognition of Emotional Engagement of People with Dementia",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-567",
        "paper_authors": [
            "Lars Steinert",
            "Felix Putze",
            "Dennis K\u00fcster",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaking Corona? Human and Machine Recognition of COVID-19 from Voice",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1771",
        "paper_authors": [
            "Pascal Hecker",
            "Florian B. Pokorny",
            "Katrin D. Bartl-Pokorny",
            "Uwe Reichel",
            "Zhao Ren",
            "Simone Hantke",
            "Florian Eyben",
            "Dagmar M. Schuller",
            "Bert Arnrich",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic-Prosodic, Lexical and Demographic Cues to Persuasiveness in Competitive Debate Speeches",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1891",
        "paper_authors": [
            "Huyen Nguyen",
            "Ralph Vente",
            "David Lupea",
            "Sarah Ita Levitan",
            "Julia Hirschberg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Bayesian Adaptation of PLDA for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-33",
        "paper_authors": [
            "Bengt J. Borgstr\u00f6m"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The DKU-Duke-Lenovo System Description for the Fearless Steps Challenge Phase III",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-235",
        "paper_authors": [
            "Weiqing Wang",
            "Danwei Cai",
            "Jin Wang",
            "Qingjian Lin",
            "Xuyang Wang",
            "Mi Hong",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Meta-Learning Training for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-405",
        "paper_authors": [
            "Yafeng Chen",
            "Wu Guo",
            "Bin Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variational Information Bottleneck Based Regularization for Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-482",
        "paper_authors": [
            "Dan Wang",
            "Yuanjie Dong",
            "Yaxing Li",
            "Yunfei Zi",
            "Zhihui Zhang",
            "Xiaoqi Li",
            "Shengwu Xiong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Out of a Hundred Trials, How Many Errors Does Your Speaker Verifier Make?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-541",
        "paper_authors": [
            "Niko Br\u00fcmmer",
            "Luciana Ferrer",
            "Albert Swart"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-646",
        "paper_authors": [
            "Roza Chojnacka",
            "Jason Pelecanos",
            "Quan Wang",
            "Ignacio L\u00f3pez-Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AntVoice Neural Speaker Embedding System for FFSVC 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-966",
        "paper_authors": [
            "Zhiming Wang",
            "Furong Xu",
            "Kaisheng Yao",
            "Yuan Cheng",
            "Tao Xiong",
            "Huijia Zhu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gradient Regularization for Noise-Robust Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1216",
        "paper_authors": [
            "Jianchen Li",
            "Jiqing Han",
            "Hongwei Song"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Feature CycleGANs: Speaker Identity Preserving Non-Parallel Microphone-Telephone Domain Adaptation for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1502",
        "paper_authors": [
            "Saurabh Kataria",
            "Jes\u00fas Villalba",
            "Piotr Zelasko",
            "Laureano Moro-Vel\u00e1zquez",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scaling Effect of Self-Supervised Speech Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1935",
        "paper_authors": [
            "Jie Pu",
            "Yuguang Yang",
            "Ruirui Li",
            "Oguz Elibol",
            "Jasha Droppo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Feature Enhancement and Speaker Recognition with Multi-Objective Task-Oriented Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1978",
        "paper_authors": [
            "Yibo Wu",
            "Longbiao Wang",
            "Kong Aik Lee",
            "Meng Liu",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Level Transfer Learning from Near-Field to Far-Field Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1980",
        "paper_authors": [
            "Li Zhang",
            "Qing Wang",
            "Kong Aik Lee",
            "Lei Xie",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Anonymisation Using the McAdams Coefficient",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1070",
        "paper_authors": [
            "Jose Patino",
            "Natalia A. Tomashenko",
            "Massimiliano Todisco",
            "Andreas Nautsch",
            "Nicholas W. D. Evans"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Stream Gated and Pyramidal Temporal Convolutional Neural Networks for Audio-Visual Speech Separation in Multi-Talker Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-366",
        "paper_authors": [
            "Yiyu Luo",
            "Jing Wang",
            "Liang Xu",
            "Lidong Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TeCANet: Temporal-Contextual Attention Network for Environment-Aware Speech Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-481",
        "paper_authors": [
            "Helin Wang",
            "Bo Wu",
            "Lianwu Chen",
            "Meng Yu",
            "Jianwei Yu",
            "Yong Xu",
            "Shi-Xiong Zhang",
            "Chao Weng",
            "Dan Su",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Residual Echo and Noise Cancellation with Feature Attention Module and Multi-Domain Loss Function",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-538",
        "paper_authors": [
            "Jianjun Gu",
            "Longbiao Cheng",
            "Xingwei Sun",
            "Junfeng Li",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MIMO Self-Attentive RNN Beamformer for Multi-Speaker Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-570",
        "paper_authors": [
            "Xiyun Li",
            "Yong Xu",
            "Meng Yu",
            "Shi-Xiong Zhang",
            "Jiaming Xu",
            "Bo Xu",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Personalized PercepNet: Real-Time, Low-Complexity Target Voice Separation and Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-694",
        "paper_authors": [
            "Ritwik Giri",
            "Shrikant Venkataramani",
            "Jean-Marc Valin",
            "Umut Isik",
            "Arvindh Krishnaswamy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scene-Agnostic Multi-Microphone Speech Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-889",
        "paper_authors": [
            "Yochai Yemini",
            "Ethan Fetaya",
            "Haggai Maron",
            "Sharon Gannot"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Manifold-Aware Deep Clustering: Maximizing Angles Between Embedding Vectors Based on Regular Simplex",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1029",
        "paper_authors": [
            "Keitaro Tanaka",
            "Ryosuke Sawata",
            "Shusuke Takahashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep Learning Approach to Multi-Channel and Multi-Microphone Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1508",
        "paper_authors": [
            "Hao Zhang",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Online Multichannel Acoustic Echo Cancellation, Speech Dereverberation and Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1950",
        "paper_authors": [
            "Yueyue Na",
            "Ziteng Wang",
            "Zhang Liu",
            "Biao Tian",
            "Qiang Fu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Should We Always Separate?: Switching Between Enhanced and Observed Signals for Overlapping Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2253",
        "paper_authors": [
            "Hiroshi Sato",
            "Tsubasa Ochiai",
            "Marc Delcroix",
            "Keisuke Kinoshita",
            "Takafumi Moriya",
            "Naoyuki Kamo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Estimating Articulatory Movements in Speech Production with Transformer Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1375",
        "paper_authors": [
            "Sathvik Udupa",
            "Anwesha Roy",
            "Abhayjeet Singh",
            "Aravind Illa",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-300",
        "paper_authors": [
            "Dongchao Yang",
            "Helin Wang",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Decomposition Based on a Hybrid Speech Model and Optimal Segmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-47",
        "paper_authors": [
            "Alfredo Esquivel Jaramillo",
            "Jesper Kj\u00e6r Nielsen",
            "Mads Gr\u00e6sb\u00f8ll Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dropout Regularization for Self-Supervised Learning of Transformer Encoder Speech Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1066",
        "paper_authors": [
            "Jian Luo",
            "Jianzong Wang",
            "Ning Cheng",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Noise Robust Pitch Stylization Using Minimum Mean Absolute Error Criterion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1307",
        "paper_authors": [
            "Chiranjeevi Yarra",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Attribute-Aligned Strategy for Learning Speech Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1341",
        "paper_authors": [
            "Yu-Lin Huang",
            "Bo-Hao Su",
            "Y.-W. Peter Hong",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Raw Speech-to-Articulatory Inversion by Temporal Filtering and Decimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1429",
        "paper_authors": [
            "Abdolreza Sabzi Shahrebabaki",
            "Sabato Marco Siniscalchi",
            "Torbj\u00f8rn Svendsen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Training of a DNN-Based Formant Tracker",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1690",
        "paper_authors": [
            "Jason Lilley",
            "H. Timothy Bunnell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SUPERB: Speech Processing Universal PERformance Benchmark",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1775",
        "paper_authors": [
            "Shu-Wen Yang",
            "Po-Han Chi",
            "Yung-Sung Chuang",
            "Cheng-I Jeff Lai",
            "Kushal Lakhotia",
            "Yist Y. Lin",
            "Andy T. Liu",
            "Jiatong Shi",
            "Xuankai Chang",
            "Guan-Ting Lin",
            "Tzu-Hsien Huang",
            "Wei-Cheng Tseng",
            "Ko-tik Lee",
            "Da-Rong Liu",
            "Zili Huang",
            "Shuyan Dong",
            "Shang-Wen Li",
            "Shinji Watanabe",
            "Abdelrahman Mohamed",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Synchronising Speech Segments with Musical Beats in Mandarin and English Singing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1841",
        "paper_authors": [
            "Cong Zhang",
            "Jian Zhu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FRILL: A Non-Semantic Speech Embedding for Mobile Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2070",
        "paper_authors": [
            "Jacob Peplinski",
            "Joel Shor",
            "Sachin Joglekar",
            "Jake Garrison",
            "Shwetak N. Patel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pitch Contour Separation from Overlapping Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2164",
        "paper_authors": [
            "Hiroki Mori"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Do Sound Event Representations Generalize to Other Audio Tasks? A Case Study in Audio Transfer Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-347",
        "paper_authors": [
            "Anurag Kumar",
            "Yun Wang",
            "Vamsi Krishna Ithapu",
            "Christian Fuegen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation for Spoken Language Understanding via Pretrained Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-117",
        "paper_authors": [
            "Baolin Peng",
            "Chenguang Zhu",
            "Michael Zeng",
            "Jianfeng Gao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FANS: Fusing ASR and NLU for On-Device SLU",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-793",
        "paper_authors": [
            "Martin Radfar",
            "Athanasios Mouchtaris",
            "Siegfried Kunzmann",
            "Ariya Rastrow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sequential End-to-End Intent and Slot Label Classification and Localization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1569",
        "paper_authors": [
            "Yiran Cao",
            "Nihal Potdar",
            "Anderson R. Avila"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DEXTER: Deep Encoding of External Knowledge for Named Entity Recognition in Virtual Assistants",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1877",
        "paper_authors": [
            "Deepak Muralidharan",
            "Joel Ruben Antony Moniz",
            "Weicheng Zhang",
            "Stephen Pulman",
            "Lin Li",
            "Megan Barnes",
            "Jingjing Pan",
            "Jason D. Williams",
            "Alex Acero"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Context-Aware Hierarchical BERT Fusion Network for Multi-Turn Dialog Act Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-95",
        "paper_authors": [
            "Ting-Wei Wu",
            "Ruolin Su",
            "Biing-Hwang Juang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pre-Training for Spoken Language Understanding with Joint Textual and Phonetic Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-234",
        "paper_authors": [
            "Qian Chen",
            "Wen Wang",
            "Qinglin Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Temporal Performance Drop of Deployed Production Spoken Language Understanding Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-580",
        "paper_authors": [
            "Quynh Do",
            "Judith Gaspers",
            "Daniil Sorokin",
            "Patrick Lehnen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Integrating Dialog History into End-to-End Spoken Language Understanding Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1460",
        "paper_authors": [
            "Jatin Ganhotra",
            "Samuel Thomas",
            "Hong-Kwang Jeff Kuo",
            "Sachindra Joshi",
            "George Saon",
            "Zolt\u00e1n T\u00fcske",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1463",
        "paper_authors": [
            "Ting Han",
            "Chongxuan Huang",
            "Wei Peng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1537",
        "paper_authors": [
            "Siddhant Arora",
            "Alissa Ostapenko",
            "Vijay Viswanathan",
            "Siddharth Dalmia",
            "Florian Metze",
            "Shinji Watanabe",
            "Alan W. Black"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantic Data Augmentation for End-to-End Mandarin Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1162",
        "paper_authors": [
            "Jianwei Sun",
            "Zhiyuan Tang",
            "Hengxin Yin",
            "Wei Wang",
            "Xi Zhao",
            "Shuaijiang Zhao",
            "Xiaoning Lei",
            "Wei Zou",
            "Xiangang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Layer-Wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1075",
        "paper_authors": [
            "Xun Gong",
            "Yizhou Lu",
            "Zhikai Zhou",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low Resource German ASR with Untranscribed Data Spoken by Non-Native Children - INTERSPEECH 2021 Shared Task SPAPL System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1974",
        "paper_authors": [
            "Jinhan Wang",
            "Yunzheng Zhu",
            "Ruchao Fan",
            "Wei Chu",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Continuous On-Device Personalization for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-318",
        "paper_authors": [
            "Khe Chai Sim",
            "Angad Chandorkar",
            "Fan Gao",
            "Mason Chua",
            "Tsendsuren Munkhdalai",
            "Fran\u00e7oise Beaufays"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Normalization Using Joint Variational Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-467",
        "paper_authors": [
            "Shashi Kumar",
            "Shakti P. Rath",
            "Abhishek Pandey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1104",
        "paper_authors": [
            "Gaopeng Xu",
            "Song Yang",
            "Lu Ma",
            "Chengfei Li",
            "Zhongqin Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1679",
        "paper_authors": [
            "Tsz Kin Lam",
            "Mayumi Ohta",
            "Shigehiko Schamoni",
            "Stefan Riezler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Cross-Lingual Phonetic Recognition with External Language Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1843",
        "paper_authors": [
            "Heting Gao",
            "Junrui Ni",
            "Yang Zhang",
            "Kaizhi Qian",
            "Shiyu Chang",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rapid Speaker Adaptation for Conformer Transducer: Attention and Bias Are All You Need",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1884",
        "paper_authors": [
            "Yan Huang",
            "Guoli Ye",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Best of Both Worlds: Robust Accented Speech Recognition with Adversarial Transfer Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1888",
        "paper_authors": [
            "Nilaksh Das",
            "Sravan Bodapati",
            "Monica Sunkara",
            "Sundararajan Srinivasan",
            "Duen Horng Chau"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extending Pronunciation Dictionary with Automatically Detected Word Mispronunciations to Improve PAII's System for Interspeech 2021 Non-Native Child English Close Track ASR Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2053",
        "paper_authors": [
            "Wei Chu",
            "Peng Chang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CVC: Contrastive Learning for Non-Parallel Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-137",
        "paper_authors": [
            "Tingle Li",
            "Yichen Liu",
            "Chenxu Hu",
            "Hang Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker Identity in Dysarthric Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-208",
        "paper_authors": [
            "Wen-Chin Huang",
            "Kazuhiro Kobayashi",
            "Yu-Huai Peng",
            "Ching-Feng Liu",
            "Yu Tsao",
            "Hsin-Min Wang",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One-Shot Voice Conversion with Speaker-Agnostic StarGAN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-221",
        "paper_authors": [
            "Sefik Emre Eskimez",
            "Dimitrios Dimitriadis",
            "Ken'ichi Kumatani",
            "Robert Gmyr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fine-Tuning Pre-Trained Voice Conversion Model for Adding New Target Speakers with Limited Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-244",
        "paper_authors": [
            "Takeshi Koshizuka",
            "Hidefumi Ohmura",
            "Kouichi Katsurada"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VQMIVC: Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disentanglement for One-Shot Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-283",
        "paper_authors": [
            "Disong Wang",
            "Liqun Deng",
            "Yu Ting Yeung",
            "Xiao Chen",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "StarGANv2-VC: A Diverse, Unsupervised, Non-Parallel Framework for Natural-Sounding Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-319",
        "paper_authors": [
            "Yinghao Aaron Li",
            "Ali Zare",
            "Nima Mesgarani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Normalization Driven Zero-Shot Multi-Speaker Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-441",
        "paper_authors": [
            "Neeraj Kumar",
            "Srishti Goel",
            "Ankur Narang",
            "Brejesh Lall"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "StarGAN-VC+ASR: StarGAN-Based Non-Parallel Voice Conversion Regularized by Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-492",
        "paper_authors": [
            "Shoki Sakamoto",
            "Akira Taniguchi",
            "Tadahiro Taniguchi",
            "Hirokazu Kameoka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Two-Pathway Style Embedding for Arbitrary Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-506",
        "paper_authors": [
            "Xuexin Xu",
            "Liang Shi",
            "Jinhui Chen",
            "Xunquan Chen",
            "Jie Lian",
            "Pingyuan Lin",
            "Zhihong Zhang",
            "Edwin R. Hancock"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Parallel Any-to-Many Voice Conversion by Replacing Speaker Statistics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-557",
        "paper_authors": [
            "Yufei Liu",
            "Chengzhu Yu",
            "Shuai Wang",
            "Zhenchuan Yang",
            "Yang Chao",
            "Weibin Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Lingual Voice Conversion with a Cycle Consistency Loss on Linguistic Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-687",
        "paper_authors": [
            "Yi Zhou",
            "Xiaohai Tian",
            "Zhizheng Wu",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Robustness of One-Shot Voice Conversion with Deep Discriminative Speaker Encoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2132",
        "paper_authors": [
            "Hongqiang Du",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimizing an Automatic Creaky Voice Detection Method for Australian English Speaking Females",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-711",
        "paper_authors": [
            "Hannah White",
            "Joshua Penney",
            "Andy Gibson",
            "Anita Szakay",
            "Felicity Cox"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-729",
        "paper_authors": [
            "Joshua Penney",
            "Andy Gibson",
            "Felicity Cox",
            "Michael I. Proctor",
            "Anita Szakay"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Voice Function Characteristics of Greek Speakers with Hearing Loss Using Automatic Glottal Source Feature Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-870",
        "paper_authors": [
            "Anna Sfakianaki",
            "George P. Kafentzis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automated Detection of Voice Disorder in the Saarbr\u00fccken Voice Database: Effects of Pathology Subset and Audio Materials",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1507",
        "paper_authors": [
            "Mark A. Huckvale",
            "Catinca Buciuleac"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Accelerometer-Based Measurements of Voice Quality in Children During Semi-Occluded Vocal Tract Exercise with a Narrow Straw in Air",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1918",
        "paper_authors": [
            "Steven M. Lulich",
            "Rita R. Patel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Articulatory Coordination for Speech Motor Tracking in Huntington Disease",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-688",
        "paper_authors": [
            "Matthew Perez",
            "Amrit Romana",
            "Angela Roberts",
            "Noelle Carlozzi",
            "Jennifer Ann Miner",
            "Praveen Dayalu",
            "Emily Mower Provost"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling Dysphonia Severity as a Function of Roughness and Breathiness Ratings in the GRBAS Scale",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1540",
        "paper_authors": [
            "Carlos A. Ferrer",
            "Efren Arag\u00f3n",
            "Mar\u00eda E. Hdez-D\u00edaz",
            "Marc S. De Bodt",
            "Roman Cmejla",
            "Marina Englert",
            "Mara Behlau",
            "Elmar N\u00f6th"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Golos: Russian Dataset for Speech Research",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-462",
        "paper_authors": [
            "Nikolay Karpov",
            "Alexander Denisenko",
            "Fedor Minkin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Radically Old Way of Computing Spectra: Applications in End-to-End ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-643",
        "paper_authors": [
            "Samik Sadhu",
            "Hynek Hermansky"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised End-to-End ASR for Low Resource L2 Swedish",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1710",
        "paper_authors": [
            "Ragheb Al-Ghezi",
            "Yaroslav Getman",
            "Aku Rouhe",
            "Raili Hild\u00e9n",
            "Mikko Kurimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SPGISpeech: 5, 000 Hours of Transcribed Financial Audio for Fully Formatted End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1860",
        "paper_authors": [
            "Patrick K. O'Neill",
            "Vitaly Lavrukhin",
            "Somshubra Majumdar",
            "Vahid Noroozi",
            "Yuekai Zhang",
            "Oleksii Kuchaiev",
            "Jagadeesh Balam",
            "Yuliya Dovzhenko",
            "Keenan Freyberg",
            "Michael D. Shulman",
            "Boris Ginsburg",
            "Shinji Watanabe",
            "Georg Kucsko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-556",
        "paper_authors": [
            "Sol\u00e8ne Evain",
            "Ha Nguyen",
            "Hang Le",
            "Marcely Zanon Boito",
            "Salima Mdhaffar",
            "Sina Alisamir",
            "Ziyi Tong",
            "Natalia A. Tomashenko",
            "Marco Dinarelli",
            "Titouan Parcollet",
            "Alexandre Allauzen",
            "Yannick Est\u00e8ve",
            "Benjamin Lecouteux",
            "Fran\u00e7ois Portet",
            "Solange Rossato",
            "Fabien Ringeval",
            "Didier Schwab",
            "Laurent Besacier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosodic Accommodation in Face-to-Face and Telephone Dialogues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-130",
        "paper_authors": [
            "Pavel Sturm",
            "Radek Skarnitzl",
            "Tom\u00e1s Nechansk\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dialect Features in Heterogeneous and Homogeneous Gheg Speaking Communities",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1090",
        "paper_authors": [
            "Josiane Riverin-Coutl\u00e9e",
            "Concei\u00e7\u00e3o Cunha",
            "Enkeleida Kapia",
            "Jonathan Harrington"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Exploration of the Acoustic Space of Rhotics and Laterals in Ruruuli",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1328",
        "paper_authors": [
            "Margaret Zellers",
            "Alena Witzlack-Makarevich",
            "Lilja Saeboe",
            "Saudah Namyalo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain-Initial Strengthening in Turkish: Acoustic Cues to Prosodic Hierarchy in Stop Consonants",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2230",
        "paper_authors": [
            "K\u00fcbra Bodur",
            "Sweeney Branje",
            "Morgane Peirolo",
            "Ingrid Tiscareno",
            "James Sneed German"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Auxiliary Loss Function for Target Speech Extraction and Recognition with Weak Supervision Based on Speaker Characteristics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-986",
        "paper_authors": [
            "Katerina Zmol\u00edkov\u00e1",
            "Marc Delcroix",
            "Desh Raj",
            "Shinji Watanabe",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Universal Speaker Extraction in the Presence and Absence of Target Speakers for Speech of One and Two Talkers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1939",
        "paper_authors": [
            "Marvin Borsdorf",
            "Chenglin Xu",
            "Haizhou Li",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using X-Vectors for Speech Activity Detection in Broadcast Streams",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-192",
        "paper_authors": [
            "Luk\u00e1s Mateju",
            "Frantisek Kynych",
            "Petr Cerva",
            "Jindrich Zd\u00e1nsk\u00fd",
            "Jir\u00ed M\u00e1lek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Time Delay Estimation for Speaker Localization Using CNN-Based Parametrized GCC-PHAT Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-988",
        "paper_authors": [
            "Daniele Salvati",
            "Carlo Drioli",
            "Gian Luca Foresti"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time Speaker Counting in a Cocktail Party Scenario Using Attention-Guided Convolutional Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-331",
        "paper_authors": [
            "Midia Yousefi",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Language Diarization for Bilingual Code-Switching Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-82",
        "paper_authors": [
            "Hexin Liu",
            "Leibny Paola Garc\u00eda-Perera",
            "Xinyi Zhang",
            "Justin Dauwels",
            "Andy W. H. Khong",
            "Sanjeev Khudanpur",
            "Suzy J. Styles"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling and Training Strategies for Language Recognition Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-277",
        "paper_authors": [
            "Rapha\u00ebl Duroselle",
            "Md. Sahidullah",
            "Denis Jouvet",
            "Irina Illina"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Weight Moving Average Based Alternate Decoupled Learning Algorithm for Long-Tailed Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-776",
        "paper_authors": [
            "Hui Wang",
            "Lin Liu",
            "Yan Song",
            "Lei Fang",
            "Ian McLoughlin",
            "Li-Rong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1186",
        "paper_authors": [
            "Keqi Deng",
            "Songjun Cao",
            "Long Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring wav2vec 2.0 on Speaker Verification and Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1280",
        "paper_authors": [
            "Zhiyun Fan",
            "Meng Li",
            "Shiyu Zhou",
            "Bo Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Phonotactic Representations for Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1310",
        "paper_authors": [
            "Gundluru Ramesh",
            "C. Shiva Kumar",
            "K. Sri Rama Murty"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "E2E-Based Multi-Task Learning Approach to Joint Speech and Accent Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1495",
        "paper_authors": [
            "Jicheng Zhang",
            "Yizhou Peng",
            "Van Tung Pham",
            "Haihua Xu",
            "Hao Huang",
            "Eng Siong Chng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Excitation Source Feature Based Dialect Identification in Ao - A Low Resource Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1672",
        "paper_authors": [
            "Moakala Tzudir",
            "Shikha Baghel",
            "Priyankoo Sarmah",
            "S. R. Mahadeva Prasanna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2062",
        "paper_authors": [
            "Shreya Khare",
            "Ashish R. Mittal",
            "Anuj Diwan",
            "Sunita Sarawagi",
            "Preethi Jyothi",
            "Samarth Bharadwaj"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Acoustic Unit Discovery by Leveraging a Language-Independent Subword Discriminative Feature Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1664",
        "paper_authors": [
            "Siyuan Feng",
            "Piotr Zelasko",
            "Laureano Moro-Vel\u00e1zquez",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Unsupervised Phone and Word Segmentation Using Self-Supervised Vector-Quantized Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-50",
        "paper_authors": [
            "Herman Kamper",
            "Benjamin van Niekerk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech SimCLR: Combining Contrastive and Reconstruction Objective for Self-Supervised Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-391",
        "paper_authors": [
            "Dongwei Jiang",
            "Wubo Li",
            "Miao Cao",
            "Wei Zou",
            "Xiangang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multilingual Transfer of Acoustic Word Embeddings Improves When Training on Languages Related to the Target Zero-Resource Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-461",
        "paper_authors": [
            "Christiaan Jacobs",
            "Herman Kamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analyzing Speaker Information in Self-Supervised Models to Improve Zero-Resource Speech Processing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1182",
        "paper_authors": [
            "Benjamin van Niekerk",
            "Leanne Nortje",
            "Matthew Baas",
            "Herman Kamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Neural-Based Graph Clustering for Variable-Length Speech Representation Discovery of Zero-Resource Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1340",
        "paper_authors": [
            "Shun Takahashi",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Representation Learning Combining Conformer CPC with Deep Cluster for the ZeroSpeech Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1503",
        "paper_authors": [
            "Takashi Maekaku",
            "Xuankai Chang",
            "Yuya Fujita",
            "Li-Wei Chen",
            "Shinji Watanabe",
            "Alexander I. Rudnicky"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identifying Indicators of Vulnerability from Short Speech Segments Using Acoustic and Textual Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1525",
        "paper_authors": [
            "Xia Cui",
            "Amila Gamage",
            "Terry Hanley",
            "Tingting Mu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Zero Resource Speech Challenge 2021: Spoken Language Modelling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1755",
        "paper_authors": [
            "Ewan Dunbar",
            "Mathieu Bernard",
            "Nicolas Hamilakis",
            "Tu Anh Nguyen",
            "Maureen de Seyssel",
            "Patricia Roz\u00e9",
            "Morgane Rivi\u00e8re",
            "Eugene Kharitonov",
            "Emmanuel Dupoux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Federated Learning with New Classes for Audio Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2264",
        "paper_authors": [
            "Gautham Krishna Gudur",
            "Satheesh Kumar Perepu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AVLnet: Learning Audio-Visual Language Representations from Instructional Videos",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1312",
        "paper_authors": [
            "Andrew Rouditchenko",
            "Angie W. Boggust",
            "David Harwath",
            "Brian Chen",
            "Dhiraj Joshi",
            "Samuel Thomas",
            "Kartik Audhkhasi",
            "Hilde Kuehne",
            "Rameswar Panda",
            "Rog\u00e9rio Schmidt Feris",
            "Brian Kingsbury",
            "Michael Picheny",
            "Antonio Torralba",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "N-Singer: A Non-Autoregressive Korean Singing Voice Synthesis System for Pronunciation Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-239",
        "paper_authors": [
            "Gyeong-Hoon Lee",
            "Tae-Woo Kim",
            "Hanbin Bae",
            "Min-Ji Lee",
            "Young-Ik Kim",
            "Hoon-Young Cho"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Lingual Low Resource Speaker Adaptation Using Phonological Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-327",
        "paper_authors": [
            "Georgia Maniati",
            "Nikolaos Ellinas",
            "Konstantinos Markopoulos",
            "Georgios Vamvoukakis",
            "June Sig Sung",
            "Hyoungmin Park",
            "Aimilios Chalamandaris",
            "Pirros Tsiakoulis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improve Cross-Lingual Text-To-Speech Synthesis on Monolingual Corpora with Pitch Contour Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-474",
        "paper_authors": [
            "Haoyue Zhan",
            "Haitong Zhang",
            "Wenjie Ou",
            "Yue Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Lingual Voice Conversion with Disentangled Universal Linguistic Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-552",
        "paper_authors": [
            "Zhenchuan Yang",
            "Weibin Zhang",
            "Yufei Liu",
            "Xiaofen Xing"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EfficientSing: A Chinese Singing Voice Synthesis System Using Duration-Free Acoustic Model and HiFi-GAN Vocoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-771",
        "paper_authors": [
            "Zhengchen Liu",
            "Chenfeng Miao",
            "Qingying Zhu",
            "Minchuan Chen",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Lingual Speaker Adaptation Using Domain Adaptation and Speaker Consistency Loss for Text-To-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-897",
        "paper_authors": [
            "Detai Xin",
            "Yuki Saito",
            "Shinnosuke Takamichi",
            "Tomoki Koriyama",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incorporating Cross-Speaker Style Transfer for Multi-Language Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1265",
        "paper_authors": [
            "Zengqiang Shang",
            "Zhihua Huang",
            "Haozhe Zhang",
            "Pengyuan Zhang",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Contributions of Speech and Facial Landmarks for Talking Head Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1585",
        "paper_authors": [
            "Ege Kesim",
            "Engin Erzin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech2Video: Cross-Modal Distillation for Speech to Video Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1996",
        "paper_authors": [
            "Shijing Si",
            "Jianzong Wang",
            "Xiaoyang Qu",
            "Ning Cheng",
            "Wenqi Wei",
            "Xinghua Zhu",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-36",
        "paper_authors": [
            "Junhyeok Lee",
            "Seungu Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "QISTA-Net-Audio: Audio Super-Resolution via Non-Convex \u2113_q-Norm Minimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-670",
        "paper_authors": [
            "Gang-Xuan Lin",
            "Shih-Wei Hu",
            "Yen-Ju Lu",
            "Yu Tsao",
            "Chun-Shien Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "X-net: A Joint Scale Down and Scale Up Method for Voice Call",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-812",
        "paper_authors": [
            "Liang Wen",
            "Lizhong Wang",
            "Xue Wen",
            "Yuxing Zheng",
            "Youngo Park",
            "Kwang Pyo Choi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WSRGlow: A Glow-Based Waveform Generative Model for Audio Super-Resolution",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-892",
        "paper_authors": [
            "Kexun Zhang",
            "Yi Ren",
            "Changliang Xu",
            "Zhou Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Half-Truth: A Partially Fake Audio Detection Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-930",
        "paper_authors": [
            "Jiangyan Yi",
            "Ye Bai",
            "Jianhua Tao",
            "Haoxin Ma",
            "Zhengkun Tian",
            "Chenglong Wang",
            "Tao Wang",
            "Ruibo Fu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Quality as Predictor of Voice Anti-Spoofing Generalization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1180",
        "paper_authors": [
            "Bhusan Chettri",
            "Rosa Gonz\u00e1lez Hautam\u00e4ki",
            "Md. Sahidullah",
            "Tomi Kinnunen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coded Speech Enhancement Using Neural Network-Based Vector-Quantized Residual Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1204",
        "paper_authors": [
            "Youngju Cheon",
            "Soojoong Hwang",
            "Sangwook Han",
            "Inseon Jang",
            "Jong Won Shin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Channel Opus Compression for Far-Field Automatic Speech Recognition with a Fixed Bitrate Budget",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1214",
        "paper_authors": [
            "Lukas Drude",
            "Jahn Heymann",
            "Andreas Schwarz",
            "Jean-Marc Valin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Prosodic Variations on Accidental Triggers of a Commercial Voice Assistant",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1354",
        "paper_authors": [
            "Ingo Siegert"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving the Expressiveness of Neural Vocoding with Non-Affine Normalizing Flows",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1555",
        "paper_authors": [
            "Adam Gabrys",
            "Yunlong Jiao",
            "Viacheslav Klimkov",
            "Daniel Korzekwa",
            "Roberto Barra-Chicote"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Privacy Through x-Vector and CycleGAN-Based Anonymization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1573",
        "paper_authors": [
            "Gauri P. Prajapati",
            "Dipesh K. Singh",
            "Preet P. Amin",
            "Hemant A. Patil"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Two-Stage Approach to Speech Bandwidth Extension",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1941",
        "paper_authors": [
            "Ju Lin",
            "Yun Wang",
            "Kaustubh Kalgaonkar",
            "Gil Keren",
            "Didi Zhang",
            "Christian Fuegen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Development of a Psychoacoustic Loss Function for the Deep Neural Network (DNN)-Based Speech Coder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2151",
        "paper_authors": [
            "Joon Byun",
            "Seungmin Shin",
            "Youngcheol Park",
            "Jongmo Sung",
            "Seungkwon Beack"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Protecting Gender and Identity with Disentangled Speech Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2163",
        "paper_authors": [
            "Dimitrios Stoidis",
            "Andrea Cavallaro"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perception of Standard Arabic Synthetic Speech Rate",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-39",
        "paper_authors": [
            "Yahya Aldholmi",
            "Rawan Aldhafyan",
            "Asma Alqahtani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Influence of Parallel Processing on Illusory Vowels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-89",
        "paper_authors": [
            "Takeshi Kishiyama"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring the Potential of Lexical Paraphrases for Mitigating Noise-Induced Comprehension Errors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-306",
        "paper_authors": [
            "Anupama Chingacham",
            "Vera Demberg",
            "Dietrich Klakow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeechAdjuster: A Tool for Investigating Listener Preferences and Speech Intelligibility",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-324",
        "paper_authors": [
            "Olympia Simantiraki",
            "Martin Cooke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VocalTurk: Exploring Feasibility of Crowdsourced Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-464",
        "paper_authors": [
            "Susumu Saito",
            "Yuta Ide",
            "Teppei Nakano",
            "Tetsuji Ogawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Aging and Age-Related Hearing Loss on Talker Discrimination",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-682",
        "paper_authors": [
            "Min Xu",
            "Jing Shao",
            "Lan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relationships Between Perceptual Distinctiveness, Articulatory Complexity and Functional Load in Speech Communication",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-721",
        "paper_authors": [
            "Yuqing Zhang",
            "Zhu Li",
            "Bin Wu",
            "Yanlu Xie",
            "Binghuai Lin",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Human Spoofing Detection Performance on Degraded Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1225",
        "paper_authors": [
            "Camryn Terblanche",
            "Philip Harrison",
            "Amelia Jane Gully"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reliable Estimates of Interpretable Cue Effects with Active Learning in Psycholinguistic Research",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1524",
        "paper_authors": [
            "Marieke Einfeldt",
            "Rita Sevastjanova",
            "Katharina Zahner-Ritter",
            "Ekaterina Kazak",
            "Bettina Braun"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards the Explainability of Multimodal Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1718",
        "paper_authors": [
            "Puneet Kumar",
            "Vishesh Kaushik",
            "Balasubramanian Raman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Primacy of Mouth over Eyes: Eye Movement Evidence from Audiovisual Mandarin Lexical Tones and Vowels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1741",
        "paper_authors": [
            "Biao Zeng",
            "Rui Wang",
            "Guoxing Yu",
            "Christian Dobel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the Impact of Spectral and Temporal Degradation on End-to-End Automatic Speech Recognition Performance",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2091",
        "paper_authors": [
            "Takanori Ashihara",
            "Takafumi Moriya",
            "Makio Kashino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Super-Human Performance in Online Low-Latency Recognition of Conversational Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1114",
        "paper_authors": [
            "Thai-Son Nguyen",
            "Sebastian St\u00fcker",
            "Alex Waibel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multiple Softmax Architecture for Streaming Multilingual End-to-End ASR Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1298",
        "paper_authors": [
            "Vikas Joshi",
            "Amit Das",
            "Eric Sun",
            "Rupesh R. Mehta",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1566",
        "paper_authors": [
            "Duc Le",
            "Mahaveer Jain",
            "Gil Keren",
            "Suyoun Kim",
            "Yangyang Shi",
            "Jay Mahadeokar",
            "Julian Chan",
            "Yuan Shangguan",
            "Christian Fuegen",
            "Ozlem Kalinli",
            "Yatharth Saraf",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Efficient Streaming Non-Recurrent On-Device End-to-End Model with Improvements to Rare-Word Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-206",
        "paper_authors": [
            "Tara N. Sainath",
            "Yanzhang He",
            "Arun Narayanan",
            "Rami Botros",
            "Ruoming Pang",
            "David Rybach",
            "Cyril Allauzen",
            "Ehsan Variani",
            "James Qin",
            "Quoc-Nam Le-The",
            "Shuo-Yiin Chang",
            "Bo Li",
            "Anmol Gulati",
            "Jiahui Yu",
            "Chung-Cheng Chiu",
            "Diamantino Caseiro",
            "Wei Li",
            "Qiao Liang",
            "Pat Rondon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Multi-Talker Speech Recognition with Joint Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-207",
        "paper_authors": [
            "Liang Lu",
            "Naoyuki Kanda",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming End-to-End Speech Recognition for Hybrid RNN-T/Attention Architecture",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-437",
        "paper_authors": [
            "Takafumi Moriya",
            "Tomohiro Tanaka",
            "Takanori Ashihara",
            "Tsubasa Ochiai",
            "Hiroshi Sato",
            "Atsushi Ando",
            "Ryo Masumura",
            "Marc Delcroix",
            "Taichi Asami"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving RNN-T ASR Accuracy Using Context Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-542",
        "paper_authors": [
            "Andreas Schwarz",
            "Ilya Sklyar",
            "Simon Wiesler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HMM-Free Encoder Pre-Training for Streaming RNN Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-586",
        "paper_authors": [
            "Lu Huang",
            "Jingyu Sun",
            "Yufeng Tang",
            "Junfeng Hou",
            "Jinkun Chen",
            "Jun Zhang",
            "Zejun Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reducing Exposure Bias in Training Recurrent Neural Network Transducers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-587",
        "paper_authors": [
            "Xiaodong Cui",
            "Brian Kingsbury",
            "George Saon",
            "David Haws",
            "Zolt\u00e1n T\u00fcske"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bridging the Gap Between Streaming and Non-Streaming ASR Systems by Distilling Ensembles of CTC and RNN-T Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-637",
        "paper_authors": [
            "Thibault Doutre",
            "Wei Han",
            "Chung-Cheng Chiu",
            "Ruoming Pang",
            "Olivier Siohan",
            "Liangliang Cao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mixture Model Attention: Flexible Streaming and Non-Streaming Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-720",
        "paper_authors": [
            "Kartik Audhkhasi",
            "Tongzhou Chen",
            "Bhuvana Ramabhadran",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "StableEmit: Selection Probability Discount for Reducing Emission Latency of Streaming Monotonic Attention ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1110",
        "paper_authors": [
            "Hirofumi Inaguma",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1693",
        "paper_authors": [
            "Niko Moritz",
            "Takaaki Hori",
            "Jonathan Le Roux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Mode Transformer Transducer with Stochastic Future Context",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1953",
        "paper_authors": [
            "Kwangyoun Kim",
            "Felix Wu",
            "Prashant Sridhar",
            "Kyu Jeong Han",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Causal U-Net Based Neural Beamforming Network for Real-Time Multi-Channel Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1457",
        "paper_authors": [
            "Xinlei Ren",
            "Xu Zhang",
            "Lianwu Chen",
            "Xiguang Zheng",
            "Chen Zhang",
            "Liang Guo",
            "Bing Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Partitioned-Block Frequency-Domain Adaptive Kalman Filter for Stereophonic Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-135",
        "paper_authors": [
            "Rui Zhu",
            "Feiran Yang",
            "Yuepeng Li",
            "Shidong Shang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time Independent Vector Analysis Using Semi-Supervised Nonnegative Matrix Factorization as a Source Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-146",
        "paper_authors": [
            "Taihui Wang",
            "Feiran Yang",
            "Rui Zhu",
            "Jun Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Channel Decorrelation for Multi-Channel Target Speech Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-298",
        "paper_authors": [
            "Jiangyu Han",
            "Wei Rao",
            "Yannan Wang",
            "Yanhua Long"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Inplace Gated Convolutional Recurrent Neural Network for Dual-Channel Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-899",
        "paper_authors": [
            "Jinjiang Liu",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SRIB-LEAP Submission to Far-Field Multi-Channel Speech Enhancement Challenge for Video Conferencing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1111",
        "paper_authors": [
            "R. G. Prithvi Raj",
            "Rohit Kumar",
            "M. K. Jayesh",
            "Anurenjan Purushothaman",
            "Sriram Ganapathy",
            "M. Ali Basha Shaik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time Multi-Channel Speech Enhancement Based on Neural Network Masking with Attention Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2266",
        "paper_authors": [
            "Cheng Xue",
            "Weilong Huang",
            "Weiguang Chen",
            "Jinwei Feng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Uncovering the Acoustic Cues of COVID-19 Infection",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/ganapathy21_interspeech.html",
        "paper_authors": [
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ethical and Technological Challenges of Conversational AI",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/fung21_interspeech.html",
        "paper_authors": [
            "Pascale Fung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BERT-Based Semantic Model for Rescoring N-Best Speech Recognition List",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-313",
        "paper_authors": [
            "Dominique Fohr",
            "Irina Illina"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text Augmentation for Language Models in High Error Recognition Scenario",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-627",
        "paper_authors": [
            "Karel Benes",
            "Luk\u00e1s Burget"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Sampling-Based Training Criteria for Neural Language Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1067",
        "paper_authors": [
            "Yingbo Gao",
            "David Thulke",
            "Alexander Gerstenberger",
            "Khoa Viet Tran",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fast Text-Only Domain Adaptation of RNN-Transducer Prediction Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1191",
        "paper_authors": [
            "Janne Pylkk\u00f6nen",
            "Antti Ukkonen",
            "Juho Kilpikoski",
            "Samu Tamminen",
            "Hannes Heikinheimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Games to Augment Corpora for Language Recognition and Confusability",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1611",
        "paper_authors": [
            "Christopher Cieri",
            "James Fiumara",
            "Jonathan Wright"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fair Voice Biometrics: Impact of Demographic Imbalance on Group Fairness in Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1857",
        "paper_authors": [
            "Gianni Fenu",
            "Mirko Marras",
            "Giacomo Medda",
            "Giacomo Meloni"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation from Multi-Modality to Single-Modality for Person Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2119",
        "paper_authors": [
            "Leying Zhang",
            "Zhengyang Chen",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Disentanglement of Speaker Representation for Attribute-Driven Privacy Preservation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1712",
        "paper_authors": [
            "Paul-Gauthier No\u00e9",
            "Mohammad MohammadAmini",
            "Driss Matrouf",
            "Titouan Parcollet",
            "Andreas Nautsch",
            "Jean-Fran\u00e7ois Bonastre"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatically Detecting Errors and Disfluencies in Read Speech to Predict Cognitive Impairment in People with Parkinson's Disease",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1694",
        "paper_authors": [
            "Amrit Romana",
            "John Bandon",
            "Matthew Perez",
            "Stephanie Gutierrez",
            "Richard Richter",
            "Angela Roberts",
            "Emily Mower Provost"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Extraction of Speech Rhythm Descriptors for Speech Intelligibility Assessment in the Context of Head and Neck Cancers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1736",
        "paper_authors": [
            "Robin Vaysse",
            "J\u00e9r\u00f4me Farinas",
            "Corine Ast\u00e9sano",
            "R\u00e9gine Andr\u00e9-Obrecht"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Disorder Classification Using Extended Factorized Hierarchical Variational Auto-Encoders",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2180",
        "paper_authors": [
            "Jinzi Qi",
            "Hugo Van hamme"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Impact of Forced-Alignment Errors on Automatic Pronunciation Evaluation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1403",
        "paper_authors": [
            "Vikram C. Mathad",
            "Tristan J. Mahr",
            "Nancy Scherer",
            "Kathy Chapman",
            "Katherine C. Hustad",
            "Julie Liss",
            "Visar Berisha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Late Fusion of the Available Lexicon and Raw Waveform-Based Acoustic Modeling for Depression and Dementia Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1288",
        "paper_authors": [
            "Esa\u00fa Villatoro-Tello",
            "S. Pavankumar Dubagunta",
            "Julian Fritsch",
            "Gabriela Ram\u00edrez-de-la-Rosa",
            "Petr Motl\u00edcek",
            "Mathew Magimai-Doss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Speaker Embeddings for Ultrasound-Based Silent Speech Interfaces",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1466",
        "paper_authors": [
            "Amin Honarmandi Shandiz",
            "L\u00e1szl\u00f3 T\u00f3th",
            "G\u00e1bor Gosztolya",
            "Alexandra Mark\u00f3",
            "Tam\u00e1s G\u00e1bor Csap\u00f3"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Modal Learning for Audio-Visual Video Parsing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2135",
        "paper_authors": [
            "Jatin Lamba",
            "Abhishek",
            "Jayaprakash Akula",
            "Rishabh Dabral",
            "Preethi Jyothi",
            "Ganesh Ramakrishnan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Psychology-Driven Computational Analysis of Political Interviews",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2249",
        "paper_authors": [
            "Darren Cook",
            "Miri Zilka",
            "Simon Maskell",
            "Laurence Alison"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion Recognition Based on Attention Weight Correction Using Word-Level Confidence Measure",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-411",
        "paper_authors": [
            "Jennifer Santoso",
            "Takeshi Yamada",
            "Shoji Makino",
            "Kenkichi Ishizuka",
            "Takekatsu Hiramura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Voice Type and Task on L2 Learners' Awareness of Pronunciation Errors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-701",
        "paper_authors": [
            "Alif Silpachai",
            "Ivana Rehman",
            "Taylor Anne Barriuso",
            "John Levis",
            "Evgeny Chukharev-Hudilainen",
            "Guanlong Zhao",
            "Ricardo Gutierrez-Osuna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lexical Entrainment and Intra-Speaker Variability in Cooperative Dialogues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1441",
        "paper_authors": [
            "Alla Menshikova",
            "Daniil Kocharov",
            "Tatiana Kachkovskaia"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Alzheimer's Disease Using Interactional and Acoustic Features from Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1526",
        "paper_authors": [
            "Shamila Nasreen",
            "Julian Hough",
            "Matthew Purver"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the Interplay Between Affective, Phonatory and Motoric Subsystems in Autism Spectrum Disorder Using a Multimodal Dialogue Agent",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1796",
        "paper_authors": [
            "Hardik Kothare",
            "Vikram Ramanarayanan",
            "Oliver Roesler",
            "Michael Neumann",
            "Jackson Liscombe",
            "William Burke",
            "Andrew Cornish",
            "Doug Habberstad",
            "Alaa Sakallah",
            "Sara Markuson",
            "Seemran Kansara",
            "Afik Faerman",
            "Yasmine Bensidi-Slimane",
            "Laura Fry",
            "Saige Portera",
            "David Suendermann-Oeft",
            "David Pautler",
            "Carly Demopoulos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis of Eye Gaze Reasons and Gaze Aversions During Three-Party Conversations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2134",
        "paper_authors": [
            "Carlos Toshinori Ishi",
            "Taiken Shintani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantic Distance: A New Metric for ASR Performance Analysis Towards Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1929",
        "paper_authors": [
            "Suyoun Kim",
            "Abhinav Arora",
            "Duc Le",
            "Ching-Feng Yeh",
            "Christian Fuegen",
            "Ozlem Kalinli",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Light-Weight Contextual Spelling Correction Model for Customizing Transducer-Based Speech Recognition Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-379",
        "paper_authors": [
            "Xiaoqiang Wang",
            "Yanqing Liu",
            "Sheng Zhao",
            "Jinyu Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incorporating External POS Tagger for Punctuation Restoration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1708",
        "paper_authors": [
            "Ning Shi",
            "Wei Wang",
            "Boxin Wang",
            "Jinfeng Li",
            "Xiangyu Liu",
            "Zhouhan Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetically Induced Subwords for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1787",
        "paper_authors": [
            "Vasileios Papadourakis",
            "Markus M\u00fcller",
            "Jing Liu",
            "Athanasios Mouchtaris",
            "Maurizio Omologo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revisiting Parity of Human vs. Machine Conversational Speech Transcription",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1908",
        "paper_authors": [
            "Courtney Mansfield",
            "Sara Ng",
            "Gina-Anne Levow",
            "Richard A. Wright",
            "Mari Ostendorf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lookup-Table Recurrent Language Models for Long Tail Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-340",
        "paper_authors": [
            "W. Ronny Huang",
            "Tara N. Sainath",
            "Cal Peyser",
            "Shankar Kumar",
            "David Rybach",
            "Trevor Strohman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextual Density Ratio for Language Model Biasing of Sequence to Sequence ASR Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-443",
        "paper_authors": [
            "Jes\u00fas Andr\u00e9s-Ferrer",
            "Dario Albesano",
            "Puming Zhan",
            "Paul Vozila"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Token-Level Supervised Contrastive Learning for Punctuation Restoration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-661",
        "paper_authors": [
            "Qiushi Huang",
            "Tom Ko",
            "H. Lilian Tang",
            "Xubo Liu",
            "Bo Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BART Based Semantic Correction for Mandarin Automatic Speech Recognition System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-739",
        "paper_authors": [
            "Yun Zhao",
            "Xuerui Yang",
            "Jinchao Wang",
            "Yongyu Gao",
            "Chao Yan",
            "Yuanfu Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Class-Based Neural Network Language Model for Second-Pass Rescoring in ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1080",
        "paper_authors": [
            "Lingfeng Dai",
            "Qi Liu",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Customization of Neural Transducers by Mitigating Acoustic Mismatch of Synthesized Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1656",
        "paper_authors": [
            "Gakuto Kurata",
            "George Saon",
            "Brian Kingsbury",
            "David Haws",
            "Zolt\u00e1n T\u00fcske"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Discriminative Entity-Aware Language Model for Virtual Assistants",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1767",
        "paper_authors": [
            "Mandana Saebi",
            "Ernest Pusateri",
            "Aaksha Meghawat",
            "Christophe Van Gysel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Correcting Automated and Manual Speech Transcription Errors Using Warped Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-591",
        "paper_authors": [
            "Mahdi Namazifar",
            "John Malik",
            "Li Erran Li",
            "G\u00f6khan T\u00fcr",
            "Dilek Hakkani-T\u00fcr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Encoder Transducer: A Flexible Solution for Trading Off Accuracy for Latency",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1272",
        "paper_authors": [
            "Yangyang Shi",
            "Varun Nagaraja",
            "Chunyang Wu",
            "Jay Mahadeokar",
            "Duc Le",
            "Rohit Prabhavalkar",
            "Alex Xiao",
            "Ching-Feng Yeh",
            "Julian Chan",
            "Christian Fuegen",
            "Ozlem Kalinli",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain-Aware Self-Attention for Multi-Domain Neural Machine Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1477",
        "paper_authors": [
            "Shiqi Zhang",
            "Yan Liu",
            "Deyi Xiong",
            "Pei Zhang",
            "Boxing Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Librispeech Transducer Model with Internal Language Model Prior Correction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1510",
        "paper_authors": [
            "Albert Zeyer",
            "Andr\u00e9 Merboldt",
            "Wilfried Michel",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deliberation-Based Joint Acoustic and Text Decoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-165",
        "paper_authors": [
            "Sepand Mavandadi",
            "Tara N. Sainath",
            "Ke Hu",
            "Zelin Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Limit of English Conversational Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-211",
        "paper_authors": [
            "Zolt\u00e1n T\u00fcske",
            "George Saon",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deformable TDNN with Adaptive Receptive Fields for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-387",
        "paper_authors": [
            "Keyu An",
            "Yi Zhang",
            "Zhijian Ou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeechMoE: Scaling to Large Acoustic Models with Dynamic Routing Mixture of Experts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-478",
        "paper_authors": [
            "Zhao You",
            "Shulin Feng",
            "Dan Su",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Compressive Transformer for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-545",
        "paper_authors": [
            "Chi-Hang Leong",
            "Yu-Han Huang",
            "Jen-Tzung Chien"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End to End Transformer-Based Contextual Speech Recognition Based on Pointer Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-774",
        "paper_authors": [
            "Binghuai Lin",
            "Liyuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparative Study on Neural Architectures and Training Methods for Japanese Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-775",
        "paper_authors": [
            "Shigeki Karita",
            "Yotaro Kubo",
            "Michiel Adriaan Unico Bacchiani",
            "Llion Jones"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Advanced Long-Context End-to-End Speech Recognition Using Context-Expanded Transformers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1643",
        "paper_authors": [
            "Takaaki Hori",
            "Niko Moritz",
            "Chiori Hori",
            "Jonathan Le Roux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer-Based ASR Incorporating Time-Reduction Layer and Fine-Tuning with Self-Knowledge Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1743",
        "paper_authors": [
            "Md. Akmal Haidar",
            "Chao Xing",
            "Mehdi Rezagholizadeh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Flexi-Transducer: Optimizing Latency, Accuracy and Compute for Multi-Domain On-Device Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1921",
        "paper_authors": [
            "Jay Mahadeokar",
            "Yangyang Shi",
            "Yuan Shangguan",
            "Chunyang Wu",
            "Alex Xiao",
            "Hang Su",
            "Duc Le",
            "Ozlem Kalinli",
            "Christian Fuegen",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Difference in Perceived Speech Signal Quality Assessment Among Monolingual and Bilingual Teenage Students",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-16",
        "paper_authors": [
            "Przemyslaw Falkowski-Gilski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PILOT: Introducing Transformers for Probabilistic Sound Event Localization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-124",
        "paper_authors": [
            "Christopher Schymura",
            "Benedikt T. B\u00f6nninghoff",
            "Tsubasa Ochiai",
            "Marc Delcroix",
            "Keisuke Kinoshita",
            "Tomohiro Nakatani",
            "Shoko Araki",
            "Dorothea Kolossa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sound Source Localization with Majorization Minimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-126",
        "paper_authors": [
            "Masahito Togami",
            "Robin Scheibler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NISQA: A Deep CNN-Self-Attention Model for Multidimensional Speech Quality Prediction with Crowdsourced Datasets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-299",
        "paper_authors": [
            "Gabriel Mittag",
            "Babak Naderi",
            "Assmaa Chehadi",
            "Sebastian M\u00f6ller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Subjective Evaluation of Noise Suppression Algorithms in Crowdsourcing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-343",
        "paper_authors": [
            "Babak Naderi",
            "Ross Cutler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reliable Intensity Vector Selection for Multi-Source Direction-of-Arrival Estimation Using a Single Acoustic Vector Sensor",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-375",
        "paper_authors": [
            "Jianhua Geng",
            "Sifan Wang",
            "Juan Li",
            "Jingwei Li",
            "Xin Lou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MetricNet: Towards Improved Modeling For Non-Intrusive Speech Quality Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-659",
        "paper_authors": [
            "Meng Yu",
            "Chunlei Zhang",
            "Yong Xu",
            "Shi-Xiong Zhang",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CNN-Based Processing of Acoustic and Radio Frequency Signals for Speaker Localization from MAVs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-886",
        "paper_authors": [
            "Andrea Toma",
            "Daniele Salvati",
            "Carlo Drioli",
            "Gian Luca Foresti"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Assessment of von Mises-Bernoulli Deep Neural Network in Sound Source Localization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1050",
        "paper_authors": [
            "Katsutoshi Itoyama",
            "Yoshiya Morimoto",
            "Shungo Masaki",
            "Ryosuke Kojima",
            "Kenji Nishida",
            "Kazuhiro Nakadai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Feature Fusion by Attention Networks for Robust DOA Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1051",
        "paper_authors": [
            "Rongliang Liu",
            "Nengheng Zheng",
            "Xi Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Far-Field Speaker Localization and Adaptive GLMB Tracking",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1160",
        "paper_authors": [
            "Shoufeng Lin",
            "Zhaojie Luo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Design of Deep Priors for Unsupervised Audio Restoration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1890",
        "paper_authors": [
            "Vivek Sivaraman Narayanaswamy",
            "Jayaraman J. Thiagarajan",
            "Andreas Spanias"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cram\u00e9r-Rao Lower Bound for DOA Estimation with an Array of Directional Microphones in Reverberant Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2267",
        "paper_authors": [
            "Weiguang Chen",
            "Cheng Xue",
            "Xionghu Zhong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GAN Vocoder: Multi-Resolution Discriminator Is All You Need",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-41",
        "paper_authors": [
            "Jaeseong You",
            "Dalhyun Kim",
            "Gyuhyeon Nam",
            "Geumbyeol Hwang",
            "Gyeongsu Chae"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Glow-WaveGAN: Learning Speech Representations from GAN-Based Variational Auto-Encoder for High Fidelity Flow-Based Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-414",
        "paper_authors": [
            "Jian Cong",
            "Shan Yang",
            "Lei Xie",
            "Dan Su"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unified Source-Filter GAN: Unified Source-Filter Network Based On Factorization of Quasi-Periodic Parallel WaveGAN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-517",
        "paper_authors": [
            "Reo Yoneyama",
            "Yi-Chiao Wu",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Harmonic WaveGAN: GAN-Based Speech Waveform Generation Model with Harmonic Structure Discriminator",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-583",
        "paper_authors": [
            "Kazuki Mizuta",
            "Tomoki Koriyama",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fre-GAN: Adversarial Frequency-Consistent Audio Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-845",
        "paper_authors": [
            "Ji-Hoon Kim",
            "Sang-Hoon Lee",
            "Ji-Hyun Lee",
            "Seong-Whan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-971",
        "paper_authors": [
            "Jinhyeok Yang",
            "Jae-Sung Bae",
            "Taejun Bak",
            "Young-Ik Kim",
            "Hoon-Young Cho"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1016",
        "paper_authors": [
            "Won Jang",
            "Dan Lim",
            "Jaesam Yoon",
            "Bongwan Kim",
            "Juntae Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continuous Wavelet Vocoder-Based Decomposition of Parametric Speech Waveform Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1600",
        "paper_authors": [
            "Mohammed Salah Al-Radhi",
            "Tam\u00e1s G\u00e1bor Csap\u00f3",
            "Csaba Zaink\u00f3",
            "G\u00e9za N\u00e9meth"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "High-Fidelity and Low-Latency Universal Neural Vocoder Based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1984",
        "paper_authors": [
            "Patrick Lumban Tobing",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Basis-MelGAN: Efficient Neural Vocoder Based on Audio Decomposition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2173",
        "paper_authors": [
            "Zhengxi Liu",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "High-Fidelity Parallel WaveGAN with Multi-Band Harmonic-Plus-Noise Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-976",
        "paper_authors": [
            "Min-Jae Hwang",
            "Ryuichi Yamamoto",
            "Eunwoo Song",
            "Jae-Min Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpecRec: An Alternative Solution for Improving End-to-End Speech-to-Text Translation via Spectrogram Reconstruction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-733",
        "paper_authors": [
            "Junkun Chen",
            "Mingbo Ma",
            "Renjie Zheng",
            "Liang Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Subtitle Translation as Markup Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-744",
        "paper_authors": [
            "Colin Cherry",
            "Naveen Arivazhagan",
            "Dirk Padfield",
            "Maxim Krikun"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large-Scale Self- and Semi-Supervised Learning for Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1912",
        "paper_authors": [
            "Changhan Wang",
            "Anne Wu",
            "Juan Pino",
            "Alexei Baevski",
            "Michael Auli",
            "Alexis Conneau"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CoVoST 2 and Massively Multilingual Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2027",
        "paper_authors": [
            "Changhan Wang",
            "Anne Wu",
            "Jiatao Gu",
            "Juan Pino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AlloST: Low-Resource Speech Translation Without Source Transcription",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-526",
        "paper_authors": [
            "Yao-Fei Cheng",
            "Hung-Shin Lee",
            "Hsin-Min Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly-Supervised Speech-to-Text Mapping with Visually Connected Non-Parallel Speech-Text Data Using Cyclic Partially-Aligned Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-970",
        "paper_authors": [
            "Johanes Effendi",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transcribing Paralinguistic Acoustic Cues to Target Language Text in Transformer-Based Speech-to-Text Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1020",
        "paper_authors": [
            "Hirotaka Tokuyama",
            "Sakriani Sakti",
            "Katsuhito Sudoh",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Speech Translation via Cross-Modal Progressive Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1065",
        "paper_authors": [
            "Rong Ye",
            "Mingxuan Wang",
            "Lei Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR Posterior-Based Loss for Multi-Task End-to-End Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1105",
        "paper_authors": [
            "Yuka Ko",
            "Katsuhito Sudoh",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Simultaneous Machine Interpretation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-201",
        "paper_authors": [
            "Alejandro P\u00e9rez Gonz\u00e1lez de Martos",
            "Javier Iranzo-S\u00e1nchez",
            "Adri\u00e0 Gim\u00e9nez-Pastor",
            "Javier Jorge",
            "Joan Albert Silvestre-Cerd\u00e0",
            "Jorge Civera",
            "Albert Sanch\u00eds",
            "Alfons Juan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lexical Modeling of ASR Errors for Robust Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-265",
        "paper_authors": [
            "Giuseppe Martucci",
            "Mauro Cettolo",
            "Matteo Negri",
            "Marco Turchi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimally Encoding Inductive Biases into the Transformer Improves End-to-End Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2007",
        "paper_authors": [
            "Piyush Vyas",
            "Anastasia Kuznetsova",
            "Donald S. Williamson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Feature Scaling and Fusion on Sign Language Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1863",
        "paper_authors": [
            "Tejaswini Ananthanarayana",
            "Lipisha Chaudhary",
            "Ifeoma Nwogu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The ID R&D System Description for Short-Duration Speaker Verification Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1553",
        "paper_authors": [
            "Alexander Alenin",
            "Anton Okhotnikov",
            "Rostislav Makarov",
            "Nikita Torgashov",
            "Ilya Shigabeev",
            "Konstantin Simonchik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Integrating Frequency Translational Invariance in TDNNs and Frequency Positional Information in 2D ResNets to Enhance Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1570",
        "paper_authors": [
            "Jenthe Thienpondt",
            "Brecht Desplanques",
            "Kris Demuynck"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SdSVC Challenge 2021: Tips and Tricks to Boost the Short-Duration Speaker Verification System Performance",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1737",
        "paper_authors": [
            "Aleksei Gusev",
            "Alisa Vinogradova",
            "Sergey Novoselov",
            "Sergei Astapov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Team02 Text-Independent Speaker Verification System for SdSV Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-249",
        "paper_authors": [
            "Woo Hyun Kang",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Our Learned Lessons from Cross-Lingual Speaker Verification: The CRMI-DKU System Description for the Short-Duration Speaker Verification Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-398",
        "paper_authors": [
            "Xiaoyi Qin",
            "Chao Wang",
            "Yong Ma",
            "Min Liu",
            "Shilei Zhang",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of IMU&Elevoc Submission for the Short-Duration Speaker Verification Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-743",
        "paper_authors": [
            "Peng Zhang",
            "Peng Hu",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Sogou System for Short-Duration Speaker Verification Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-965",
        "paper_authors": [
            "Jie Yan",
            "Shengyu Yao",
            "Yiqian Pan",
            "Wei Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The SJTU System for Short-Duration Speaker Verification Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2136",
        "paper_authors": [
            "Bing Han",
            "Zhengyang Chen",
            "Zhikai Zhou",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Speaker Emotional Text-to-Speech Synthesizer",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/cho21_interspeech.html",
        "paper_authors": [
            "Sungjae Cho",
            "Soo-Young Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Live TV Subtitling Through Respeaking",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/prazak21_interspeech.html",
        "paper_authors": [
            "Ales Praz\u00e1k",
            "Zdenek Loose",
            "Josef V. Psutka",
            "Vlasta Radov\u00e1",
            "Josef Psutka",
            "Jan Svec"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Autonomous Robot for Measuring Room Impulse Responses",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/fragner21_interspeech.html",
        "paper_authors": [
            "Stefan Fragner",
            "Tobias Topar",
            "Maximilian Giller",
            "Lukas Pfeifenberger",
            "Franz Pernkopf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Expressive Robot Performance Based on Facial Motion Capture",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/beskow21_interspeech.html",
        "paper_authors": [
            "Jonas Beskow",
            "Charlie Caper",
            "Johan Ehrenfors",
            "Nils Hagberg",
            "Anne Jansen",
            "Chris Wood"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ThemePro 2.0: Showcasing the Role of Thematic Progression in Engaging Human-Computer Interaction",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/dominguez21_interspeech.html",
        "paper_authors": [
            "M\u00f3nica Dom\u00ednguez",
            "Juan Soler Company",
            "Leo Wanner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Addressing Compliance in Call Centers with Entity Extraction",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/guruju21_interspeech.html",
        "paper_authors": [
            "Sai Guruju",
            "Jithendra Vepa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio Segmentation Based Conversational Silence Detection for Contact Center Calls",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/gogineni21_interspeech.html",
        "paper_authors": [
            "Krishnachaitanya Gogineni",
            "Tarun Reddy Yadama",
            "Jithendra Vepa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reformulating DOVER-Lap Label Mapping as a Graph Partitioning Problem",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-323",
        "paper_authors": [
            "Desh Raj",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph Attention Networks for Anti-Spoofing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-993",
        "paper_authors": [
            "Hemlata Tak",
            "Jee-weon Jung",
            "Jose Patino",
            "Massimiliano Todisco",
            "Nicholas W. D. Evans"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Log-Likelihood-Ratio Cost Function as Objective Loss for Speaker Verification Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1085",
        "paper_authors": [
            "Victoria Mingote",
            "Antonio Miguel",
            "Alfonso Ortega Gim\u00e9nez",
            "Eduardo Lleida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effective Phase Encoding for End-To-End Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2025",
        "paper_authors": [
            "Junyi Peng",
            "Xiaoyang Qu",
            "Rongzhi Gu",
            "Jianzong Wang",
            "Jing Xiao",
            "Luk\u00e1s Burget",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Impact of Encoding and Segmentation Strategies on End-to-End Simultaneous Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-608",
        "paper_authors": [
            "Ha Nguyen",
            "Yannick Est\u00e8ve",
            "Laurent Besacier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lost in Interpreting: Speech Translation from Source or Interpreter?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2232",
        "paper_authors": [
            "Dominik Mach\u00e1cek",
            "Mat\u00fas Zilinec",
            "Ondrej Bojar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Active Speaker Detection as a Multi-Objective Optimization with Uncertainty-Based Multimodal Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-80",
        "paper_authors": [
            "Baptiste Pouthier",
            "Laurent Pilati",
            "Leela K. Gudupudi",
            "Charles Bouveyron",
            "Fr\u00e9d\u00e9ric Precioso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "It's Not What You Said, it's How You Said it: Discriminative Perception of Speech as a Multichannel Communication System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1658",
        "paper_authors": [
            "Sarenne Wallbridge",
            "Peter Bell",
            "Catherine Lai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extending the Fullband E-Model Towards Background Noise, Bursty Packet Loss, and Conversational Degradations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-314",
        "paper_authors": [
            "Thilo Michael",
            "Gabriel Mittag",
            "Andreas B\u00fctow",
            "Sebastian M\u00f6ller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ORCA-SLANG: An Automatic Multi-Stage Semi-Supervised Deep Learning Framework for Large-Scale Killer Whale Call Type Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-616",
        "paper_authors": [
            "Christian Bergler",
            "Manuel Schmitt",
            "Andreas K. Maier",
            "Helena Symonds",
            "Paul Spong",
            "Steven R. Ness",
            "George Tzanetakis",
            "Elmar N\u00f6th"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audiovisual Transfer Learning for Audio Tagging and Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-695",
        "paper_authors": [
            "Wim Boes",
            "Hugo Van hamme"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Intrusive Speech Quality Assessment with Transfer Learning and Subject-Specific Scaling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1685",
        "paper_authors": [
            "Natalia Nessler",
            "Milos Cernak",
            "Paolo Prandoni",
            "Pablo Mainar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio Retrieval with Natural Language Queries",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2227",
        "paper_authors": [
            "Andreea-Maria Oncescu",
            "A. Sophia Koepke",
            "Jo\u00e3o F. Henriques",
            "Zeynep Akata",
            "Samuel Albanie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bootstrap an End-to-End ASR System by Multilingual Training, Transfer Learning, Text-to-Text Mapping and Synthetic Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-198",
        "paper_authors": [
            "Manuel Giollo",
            "Deniz Gunceler",
            "Yulan Liu",
            "Daniel Willett"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Weight Factorization for Multilingual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-216",
        "paper_authors": [
            "Ngoc-Quan Pham",
            "Tuan-Nam Nguyen",
            "Sebastian St\u00fcker",
            "Alex Waibel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Cross-Lingual Representation Learning for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-329",
        "paper_authors": [
            "Alexis Conneau",
            "Alexei Baevski",
            "Ronan Collobert",
            "Abdelrahman Mohamed",
            "Michael Auli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language and Speaker-Independent Feature Transformation for End-to-End Multilingual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-390",
        "paper_authors": [
            "Tomoaki Hayakawa",
            "Chee Siang Leow",
            "Akio Kobayashi",
            "Takehito Utsuro",
            "Hiromitsu Nishizaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Large Self-Supervised Models for Low-Resource Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-631",
        "paper_authors": [
            "Krishna D. N",
            "Pinyi Wang",
            "Bruno Bozza"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual Script E2E Framework for Multilingual and Code-Switching ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-978",
        "paper_authors": [
            "Mari Ganesh Kumar",
            "Jom Kuriakose",
            "Anand Thyagachandran",
            "Arun Kumar A",
            "Ashish Seth",
            "Lodagala Durga Prasad",
            "Saish Jaiswal",
            "Anusha Prakash",
            "Hema A. Murthy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MUCS 2021: Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1339",
        "paper_authors": [
            "Anuj Diwan",
            "Rakesh Vaideeswaran",
            "Sanket Shah",
            "Ankita Singh",
            "Srinivasa Raghavan K. M.",
            "Shreya Khare",
            "Vinit Unni",
            "Saurabh Vyas",
            "Akash Rajpuria",
            "Chiranjeevi Yarra",
            "Ashish R. Mittal",
            "Prasanta Kumar Ghosh",
            "Preethi Jyothi",
            "Kalika Bali",
            "Vivek Seshadri",
            "Sunayana Sitaram",
            "Samarth Bharadwaj",
            "Jai Nanavati",
            "Raoul Nanavati",
            "Karthik Sankaranarayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1390",
        "paper_authors": [
            "Genta Indra Winata",
            "Guangsen Wang",
            "Caiming Xiong",
            "Steven C. H. Hoi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SRI-B End-to-End System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1578",
        "paper_authors": [
            "Hardik B. Sailor",
            "Kiran Praveen",
            "Vikas Agrawal",
            "Abhinav Jain",
            "Abhishek Pandey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical Phone Recognition with Compositional Phonetics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1803",
        "paper_authors": [
            "Xinjian Li",
            "Juncheng Li",
            "Florian Metze",
            "Alan W. Black"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards One Model to Rule All: Multilingual Strategy for Dialectal Code-Switching Arabic ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1809",
        "paper_authors": [
            "Shammur Absar Chowdhury",
            "Amir Hussein",
            "Ahmed Abdelali",
            "Ahmed Ali"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Differentiable Allophone Graphs for Language-Universal Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1944",
        "paper_authors": [
            "Brian Yan",
            "Siddharth Dalmia",
            "David R. Mortensen",
            "Florian Metze",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Speech Recognition Systems Errors for Objective Sleepiness Detection Through Voice",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-291",
        "paper_authors": [
            "Vincent P. Martin",
            "Jean-Luc Rouas",
            "Florian Boyer",
            "Pierre Philip"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Laughter Detection in Noisy Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-353",
        "paper_authors": [
            "Jon Gillick",
            "Wesley Deng",
            "Kimiko Ryokai",
            "David Bamman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Impact of Emotional State on Estimation of Willingness to Buy from Advertising Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-827",
        "paper_authors": [
            "Mizuki Nagano",
            "Yusuke Ijima",
            "Sadao Hiroya"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stacked Recurrent Neural Networks for Speech-Based Inference of Attachment Condition in School Age Children",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-904",
        "paper_authors": [
            "Huda Alsofyani",
            "Alessandro Vinciarelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language or Paralanguage, This is the Problem: Comparing Depressed and Non-Depressed Speakers Through the Analysis of Gated Multimodal Units",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-928",
        "paper_authors": [
            "Nujud Aloshban",
            "Anna Esposito",
            "Alessandro Vinciarelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emotion Carrier Recognition from Personal Narratives",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1100",
        "paper_authors": [
            "Aniruddha Tammewar",
            "Alessandra Cervone",
            "Giuseppe Riccardi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Verbal Vocalisation and Laughter Detection Using Sequence-to-Sequence Models and Multi-Label Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1159",
        "paper_authors": [
            "Scott Condron",
            "Georgia Clarke",
            "Anita Klementiev",
            "Daniela Morse-Kopp",
            "Jack Parry",
            "Dimitri Palaz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TDCA-Net: Time-Domain Channel Attention Network for Depression Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1176",
        "paper_authors": [
            "Cong Cai",
            "Mingyue Niu",
            "Bin Liu",
            "Jianhua Tao",
            "Xuefei Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visual Speech for Obstructive Sleep Apnea Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1717",
        "paper_authors": [
            "Catarina Botelho",
            "Alberto Abad",
            "Tanja Schultz",
            "Isabel Trancoso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis of Contextual Voice Changes in Remote Meetings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1932",
        "paper_authors": [
            "H\u00e9ctor A. Cordourier Maruri",
            "Sinem Aslan",
            "Georg Stemmer",
            "Nese Aly\u00fcz",
            "Lama Nachman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Based Depression Severity Level Classification Using a Multi-Stage Dilated CNN-LSTM Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1967",
        "paper_authors": [
            "Nadee Seneviratne",
            "Carol Y. Espy-Wilson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Domain Knowledge Distillation via Uncertainty-Matching for End-to-End ASR Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1169",
        "paper_authors": [
            "Ho-Gyeong Kim",
            "Min-Joong Lee",
            "Hoshik Lee",
            "Tae Gyoon Kang",
            "Jihyun Lee",
            "Eunho Yang",
            "Sung Ju Hwang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning a Neural Diff for Speech Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1575",
        "paper_authors": [
            "Jonathan Macoskey",
            "Grant P. Strimel",
            "Ariya Rastrow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Attention Head Removal: A Simple and Effective Method for Improving Transformer Based ASR Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-280",
        "paper_authors": [
            "Shucong Zhang",
            "Erfan Loweimi",
            "Peter Bell",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Model-Agnostic Fast Adaptive Multi-Objective Balancing Algorithm for Multilingual Automatic Speech Recognition Model Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-355",
        "paper_authors": [
            "Jiabin Xue",
            "Tieran Zheng",
            "Jiqing Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Lifelong Learning of End-to-End ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-563",
        "paper_authors": [
            "Heng-Jui Chang",
            "Hung-yi Lee",
            "Lin-Shan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Adaptive Distillation for Multilingual Speech Recognition: Leveraging Student Independence",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-614",
        "paper_authors": [
            "Isabel Leal",
            "Neeraj Gaur",
            "Parisa Haghani",
            "Brian Farris",
            "Pedro J. Moreno",
            "Manasa Prasad",
            "Bhuvana Ramabhadran",
            "Yun Zhu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Regularizing Word Segmentation by Creating Misspellings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-648",
        "paper_authors": [
            "Hainan Xu",
            "Kartik Audhkhasi",
            "Yinghui Huang",
            "Jesse Emond",
            "Bhuvana Ramabhadran"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multitask Training with Text Data for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-683",
        "paper_authors": [
            "Peidong Wang",
            "Tara N. Sainath",
            "Ron J. Weiss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emitting Word Timings with HMM-Free End-to-End System in Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-894",
        "paper_authors": [
            "Xianzhao Chen",
            "Hao Ni",
            "Yi He",
            "Kang Wang",
            "Zejun Ma",
            "Zongxia Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scaling Laws for Acoustic Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1644",
        "paper_authors": [
            "Jasha Droppo",
            "Oguz Elibol"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Non-Target Language Resources to Improve ASR Performance in a Target Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1657",
        "paper_authors": [
            "Jayadev Billa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "4-Bit Quantization of LSTM-Based Speech Recognition Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1962",
        "paper_authors": [
            "Andrea Fasoli",
            "Chia-Yu Chen",
            "Mauricio J. Serrano",
            "Xiao Sun",
            "Naigang Wang",
            "Swagath Venkataramani",
            "George Saon",
            "Xiaodong Cui",
            "Brian Kingsbury",
            "Wei Zhang",
            "Zolt\u00e1n T\u00fcske",
            "Kailash Gopalakrishnan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unified Autoregressive Modeling for Joint End-to-End Multi-Talker Overlapped Speech Recognition and Speaker Attribute Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2043",
        "paper_authors": [
            "Ryo Masumura",
            "Daiki Okamura",
            "Naoki Makishima",
            "Mana Ihori",
            "Akihiko Takashima",
            "Tomohiro Tanaka",
            "Shota Orihashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2075",
        "paper_authors": [
            "Zhong Meng",
            "Yu Wu",
            "Naoyuki Kanda",
            "Liang Lu",
            "Xie Chen",
            "Guoli Ye",
            "Eric Sun",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variable Frame Rate Acoustic Models Using Minimum Error Reinforcement Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2198",
        "paper_authors": [
            "Dongcheng Jiang",
            "Chao Zhang",
            "Philip C. Woodland"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How f0 and Phrase Position Affect Papuan Malay Word Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-6",
        "paper_authors": [
            "Constantijn Kaland",
            "Matthew Gordon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Feasibility of the Danish Model of Intonational Transcription: Phonetic Evidence from Jutlandic Danish",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-190",
        "paper_authors": [
            "Anna Bothe Jespersen",
            "Pavel Sturm",
            "M\u00edsa Hejn\u00e1"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Experiment in Paratone Detection in a Prosodically Annotated EAP Spoken Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-294",
        "paper_authors": [
            "Adrien M\u00e9li",
            "Nicolas Ballier",
            "Achille Falaise",
            "Alice Henderson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ProsoBeast Prosody Annotation Tool",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-304",
        "paper_authors": [
            "Branislav Gerazov",
            "Michael Wagner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Assessing the Use of Prosody in Constituency Parsing of Imperfect Transcripts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-373",
        "paper_authors": [
            "Trang Tran",
            "Mari Ostendorf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Targeted and Targetless Neutral Tones in Taiwanese Southern Min",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-434",
        "paper_authors": [
            "Roger Cheng-yen Liu",
            "Feng-fan Hsieh",
            "Yueh-Chin Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Interaction of Word Complexity and Word Duration in an Agglutinative Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-594",
        "paper_authors": [
            "M\u00e1ria G\u00f3sy",
            "K\u00e1lm\u00e1n Abari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Taiwan Min Nan (Taiwanese) Checked Tones Sound Change",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-672",
        "paper_authors": [
            "Ho-hsien Pan",
            "Shao-Ren Lyu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "In-Group Advantage in the Perception of Emotions: Evidence from Three Varieties of German",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1172",
        "paper_authors": [
            "Moritz Jakob",
            "Bettina Braun",
            "Katharina Zahner-Ritter"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The LF Model in the Frequency Domain for Glottal Airflow Modelling Without Aliasing Distortion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1625",
        "paper_authors": [
            "Christer Gobl"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parsing Speech for Grouping and Prominence, and the Typology of Rhythm",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1684",
        "paper_authors": [
            "Michael Wagner",
            "Alvaro Iturralde Zurita",
            "Sijia Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosody of Case Markers in Urdu",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1776",
        "paper_authors": [
            "Benazir Mumtaz",
            "Massimiliano Canzi",
            "Miriam Butt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Articulatory Characteristics of Icelandic Voiced Fricative Lenition: Gradience, Categoricity, and Speaker/Gesture-Specific Effects",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1903",
        "paper_authors": [
            "Brynhildur Stefansdottir",
            "Francesco Burroni",
            "Sam Tilsen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging the Uniformity Framework to Examine Crosslinguistic Similarity for Long-Lag Stops in Spontaneous Cantonese-English Bilingual Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1780",
        "paper_authors": [
            "Khia A. Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Personalized Speech Enhancement Through Self-Supervised Data Augmentation and Purification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1868",
        "paper_authors": [
            "Aswin Sivaraman",
            "Sunwoo Kim",
            "Minje Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Denoising with Auditory Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1973",
        "paper_authors": [
            "Mark R. Saddler",
            "Andrew Francl",
            "Jenelle Feather",
            "Kaizhi Qian",
            "Yang Zhang",
            "Josh H. McDermott"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Human Listening and Live Captioning: Multi-Task Training for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-220",
        "paper_authors": [
            "Sefik Emre Eskimez",
            "Xiaofei Wang",
            "Min Tang",
            "Hemin Yang",
            "Zirun Zhu",
            "Zhuo Chen",
            "Huaming Wang",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Stage Progressive Speech Enhancement Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-520",
        "paper_authors": [
            "Xinmeng Xu",
            "Yang Wang",
            "Dongxiang Xu",
            "Yiyuan Peng",
            "Cong Zhang",
            "Jie Jia",
            "Binbin Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Single-Channel Speech Enhancement Using Learnable Loss Mixup",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-859",
        "paper_authors": [
            "Oscar Chang",
            "Dung N. Tran",
            "Kazuhito Koishida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Maximum Likelihood Approach to SNR-Progressive Learning Using Generalized Gaussian Distribution for LSTM-Based Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-922",
        "paper_authors": [
            "Xiaoqi Zhang",
            "Jun Du",
            "Li Chai",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Whisper Speech Enhancement Using Joint Variational Autoencoder for Improved Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-953",
        "paper_authors": [
            "Vikas Agrawal",
            "Shashi Kumar",
            "Shakti P. Rath"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DEMUCS-Mobile : On-Device Lightweight Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1025",
        "paper_authors": [
            "Lukas Lee",
            "Youna Ji",
            "Minjae Lee",
            "Min-Seok Choi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Denoising Without Clean Training Data: A Noise2Noise Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1130",
        "paper_authors": [
            "Madhav Mahesh Kashyap",
            "Anuj Tambwekar",
            "Krishnamoorthy Manohara",
            "S. Natarajan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Speech Enhancement Using a Complex-Domain GAN with Fused Time-Domain and Time-Frequency Domain Constraints",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1134",
        "paper_authors": [
            "Feng Dang",
            "Pengyuan Zhang",
            "Hangting Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Enhancement with Topology-Enhanced Generative Adversarial Networks (GANs)",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1411",
        "paper_authors": [
            "Xudong Zhang",
            "Liang Zhao",
            "Feng Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Speech Structure to Improve Time-Frequency Masks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1859",
        "paper_authors": [
            "Suliang Bu",
            "Yunxin Zhao",
            "Shaojun Wang",
            "Mei Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SE-Conformer: Time-Domain Speech Enhancement Using Conformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2207",
        "paper_authors": [
            "Eesung Kim",
            "Hyeji Seo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spectral and Latent Speech Representation Distortion for TTS Evaluation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2258",
        "paper_authors": [
            "Thananchai Kongthaworn",
            "Burin Naowarat",
            "Ekapol Chuangsuwanich"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detection and Analysis of Attention Errors in Sequence-to-Sequence Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-286",
        "paper_authors": [
            "Cassia Valentini-Botinhao",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RyanSpeech: A Corpus for Conversational Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-341",
        "paper_authors": [
            "Rohola Zandie",
            "Mohammad H. Mahoor",
            "Julia Madsen",
            "Eshrat S. Emamian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AISHELL-3: A Multi-Speaker Mandarin TTS Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-755",
        "paper_authors": [
            "Yao Shi",
            "Hui Bu",
            "Xin Xu",
            "Shaoji Zhang",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparing Speech Enhancement Techniques for Voice Adaptation-Based Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-800",
        "paper_authors": [
            "Nicholas Eng",
            "C. T. Justine Hui",
            "Yusuke Hioka",
            "Catherine I. Watson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1148",
        "paper_authors": [
            "Chenye Cui",
            "Yi Ren",
            "Jinglin Liu",
            "Feiyang Chen",
            "Rongjie Huang",
            "Ming Lei",
            "Zhou Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perception of Social Speaker Characteristics in Synthetic Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1229",
        "paper_authors": [
            "Sai Sirisha Rallabandi",
            "Abhinav Bharadwaj",
            "Babak Naderi",
            "Sebastian M\u00f6ller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hi-Fi Multi-Speaker English TTS Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1599",
        "paper_authors": [
            "Evelina Bakhturina",
            "Vitaly Lavrukhin",
            "Boris Ginsburg",
            "Yang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Utilizing Self-Supervised Representations for MOS Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2013",
        "paper_authors": [
            "Wei-Cheng Tseng",
            "Chien-yu Huang",
            "Wei-Tsung Kao",
            "Yist Y. Lin",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "KazakhTTS: An Open-Source Kazakh Text-to-Speech Synthesis Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2124",
        "paper_authors": [
            "Saida Mussakhojayeva",
            "Aigerim Janaliyeva",
            "Almas Mirzakhmetov",
            "Yerbolat Khassanov",
            "Huseyin Atakan Varol"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Confidence Intervals for ASR-Based TTS Evaluation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2203",
        "paper_authors": [
            "Jason Taylor",
            "Korin Richmond"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "INTERSPEECH 2021 Deep Noise Suppression Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1609",
        "paper_authors": [
            "Chandan K. A. Reddy",
            "Harishchandra Dubey",
            "Kazuhito Koishida",
            "Arun Asokan Nair",
            "Vishak Gopal",
            "Ross Cutler",
            "Sebastian Braun",
            "Hannes Gamper",
            "Robert Aichner",
            "Sriram Srinivasan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Simultaneous Denoising and Dereverberation Framework with Target Decoupling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1137",
        "paper_authors": [
            "Andong Li",
            "Wenzhe Liu",
            "Xiaoxue Luo",
            "Guochen Yu",
            "Chengshi Zheng",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Noise Suppression with Non-Intrusive PESQNet Supervision Enabling the Use of Real Training Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-936",
        "paper_authors": [
            "Ziyi Xu",
            "Maximilian Strake",
            "Tim Fingscheidt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DPCRN: Dual-Path Convolution Recurrent Network for Single Channel Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-296",
        "paper_authors": [
            "Xiaohuai Le",
            "Hongsheng Chen",
            "Kai Chen",
            "Jing Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DCCRN+: Channel-Wise Subband DCCRN with SNR Estimation for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1482",
        "paper_authors": [
            "Shubo Lv",
            "Yanxin Hu",
            "Shimin Zhang",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DBNet: A Dual-Branch Network Architecture Processing on Spectrum and Waveform for Single-Channel Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1042",
        "paper_authors": [
            "Kanghao Zhang",
            "Shulin He",
            "Hao Li",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-Delay Speech Enhancement Using Perceptually Motivated Target and Loss",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1410",
        "paper_authors": [
            "Xu Zhang",
            "Xinlei Ren",
            "Xiguang Zheng",
            "Lianwu Chen",
            "Chen Zhang",
            "Liang Guo",
            "Bing Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lightweight Causal Transformer with Local Self-Attention for Real-Time Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-668",
        "paper_authors": [
            "Koen Oostermeijer",
            "Qing Wang",
            "Jun Du"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Paced Ensemble Learning for Speech and Audio Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-155",
        "paper_authors": [
            "Nicolae-Catalin Ristea",
            "Radu Tudor Ionescu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation for Streaming Transformer-Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-175",
        "paper_authors": [
            "Atsushi Kojima"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Encoder Learning and Stream Fusion for Transformer-Based End-to-End Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-555",
        "paper_authors": [
            "Timo Lohrenz",
            "Zhengyang Li",
            "Tim Fingscheidt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conditional Independence for Pretext Task Selection in Self-Supervised Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1027",
        "paper_authors": [
            "Salah Zaiem",
            "Titouan Parcollet",
            "Slim Essid"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Methods to Improve Language Model Integration for Attention-Based Encoder-Decoder ASR Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1255",
        "paper_authors": [
            "Mohammad Zeineldeen",
            "Aleksandr Glushko",
            "Wilfried Michel",
            "Albert Zeyer",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparing CTC and LFMMI for Out-of-Domain Adaptation of wav2vec 2.0 Acoustic Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1683",
        "paper_authors": [
            "Apoorv Vyas",
            "Srikanth R. Madikeri",
            "Herv\u00e9 Bourlard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Attentive Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-573",
        "paper_authors": [
            "Cl\u00e9ment Le Moine",
            "Nicolas Obin",
            "Axel Roebel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Separation of Emotional and Reconstruction Embeddings on Ladder Network to Improve Speech Emotion Recognition Robustness in Noisy Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1438",
        "paper_authors": [
            "Seong-Gyun Leem",
            "Daniel Fulford",
            "Jukka-Pekka Onnela",
            "David Gard",
            "Carlos Busso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "M3: MultiModal Masking Applied to Sentiment Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1739",
        "paper_authors": [
            "Efthymios Georgiou",
            "Georgios Paraskevopoulos",
            "Alexandros Potamianos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The CSTR System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1035",
        "paper_authors": [
            "Ondrej Klejch",
            "Electra Wallington",
            "Peter Bell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1623",
        "paper_authors": [
            "Wei Zhou",
            "Mohammad Zeineldeen",
            "Zuoyun Zheng",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Equivalence of Segmental and Neural Transducer Modeling: A Proof of Concept",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1671",
        "paper_authors": [
            "Wei Zhou",
            "Albert Zeyer",
            "Andr\u00e9 Merboldt",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling Dialectal Variation for Swiss German Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1735",
        "paper_authors": [
            "Abbas Khosravani",
            "Philip N. Garner",
            "Alexandros Lazaridis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Out-of-Vocabulary Words Detection with Attention and CTC Alignments in an End-to-End ASR System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1756",
        "paper_authors": [
            "Ekaterina Egorova",
            "Hari Krishna Vydana",
            "Luk\u00e1s Burget",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training Hybrid Models on Noisy Transliterated Transcripts for Code-Switched Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2127",
        "paper_authors": [
            "Matthew Wiesner",
            "Mousmita Sarma",
            "Ashish Arora",
            "Desh Raj",
            "Dongji Gao",
            "Ruizhe Huang",
            "Supreet Preet",
            "Moris Johnson",
            "Zikra Iqbal",
            "Nagendra Goel",
            "Jan Trmal",
            "Leibny Paola Garc\u00eda-Perera",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Intelligibility of Dysarthric Speech: Human Scores and Acoustic-Phonetic Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1189",
        "paper_authors": [
            "Wei Xue",
            "Roeland van Hout",
            "Fleur Boogmans",
            "Mario Ganzeboom",
            "Catia Cucchiarini",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analyzing Short Term Dynamic Speech Features for Understanding Behavioral Traits of Children with Autism Spectrum Disorder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2111",
        "paper_authors": [
            "Young-Kyung Kim",
            "Rimita Lahiri",
            "Md. Nasir",
            "So Hyun Kim",
            "Somer Bishop",
            "Catherine Lord",
            "Shrikanth S. Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vocalization Recognition of People with Profound Intellectual and Multiple Disabilities (PIMD) Using Machine Learning Algorithms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1239",
        "paper_authors": [
            "Waldemar Jesko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic Complexity, Speech Accuracy and Intelligibility Assessment of Italian Dysarthric Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1862",
        "paper_authors": [
            "Barbara Gili Fivela",
            "Vincenzo Sallustio",
            "Silvia Pede",
            "Danilo Patrocinio"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detection of Consonant Errors in Disordered Speech Based on Consonant-Vowel Segment Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1305",
        "paper_authors": [
            "Si Ioi Ng",
            "Cymie Wing-Yee Ng",
            "Jingyu Li",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Assessing Posterior-Based Mispronunciation Detection on Field-Collected Recordings from Child Speech Therapy Sessions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-69",
        "paper_authors": [
            "Adam Hair",
            "Guanlong Zhao",
            "Beena Ahmed",
            "Kirrie J. Ballard",
            "Ricardo Gutierrez-Osuna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identifying Cognitive Impairment Using Sentence Representation Vectors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-915",
        "paper_authors": [
            "Bahman Mirheidari",
            "Yilin Pan",
            "Daniel Blackburn",
            "Ronan O'Malley",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parental Spoken Scaffolding and Narrative Skills in Crowd-Sourced Storytelling Samples of Young Children",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1297",
        "paper_authors": [
            "Zhengjun Yue",
            "Jon Barker",
            "Heidi Christensen",
            "Cristina McKean",
            "Elaine Ashton",
            "Yvonne Wren",
            "Swapnil Gadgil",
            "Rebecca Bright"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1320",
        "paper_authors": [
            "Tong Xia",
            "Jing Han",
            "Lorena Qendro",
            "Ting Dang",
            "Cecilia Mascolo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Domain Adaptation for Dysarthric Speech Detection via Domain Adversarial Training and Mutual Information Minimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2139",
        "paper_authors": [
            "Disong Wang",
            "Liqun Deng",
            "Yu Ting Yeung",
            "Xiao Chen",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Source and Vocal Tract Cues for Speech-Based Classification of Patients with Parkinson's Disease and Healthy Subjects",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2008",
        "paper_authors": [
            "Tanuka Bhattacharjee",
            "Jhansi Mallela",
            "Yamini Belur",
            "Atchayaram Nalini",
            "Ravi Yadav",
            "Pradeep Reddy",
            "Dipanjan Gope",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CLAC: A Speech Corpus of Healthy English Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1810",
        "paper_authors": [
            "R'mani Haulcy",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Direct Multimodal Few-Shot Learning of Speech and Images",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-49",
        "paper_authors": [
            "Leanne Nortje",
            "Herman Kamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-96",
        "paper_authors": [
            "Ramon Sanabria",
            "Austin Waters",
            "Jason Baldridge"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Fast Discrete Two-Step Learning Hashing for Scalable Cross-Modal Retrieval",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-287",
        "paper_authors": [
            "Huan Zhao",
            "Kaili Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Modal Knowledge Distillation Method for Automatic Cued Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-432",
        "paper_authors": [
            "Jianrong Wang",
            "Ziyue Tang",
            "Xuewei Li",
            "Mei Yu",
            "Qiang Fang",
            "Li Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention-Based Keyword Localisation in Speech Using Visual Grounding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-435",
        "paper_authors": [
            "Kayode Olaleye",
            "Herman Kamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluation of Audio-Visual Alignments in Visually Grounded Speech Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-496",
        "paper_authors": [
            "Khazar Khorrami",
            "Okko R\u00e4s\u00e4nen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Lip-Reading with Hierarchical Pyramidal Convolution and Self-Attention for Image Sequences with No Word Boundaries",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-723",
        "paper_authors": [
            "Hang Chen",
            "Jun Du",
            "Yu Hu",
            "Li-Rong Dai",
            "Bao-Cai Yin",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cascaded Multilingual Audio-Visual Learning from Videos",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1352",
        "paper_authors": [
            "Andrew Rouditchenko",
            "Angie W. Boggust",
            "David Harwath",
            "Samuel Thomas",
            "Hilde Kuehne",
            "Brian Chen",
            "Rameswar Panda",
            "Rog\u00e9rio Feris",
            "Brian Kingsbury",
            "Michael Picheny",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LiRA: Learning Visual Speech Representations from Audio Through Self-Supervision",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1360",
        "paper_authors": [
            "Pingchuan Ma",
            "Rodrigo Mira",
            "Stavros Petridis",
            "Bj\u00f6rn W. Schuller",
            "Maja Pantic"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Audio-Visual Speech Recognition for Overlapping Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1621",
        "paper_authors": [
            "Richard Rose",
            "Olivier Siohan",
            "Anshuman Tripathi",
            "Otavio Braga"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Multi-Talker Speech Recognition in a Cocktail Party",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2128",
        "paper_authors": [
            "Yifei Wu",
            "Chenda Li",
            "Song Yang",
            "Zhongqin Wu",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ultra Fast Speech Separation Model with Teacher Student Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-142",
        "paper_authors": [
            "Sanyuan Chen",
            "Yu Wu",
            "Zhuo Chen",
            "Jian Wu",
            "Takuya Yoshioka",
            "Shujie Liu",
            "Jinyu Li",
            "Xiangzhan Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Group Delay Based Re-Weighted Sparse Recovery Algorithms for Robust and High-Resolution Source Separation in DOA Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-164",
        "paper_authors": [
            "Murtiza Ali",
            "Ashwani Koul",
            "Karan Nathwani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continuous Speech Separation Using Speaker Inventory for Long Recording",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-338",
        "paper_authors": [
            "Cong Han",
            "Yi Luo",
            "Chenda Li",
            "Tianyan Zhou",
            "Keisuke Kinoshita",
            "Shinji Watanabe",
            "Marc Delcroix",
            "Hakan Erdogan",
            "John R. Hershey",
            "Nima Mesgarani",
            "Zhuo Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Crossfire Conditional Generative Adversarial Networks for Singing Voice Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-433",
        "paper_authors": [
            "Weitao Yuan",
            "Shengbei Wang",
            "Xiangrui Li",
            "Masashi Unoki",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Speech Separation Using Orthogonal Representation in Complex and Real Time-Frequency Domain",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-504",
        "paper_authors": [
            "Kai Wang",
            "Hao Huang",
            "Ying Hu",
            "Zhihua Huang",
            "Sheng Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient and Stable Adversarial Learning Using Unpaired Data for Unsupervised Multichannel Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-523",
        "paper_authors": [
            "Yu Nakagome",
            "Masahito Togami",
            "Tetsuji Ogawa",
            "Tetsunori Kobayashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stabilizing Label Assignment for Speech Separation by Self-Supervised Pre-Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-763",
        "paper_authors": [
            "Sung-Feng Huang",
            "Shun-Po Chuang",
            "Da-Rong Liu",
            "Yi-Chen Chen",
            "Gene-Ping Yang",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual-Path Filter Network: Speaker-Aware Modeling for Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-858",
        "paper_authors": [
            "Fan-Lin Wang",
            "Yu-Huai Peng",
            "Hung-Shin Lee",
            "Hsin-Min Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of Practical Aspects of Single Channel Speech Separation for ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-921",
        "paper_authors": [
            "Jian Wu",
            "Zhuo Chen",
            "Sanyuan Chen",
            "Yu Wu",
            "Takuya Yoshioka",
            "Naoyuki Kanda",
            "Shujie Liu",
            "Jinyu Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Implicit Filter-and-Sum Network for End-to-End Multi-Channel Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1158",
        "paper_authors": [
            "Yi Luo",
            "Nima Mesgarani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Spatio-Temporal RNN Beamformer for Target Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-430",
        "paper_authors": [
            "Yong Xu",
            "Zhuohuang Zhang",
            "Meng Yu",
            "Shi-Xiong Zhang",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Neural Diarization: From Transformer to Conformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1909",
        "paper_authors": [
            "Yi-Chieh Liu",
            "Eunjung Han",
            "Chul Lee",
            "Andreas Stolcke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Three-Class Overlapped Speech Detection Using a Convolutional Recurrent Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-149",
        "paper_authors": [
            "Jee-weon Jung",
            "Hee-Soo Heo",
            "Youngki Kwon",
            "Joon Son Chung",
            "Bong-Jin Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Speaker Diarization Equipped with Discriminative Modeling and Guided Inference",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-261",
        "paper_authors": [
            "Xucheng Wan",
            "Kai Liu",
            "Huan Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised Training with Pseudo-Labeling for End-To-End Neural Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-384",
        "paper_authors": [
            "Yuki Takashima",
            "Yusuke Fujita",
            "Shota Horiguchi",
            "Shinji Watanabe",
            "Leibny Paola Garc\u00eda-Perera",
            "Kenji Nagamatsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adapting Speaker Embeddings for Speaker Diarisation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-448",
        "paper_authors": [
            "Youngki Kwon",
            "Jee-weon Jung",
            "Hee-Soo Heo",
            "You Jin Kim",
            "Bong-Jin Lee",
            "Joon Son Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scenario-Dependent Speaker Diarization for DIHARD-III Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-516",
        "paper_authors": [
            "Yu-Xuan Wang",
            "Jun Du",
            "Maokui He",
            "Shutong Niu",
            "Lei Sun",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-To-End Speaker Segmentation for Overlap-Aware Resegmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-560",
        "paper_authors": [
            "Herv\u00e9 Bredin",
            "Antoine Laurent"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Streaming End-to-End Neural Diarization Handling Overlapping Speech and Flexible Numbers of Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-708",
        "paper_authors": [
            "Yawen Xue",
            "Shota Horiguchi",
            "Yusuke Fujita",
            "Yuki Takashima",
            "Shinji Watanabe",
            "Leibny Paola Garc\u00eda-Perera",
            "Kenji Nagamatsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Thousand Words are Worth More Than One Recording: Word-Embedding Based Speaker Change Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-87",
        "paper_authors": [
            "Or Haim Anidjar",
            "Itshak Lapidot",
            "Chen Hajaj",
            "Amit Dvir"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phrase Break Prediction with Bidirectional Encoder Representations in Japanese Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-252",
        "paper_authors": [
            "Kosuke Futamata",
            "Byeongseon Park",
            "Ryuichi Yamamoto",
            "Kentaro Tachibana"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Multi-Speaker TTS Prosody Variance with a Residual Encoder and Normalizing Flows",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-562",
        "paper_authors": [
            "Iv\u00e1n Vall\u00e9s-P\u00e9rez",
            "Julian Roth",
            "Grzegorz Beringer",
            "Roberto Barra-Chicote",
            "Jasha Droppo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rich Prosody Diversity Modelling with Phone-Level Mixture Density Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-802",
        "paper_authors": [
            "Chenpeng Du",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phoneme Duration Modeling Using Speech Rhythm-Based Speaker Embeddings for Multi-Speaker Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-826",
        "paper_authors": [
            "Kenichi Fujita",
            "Atsushi Ando",
            "Yusuke Ijima"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fine-Grained Prosody Modeling in Neural Speech Synthesis Using ToBI Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-883",
        "paper_authors": [
            "Yuxiang Zou",
            "Shichao Liu",
            "Xiang Yin",
            "Haopeng Lin",
            "Chunfeng Wang",
            "Haoyu Zhang",
            "Zejun Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intra-Sentential Speaking Rate Control in Neural Text-To-Speech for Automatic Dubbing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1012",
        "paper_authors": [
            "Mayank Sharma",
            "Yogesh Virkar",
            "Marcello Federico",
            "Roberto Barra-Chicote",
            "Robert Enyedi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Applying the Information Bottleneck Principle to Prosodic Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1049",
        "paper_authors": [
            "Guangyan Zhang",
            "Ying Qin",
            "Daxin Tan",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Prototypical Network Approach for Evaluating Generated Emotional Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1123",
        "paper_authors": [
            "Alice Baird",
            "Silvan Mertes",
            "Manuel Milling",
            "Lukas Stappen",
            "Thomas Wiest",
            "Elisabeth Andr\u00e9",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Simplified Model for the Vocal Tract of [s] with Inclined Incisors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-231",
        "paper_authors": [
            "Tsukasa Yoshinaga",
            "Kohei Tada",
            "Kazunori Nozaki",
            "Akiyoshi Iida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vocal-Tract Models to Visualize the Airstream of Human Breath and Droplets While Producing Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-449",
        "paper_authors": [
            "Takayuki Arai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Transposed Convolution for Articulatory-to-Acoustic Conversion from Real-Time MRI Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-906",
        "paper_authors": [
            "Ryo Tanji",
            "Hidefumi Ohmura",
            "Kouichi Katsurada"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison Between Lumped-Mass Modeling and Flow Simulation of the Reed-Type Artificial Vocal Fold",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-929",
        "paper_authors": [
            "Rafia Inaam",
            "Tsukasa Yoshinaga",
            "Takayuki Arai",
            "Hiroshi Yokoyama",
            "Akiyoshi Iida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Inhalations in Speech: Acoustic and Physiological Characteristics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1262",
        "paper_authors": [
            "Raphael Werner",
            "Susanne Fuchs",
            "J\u00fcrgen Trouvain",
            "Bernd M\u00f6bius"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Model-Based Exploration of Linking Between Vowel Articulatory Space and Acoustic Space",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1422",
        "paper_authors": [
            "Anqi Xu",
            "Daniel R. van Niekerk",
            "Branislav Gerazov",
            "Paul Konstantin Krug",
            "Santitham Prom-on",
            "Peter Birkholz",
            "Yi Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Take a Breath: Respiratory Sounds Improve Recollection in Synthetic Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1496",
        "paper_authors": [
            "Mikey Elmers",
            "Raphael Werner",
            "Beeke Muhlack",
            "Bernd M\u00f6bius",
            "J\u00fcrgen Trouvain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling Sensorimotor Adaptation in Speech Through Alterations to Forward and Inverse Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1746",
        "paper_authors": [
            "Taijing Chen",
            "Adam C. Lammert",
            "Benjamin Parrell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mixture of Orthogonal Sequences Made from Extended Time-Stretched Pulses Enables Measurement of Involuntary Voice Fundamental Frequency Response to Pitch Perturbation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2073",
        "paper_authors": [
            "Hideki Kawahara",
            "Toshie Matsui",
            "Kohei Yatabe",
            "Ken-Ichi Sakakibara",
            "Minoru Tsuzaki",
            "Masanori Morise",
            "Toshio Irino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextualized Attention-Based Knowledge Transfer for Spoken Conversational Question Answering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-110",
        "paper_authors": [
            "Chenyu You",
            "Nuo Chen",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Injecting Descriptive Meta-Information into Pre-Trained Language Models with Hypernetworks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-229",
        "paper_authors": [
            "Wenying Duan",
            "Xiaoxi He",
            "Zimu Zhou",
            "Hong Rao",
            "Lothar Thiele"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Causal Confusion Reduction for Robust Multi-Domain Dialogue Policy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-534",
        "paper_authors": [
            "Mahdin Rohmatillah",
            "Jen-Tzung Chien"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Timing Generating Networks: Neural Network Based Precise Turn-Taking Timing Prediction in Multiparty Conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-874",
        "paper_authors": [
            "Shinya Fujie",
            "Hayato Katayama",
            "Jin Sakuma",
            "Tetsunori Kobayashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Human-to-Human Conversation Dataset for Learning Fine-Grained Turn-Taking Action",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-994",
        "paper_authors": [
            "Kehan Chen",
            "Zezhong Li",
            "Suyang Dai",
            "Wei Zhou",
            "Haiqing Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PhonemeBERT: Joint Language Modelling of Phoneme Sequence and ASR Transcript",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1582",
        "paper_authors": [
            "Mukuntha Narayanan Sundararaman",
            "Ayush Kumar",
            "Jithendra Vepa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Retrieval-Extraction Training for Evidence-Aware Dialog Response Selection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1689",
        "paper_authors": [
            "Hongyin Luo",
            "James R. Glass",
            "Garima Lalwani",
            "Yi Zhang",
            "Shang-Wen Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adapting Long Context NLM for ASR Rescoring in Conversational Agents",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1849",
        "paper_authors": [
            "Ashish Shenoy",
            "Sravan Bodapati",
            "Monica Sunkara",
            "Srikanth Ronanki",
            "Katrin Kirchhoff"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Oriental Language Recognition (OLR) 2020: Summary and Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2171",
        "paper_authors": [
            "Jing Li",
            "Binling Wang",
            "Yiming Zhi",
            "Zheng Li",
            "Lin Li",
            "Qingyang Hong",
            "Dong Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language Recognition on Unknown Conditions: The LORIA-Inria-MULTISPEECH System for AP20-OLR Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-276",
        "paper_authors": [
            "Rapha\u00ebl Duroselle",
            "Md. Sahidullah",
            "Denis Jouvet",
            "Irina Illina"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Multi-Scale Convolution for Dialect Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-56",
        "paper_authors": [
            "Tianlong Kong",
            "Shouyi Yin",
            "Dawei Zhang",
            "Wang Geng",
            "Xin Wang",
            "Dandan Song",
            "Jinwen Huang",
            "Huiyu Shi",
            "Xiaorui Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An End-to-End Dialect Identification System with Transfer Learning from a Multilingual Automatic Speech Recognition Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-374",
        "paper_authors": [
            "Ding Wang",
            "Shuaishuai Ye",
            "Xinhui Hu",
            "Sheng Li",
            "Xinkang Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language Recognition Based on Unsupervised Pretrained Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-807",
        "paper_authors": [
            "Haibin Yu",
            "Jing Zhao",
            "Song Yang",
            "Zhongqin Wu",
            "Yuting Nie",
            "Wei-Qiang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Additive Phoneme-Aware Margin Softmax Loss for Language Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1167",
        "paper_authors": [
            "Zheng Li",
            "Yan Liu",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards an Accent-Robust Approach for ATC Communications Transcription",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-333",
        "paper_authors": [
            "Nataly Jahchan",
            "Florentin Barbier",
            "Ariyanidevi Dharma Gita",
            "Khaled Khelif",
            "Estelle Delpech"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting English Speech in the Air Traffic Control Voice Communication",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1033",
        "paper_authors": [
            "Igor Sz\u00f6ke",
            "Santosh Kesiraju",
            "Ondrej Novotn\u00fd",
            "Martin Kocour",
            "Karel Vesel\u00fd",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Command Recognition for Lithuanian Air Traffic Control Tower Utterances",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-935",
        "paper_authors": [
            "Oliver Ohneiser",
            "Seyyed Saeed Sarfjoo",
            "Hartmut Helmke",
            "Shruthi Shetty",
            "Petr Motl\u00edcek",
            "Matthias Kleinert",
            "Heiko Ehr",
            "Sarunas Murauskas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextual Semi-Supervised Learning: An Approach to Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1373",
        "paper_authors": [
            "Juan Zuluaga-Gomez",
            "Iuliia Nigmatulina",
            "Amrutha Prasad",
            "Petr Motl\u00edcek",
            "Karel Vesel\u00fd",
            "Martin Kocour",
            "Igor Sz\u00f6ke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Boosting of Contextual Information in ASR for Air-Traffic Call-Sign Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1619",
        "paper_authors": [
            "Martin Kocour",
            "Karel Vesel\u00fd",
            "Alexander Blatt",
            "Juan Zuluaga-Gomez",
            "Igor Sz\u00f6ke",
            "Jan Cernock\u00fd",
            "Dietrich Klakow",
            "Petr Motl\u00edcek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling the Effect of Military Oxygen Masks on Speech Characteristics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1650",
        "paper_authors": [
            "Benjamin Elie",
            "Jodie Gauvain",
            "Jean-Luc Gauvain",
            "Lori Lamel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MoM: Minutes of Meeting Bot",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/milde21_interspeech.html",
        "paper_authors": [
            "Benjamin Milde",
            "Tim Fischer",
            "Steffen Remus",
            "Chris Biemann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Articulatory Data Recorder: A Framework for Real-Time Articulatory Data Recording",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/wilbrandt21_interspeech.html",
        "paper_authors": [
            "Alexander Wilbrandt",
            "Simon Stone",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The INGENIOUS Multilingual Operations App",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/codinafilba21_interspeech.html",
        "paper_authors": [
            "Joan Codina-Filb\u00e0",
            "Guillermo C\u00e1mbara",
            "Alex Peir\u00f3 Lilja",
            "Jens Grivolla",
            "Roberto Carlini",
            "Mireia Farr\u00fas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Digital Einstein Experience: Fast Text-to-Speech for Conversational AI",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/rownicka21_interspeech.html",
        "paper_authors": [
            "Joanna Rownicka",
            "Kilian Sprenkamp",
            "Antonio Tripiana",
            "Volodymyr Gromoglasov",
            "Timo P. Kunz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Live Subtitling for BigBlueButton with Open-Source Software",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/geislinger21_interspeech.html",
        "paper_authors": [
            "Robert Geislinger",
            "Benjamin Milde",
            "Timo Baumann",
            "Chris Biemann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Expressive Latvian Speech Synthesis for Dialog Systems",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/nicmanis21_interspeech.html",
        "paper_authors": [
            "Davis Nicmanis",
            "Askars Salimbajevs"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ViSTAFAE: A Visual Speech-Training Aid with Feedback of Articulatory Efforts",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/kachare21_interspeech.html",
        "paper_authors": [
            "Pramod H. Kachare",
            "Prem C. Pandey",
            "Vishal Mane",
            "Hirak Dasgupta",
            "K. S. Nataraj",
            "Akshada Rathod",
            "Sheetal K. Pathak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Speech Models from Multi-Modal Data",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/livescu21_interspeech.html",
        "paper_authors": [
            "Karen Livescu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Listening to Everyday Soundscapes",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/elhilali21_interspeech.html",
        "paper_authors": [
            "Mounya Elhilali"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards the Prediction of the Vocal Tract Shape from the Sequence of Phonemes to be Articulated",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-184",
        "paper_authors": [
            "Vinicius Ribeiro",
            "Karyna Isaieva",
            "Justine Leclere",
            "Pierre-Andr\u00e9 Vuissoz",
            "Yves Laprie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison of the Finite Element Method, the Multimodal Method and the Transmission-Line Model for the Computation of Vocal Tract Transfer Functions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-975",
        "paper_authors": [
            "R\u00e9mi Blandin",
            "Marc Arnela",
            "Simon F\u00e9lix",
            "Jean-Baptiste Doc",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Time Pressure and Spontaneity on Phonotactic Innovations in German Dialogues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1539",
        "paper_authors": [
            "Petra Wagner",
            "Sina Zarrie\u00df",
            "Joana Cholin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Importance of Parasagittal Sensor Information in Tongue Motion Capture Through a Diphonic Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1732",
        "paper_authors": [
            "Salvador Medina",
            "Sarah Taylor",
            "Mark Tiede",
            "Alexander G. Hauptmann",
            "Iain A. Matthews"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Robust Speech Representation with an Articulatory-Regularized Variational Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1604",
        "paper_authors": [
            "Marc-Antoine Georges",
            "Laurent Girin",
            "Jean-Luc Schwartz",
            "Thomas Hueber"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Changes in Glottal Source Parameter Values with Light to Moderate Physical Load",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1881",
        "paper_authors": [
            "Heather Weston",
            "Laura L. Koenig",
            "Susanne Fuchs"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Optimized Multi-Stage Vector Quantization of Spectral Envelopes for Speech and Audio Coding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-867",
        "paper_authors": [
            "Mohammad Hassan Vali",
            "Tom B\u00e4ckstr\u00f6m"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fusion-Net: Time-Frequency Information Fusion Y-Network for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1184",
        "paper_authors": [
            "Santhan Kumar Reddy Nareddula",
            "Subrahmanyam Gorthi",
            "Rama Krishna Sai Subrahmanyam Gorthi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "N-MTTL SI Model: Non-Intrusive Multi-Task Transfer Learning-Based Speech Intelligibility Prediction Model with Scenery Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1878",
        "paper_authors": [
            "Lubos Marcinek",
            "Michael Stone",
            "Rebecca E. Millman",
            "Patrick Gaydecki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Temporal Context in Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1840",
        "paper_authors": [
            "Yangyang Xia",
            "Li-Wei Chen",
            "Alexander Rudnicky",
            "Richard M. Stern"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Fine-Grained Cross Modality Excitement for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-158",
        "paper_authors": [
            "Hang Li",
            "Wenbiao Ding",
            "Zhongqin Wu",
            "Zitao Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Analysis of the Emotional Content of Speech in Daylong Child-Centered Recordings from a Neonatal Intensive Care Unit",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-303",
        "paper_authors": [
            "Einari Vaaras",
            "Sari Ahlqvist-Bj\u00f6rkroth",
            "Konstantinos Drossos",
            "Okko R\u00e4s\u00e4nen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Sentiment Analysis with Temporal Modality Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-487",
        "paper_authors": [
            "Fan Qian",
            "Jiqing Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Process Regression for Cross-Cultural Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-610",
        "paper_authors": [
            "Mani Kumar Tellamekala",
            "Enrique Sanchez",
            "Georgios Tzimiropoulos",
            "Timo Giesbrecht",
            "Michel F. Valstar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-666",
        "paper_authors": [
            "Haoqi Li",
            "Yelin Kim",
            "Cheng-Hao Kuo",
            "Shrikanth S. Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emotion Recognition from Speech Using wav2vec 2.0 Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-703",
        "paper_authors": [
            "Leonardo Pepino",
            "Pablo Riera",
            "Luciana Ferrer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph Isomorphism Network for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1154",
        "paper_authors": [
            "Jiawang Liu",
            "Haoxiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Applying TDNN Architectures for Analyzing Duration Dependencies on Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2168",
        "paper_authors": [
            "Pooja Kumawat",
            "Aurobinda Routray"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Features and Neural Representations for Categorical Emotion Recognition from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2217",
        "paper_authors": [
            "Aaron Keesing",
            "Yun Sing Koh",
            "Michael Witbrock"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Pre-Trained Language Model for Speech Sentiment Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1723",
        "paper_authors": [
            "Suwon Shon",
            "Pablo Brusco",
            "Jing Pan",
            "Kyu Jeong Han",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Domain Speech Recognition with Unsupervised Character-Level Distribution Matching",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-57",
        "paper_authors": [
            "Wenxin Hou",
            "Jindong Wang",
            "Xu Tan",
            "Tao Qin",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large-Scale Pre-Training of End-to-End Multi-Talker ASR for Meeting Transcription with Single Distant Microphone",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-102",
        "paper_authors": [
            "Naoyuki Kanda",
            "Guoli Ye",
            "Yu Wu",
            "Yashesh Gaur",
            "Xiaofei Wang",
            "Zhong Meng",
            "Zhuo Chen",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Minimum Word Error Rate Training of the Hybrid Autoregressive Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-161",
        "paper_authors": [
            "Liang Lu",
            "Zhong Meng",
            "Naoyuki Kanda",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reducing Streaming ASR Model Delay with Self Alignment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-322",
        "paper_authors": [
            "Jaeyoung Kim",
            "Han Lu",
            "Anshuman Tripathi",
            "Qian Zhang",
            "Hasim Sak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-644",
        "paper_authors": [
            "Anuj Diwan",
            "Preethi Jyothi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation Based Training of Universal ASR Source Models for Cross-Lingual Transfer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-796",
        "paper_authors": [
            "Takashi Fukuda",
            "Samuel Thomas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Listen with Intent: Improving Speech Recognition with Audio-to-Intent Front-End",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-836",
        "paper_authors": [
            "Swayambhu Nath Ray",
            "Minhua Wu",
            "Anirudh Raju",
            "Pegah Ghahremani",
            "Raghavendra Bilgi",
            "Milind Rao",
            "Harish Arsikere",
            "Ariya Rastrow",
            "Andreas Stolcke",
            "Jasha Droppo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Targeted Universal Adversarial Perturbations to End-to-End ASR Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1668",
        "paper_authors": [
            "Zhiyun Lu",
            "Wei Han",
            "Yu Zhang",
            "Liangliang Cao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Earnings-21: A Practical Benchmark for ASR in the Wild",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1915",
        "paper_authors": [
            "Miguel Del Rio",
            "Natalie Delworth",
            "Ryan Westerman",
            "Michelle Huang",
            "Nishchal Bhandari",
            "Joseph Palakapilly",
            "Quinten McNamara",
            "Joshua Dong",
            "Piotr Zelasko",
            "Miguel Jette"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Multilingual Transformer Transducer Models by Reducing Language Confusions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1949",
        "paper_authors": [
            "Eric Sun",
            "Jinyu Li",
            "Zhong Meng",
            "Yu Wu",
            "Jian Xue",
            "Shujie Liu",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Arabic Code-Switching Speech Recognition Using Monolingual Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2231",
        "paper_authors": [
            "Ahmed Ali",
            "Shammur Absar Chowdhury",
            "Amir Hussein",
            "Yasser Hifny"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Blind Audio Source Separation Using Recursive Expectation-Maximization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-662",
        "paper_authors": [
            "Aviad Eisenberg",
            "Boaz Schwartz",
            "Sharon Gannot"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Empirical Analysis of Generalized Iterative Speech Separation Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1161",
        "paper_authors": [
            "Yi Luo",
            "Cong Han",
            "Nima Mesgarani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph-PIT: Generalized Permutation Invariant Training for Continuous Separation of Arbitrary Numbers of Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1177",
        "paper_authors": [
            "Thilo von Neumann",
            "Keisuke Kinoshita",
            "Christoph B\u00f6ddeker",
            "Marc Delcroix",
            "Reinhold Haeb-Umbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Teacher-Student MixIT for Unsupervised and Semi-Supervised Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1243",
        "paper_authors": [
            "Jisi Zhang",
            "Catalin Zorila",
            "Rama Doddipatla",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Few-Shot Learning of New Sound Classes for Target Sound Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1369",
        "paper_authors": [
            "Marc Delcroix",
            "Jorge Bennasar V\u00e1zquez",
            "Tsubasa Ochiai",
            "Keisuke Kinoshita",
            "Shoko Araki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Binaural Speech Separation of Moving Speakers With Preserved Spatial Cues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1372",
        "paper_authors": [
            "Cong Han",
            "Yi Luo",
            "Nima Mesgarani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AvaTr: One-Shot Speaker Extraction with Transformers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1378",
        "paper_authors": [
            "Shell Xu Hu",
            "Md Rifat Arefin",
            "Viet-Nhat Nguyen",
            "Alish Dipani",
            "Xaq Pitkow",
            "Andreas Savas Tolias"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vocal Harmony Separation Using Time-Domain Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1531",
        "paper_authors": [
            "Saurjya Sarkar",
            "Emmanouil Benetos",
            "Mark B. Sandler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Verification-Based Evaluation of Single-Channel Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1924",
        "paper_authors": [
            "Matthew Maciejewski",
            "Shinji Watanabe",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Speech Separation with Time-and-Frequency Cross-Domain Feature Selection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2246",
        "paper_authors": [
            "Tian Lan",
            "Yuxin Qian",
            "Yilan Lyu",
            "Refuoe Mokhosi",
            "Wenxin Tai",
            "Qiao Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Speaker Extraction Network Based on Iterative Refined Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2250",
        "paper_authors": [
            "Chengyun Deng",
            "Shiqian Ma",
            "Yongtao Sha",
            "Yi Zhang",
            "Hui Zhang",
            "Hui Song",
            "Fei Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Speaker Extraction with Speaker-Speech Cross-Attention Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2260",
        "paper_authors": [
            "Wupeng Wang",
            "Chenglin Xu",
            "Meng Ge",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Audio-Visual Speech Separation Based on Facial Motion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1560",
        "paper_authors": [
            "R\u00e9mi Rigal",
            "Jacques Chodorowski",
            "Beno\u00eet Zerr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LEAP Submission for the Third DIHARD Diarization Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-728",
        "paper_authors": [
            "Prachi Singh",
            "Rajat Varma",
            "Venkat Krishnamohan",
            "Srikanth Raj Chetupalli",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of Spatial-Acoustic Features for Overlapping Speech Detection in Multiparty Meetings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-747",
        "paper_authors": [
            "Shiliang Zhang",
            "Siqi Zheng",
            "Weilong Huang",
            "Ming Lei",
            "Hongbin Suo",
            "Jinwei Feng",
            "Zhijie Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Target-Speaker Voice Activity Detection with Improved i-Vector Estimation for Unknown Number of Speaker",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-750",
        "paper_authors": [
            "Maokui He",
            "Desh Raj",
            "Zili Huang",
            "Jun Du",
            "Zhuo Chen",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ECAPA-TDNN Embeddings for Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-941",
        "paper_authors": [
            "Nauman Dawalatabad",
            "Mirco Ravanelli",
            "Fran\u00e7ois Grondin",
            "Jenthe Thienpondt",
            "Brecht Desplanques",
            "Hwidong Na"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Advances in Integration of End-to-End Neural and Clustering-Based Diarization for Real Conversational Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1004",
        "paper_authors": [
            "Keisuke Kinoshita",
            "Marc Delcroix",
            "Naohiro Tawara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Third DIHARD Diarization Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1208",
        "paper_authors": [
            "Neville Ryant",
            "Prachi Singh",
            "Venkat Krishnamohan",
            "Rajat Varma",
            "Kenneth Church",
            "Christopher Cieri",
            "Jun Du",
            "Sriram Ganapathy",
            "Mark Liberman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust End-to-End Speaker Diarization with Conformer and Additive Margin Penalty",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1377",
        "paper_authors": [
            "Tsun-Yat Leung",
            "Lahiru Samarakoon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Anonymous Speaker Clusters: Making Distinctions Between Anonymised Speech Recordings with Clustering Interface",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1588",
        "paper_authors": [
            "Benjamin O'Brien",
            "Natalia A. Tomashenko",
            "Ana\u00efs Chanclu",
            "Jean-Fran\u00e7ois Bonastre"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Diarization Using Two-Pass Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1807",
        "paper_authors": [
            "Kiran Karra",
            "Alan McCree"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Federated Learning with Dynamic Transformer for Text to Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2039",
        "paper_authors": [
            "Zhenhou Hong",
            "Jianzong Wang",
            "Xiaoyang Qu",
            "Jie Liu",
            "Chendong Zhao",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LiteTTS: A Lightweight Mel-Spectrogram-Free Text-to-Wave Synthesizer Based on Generative Adversarial Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-188",
        "paper_authors": [
            "Huu-Kim Nguyen",
            "Kihyuk Jeong",
            "Se-Yun Um",
            "Min-Jae Hwang",
            "Eunwoo Song",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-189",
        "paper_authors": [
            "Chuanxin Tang",
            "Chong Luo",
            "Zhiyuan Zhao",
            "Dacheng Yin",
            "Yucheng Zhao",
            "Wenjun Zeng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Diff-TTS: A Denoising Diffusion Model for Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-469",
        "paper_authors": [
            "Myeonghun Jeong",
            "Hyeongju Kim",
            "Sung Jun Cheon",
            "Byoung Jin Choi",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-471",
        "paper_authors": [
            "Jae-Sung Bae",
            "Taejun Bak",
            "Young-Sun Joo",
            "Hoon-Young Cho"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-475",
        "paper_authors": [
            "Adam Polyak",
            "Yossi Adi",
            "Jade Copet",
            "Eugene Kharitonov",
            "Kushal Lakhotia",
            "Wei-Ning Hsu",
            "Abdelrahman Mohamed",
            "Emmanuel Dupoux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Learned Conditional Prior for the VAE Acoustic Space of a TTS System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-528",
        "paper_authors": [
            "Penny Karanasou",
            "Sri Karlapati",
            "Alexis Moinet",
            "Arnaud Joly",
            "Ammar Abbas",
            "Simon Slangen",
            "Jaime Lorenzo-Trueba",
            "Thomas Drugman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Universal Multi-Speaker Multi-Style Text-to-Speech via Disentangled Representation Learning Based on R\u00e9nyi Divergence Minimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-660",
        "paper_authors": [
            "Dipjyoti Paul",
            "Sankar Mukherjee",
            "Yannis Pantazis",
            "Yannis Stylianou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relational Data Selection for Data Augmentation of Speaker-Dependent Multi-Band MelGAN Vocoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-806",
        "paper_authors": [
            "Yi-Chiao Wu",
            "Cheng-Hung Hu",
            "Hung-Shin Lee",
            "Yu-Huai Peng",
            "Wen-Chin Huang",
            "Yu Tsao",
            "Hsin-Min Wang",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reinforce-Aligner: Reinforcement Alignment Search for Robust End-to-End Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-831",
        "paper_authors": [
            "Hyunseung Chung",
            "Sang-Hoon Lee",
            "Seong-Whan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Triple M: A Practical Text-to-Speech Synthesis System with Multi-Guidance Attention and Multi-Band Multi-Time LPCNet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-851",
        "paper_authors": [
            "Shilun Lin",
            "Fenglong Xie",
            "Li Meng",
            "Xinhui Li",
            "Li Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SC-GlowTTS: An Efficient Zero-Shot Multi-Speaker Text-To-Speech Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1774",
        "paper_authors": [
            "Edresson Casanova",
            "Christopher Shulby",
            "Eren G\u00f6lge",
            "Nicolas Michael M\u00fcller",
            "Frederico Santos de Oliveira",
            "Arnaldo Candido Jr.",
            "Anderson da Silva Soares",
            "Sandra Maria Alu\u00edsio",
            "Moacir Antonelli Ponti"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoken ObjectNet: A Bias-Controlled Spoken Caption Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-245",
        "paper_authors": [
            "Ian Palmer",
            "Andrew Rouditchenko",
            "Andrei Barbu",
            "Boris Katz",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Multilingual TEDx Corpus for Speech Recognition and Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-11",
        "paper_authors": [
            "Elizabeth Salesky",
            "Matthew Wiesner",
            "Jacob Bremerman",
            "Roldano Cattoni",
            "Matteo Negri",
            "Marco Turchi",
            "Douglas W. Oard",
            "Matt Post"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tusom2021: A Phonetically Transcribed Speech Dataset from an Endangered Language for Universal Phone Recognition Experiments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1435",
        "paper_authors": [
            "David R. Mortensen",
            "Jordan Picone",
            "Xinjian Li",
            "Kathleen Siminyu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation, Recognition and Speaker Diarization in Conference Scenario",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1397",
        "paper_authors": [
            "Yihui Fu",
            "Luyao Cheng",
            "Shubo Lv",
            "Yukai Jv",
            "Yuxiang Kong",
            "Zhuo Chen",
            "Yanxin Hu",
            "Lei Xie",
            "Jian Wu",
            "Hui Bu",
            "Xin Xu",
            "Jun Du",
            "Jingdong Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GigaSpeech: An Evolving, Multi-Domain ASR Corpus with 10, 000 Hours of Transcribed Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1965",
        "paper_authors": [
            "Guoguo Chen",
            "Shuzhou Chai",
            "Guan-Bo Wang",
            "Jiayu Du",
            "Wei-Qiang Zhang",
            "Chao Weng",
            "Dan Su",
            "Daniel Povey",
            "Jan Trmal",
            "Junbo Zhang",
            "Mingjie Jin",
            "Sanjeev Khudanpur",
            "Shinji Watanabe",
            "Shuaijiang Zhao",
            "Wei Zou",
            "Xiangang Li",
            "Xuchen Yao",
            "Yongqing Wang",
            "Zhao You",
            "Zhiyong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Look Who's Talking: Active Speaker Detection in the Wild",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2041",
        "paper_authors": [
            "You Jin Kim",
            "Hee-Soo Heo",
            "Soyeon Choe",
            "Soo-Whan Chung",
            "Yoohwan Kwon",
            "Bong-Jin Lee",
            "Youngki Kwon",
            "Joon Son Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AusKidTalk: An Auditory-Visual Corpus of 3- to 12-Year-Old Australian Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2000",
        "paper_authors": [
            "Beena Ahmed",
            "Kirrie J. Ballard",
            "Denis Burnham",
            "Tharmakulasingam Sirojan",
            "Hadi Mehmood",
            "Dominique Estival",
            "Elise Baker",
            "Felicity Cox",
            "Joanne Arciuli",
            "Titia Benders",
            "Katherine Demuth",
            "Barbara Kelly",
            "Chlo\u00e9 Diskin-Holdaway",
            "Mostafa Ali Shahin",
            "Vidhyasaharan Sethu",
            "Julien Epps",
            "Chwee Beng Lee",
            "Eliathamby Ambikairajah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Human-in-the-Loop Efficiency Analysis for Binary Classification in Edyson",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-45",
        "paper_authors": [
            "Per Fallgren",
            "Jens Edlund"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Annotation Confidence vs. Training Sample Size: Trade-Off Solution for Partially-Continuous Categorical Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1636",
        "paper_authors": [
            "Elena Ryumina",
            "Oxana Verkholyak",
            "Alexey Karpov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Europarl-ASR: A Large Corpus of Parliamentary Debates for Streaming ASR Benchmarking and Speech Data Filtering/Verbatimization",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/garcesdiazmunio21_interspeech.html",
        "paper_authors": [
            "Gon\u00e7al V. Garc\u00e9s D\u00edaz-Mun\u00edo",
            "Joan Albert Silvestre-Cerd\u00e0",
            "Javier Jorge",
            "Adri\u00e0 Gim\u00e9nez-Pastor",
            "Javier Iranzo-S\u00e1nchez",
            "Pau Baquero-Arnal",
            "Nahuel Rosell\u00f3",
            "Alejandro P\u00e9rez Gonz\u00e1lez de Martos",
            "Jorge Civera",
            "Albert Sanch\u00eds",
            "Alfons Juan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Automatic Speech to Sign Language Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1094",
        "paper_authors": [
            "Parul Kapoor",
            "Rudrabha Mukhopadhyay",
            "Sindhu B. Hegde",
            "Vinay P. Namboodiri",
            "C. V. Jawahar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "kosp2e: Korean Speech to English Translation Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1040",
        "paper_authors": [
            "Won-Ik Cho",
            "Seok Min Kim",
            "Hyunchang Cho",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "speechocean762: An Open-Source Non-Native English Speech Corpus for Pronunciation Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1259",
        "paper_authors": [
            "Junbo Zhang",
            "Zhiwen Zhang",
            "Yongqing Wang",
            "Zhiyong Yan",
            "Qiong Song",
            "Yukai Huang",
            "Ke Li",
            "Daniel Povey",
            "Yujun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Improved Single Step Non-Autoregressive Transformer for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1955",
        "paper_authors": [
            "Ruchao Fan",
            "Wei Chu",
            "Peng Chang",
            "Jing Xiao",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and Conditional Speaker Chain",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2155",
        "paper_authors": [
            "Pengcheng Guo",
            "Xuankai Chang",
            "Shinji Watanabe",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pushing the Limits of Non-Autoregressive Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-337",
        "paper_authors": [
            "Edwin G. Ng",
            "Chung-Cheng Chiu",
            "Yu Zhang",
            "William Chan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-349",
        "paper_authors": [
            "Alexander H. Liu",
            "Yu-An Chung",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relaxing the Conditional Independence Assumption of CTC-Based ASR by Conditioning on Intermediate Predictions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-911",
        "paper_authors": [
            "Jumon Nozaki",
            "Tatsuya Komatsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Streaming ASR with Non-Autoregressive Insertion-Based Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1131",
        "paper_authors": [
            "Yuya Fujita",
            "Tianzi Wang",
            "Shinji Watanabe",
            "Motoi Omachi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Layer Pruning on Demand with Intermediate CTC",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1171",
        "paper_authors": [
            "Jaesong Lee",
            "Jingu Kang",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time End-to-End Monaural Multi-Speaker Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1449",
        "paper_authors": [
            "Song Li",
            "Beibei Ouyang",
            "Fuchuan Tong",
            "Dexin Liao",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming End-to-End ASR Based on Blockwise Non-Autoregressive Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1556",
        "paper_authors": [
            "Tianzi Wang",
            "Yuya Fujita",
            "Xuankai Chang",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TalkNet: Non-Autoregressive Depth-Wise Separable Convolutional Model for Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1770",
        "paper_authors": [
            "Stanislav Beliaev",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1897",
        "paper_authors": [
            "Nanxin Chen",
            "Yu Zhang",
            "Heiga Zen",
            "Ron J. Weiss",
            "Mohammad Norouzi",
            "Najim Dehak",
            "William Chan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Align-Denoise: Single-Pass Non-Autoregressive Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1906",
        "paper_authors": [
            "Nanxin Chen",
            "Piotr Zelasko",
            "Laureano Moro-Vel\u00e1zquez",
            "Jes\u00fas Villalba",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VAENAR-TTS: Variational Auto-Encoder Based Non-AutoRegressive Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2121",
        "paper_authors": [
            "Hui Lu",
            "Zhiyong Wu",
            "Xixin Wu",
            "Xu Li",
            "Shiyin Kang",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Cognitive Decline Using Speech Only: The ADReSSo Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1220",
        "paper_authors": [
            "Saturnino Luz",
            "Fasih Haider",
            "Sofia de la Fuente",
            "Davida Fromm",
            "Brian MacWhinney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Influence of the Interviewer on the Automatic Assessment of Alzheimer's Disease in the Context of the ADReSSo Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1589",
        "paper_authors": [
            "Paula Andrea P\u00e9rez-Toro",
            "Sebastian P. Bayerl",
            "Tom\u00e1s Arias-Vergara",
            "Juan Camilo V\u00e1squez-Correa",
            "Philipp Klumpp",
            "Maria Schuster",
            "Elmar N\u00f6th",
            "Juan Rafael Orozco-Arroyave",
            "Korbinian Riedhammer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WavBERT: Exploiting Semantic and Non-Semantic Speech Using Wav2vec and BERT for Dementia Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-332",
        "paper_authors": [
            "Youxiang Zhu",
            "Abdelrahman Obyat",
            "Xiaohui Liang",
            "John A. Batsis",
            "Robert M. Roth"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alzheimer Disease Recognition Using Speech-Based Embeddings From Pre-Trained Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-753",
        "paper_authors": [
            "Lara Gauder",
            "Leonardo Pepino",
            "Luciana Ferrer",
            "Pablo Riera"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparing Acoustic-Based Approaches for Alzheimer's Disease Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-759",
        "paper_authors": [
            "Aparna Balagopalan",
            "Jekaterina Novikova"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alzheimer's Disease Detection from Spontaneous Speech Through Combining Linguistic Complexity and (Dis)Fluency Features with Pretrained Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1415",
        "paper_authors": [
            "Yu Qiao",
            "Xuefeng Yin",
            "Daniel Wiechmann",
            "Elma Kerz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using the Outputs of Different Automatic Speech Recognition Paradigms for Acoustic- and BERT-Based Alzheimer's Dementia Detection Through Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1519",
        "paper_authors": [
            "Yilin Pan",
            "Bahman Mirheidari",
            "Jennifer M. Harris",
            "Jennifer C. Thompson",
            "Matthew Jones",
            "Julie S. Snowden",
            "Daniel Blackburn",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tackling the ADRESSO Challenge 2021: The MUET-RMIT System for Alzheimer's Dementia Recognition from Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1572",
        "paper_authors": [
            "Zafi Sherhan Syed",
            "Muhammad Shehram Shah Syed",
            "Margaret Lech",
            "Elena Pirogova"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alzheimer's Dementia Recognition Using Acoustic, Lexical, Disfluency and Speech Pause Features Robust to Noisy Inputs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1633",
        "paper_authors": [
            "Morteza Rohanian",
            "Julian Hough",
            "Matthew Purver"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection and Assessment of Alzheimer Disease Using Speech and Language Technologies in Low-Resource Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1850",
        "paper_authors": [
            "Raghavendra Pappagari",
            "Jaejin Cho",
            "Sonal Joshi",
            "Laureano Moro-Vel\u00e1zquez",
            "Piotr Zelasko",
            "Jes\u00fas Villalba",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection of Alzheimer's Disease Using Spontaneous Speech Only",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2002",
        "paper_authors": [
            "Jun Chen",
            "Jieping Ye",
            "Fengyi Tang",
            "Jiayu Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modular Multi-Modal Attention Network for Alzheimer's Disease Detection Using Patient Audio and Language Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2024",
        "paper_authors": [
            "Ning Wang",
            "Yupeng Cao",
            "Shuai Hao",
            "Zongru Shao",
            "K. P. Subbalakshmi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Attention Channel Combinator Frontend for End-to-End Multichannel Far-Field Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1190",
        "paper_authors": [
            "Rong Gong",
            "Carl Quillen",
            "Dushyant Sharma",
            "Andrew Goderre",
            "Jos\u00e9 La\u00ednez",
            "Ljubomir Milanovic"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ETLT 2021: Shared Task on Automatic Speech Recognition for Non-Native Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1237",
        "paper_authors": [
            "Roberto Gretter",
            "Marco Matassoni",
            "Daniele Falavigna",
            "A. Misra",
            "Chee Wee Leong",
            "K. Knill",
            "L. Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Age-Invariant Training for End-to-End Child Speech Recognition Using Adversarial Multi-Task Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1241",
        "paper_authors": [
            "Lars Rumberg",
            "Hanna Ehlert",
            "Ulrike L\u00fcdtke",
            "J\u00f6rn Ostermann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to Rank Microphones for Distant Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1315",
        "paper_authors": [
            "Samuele Cornell",
            "Alessio Brutti",
            "Marco Matassoni",
            "Stefano Squartini"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simulating Reading Mistakes for Child Speech Transformer-Based Phone Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2202",
        "paper_authors": [
            "Lucile Gelin",
            "Thomas Pellegrini",
            "Julien Pinquier",
            "Morgane Daniel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alternate Endings: Improving Prosody for Incremental Neural TTS with Predicted Future Text Input",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-275",
        "paper_authors": [
            "Brooke Stephenson",
            "Thomas Hueber",
            "Laurent Girin",
            "Laurent Besacier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Emotional Prototypes in a High Dimensional TTS Latent Space",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1538",
        "paper_authors": [
            "Pol van Rijn",
            "Silvan Mertes",
            "Dominik Schiller",
            "Peter M. C. Harrison",
            "Pauline Larrouy-Maestri",
            "Elisabeth Andr\u00e9",
            "Nori Jacoby"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1583",
        "paper_authors": [
            "Devang S. Ram Mohan",
            "Qinmin Vivian Hu",
            "Tian Huey Teh",
            "Alexandra Torresquintero",
            "Christopher G. R. Wallis",
            "Marlene Staib",
            "Lorenzo Foglianti",
            "Jiameng Gao",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ADEPT: A Dataset for Evaluating Prosody Transfer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1610",
        "paper_authors": [
            "Alexandra Torresquintero",
            "Tian Huey Teh",
            "Christopher G. R. Wallis",
            "Marlene Staib",
            "Devang S. Ram Mohan",
            "Vivian Hu",
            "Lorenzo Foglianti",
            "Jiameng Gao",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosodic Boundary Prediction Model for Vietnamese Text-To-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-125",
        "paper_authors": [
            "Thi Thu Trang Nguyen",
            "Nguyen Hoang Ky",
            "Albert Rilliard",
            "Christophe d'Alessandro"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Many-Speakers Single Channel Speech Separation with Optimal Permutation Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-493",
        "paper_authors": [
            "Shaked Dovrat",
            "Eliya Nachmani",
            "Lior Wolf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Combating Reverberation in NTF-Based Speech Separation Using a Sub-Source Weighted Multichannel Wiener Filter and Linear Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1230",
        "paper_authors": [
            "Mieszko Fras",
            "Marcin Witkowski",
            "Konrad Kowalczyk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Hands-On Comparison of DNNs for Dialog Separation Using Transfer Learning from Music Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1418",
        "paper_authors": [
            "Martin Strauss",
            "Jouni Paulus",
            "Matteo Torcoli",
            "Bernd Edler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GlobalPhone Mix-To-Separate Out of 2: A Multilingual 2000 Speakers Mixtures Database for Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1552",
        "paper_authors": [
            "Marvin Borsdorf",
            "Chenglin Xu",
            "Haizhou Li",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Linguistic Perception of the Japanese Singleton/Geminate Contrast: Korean, Mandarin and Mongolian Compared",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-21",
        "paper_authors": [
            "Kimiko Tsukada",
            "Yu Rong",
            "Joo-Yeon Kim",
            "Jeong-Im Han",
            "John Hajek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detection of Lexical Stress Errors in Non-Native (L2) English with Data Augmentation and Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-86",
        "paper_authors": [
            "Daniel Korzekwa",
            "Roberto Barra-Chicote",
            "Szymon Zaporowski",
            "Grzegorz Beringer",
            "Jaime Lorenzo-Trueba",
            "Alicja Serafinowicz",
            "Jasha Droppo",
            "Thomas Drugman",
            "Bozena Kostek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Testing Acoustic Voice Quality Classification Across Languages and Speech Styles",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-315",
        "paper_authors": [
            "Bettina Braun",
            "Nicole Deh\u00e9",
            "Marieke Einfeldt",
            "Daniela Wochner",
            "Katharina Zahner-Ritter"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acquisition of Prosodic Focus Marking by Three- to Six-Year-Old Children Learning Mandarin Chinese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-316",
        "paper_authors": [
            "Qianyutong Zhang",
            "Kexin Lyu",
            "Zening Chen",
            "Ping Tang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Listening Difficulty Detection for L2 Learners Through Moderating ASR Resources",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-372",
        "paper_authors": [
            "Maryam Sadat Mirzaei",
            "Kourosh Meshgi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "F0 Patterns of L2 English Speech by Mandarin Chinese Learners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-581",
        "paper_authors": [
            "Hongwei Ding",
            "Binghuai Lin",
            "Liyuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Neural Network-Based Noise Compensation Method for Pronunciation Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-843",
        "paper_authors": [
            "Binghuai Lin",
            "Liyuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic Distance and Surprisal in Multilingual Priming: Evidence from Slavic",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1003",
        "paper_authors": [
            "Jacek Kudera",
            "Philip Georgis",
            "Bernd M\u00f6bius",
            "Tania Avgustinova",
            "Dietrich Klakow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Preliminary Study on Discourse Prosody Encoding in L1 and L2 English Spontaneous Narratives",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1082",
        "paper_authors": [
            "Yuqing Zhang",
            "Zhu Li",
            "Binghuai Lin",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer Based End-to-End Mispronunciation Detection and Diagnosis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1467",
        "paper_authors": [
            "Minglin Wu",
            "Kun Li",
            "Wai-Kim Leung",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "L1 Identification from L2 Speech Using Neural Spectrogram Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1545",
        "paper_authors": [
            "Calbert Graham"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Real-Time MRI for Illuminating Linguistic Velum Action",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1823",
        "paper_authors": [
            "Miran Oh",
            "Dani Byrd",
            "Shrikanth S. Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Segmental Alignment of English Syllables with Singleton and Cluster Onsets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-187",
        "paper_authors": [
            "Zirui Liu",
            "Yi Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploration of Welsh English Pre-Aspiration: How Wide-Spread is it?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-685",
        "paper_authors": [
            "M\u00edsa Hejn\u00e1"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revisiting Recall Effects of Filler Particles in German and English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1056",
        "paper_authors": [
            "Beeke Muhlack",
            "Mikey Elmers",
            "Heiner Drenhaus",
            "J\u00fcrgen Trouvain",
            "Marjolein van Os",
            "Raphael Werner",
            "Margarita Ryzhova",
            "Bernd M\u00f6bius"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1122",
        "paper_authors": [
            "Chunyu Ge",
            "Yixuan Xiong",
            "Peggy Mok"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Cross-Dialectal Comparison of Apical Vowels in Beijing Mandarin, Northeastern Mandarin and Southwestern Mandarin: An EMA and Ultrasound Study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1326",
        "paper_authors": [
            "Jing Huang",
            "Feng-fan Hsieh",
            "Yueh-Chin Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dissecting the Aero-Acoustic Parameters of Open Articulatory Transitions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1379",
        "paper_authors": [
            "Mark Gibson",
            "Oihane Muxika",
            "Marianne Pouplier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Quantifying Vocal Tract Shape Variation and its Acoustic Impact: A Geometric Morphometric Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1400",
        "paper_authors": [
            "Amelia Jane Gully"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Perception and Loanword Adaptations: The Case of Copy-Vowel Epenthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1481",
        "paper_authors": [
            "Adriana Guevara-Rukoz",
            "Shi Yu",
            "Sharon Peperkamp"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speakers Coarticulate Less When Facing Real and Imagined Communicative Difficulties: An Analysis of Read and Spontaneous Speech from the LUCID Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1640",
        "paper_authors": [
            "Zhe-chen Guo",
            "Rajka Smiljanic"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Developmental Changes of Vowel Acoustics in Adolescents",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1649",
        "paper_authors": [
            "Einar Meister",
            "Lya Meister"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Context and Co-Text Influence on the Accuracy Production of Italian L2 Non-Native Sounds",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1724",
        "paper_authors": [
            "Sonia D'Apolito",
            "Barbara Gili Fivela"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A New Vowel Normalization for Sociophonetics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1846",
        "paper_authors": [
            "Wilbert Heeringa",
            "Hans Van de Velde"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Pacific Expansion: Optimizing Phonetic Transcription of Archival Corpora",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2167",
        "paper_authors": [
            "Rosey Billington",
            "Hywel Stoakes",
            "Nick Thieberger"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FSR: Accelerating the Inference Process of Transducer-Based Models by Applying Fast-Skip Regularization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1367",
        "paper_authors": [
            "Zhengkun Tian",
            "Jiangyan Yi",
            "Ye Bai",
            "Jianhua Tao",
            "Shuai Zhang",
            "Zhengqi Wen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LT-LM: A Novel Non-Autoregressive Language Model for Single-Shot Lattice Rescoring",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1716",
        "paper_authors": [
            "Anton Mitrofanov",
            "Mariya Korenevskaya",
            "Ivan Podluzhny",
            "Yuri Y. Khokhlov",
            "Aleksandr Laptev",
            "Andrei Andrusenko",
            "Aleksei Ilin",
            "Maxim Korenevsky",
            "Ivan Medennikov",
            "Aleksei Romanenko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Hybrid Seq-2-Seq ASR Design for On-Device and Server Applications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-658",
        "paper_authors": [
            "Cyril Allauzen",
            "Ehsan Variani",
            "Michael Riley",
            "David Rybach",
            "Hao Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VAD-Free Streaming Hybrid CTC/Attention ASR for Unsegmented Recording",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1107",
        "paper_authors": [
            "Hirofumi Inaguma",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WeNet: Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1983",
        "paper_authors": [
            "Zhuoyuan Yao",
            "Di Wu",
            "Xiong Wang",
            "Binbin Zhang",
            "Fan Yu",
            "Chao Yang",
            "Zhendong Peng",
            "Xiaoyu Chen",
            "Lei Xie",
            "Xin Lei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Modal Transformer-Based Neural Correction Models for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1992",
        "paper_authors": [
            "Tomohiro Tanaka",
            "Ryo Masumura",
            "Mana Ihori",
            "Akihiko Takashima",
            "Takafumi Moriya",
            "Takanori Ashihara",
            "Shota Orihashi",
            "Naoki Makishima"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Neural Network Calibration for E2E Speech Recognition System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-176",
        "paper_authors": [
            "Mun-Hak Lee",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Residual Energy-Based Models for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-690",
        "paper_authors": [
            "Qiujia Li",
            "Yu Zhang",
            "Bo Li",
            "Liangliang Cao",
            "Philip C. Woodland"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1207",
        "paper_authors": [
            "David Qiu",
            "Yanzhang He",
            "Qiujia Li",
            "Yu Zhang",
            "Liangliang Cao",
            "Ian McGraw"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Insights on Neural Representations for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1516",
        "paper_authors": [
            "Anna Ollerenshaw",
            "Md. Asif Jalal",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sequence-Level Confidence Classifier for ASR Utterance Accuracy and Application to Acoustic Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1666",
        "paper_authors": [
            "Amber Afshan",
            "Kshitiz Kumar",
            "Jian Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Learning of Disentangled Speech Content and Style Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1936",
        "paper_authors": [
            "Andros Tjandra",
            "Ruoming Pang",
            "Yu Zhang",
            "Shigeki Karita"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Label Embedding for Chinese Grapheme-to-Phoneme Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-885",
        "paper_authors": [
            "Eunbi Choi",
            "Hwa-Yeon Kim",
            "Jong-Hwan Kim",
            "Jae-Min Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PDF: Polyphone Disambiguation in Chinese by Using FLAT",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1087",
        "paper_authors": [
            "Haiteng Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Polyphone Disambiguation for Mandarin Chinese by Combining Mix-Pooling Strategy and Window-Based Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1232",
        "paper_authors": [
            "Junjie Li",
            "Zhiyu Zhang",
            "Minchuan Chen",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Polyphone Disambiguation in Mandarin Chinese with Semi-Supervised Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-502",
        "paper_authors": [
            "Yi Shi",
            "Congyi Wang",
            "Yu Chen",
            "Bin Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Neural-Network-Based Approach to Identifying Speakers in Novels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-609",
        "paper_authors": [
            "Yue Chen",
            "Zhen-Hua Ling",
            "Qing-Feng Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UnitNet-Based Hybrid Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1092",
        "paper_authors": [
            "Xiao Zhou",
            "Zhen-Hua Ling",
            "Li-Rong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamically Adaptive Machine Speech Chain Inference for TTS in Noisy Environment: Listen and Speak Louder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-946",
        "paper_authors": [
            "Sashi Novitasari",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LinearSpeech: Parallel Text-to-Speech with Linear Complexity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1192",
        "paper_authors": [
            "Haozhe Zhang",
            "Zhihua Huang",
            "Zengqiang Shang",
            "Pengyuan Zhang",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Agent for Competing with Humans in a Deceptive Game Based on Vocal Cues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-83",
        "paper_authors": [
            "Noa Mansbach",
            "Evgeny Hershkovitch Neiterman",
            "Amos Azaria"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-Branch Deep Learning Network for Automated Detection of COVID-19",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-378",
        "paper_authors": [
            "Ahmed Fakhry",
            "Xinyi Jiang",
            "Jaclyn Xiao",
            "Gunvant Chaudhari",
            "Asriel Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RW-Resnet: A Novel Speech Anti-Spoofing Model Using Raw Waveform",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-438",
        "paper_authors": [
            "Youxuan Ma",
            "Zongze Ren",
            "Shugong Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fake Audio Detection in Resource-Constrained Settings Using Microfeatures",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-524",
        "paper_authors": [
            "Hira Dhamyal",
            "Ayesha Ali",
            "Ihsan Ayyub Qazi",
            "Agha Ali Raza"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coughing-Based Recognition of Covid-19 with Spatial Attentive ConvLSTM Recurrent Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-630",
        "paper_authors": [
            "Tianhao Yan",
            "Hao Meng",
            "Emilia Parada-Cabaleiro",
            "Shuo Liu",
            "Meishu Song",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation for Singing Voice Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-636",
        "paper_authors": [
            "Soumava Paul",
            "Gurunath Reddy M",
            "K. Sreenivasa Rao",
            "Partha Pratim Das"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Age Estimation with Speech-Age Model for Heterogeneous Speech Datasets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-861",
        "paper_authors": [
            "Ryu Takeda",
            "Kazunori Komatani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Open-Set Audio Classification with Limited Training Resources Based on Augmentation Enhanced Variational Auto-Encoder GAN with Detection-Classification Joint Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1142",
        "paper_authors": [
            "Kah Kuan Teh",
            "Huy Dat Tran"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Spectral-Cepstral Fusion for Shouted and Normal Speech Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1245",
        "paper_authors": [
            "Takahiro Fukumori"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection of Shouted Speech Segments in Indian News Debates",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1592",
        "paper_authors": [
            "Shikha Baghel",
            "Mrinmoy Bhattacharjee",
            "S. R. Mahadeva Prasanna",
            "Prithwijit Guha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Spoofing Detection Inspired from Audio Generation Artifacts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1705",
        "paper_authors": [
            "Yang Gao",
            "Tyler Vuong",
            "Mahsa Elyasi",
            "Gaurav Bharaj",
            "Rita Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Overlapped Speech Detection Based on Spectral and Spatial Feature Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2138",
        "paper_authors": [
            "Weiguang Chen",
            "Van Tung Pham",
            "Eng Siong Chng",
            "Xionghu Zhong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Do Acoustic Word Embeddings Capture Phonological Similarity? An Empirical Study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-678",
        "paper_authors": [
            "Badr M. Abdullah",
            "Marius Mosbach",
            "Iuliia Zaitova",
            "Bernd M\u00f6bius",
            "Dietrich Klakow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Paraphrase Label Alignment for Voice Application Retrieval in Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-97",
        "paper_authors": [
            "Zheng Gao",
            "Radhika Arava",
            "Qian Hu",
            "Xibin Gao",
            "Thahir Mohamed",
            "Wei Xiao",
            "Mohamed Abdelhady"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Personalized Keyphrase Detection Using Speaker and Environment Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-204",
        "paper_authors": [
            "Rajeev Rikhye",
            "Quan Wang",
            "Qiao Liang",
            "Yanzhang He",
            "Ding Zhao",
            "Yiteng Huang",
            "Arun Narayanan",
            "Ian McGraw"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Transformer for Hardware Efficient Voice Trigger Detection and False Trigger Mitigation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1428",
        "paper_authors": [
            "Vineet Garg",
            "Wonil Chang",
            "Siddharth Sigtia",
            "Saurabh Adya",
            "Pramod Simha",
            "Pranay Dighe",
            "Chandra Dhir"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Few-Shot Keyword Spotting in Any Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1966",
        "paper_authors": [
            "Mark Mazumder",
            "Colby R. Banbury",
            "Josh Meyer",
            "Pete Warden",
            "Vijay Janapa Reddi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text Anchor Based Metric Learning for Small-Footprint Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-136",
        "paper_authors": [
            "Li Wang",
            "Rongzhi Gu",
            "Nuo Chen",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Meta-Learning Approach for User-Defined Spoken Term Classification with Varying Classes and Examples",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-147",
        "paper_authors": [
            "Yangbin Chen",
            "Tom Ko",
            "Jianping Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Auxiliary Sequence Labeling Tasks for Disfluency Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-400",
        "paper_authors": [
            "Dongyub Lee",
            "Byeongil Ko",
            "Myeongcheol Shin",
            "Taesun Whang",
            "Daniel Lee",
            "Eun Hwa Kim",
            "EungGyun Kim",
            "Jaechoon Jo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Energy-Friendly Keyword Spotting System Using Add-Based Convolution",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-458",
        "paper_authors": [
            "Hang Zhou",
            "Wenchao Hu",
            "Yu Ting Yeung",
            "Xiao Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The 2020 Personalized Voice Trigger Challenge: Open Datasets, Evaluation Metrics, Baseline System and Results",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-602",
        "paper_authors": [
            "Yan Jia",
            "Xingming Wang",
            "Xiaoyi Qin",
            "Yinping Zhang",
            "Xuyang Wang",
            "Junjie Wang",
            "Dong Zhang",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Auto-KWS 2021 Challenge: Task, Datasets, and Baselines",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-817",
        "paper_authors": [
            "Jingsong Wang",
            "Yuxuan He",
            "Chunyu Zhao",
            "Qijie Shao",
            "Wei-Wei Tu",
            "Tom Ko",
            "Hung-yi Lee",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Keyword Transformer: A Self-Attention Model for Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1286",
        "paper_authors": [
            "Axel Berg",
            "Mark O'Connor",
            "Miguel Tairum Cruz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Teaching Keyword Spotters to Spot New Keywords with Limited Examples",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1395",
        "paper_authors": [
            "Abhijeet Awasthi",
            "Kevin Kilgour",
            "Hassan Rom"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-702",
        "paper_authors": [
            "Xin Wang",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Initial Investigation for Detecting Partially Spoofed Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-738",
        "paper_authors": [
            "Lin Zhang",
            "Xin Wang",
            "Erica Cooper",
            "Junichi Yamagishi",
            "Jose Patino",
            "Nicholas W. D. Evans"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Siamese Network with wav2vec Feature for Spoofing Speech Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-847",
        "paper_authors": [
            "Yang Xie",
            "Zhenchuan Zhang",
            "Yingchun Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Database Replay Detection in Terminal-Dependent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-960",
        "paper_authors": [
            "Xingliang Cheng",
            "Mingxing Xu",
            "Thomas Fang Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Effect of Silence and Dual-Band Fusion in Anti-Spoofing System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1281",
        "paper_authors": [
            "Yuxiang Zhang",
            "Wenchao Wang",
            "Pengyuan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pairing Weak with Strong: Twin Models for Defending Against Adversarial Attack on Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1343",
        "paper_authors": [
            "Zhiyuan Peng",
            "Xu Li",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention-Based Convolutional Neural Network for ASV Spoofing Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1404",
        "paper_authors": [
            "Hefei Ling",
            "Leichao Huang",
            "Junrui Huang",
            "Baiyan Zhang",
            "Ping Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voting for the Right Answer: Adversarial Defense for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1452",
        "paper_authors": [
            "Haibin Wu",
            "Yang Zhang",
            "Zhiyong Wu",
            "Dong Wang",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1522",
        "paper_authors": [
            "Tomi Kinnunen",
            "Andreas Nautsch",
            "Md. Sahidullah",
            "Nicholas W. D. Evans",
            "Xin Wang",
            "Massimiliano Todisco",
            "H\u00e9ctor Delgado",
            "Junichi Yamagishi",
            "Kong Aik Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Representation Learning to Classify and Detect Adversarial Attacks Against Speaker and Speech Recognition Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1759",
        "paper_authors": [
            "Jes\u00fas Villalba",
            "Sonal Joshi",
            "Piotr Zelasko",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Empirical Study on Channel Effects for Synthetic Voice Spoofing Countermeasure Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1820",
        "paper_authors": [
            "You Zhang",
            "Ge Zhu",
            "Fei Jiang",
            "Zhiyao Duan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Channel-Wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2125",
        "paper_authors": [
            "Xu Li",
            "Xixin Wu",
            "Hui Lu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Partially-Connected Differentiable Architecture Search for Deepfake and Spoofing Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1187",
        "paper_authors": [
            "Wanying Ge",
            "Michele Panariello",
            "Jose Patino",
            "Massimiliano Todisco",
            "Nicholas W. D. Evans"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OpenASR20: An Open Challenge for Automatic Speech Recognition of Conversational Telephone Speech in Low-Resource Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1930",
        "paper_authors": [
            "Kay Peterson",
            "Audrey Tong",
            "Yan Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multitask Adaptation with Lattice-Free MMI for Multi-Genre Speech Recognition of Low Resource Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1778",
        "paper_authors": [
            "Srikanth R. Madikeri",
            "Petr Motl\u00edcek",
            "Herv\u00e9 Bourlard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Improved Wav2Vec 2.0 Pre-Training Approach Using Enhanced Local Dependency Modeling for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-67",
        "paper_authors": [
            "Qiu-Shi Zhu",
            "Jie Zhang",
            "Ming-Hui Wu",
            "Xin Fang",
            "Li-Rong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Systems for Low-Resource Speech Recognition Tasks in Open Automatic Speech Recognition and Formosa Speech Recognition Challenges",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-358",
        "paper_authors": [
            "Hung-Pang Lin",
            "Yu-Jia Zhang",
            "Chia-Ping Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The TNT Team System Descriptions of Cantonese and Mongolian for IARPA OpenASR20",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1063",
        "paper_authors": [
            "Jing Zhao",
            "Zhiqiang Lv",
            "Ambyera Han",
            "Guan-Bo Wang",
            "Gui-Xin Shi",
            "Jian Kang",
            "Jinghao Yan",
            "Pengfei Hu",
            "Shen Huang",
            "Weiqiang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Combining Hybrid and End-to-End Approaches for the OpenASR20 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1086",
        "paper_authors": [
            "Tanel Alum\u00e4e",
            "Jiaming Kong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One Size Does Not Fit All in Resource-Constrained ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1970",
        "paper_authors": [
            "Ethan Morris",
            "Robbie Jimerson",
            "Emily Prud'hommeaux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Child Language Acquisition Studied with Wearables",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/cristia21_interspeech.html",
        "paper_authors": [
            "Alejandrina Cristi\u00e0"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language Modeling and Artificial Intelligence",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/mikolov21_interspeech.html",
        "paper_authors": [
            "Tom\u00e1s Mikolov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Representation Learning for Speech Activity Detection in the Fearless Steps Challenge 2021",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-309",
        "paper_authors": [
            "Pablo Gimeno",
            "Alfonso Ortega Gim\u00e9nez",
            "Antonio Miguel",
            "Eduardo Lleida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Application of Learnable STRF Kernels to the 2021 Fearless Steps Phase-03 SAD Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-651",
        "paper_authors": [
            "Tyler Vuong",
            "Yangyang Xia",
            "Richard M. Stern"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Activity Detection Based on Multilingual Speech Recognition System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1058",
        "paper_authors": [
            "Seyyed Saeed Sarfjoo",
            "Srikanth R. Madikeri",
            "Petr Motl\u00edcek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Activity Detection with Teacher-Student Domain Emulation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1234",
        "paper_authors": [
            "Jarrod Luckenbaugh",
            "Samuel Abplanalp",
            "Rachel Gonzalez",
            "Daniel Fulford",
            "David Gard",
            "Carlos Busso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EML Online Speech Activity Detection for the Fearless Steps Challenge Phase-III",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1456",
        "paper_authors": [
            "Omid Ghahabi",
            "Volker Fischer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Device Playback Augmentation with Echo Cancellation for Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1316",
        "paper_authors": [
            "Kuba Lopatka",
            "Katarzyna Kaszuba-Miotke",
            "Piotr Klinke",
            "Pawel Trella"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Open Vocabulary Keyword Search",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1399",
        "paper_authors": [
            "Bolaji Yusuf",
            "Alican G\u00f6k",
            "Batuhan G\u00fcndogdu",
            "Murat Saraclar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantic Sentence Similarity: Size does not Always Matter",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1464",
        "paper_authors": [
            "Danny Merkx",
            "Stefan L. Frank",
            "Mirjam Ernestus"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoken Term Detection and Relevance Score Estimation Using Dot-Product of Pronunciation Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1704",
        "paper_authors": [
            "Jan Svec",
            "Lubos Sm\u00eddl",
            "Josef V. Psutka",
            "Ales Praz\u00e1k"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Genre Adapted Closed Captioning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1762",
        "paper_authors": [
            "Fran\u00e7ois Buet",
            "Fran\u00e7ois Yvon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly-Supervised Word-Level Pronunciation Error Detection in Non-Native English Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-38",
        "paper_authors": [
            "Daniel Korzekwa",
            "Jaime Lorenzo-Trueba",
            "Thomas Drugman",
            "Shira Calamaro",
            "Bozena Kostek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Speaker-Attributed ASR with Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-101",
        "paper_authors": [
            "Naoyuki Kanda",
            "Guoli Ye",
            "Yashesh Gaur",
            "Xiaofei Wang",
            "Zhong Meng",
            "Zhuo Chen",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding Medical Conversations: Rich Transcription, Confidence Scores & Information Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-691",
        "paper_authors": [
            "Hagen Soltau",
            "Mingqiu Wang",
            "Izhak Shafran",
            "Laurent El Shafey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phone-Level Pronunciation Scoring for Spanish Speakers Learning English Using a GOP-DNN System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-745",
        "paper_authors": [
            "Jazm\u00edn Vidal",
            "Cyntia Bonomi",
            "Marcelo Sancinetti",
            "Luciana Ferrer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Explore wav2vec 2.0 for Mispronunciation Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-777",
        "paper_authors": [
            "Xiaoshuo Xu",
            "Yueteng Kang",
            "Songjun Cao",
            "Binghuai Lin",
            "Long Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lexical Density Analysis of Word Productions in Japanese English Using Acoustic Word Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-853",
        "paper_authors": [
            "Shintaro Ando",
            "Nobuaki Minematsu",
            "Daisuke Saito"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Feature Transfer Learning for Automatic Pronunciation Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-931",
        "paper_authors": [
            "Binghuai Lin",
            "Liyuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multilingual Speech Evaluation: Case Studies on English, Malay and Tamil",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1258",
        "paper_authors": [
            "Huayun Zhang",
            "Ke Shi",
            "Nancy F. Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Study on Fine-Tuning wav2vec2.0 Model for the Task of Mispronunciation Detection and Diagnosis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1344",
        "paper_authors": [
            "Linkai Peng",
            "Kaiqi Fu",
            "Binghuai Lin",
            "Dengfeng Ke",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Impact of ASR on the Automatic Analysis of Linguistic Complexity and Sophistication in Spontaneous L2 Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1402",
        "paper_authors": [
            "Yu Qiao",
            "Wei Zhou",
            "Elma Kerz",
            "Ralf Schl\u00fcter"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Rich Transcription-Style Automatic Speech Recognition with Semi-Supervised Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1981",
        "paper_authors": [
            "Tomohiro Tanaka",
            "Ryo Masumura",
            "Mana Ihori",
            "Akihiko Takashima",
            "Shota Orihashi",
            "Naoki Makishima"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "\"You don't understand me!\": Comparing ASR Results for L1 and L2 Speakers of Swedish",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2140",
        "paper_authors": [
            "Ronald Cumbal",
            "Birger Mo\u00ebll",
            "Jos\u00e9 Lopes",
            "Olov Engwall"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NeMo Inverse Text Normalization: From Development to Production",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1571",
        "paper_authors": [
            "Yang Zhang",
            "Evelina Bakhturina",
            "Kyle Gorman",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improvement of Automatic English Pronunciation Assessment with Small Number of Utterances Using Sentence Speakability",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1132",
        "paper_authors": [
            "Satsuki Naijo",
            "Akinori Ito",
            "Takashi Nose"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Affect Recognition Through Scalogram and Multi-Resolution Cochleagram Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1761",
        "paper_authors": [
            "Fasih Haider",
            "Saturnino Luz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Speech Emotion Recognition Framework for Better Discrimination of Confusions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-718",
        "paper_authors": [
            "Jiawang Liu",
            "Haoxiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion Recognition via Multi-Level Cross-Modal Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-785",
        "paper_authors": [
            "Ruichen Li",
            "Jinming Zhao",
            "Qin Jin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Speech Emotion Recognition by Disentangling Emotion and Identity Attributes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-809",
        "paper_authors": [
            "Koichiro Ito",
            "Takuya Fujioka",
            "Qinghua Sun",
            "Kenji Nagamatsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parametric Distributions to Model Numerical Emotion Labels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1000",
        "paper_authors": [
            "Deboshree Bose",
            "Vidhyasaharan Sethu",
            "Eliathamby Ambikairajah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Metric Learning Based Feature Representation with Gated Fusion Model for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1133",
        "paper_authors": [
            "Yuan Gao",
            "Jiaxing Liu",
            "Longbiao Wang",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion Recognition with Multi-Task Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1852",
        "paper_authors": [
            "Xingyu Cai",
            "Jiahong Yuan",
            "Renjie Zheng",
            "Liang Huang",
            "Kenneth Church"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Dilated CNN Models for Depression Detection Using Inverted Vocal Tract Variables",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1960",
        "paper_authors": [
            "Nadee Seneviratne",
            "Carol Y. Espy-Wilson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Mutual Correlation in Multimodal Transformer for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2004",
        "paper_authors": [
            "Yuhua Wang",
            "Guang Shen",
            "Yuezhu Xu",
            "Jiahang Li",
            "Zhengdao Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Time-Frequency Representation Learning with Graph Convolutional Network for Dialogue-Level Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2067",
        "paper_authors": [
            "Jiaxing Liu",
            "Yaodong Song",
            "Longbiao Wang",
            "Jianwu Dang",
            "Ruiguo Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Compressing 1D Time-Channel Separable Convolutions Using Sparse Random Ternary Matrices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-141",
        "paper_authors": [
            "Gon\u00e7alo Mordido",
            "Matthijs Van Keirsbilck",
            "Alexander Keller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly Supervised Construction of ASR Systems from Massive Video Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-7",
        "paper_authors": [
            "Mengli Cheng",
            "Chengyu Wang",
            "Jun Huang",
            "Xiaobo Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Broadcasted Residual Learning for Efficient Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-383",
        "paper_authors": [
            "Byeonggeun Kim",
            "Simyung Chang",
            "Jinkyu Lee",
            "Dooyong Sung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CoDERT: Distilling Encoder Representations with Co-Learning for Transducer-Based Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-797",
        "paper_authors": [
            "Rupak Vignesh Swaminathan",
            "Brian John King",
            "Grant P. Strimel",
            "Jasha Droppo",
            "Athanasios Mouchtaris"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extremely Low Footprint End-to-End ASR System for Smart Device",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-819",
        "paper_authors": [
            "Zhifu Gao",
            "Yiwu Yao",
            "Shiliang Zhang",
            "Jun Yang",
            "Ming Lei",
            "Ian McLoughlin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dissecting User-Perceived Latency of On-Device E2E Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1887",
        "paper_authors": [
            "Yuan Shangguan",
            "Rohit Prabhavalkar",
            "Hang Su",
            "Jay Mahadeokar",
            "Yangyang Shi",
            "Jiatong Zhou",
            "Chunyang Wu",
            "Duc Le",
            "Ozlem Kalinli",
            "Christian Fuegen",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Amortized Neural Networks for Low-Latency Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-712",
        "paper_authors": [
            "Jonathan Macoskey",
            "Grant P. Strimel",
            "Jinru Su",
            "Ariya Rastrow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tied & Reduced RNN-T Decoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-212",
        "paper_authors": [
            "Rami Botros",
            "Tara N. Sainath",
            "Robert David",
            "Emmanuel Guzman",
            "Wei Li",
            "Yanzhang He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PQK: Model Compression via Pruning, Quantization, and Knowledge Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-248",
        "paper_authors": [
            "Jangho Kim",
            "Simyung Chang",
            "Nojun Kwak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Collaborative Training of Acoustic Encoders for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-354",
        "paper_authors": [
            "Varun Nagaraja",
            "Yangyang Shi",
            "Ganesh Venkatesh",
            "Ozlem Kalinli",
            "Michael L. Seltzer",
            "Vikas Chandra"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Conformer with Prob-Sparse Attention Mechanism for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-415",
        "paper_authors": [
            "Xiong Wang",
            "Sining Sun",
            "Lei Xie",
            "Long Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Energy and Carbon Footprint of Training End-to-End Speech Recognizers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-456",
        "paper_authors": [
            "Titouan Parcollet",
            "Mirco Ravanelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph-Based Label Propagation for Semi-Supervised Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1209",
        "paper_authors": [
            "Long Chen",
            "Venkatesh Ravichandran",
            "Andreas Stolcke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fusion of Embeddings Networks for Robust Combination of Text Dependent and Independent Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-3",
        "paper_authors": [
            "Ruirui Li",
            "Chelsea J.-T. Ju",
            "Zeya Chen",
            "Hongda Mao",
            "Oguz Elibol",
            "Andreas Stolcke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Generative Model for Duration-Dependent Score Calibration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-114",
        "paper_authors": [
            "Sandro Cumani",
            "Salvatore Sarni"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-641",
        "paper_authors": [
            "Jason Pelecanos",
            "Quan Wang",
            "Ignacio L\u00f3pez-Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Channel Speaker Verification for Single and Multi-Talker Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-681",
        "paper_authors": [
            "Saurabh Kataria",
            "Shi-Xiong Zhang",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Chronological Self-Training for Real-Time Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-822",
        "paper_authors": [
            "Dirk Padfield",
            "Daniel J. Liebling"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Margin Circle Loss for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1043",
        "paper_authors": [
            "Runqiu Xiao",
            "Xiaoxiao Miao",
            "Wenchao Wang",
            "Pengyuan Zhang",
            "Bin Cai",
            "Liuping Luo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Presentation Matters: Evaluating Speaker Identification Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1211",
        "paper_authors": [
            "Benjamin O'Brien",
            "Christine Meunier",
            "Alain Ghio"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Error Correction for Speaker Embedding Learning with Noisy Labels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2021",
        "paper_authors": [
            "Fuchuan Tong",
            "Yan Liu",
            "Song Li",
            "Jie Wang",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Integrated Framework for Two-Pass Personalized Voice Trigger",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2161",
        "paper_authors": [
            "Dexin Liao",
            "Jing Li",
            "Yiming Zhi",
            "Song Li",
            "Qingyang Hong",
            "Lin Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Masked Proxy Loss for Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2190",
        "paper_authors": [
            "Jiachen Lian",
            "Aiswarya Vinod Kumar",
            "Hira Dhamyal",
            "Bhiksha Raj",
            "Rita Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "STYLER: Style Factor Modeling with Rapidity and Robustness via Speech Decomposition for Expressive and Controllable Neural Text to Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-838",
        "paper_authors": [
            "Keon Lee",
            "Kyumin Park",
            "Daeyoung Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reinforcement Learning for Emotional Text-to-Speech Synthesis with Improved Emotion Discriminability",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1236",
        "paper_authors": [
            "Rui Liu",
            "Berrak Sisman",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emotional Prosody Control for Speech Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-307",
        "paper_authors": [
            "Sarath Sivaprasad",
            "Saiteja Kosgi",
            "Vineet Gandhi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Controllable Context-Aware Conversational Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-412",
        "paper_authors": [
            "Jian Cong",
            "Shan Yang",
            "Na Hu",
            "Guangzhi Li",
            "Lei Xie",
            "Dan Su"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Expressive Text-to-Speech Using Style Tag",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-465",
        "paper_authors": [
            "Minchan Kim",
            "Sung Jun Cheon",
            "Byoung Jin Choi",
            "Jong Jin Kim",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Text to Speech for Spontaneous Style",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-584",
        "paper_authors": [
            "Yuzi Yan",
            "Xu Tan",
            "Bohan Li",
            "Guangyan Zhang",
            "Tao Qin",
            "Sheng Zhao",
            "Yuan Shen",
            "Wei-Qiang Zhang",
            "Tie-Yan Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Multi-Scale Style Control for Expressive Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-947",
        "paper_authors": [
            "Xiang Li",
            "Changhe Song",
            "Jingbei Li",
            "Zhiyong Wu",
            "Jia Jia",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Speaker Style Transfer with Prosody Bottleneck in Neural Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-979",
        "paper_authors": [
            "Shifeng Pan",
            "Lei He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fine-Grained Style Modeling, Transfer and Prediction in Text-to-Speech Synthesis via Phone-Level Content-Style Disentanglement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1129",
        "paper_authors": [
            "Daxin Tan",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Performance of Seen and Unseen Speech Style Transfer in End-to-End Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1407",
        "paper_authors": [
            "Xiaochun An",
            "Frank K. Soong",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Synthesis of Expressive Speaking Styles with Limited Training Data in a Multi-Speaker, Prosody-Controllable Sequence-to-Sequence Architecture",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1446",
        "paper_authors": [
            "Slava Shechtman",
            "Raul Fernandez",
            "Alexander Sorin",
            "David Haws"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intent Detection and Slot Filling for Vietnamese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-618",
        "paper_authors": [
            "Mai Hoang Dao",
            "Thinh Hung Truong",
            "Dat Quoc Nguyen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Augmenting Slot Values and Contexts for Spoken Language Understanding with Pretrained Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-55",
        "paper_authors": [
            "Haitao Lin",
            "Lu Xiang",
            "Yu Zhou",
            "Jiajun Zhang",
            "Chengqing Zong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Impact of Intent Distribution Mismatch on Semi-Supervised Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-335",
        "paper_authors": [
            "Judith Gaspers",
            "Quynh Do",
            "Daniil Sorokin",
            "Patrick Lehnen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation from BERT Transformer to Speech Transformer for Intent Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-402",
        "paper_authors": [
            "Yidi Jiang",
            "Bidisha Sharma",
            "Maulik C. Madhavi",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Three-Module Modeling For End-to-End Spoken Language Understanding Using Pre-Trained DNN-HMM-Based Acoustic-Phonetic Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-501",
        "paper_authors": [
            "Nick J. C. Wang",
            "Lu Wang",
            "Yandan Sun",
            "Haimei Kang",
            "Dejun Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-788",
        "paper_authors": [
            "Sujeong Cha",
            "Wangrui Hou",
            "Hyun Jung",
            "My Phung",
            "Michael Picheny",
            "Hong-Kwang Jeff Kuo",
            "Samuel Thomas",
            "Edmilson da Silva Morais"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Cross-Lingual Spoken Language Understanding Model with Multilingual Pretraining",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-818",
        "paper_authors": [
            "Xianwei Zhang",
            "Liang He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Factorization-Aware Training of Transformers for Natural Language Understanding on the Edge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1816",
        "paper_authors": [
            "Hamidreza Saghir",
            "Samridhi Choudhary",
            "Sepehr Eghbali",
            "Clement Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Spoken Language Understanding for Generalized Voice Assistants",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1826",
        "paper_authors": [
            "Michael Saxon",
            "Samridhi Choudhary",
            "Joseph P. McKenna",
            "Athanasios Mouchtaris"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bi-Directional Joint Neural Networks for Intent Classification and Slot Filling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2044",
        "paper_authors": [
            "Soyeon Caren Han",
            "Siqu Long",
            "Huichun Li",
            "Henry Weld",
            "Josiah Poon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "INTERSPEECH 2021 Acoustic Echo Cancellation Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1870",
        "paper_authors": [
            "Ross Cutler",
            "Ando Saabas",
            "Tanel P\u00e4rnamaa",
            "Markus Loide",
            "Sten Sootla",
            "Marju Purin",
            "Hannes Gamper",
            "Sebastian Braun",
            "Karsten S\u00f8rensen",
            "Robert Aichner",
            "Sriram Srinivasan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Echo Cancellation with Cross-Domain Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-85",
        "paper_authors": [
            "Lukas Pfeifenberger",
            "Matthias Z\u00f6hrer",
            "Franz Pernkopf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "F-T-LSTM Based Complex Network for Joint Acoustic Echo Cancellation and Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1359",
        "paper_authors": [
            "Shimin Zhang",
            "Yuxiang Kong",
            "Shubo Lv",
            "Yanxin Hu",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Y2-Net FCRN for Acoustic Echo and Noise Suppression",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1590",
        "paper_authors": [
            "Ernst Seidel",
            "Jan Franzen",
            "Maximilian Strake",
            "Tim Fingscheidt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Echo Cancellation Using Deep Complex Neural Network with Nonlinear Magnitude Compression and Phase Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2022",
        "paper_authors": [
            "Renhua Peng",
            "Linjuan Cheng",
            "Chengshi Zheng",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nonlinear Acoustic Echo Cancellation with Deep Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-722",
        "paper_authors": [
            "Amir Ivry",
            "Israel Cohen",
            "Baruch Berdugo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Speech Recognition of Disordered Speech: Personalized Models Outperforming Human Listeners on Short Phrases",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1384",
        "paper_authors": [
            "Jordan R. Green",
            "Robert L. MacDonald",
            "Pan-Pan Jiang",
            "Julie Cattiau",
            "Rus Heywood",
            "Richard Cave",
            "Katie Seaver",
            "Marilyn A. Ladewig",
            "Jimmy Tobin",
            "Michael P. Brenner",
            "Philip C. Nelson",
            "Katrin Tomanek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the Utility of Multimodal Conversational Technology and Audiovisual Analytic Measures for the Assessment and Monitoring of Amyotrophic Lateral Sclerosis at Scale",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1801",
        "paper_authors": [
            "Michael Neumann",
            "Oliver Roesler",
            "Jackson Liscombe",
            "Hardik Kothare",
            "David Suendermann-Oeft",
            "David Pautler",
            "Indu Navar",
            "Aria Anvar",
            "Jochen Kumm",
            "Raquel Norel",
            "Ernest Fraenkel",
            "Alexander V. Sherman",
            "James D. Berry",
            "Gary L. Pattee",
            "Jun Wang",
            "Jordan R. Green",
            "Vikram Ramanarayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Handling Acoustic Variation in Dysarthric Speech Recognition Systems Through Model Combination",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2212",
        "paper_authors": [
            "Enno Hermann",
            "Mathew Magimai-Doss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spectro-Temporal Deep Features for Disordered Speech Assessment and Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-60",
        "paper_authors": [
            "Mengzhe Geng",
            "Shansong Liu",
            "Jianwei Yu",
            "Xurong Xie",
            "Shoukang Hu",
            "Zi Ye",
            "Zengrui Jin",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaking with a KN95 Face Mask: ASR Performance and Speaker Compensation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-99",
        "paper_authors": [
            "Sarah E. Gutz",
            "Hannah P. Rowe",
            "Jordan R. Green"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Data Augmentation for Disordered Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-168",
        "paper_authors": [
            "Zengrui Jin",
            "Mengzhe Geng",
            "Xurong Xie",
            "Jianwei Yu",
            "Shansong Liu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variational Auto-Encoder Based Variability Encoding for Dysarthric Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-173",
        "paper_authors": [
            "Xurong Xie",
            "Rukiye Ruzi",
            "Xunying Liu",
            "Lan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Explicit Prosody Models and Deep Speaker Embeddings for Atypical Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-285",
        "paper_authors": [
            "Disong Wang",
            "Songxiang Liu",
            "Lifa Sun",
            "Xixin Wu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bayesian Parametric and Architectural Domain Adaptation of LF-MMI Trained TDNNs for Elderly and Dysarthric Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-289",
        "paper_authors": [
            "Jiajun Deng",
            "Fabian Ritter Gutierrez",
            "Shoukang Hu",
            "Mengzhe Geng",
            "Xurong Xie",
            "Zi Ye",
            "Shansong Liu",
            "Jianwei Yu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Voice-Activated Switch for Persons with Motor and Speech Impairments: Isolated-Vowel Spotting Using Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-330",
        "paper_authors": [
            "Shanqing Cai",
            "Lisie Lillianfeld",
            "Katie Seaver",
            "Jordan R. Green",
            "Michael P. Brenner",
            "Philip C. Nelson",
            "D. Sculley"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conformer Parrotron: A Faster and Stronger End-to-End Speech Conversion and Recognition Model for Atypical Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-676",
        "paper_authors": [
            "Zhehuai Chen",
            "Bhuvana Ramabhadran",
            "Fadi Biadsy",
            "Xia Zhang",
            "Youzheng Chen",
            "Liyang Jiang",
            "Fang Chu",
            "Rohan Doshi",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Disordered Speech Data Collection: Lessons Learned at 1 Million Utterances from Project Euphonia",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-697",
        "paper_authors": [
            "Robert L. MacDonald",
            "Pan-Pan Jiang",
            "Julie Cattiau",
            "Rus Heywood",
            "Richard Cave",
            "Katie Seaver",
            "Marilyn A. Ladewig",
            "Jimmy Tobin",
            "Michael P. Brenner",
            "Philip C. Nelson",
            "Jordan R. Green",
            "Katrin Tomanek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Severity Classification of Korean Dysarthric Speech Using Phoneme-Level Pronunciation Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1353",
        "paper_authors": [
            "Eun Jung Yeo",
            "Sunhee Kim",
            "Minhwa Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparing Supervised Models and Learned Speech Representations for Classifying Intelligibility of Disordered Speech on Selected Phrases",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-1913",
        "paper_authors": [
            "Subhashini Venugopalan",
            "Joel Shor",
            "Manoj Plakal",
            "Jimmy Tobin",
            "Katrin Tomanek",
            "Jordan R. Green",
            "Michael P. Brenner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis and Tuning of a Voice Assistant System for Dysfluent Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2021-2006",
        "paper_authors": [
            "Vikramjit Mitra",
            "Zifang Huang",
            "Colin Lea",
            "Lauren Tooley",
            "Sarah Wu",
            "Darren Botten",
            "Ashwini Palekar",
            "Shrinath Thelapurath",
            "Panayiotis G. Georgiou",
            "Sachin Kajarekar",
            "Jeffrey P. Bigham"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interactive and Real-Time Acoustic Measurement Tools for Speech Data Acquisition and Presentation: Application of an Extended Member of Time Stretched Pulses",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/kawahara21b_interspeech.html",
        "paper_authors": [
            "Hideki Kawahara",
            "Kohei Yatabe",
            "Ken-Ichi Sakakibara",
            "Mitsunori Mizumachi",
            "Masanori Morise",
            "Hideki Banno",
            "Toshio Irino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Save Your Voice: Voice Banking and TTS for Anyone",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/tihelka21_interspeech.html",
        "paper_authors": [
            "Daniel Tihelka",
            "Mark\u00e9ta Rez\u00e1ckov\u00e1",
            "Martin Gruber",
            "Zdenek Hanzl\u00edcek",
            "Jakub V\u00edt",
            "Jindrich Matousek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NeMo (Inverse) Text Normalization: From Development to Production",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/zhang21ja_interspeech.html",
        "paper_authors": [
            "Yang Zhang",
            "Evelina Bakhturina",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lalilo: A Reading Assistant for Children Featuring Speech Recognition-Based Reading Mistake Detection",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/hembise21_interspeech.html",
        "paper_authors": [
            "Corentin Hembise",
            "Lucile Gelin",
            "Morgane Daniel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Radiology Report Editing Through Voice",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/nguyen21f_interspeech.html",
        "paper_authors": [
            "Manh Hung Nguyen",
            "Vu Hoang",
            "Tu Anh Nguyen",
            "Trung H. Bui"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WittyKiddy: Multilingual Spoken Language Learning for Kids",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/shi21e_interspeech.html",
        "paper_authors": [
            "Ke Shi",
            "Kye Min Tan",
            "Huayun Zhang",
            "Siti Umairah Md. Salleh",
            "Shikang Ni",
            "Nancy F. Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Duplex Conversation in Outbound Agent System",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/jin21b_interspeech.html",
        "paper_authors": [
            "Chunxiang Jin",
            "Minghui Yang",
            "Zujie Wen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Web Interface for Estimating Articulatory Movements in Speech Production from Acoustics and Text",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html",
        "paper_authors": [
            "Sathvik Udupa",
            "Anwesha Roy",
            "Abhayjeet Singh",
            "Aravind Illa",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    }
]