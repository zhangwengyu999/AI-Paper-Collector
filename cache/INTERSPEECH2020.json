[
    {
        "paper_name": "Interspeech 2020, 21st Annual Conference of the International Speech Communication Association, Virtual Event, Shanghai, China, 25-29 October 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020",
        "paper_authors": [
            "Helen Meng",
            "Bo Xu",
            "Thomas Fang Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The cognitive status of simple and complex models",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/pierrehumbert20_interspeech.html",
        "paper_authors": [
            "Janet B. Pierrehumbert"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Comparison of Popular End-to-End Models for Large Scale Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2846",
        "paper_authors": [
            "Jinyu Li",
            "Yu Wu",
            "Yashesh Gaur",
            "Chengyi Wang",
            "Rui Zhao",
            "Shujie Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SAN-M: Memory Equipped Self-Attention for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2471",
        "paper_authors": [
            "Zhifu Gao",
            "Shiliang Zhang",
            "Ming Lei",
            "Ian McLoughlin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextual RNN-T for Open Domain ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2986",
        "paper_authors": [
            "Mahaveer Jain",
            "Gil Keren",
            "Jay Mahadeokar",
            "Geoffrey Zweig",
            "Florian Metze",
            "Yatharth Saraf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2947",
        "paper_authors": [
            "Jing Pan",
            "Joshua Shapiro",
            "Jeremy Wohlwend",
            "Kyu Jeong Han",
            "Tao Lei",
            "Tao Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Compressing LSTM Networks with Hierarchical Coarse-Grain Sparsity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1270",
        "paper_authors": [
            "Deepak Kadetotad",
            "Jian Meng",
            "Visar Berisha",
            "Chaitali Chakrabarti",
            "Jae-sun Seo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BLSTM-Driven Stream Fusion for Automatic Speech Recognition: Novel Methods and a Multi-Size Window Fusion Example",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2560",
        "paper_authors": [
            "Timo Lohrenz",
            "Tim Fingscheidt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relative Positional Encoding for Speech Recognition and Direct Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2526",
        "paper_authors": [
            "Ngoc-Quan Pham",
            "Thanh-Le Ha",
            "Tuan-Nam Nguyen",
            "Thai-Son Nguyen",
            "Elizabeth Salesky",
            "Sebastian St\u00fcker",
            "Jan Niehues",
            "Alex Waibel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Speaker Counting, Speech Recognition, and Speaker Identification for Overlapped Speech of any Number of Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1085",
        "paper_authors": [
            "Naoyuki Kanda",
            "Yashesh Gaur",
            "Xiaofei Wang",
            "Zhong Meng",
            "Zhuo Chen",
            "Tianyan Zhou",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Implicit Transfer of Privileged Acoustic Information in a Generalized Knowledge Distillation Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1575",
        "paper_authors": [
            "Takashi Fukuda",
            "Samuel Thomas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effect of Adding Positional Information on Convolutional Neural Networks for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3163",
        "paper_authors": [
            "Jinhwan Park",
            "Wonyong Sung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Neural Network-Based Generalized Sidelobe Canceller for Robust Multi-Channel Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1101",
        "paper_authors": [
            "Guanjun Li",
            "Shan Liang",
            "Shuai Nie",
            "Wenju Liu",
            "Zhanlei Yang",
            "Longshuai Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Spatio-Temporal Beamformer for Target Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1458",
        "paper_authors": [
            "Yong Xu",
            "Meng Yu",
            "Shi-Xiong Zhang",
            "Lianwu Chen",
            "Chao Weng",
            "Jianming Liu",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Directional Speech Enhancement Using Geometrically Constrained Independent Vector Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1484",
        "paper_authors": [
            "Li Li",
            "Kazuhito Koishida",
            "Shoji Makino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Multi-Look Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1521",
        "paper_authors": [
            "Meng Yu",
            "Xuan Ji",
            "Bo Wu",
            "Dan Su",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Differential Beamforming for Uniform Circular Array with Directional Microphones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1571",
        "paper_authors": [
            "Weilong Huang",
            "Jinwei Feng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Deep Hybrid Tensor-to-Vector Network Architectures for Regression Based Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1900",
        "paper_authors": [
            "Jun Qi",
            "Hu Hu",
            "Yannan Wang",
            "Chao-Han Huck Yang",
            "Sabato Marco Siniscalchi",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An End-to-End Architecture of Online Multi-Channel Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1981",
        "paper_authors": [
            "Jian Wu",
            "Zhuo Chen",
            "Jinyu Li",
            "Takuya Yoshioka",
            "Zhili Tan",
            "Ed Lin",
            "Yi Luo",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mentoring-Reverse Mentoring for Unsupervised Multi-Channel Speech Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2082",
        "paper_authors": [
            "Yu Nakagome",
            "Masahito Togami",
            "Tetsuji Ogawa",
            "Tetsunori Kobayashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Computationally Efficient and Versatile Framework for Joint Optimization of Blind Speech Separation and Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2138",
        "paper_authors": [
            "Tomohiro Nakatani",
            "Rintaro Ikeshita",
            "Keisuke Kinoshita",
            "Hiroshi Sawada",
            "Shoko Araki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Space-and-Speaker-Aware Iterative Mask Estimation Approach to Multi-Channel Speech Recognition in the CHiME-6 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2150",
        "paper_authors": [
            "Yanhui Tu",
            "Jun Du",
            "Lei Sun",
            "Feng Ma",
            "Jia Pan",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identifying Causal Relationships Between Behavior and Local Brain Activity During Natural Conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2074",
        "paper_authors": [
            "Youssef Hmamouche",
            "Laurent Pr\u00e9vot",
            "Magalie Ochs",
            "Thierry Chaminade"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Entrainment to Natural Speech Envelope Based on Subject Aligned EEG Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1558",
        "paper_authors": [
            "Di Zhou",
            "Gaoyan Zhang",
            "Jianwu Dang",
            "Shuang Wu",
            "Zhuo Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Does Lexical Retrieval Deteriorate in Patients with Mild Cognitive Impairment? Analysis of Brain Functional Network Will Tell",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2490",
        "paper_authors": [
            "Chongyuan Lian",
            "Tianqi Wang",
            "Mingxiao Gu",
            "Manwa L. Ng",
            "Feiqi Zhu",
            "Lan Wang",
            "Nan Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Congruent Audiovisual Speech Enhances Cortical Envelope Tracking During Auditory Selective Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1957",
        "paper_authors": [
            "Zhen Fu",
            "Jing Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contribution of RMS-Level-Based Speech Segments to Target Speech Decoding Under Noisy Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1652",
        "paper_authors": [
            "Lei Wang",
            "Ed X. Wu",
            "Fei Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cortical Oscillatory Hierarchy for Natural Sentence Processing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1633",
        "paper_authors": [
            "Bin Zhao",
            "Jianwu Dang",
            "Gaoyan Zhang",
            "Masashi Unoki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparing EEG Analyses with Different Epoch Alignments in an Auditory Lexical Decision Experiment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2450",
        "paper_authors": [
            "Louis ten Bosch",
            "Kimberley Mulder",
            "Lou Boves"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detection of Subclinical Mild Traumatic Brain Injury (mTBI) Through Speech and Gait",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2651",
        "paper_authors": [
            "Tanya Talkar",
            "Sophia Yuditskaya",
            "James R. Williamson",
            "Adam C. Lammert",
            "Hrishikesh Rao",
            "Daniel J. Hannon",
            "Anne T. O'Brien",
            "Gloria Vergara-Diaz",
            "Richard DeLaura",
            "Douglas E. Sturim",
            "Gregory A. Ciccarelli",
            "Ross Zafonte",
            "Jeff Palmer",
            "Paolo Bonato",
            "Thomas F. Quatieri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Learning a Universal Non-Semantic Representation of Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1242",
        "paper_authors": [
            "Joel Shor",
            "Aren Jansen",
            "Ronnie Maor",
            "Oran Lang",
            "Omry Tuval",
            "F\u00e9lix de Chaumont Quitry",
            "Marco Tagliasacchi",
            "Ira Shavitt",
            "Dotan Emanuel",
            "Yinnon Haviv"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Poetic Meter Classification Using i-Vector-MTF Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1794",
        "paper_authors": [
            "Rajeev Rajan",
            "Aiswarya Vinod Kumar",
            "Ben P. Babu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Formant Tracking Using Dilated Convolutional Networks Through Dense Connection with Gating Mechanism",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1804",
        "paper_authors": [
            "Wang Dai",
            "Jinsong Zhang",
            "Yingming Gao",
            "Wei Wei",
            "Dengfeng Ke",
            "Binghuai Lin",
            "Yanlu Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Analysis of Speech Prosody in Dutch",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2142",
        "paper_authors": [
            "Na Hu",
            "Berit Janssen",
            "Judith Hanssen",
            "Carlos Gussenhoven",
            "Aoju Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Voice Representation Using Knowledge Distillation for Automatic Voice Casting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2236",
        "paper_authors": [
            "Adrien Gresse",
            "Mathias Quillot",
            "Richard Dufour",
            "Jean-Fran\u00e7ois Bonastre"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Formant Information in Spectrographic Display of Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2653",
        "paper_authors": [
            "B. Yegnanarayana",
            "Joseph M. Anand",
            "Vishala Pannala"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Methods for Evaluating Speech Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2990",
        "paper_authors": [
            "Michael Gump",
            "Wei-Ning Hsu",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Pitch Regression with Voiced/Unvoiced Classification in Nonstationary Noise Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3019",
        "paper_authors": [
            "Dung N. Tran",
            "Uros Batricevic",
            "Kazuhito Koishida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nonlinear ISA with Auxiliary Variables for Learning Speech Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3050",
        "paper_authors": [
            "Amrith Setlur",
            "Barnab\u00e1s P\u00f3czos",
            "Alan W. Black"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Harmonic Lowering for Accelerating Harmonic Convolution for Audio Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3185",
        "paper_authors": [
            "Hirotoshi Takeuchi",
            "Kunio Kashino",
            "Yasunori Ohishi",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge-and-Data-Driven Amplitude Spectrum Prediction for Hierarchical Neural Vocoders",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1046",
        "paper_authors": [
            "Yang Ai",
            "Zhen-Hua Ling"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FeatherWave: An Efficient High-Fidelity Neural Vocoder with Multi-Band Linear Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1156",
        "paper_authors": [
            "Qiao Tian",
            "Zewang Zhang",
            "Heng Lu",
            "Ling-Hui Chen",
            "Shan Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VocGAN: A High-Fidelity Real-Time Vocoder with a Hierarchically-Nested Adversarial Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1238",
        "paper_authors": [
            "Jinhyeok Yang",
            "Junmo Lee",
            "Young-Ik Kim",
            "Hoon-Young Cho",
            "Injung Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lightweight LPCNet-Based Neural Vocoder with Tensor Decomposition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1642",
        "paper_authors": [
            "Hiroki Kanagawa",
            "Yusuke Ijima"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WG-WaveNet: Real-Time High-Fidelity Speech Synthesis Without GPU",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1736",
        "paper_authors": [
            "Po-Chun Hsu",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What the Future Brings: Investigating the Impact of Lookahead for Incremental Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2103",
        "paper_authors": [
            "Brooke Stephenson",
            "Laurent Besacier",
            "Laurent Girin",
            "Thomas Hueber"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fast and Lightweight On-Device TTS with Tacotron2 and LPCNet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2169",
        "paper_authors": [
            "Vadim Popov",
            "Stanislav Kamenev",
            "Mikhail A. Kudinov",
            "Sergey Repyevsky",
            "Tasnima Sadekova",
            "Vitalii Bushaev",
            "Vladimir Kryzhanovskiy",
            "Denis Parkhomenko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient WaveGlow: An Improved WaveGlow Vocoder with Enhanced Speed",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2172",
        "paper_authors": [
            "Wei Song",
            "Guanghui Xu",
            "Zhengchen Zhang",
            "Chao Zhang",
            "Xiaodong He",
            "Bowen Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Can Auditory Nerve Models Tell us What's Different About WaveNet Vocoded Speech?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2596",
        "paper_authors": [
            "S\u00e9bastien Le Maguer",
            "Naomi Harte"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Conditional WaveRNN: Towards Universal Neural Vocoder for Unseen Speaker and Recording Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2786",
        "paper_authors": [
            "Dipjyoti Paul",
            "Yannis Pantazis",
            "Yannis Stylianou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Homomorphic Vocoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3188",
        "paper_authors": [
            "Zhijun Liu",
            "Kuan Chen",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Overview of the Interspeech TLT2020 Shared Task on ASR for Non-Native Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2133",
        "paper_authors": [
            "Roberto Gretter",
            "Marco Matassoni",
            "Daniele Falavigna",
            "Keelan Evanini",
            "Chee Wee Leong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The NTNU System at the Interspeech 2020 Non-Native Children's Speech ASR Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1990",
        "paper_authors": [
            "Tien-Hong Lo",
            "Fu-An Chao",
            "Shi-Yan Weng",
            "Berlin Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Native Children's Automatic Speech Recognition: The INTERSPEECH 2020 Shared Task ALTA Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2154",
        "paper_authors": [
            "Kate M. Knill",
            "Linlin Wang",
            "Yu Wang",
            "Xixin Wu",
            "Mark J. F. Gales"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation Using Prosody and False Starts to Recognize Non-Native Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2199",
        "paper_authors": [
            "Hemant Kumar Kathania",
            "Mittul Singh",
            "Tam\u00e1s Gr\u00f3sz",
            "Mikko Kurimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UNSW System Description for the Shared Task on Automatic Speech Recognition for Non-Native Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3111",
        "paper_authors": [
            "Mostafa Ali Shahin",
            "Ren\u00e9e Lu",
            "Julien Epps",
            "Beena Ahmed"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Speaker Diarization for an Unknown Number of Speakers with Encoder-Decoder Based Attractors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1022",
        "paper_authors": [
            "Shota Horiguchi",
            "Yusuke Fujita",
            "Shinji Watanabe",
            "Yawen Xue",
            "Kenji Nagamatsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Target-Speaker Voice Activity Detection: A Novel Approach for Multi-Speaker Diarization in a Dinner Party Scenario",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1602",
        "paper_authors": [
            "Ivan Medennikov",
            "Maxim Korenevsky",
            "Tatiana Prisyach",
            "Yuri Y. Khokhlov",
            "Mariya Korenevskaya",
            "Ivan Sorokin",
            "Tatiana Timofeeva",
            "Anton Mitrofanov",
            "Andrei Andrusenko",
            "Ivan Podluzhny",
            "Aleksandr Laptev",
            "Aleksei Romanenko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "New Advances in Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1879",
        "paper_authors": [
            "Hagai Aronowitz",
            "Weizhong Zhu",
            "Masayuki Suzuki",
            "Gakuto Kurata",
            "Ron Hoory"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Attentive Similarity Measurement Strategies in Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1908",
        "paper_authors": [
            "Qingjian Lin",
            "Yu Hou",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Attribution with Voice Profiles by Graph-Based Semi-Supervised Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1950",
        "paper_authors": [
            "Jixuan Wang",
            "Xiong Xiao",
            "Jian Wu",
            "Ranjani Ramamurthy",
            "Frank Rudzicz",
            "Michael Brudno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Self-Supervised Hierarchical Clustering for Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2297",
        "paper_authors": [
            "Prachi Singh",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spot the Conversation: Speaker Diarisation in the Wild",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2337",
        "paper_authors": [
            "Joon Son Chung",
            "Jaesung Huh",
            "Arsha Nagrani",
            "Triantafyllos Afouras",
            "Andrew Zisserman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Contextual Language Embeddings for Monaural Multi-Talker Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2015",
        "paper_authors": [
            "Wangyou Zhang",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Double Adversarial Network Based Monaural Speech Enhancement for Robust Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1504",
        "paper_authors": [
            "Zhihao Du",
            "Jiqing Han",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Anti-Aliasing Regularization in Stacking Layers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1497",
        "paper_authors": [
            "Antoine Bruguier",
            "Ananya Misra",
            "Arun Narayanan",
            "Rohit Prabhavalkar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner Party Transcription",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1074",
        "paper_authors": [
            "Andrei Andrusenko",
            "Aleksandr Laptev",
            "Ivan Medennikov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Far-Field Speech Recognition with Unified Dereverberation and Beamforming",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2432",
        "paper_authors": [
            "Wangyou Zhang",
            "Aswin Shanmugam Subramanian",
            "Xuankai Chang",
            "Shinji Watanabe",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Quaternion Neural Networks for Multi-Channel Distant Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1682",
        "paper_authors": [
            "Xinchi Qiu",
            "Titouan Parcollet",
            "Mirco Ravanelli",
            "Nicholas D. Lane",
            "Mohamed Morchid"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Guided Source Separation Integrated with a Strong Back-End for the CHiME-6 Dinner Party Scenario",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1606",
        "paper_authors": [
            "Hangting Chen",
            "Pengyuan Zhang",
            "Qian Shi",
            "Zuozhen Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Speech Separation Using Spatially Distributed Microphones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1089",
        "paper_authors": [
            "Dongmei Wang",
            "Zhuo Chen",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Utterance-Wise Meeting Transcription System Using Asynchronous Distributed Microphones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1050",
        "paper_authors": [
            "Shota Horiguchi",
            "Yusuke Fujita",
            "Kenji Nagamatsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simulating Realistically-Spatialised Simultaneous Speech Using Video-Driven Speaker Detection and the CHiME-5 Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2807",
        "paper_authors": [
            "Jack Deadman",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Silent Paralinguistics: Speech-to-EMG - Retrieving Articulatory Muscle Activity from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2926",
        "paper_authors": [
            "Catarina Botelho",
            "Lorenz Diener",
            "Dennis K\u00fcster",
            "Kevin Scheck",
            "Shahin Amiriparian",
            "Bj\u00f6rn W. Schuller",
            "Tanja Schultz",
            "Alberto Abad",
            "Isabel Trancoso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Deception Detection Using Automatically Extracted Acoustic, Visual, and Lexical Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2320",
        "paper_authors": [
            "Jiaxuan Zhang",
            "Sarah Ita Levitan",
            "Julia Hirschberg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Modal Attention for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1653",
        "paper_authors": [
            "Zexu Pan",
            "Zhaojie Luo",
            "Jichen Yang",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WISE: Word-Level Interaction-Based Multimodal Fusion for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3131",
        "paper_authors": [
            "Guang Shen",
            "Riwei Lai",
            "Rui Chen",
            "Yu Zhang",
            "Kejia Zhang",
            "Qilong Han",
            "Hongtao Song"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-Scale Fusion Framework for Bimodal Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3156",
        "paper_authors": [
            "Ming Chen",
            "Xudong Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Group Gated Fusion on Attention-Based Bidirectional Alignment for Multimodal Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2067",
        "paper_authors": [
            "Pengfei Liu",
            "Kun Li",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Modal Embeddings Using Multi-Task Learning for Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1827",
        "paper_authors": [
            "Aparna Khare",
            "Srinivas Parthasarathy",
            "Shiva Sundaram"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Speaker-Aligned Graph Memory Block in Multimodally Attentive Emotion Recognition Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1688",
        "paper_authors": [
            "Jeng-Lin Li",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Context-Dependent Domain Adversarial Neural Network for Multimodal Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1705",
        "paper_authors": [
            "Zheng Lian",
            "Jianhua Tao",
            "Bin Liu",
            "Jian Huang",
            "Zhanlei Yang",
            "Rongjun Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ATCSpeech: A Multilingual Pilot-Controller Speech Corpus from Real Air Traffic Control Environment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1020",
        "paper_authors": [
            "Bo Yang",
            "Xianlong Tan",
            "Zhengmao Chen",
            "Bing Wang",
            "Min Ruan",
            "Dan Li",
            "Zhongping Yang",
            "Xiping Wu",
            "Yi Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Developing an Open-Source Corpus of Yoruba Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1096",
        "paper_authors": [
            "Alexander Gutkin",
            "Isin Demirsahin",
            "Oddur Kjartansson",
            "Clara Rivera",
            "K\u00f3l\u00e1 T\u00fabos\u00fan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ClovaCall: Korean Goal-Oriented Dialog Speech Corpus for Automatic Speech Recognition of Contact Centers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1136",
        "paper_authors": [
            "Jung-Woo Ha",
            "Kihyun Nam",
            "Jingu Kang",
            "Sang-Woo Lee",
            "Sohee Yang",
            "Hyunhoon Jung",
            "Hyeji Kim",
            "Eunmi Kim",
            "Soojin Kim",
            "Hyun Ah Kim",
            "Kyoungtae Doh",
            "Chan Kyu Lee",
            "Nako Sung",
            "Sunghun Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LAIX Corpus of Chinese Learner English: Towards a Benchmark for L2 English ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1677",
        "paper_authors": [
            "Yanhong Wang",
            "Huan Luan",
            "Jiahong Yuan",
            "Bin Wang",
            "Hui Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Design and Development of a Human-Machine Dialog Corpus for the Automated Assessment of Conversational English Proficiency",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1988",
        "paper_authors": [
            "Vikram Ramanarayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CUCHILD: A Large-Scale Cantonese Corpus of Child Speech for Phonology and Articulation Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2148",
        "paper_authors": [
            "Si Ioi Ng",
            "Cymie Wing-Yee Ng",
            "Jiarui Wang",
            "Tan Lee",
            "Kathy Yuet-Sheung Lee",
            "Michael Chi-Fai Tong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FinChat: Corpus and Evaluation Setup for Finnish Chat Conversations on Everyday Topics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2511",
        "paper_authors": [
            "Katri Leino",
            "Juho Leinonen",
            "Mittul Singh",
            "Sami Virpioja",
            "Mikko Kurimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DiPCo - Dinner Party Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2800",
        "paper_authors": [
            "Maarten Van Segbroeck",
            "Ahmed Zaid",
            "Ksenia Kutsenko",
            "Cirenia Huerta",
            "Tinh Nguyen",
            "Xuewen Luo",
            "Bj\u00f6rn Hoffmeister",
            "Jan Trmal",
            "Maurizio Omologo",
            "Roland Maas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to Detect Bipolar Disorder and Borderline Personality Disorder with Language and Speech in Non-Clinical Interviews",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3040",
        "paper_authors": [
            "Bo Wang",
            "Yue Wu",
            "Niall Taylor",
            "Terry J. Lyons",
            "Maria Liakata",
            "Alejo J. Nevado-Holgado",
            "Kate E. A. Saunders"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FT Speech: Danish Parliament Speech Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3164",
        "paper_authors": [
            "Andreas Kirkedal",
            "Marija Stepanovic",
            "Barbara Plank"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Metric Learning Loss Functions to Reduce Domain Mismatch in the x-Vector Space for Language Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1708",
        "paper_authors": [
            "Rapha\u00ebl Duroselle",
            "Denis Jouvet",
            "Irina Illina"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The XMUSPEECH System for the AP19-OLR Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1923",
        "paper_authors": [
            "Zheng Li",
            "Miao Zhao",
            "Jing Li",
            "Yiming Zhi",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Usage of Multi-Feature Integration for Speaker Verification and Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1960",
        "paper_authors": [
            "Zheng Li",
            "Miao Zhao",
            "Jing Li",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What Does an End-to-End Dialect Identification Model Learn About Non-Dialectal Information?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2235",
        "paper_authors": [
            "Shammur A. Chowdhury",
            "Ahmed Ali",
            "Suwon Shon",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Releasing a Toolkit and Comparing the Performance of Language Embeddings Across Various Spoken Language Identification Datasets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2706",
        "paper_authors": [
            "Matias Lindgren",
            "Tommi Jauhiainen",
            "Mikko Kurimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Intonation Pattern Embeddings for Arabic Dialect Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2906",
        "paper_authors": [
            "Aitor Arronte Alvarez",
            "Elsayed Sabry Abdelaal Issa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Domain Adaptation of Spoken Language Identification for Related Languages: The Curious Case of Slavic Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2930",
        "paper_authors": [
            "Badr M. Abdullah",
            "Tania Avgustinova",
            "Bernd M\u00f6bius",
            "Dietrich Klakow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ICE-Talk: An Interface for a Controllable Expressive Talking Machine",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/tits20_interspeech.html",
        "paper_authors": [
            "No\u00e9 Tits",
            "Kevin El Haddad",
            "Thierry Dutoit"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Kaldi-Web: An Installation-Free, On-Device Speech Recognition System",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/hu20b_interspeech.html",
        "paper_authors": [
            "Mathieu Hu",
            "Laurent Pierron",
            "Emmanuel Vincent",
            "Denis Jouvet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Soapbox Labs Verification Platform for Child Speech",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/kelly20_interspeech.html",
        "paper_authors": [
            "Amelia C. Kelly",
            "Eleni Karamichali",
            "Armin Saeb",
            "Karel Vesel\u00fd",
            "Nicholas Parslow",
            "Agape Deng",
            "Arnaud Letondor",
            "Robert O'Regan",
            "Qiru Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SoapBox Labs Fluency Assessment Platform for Child Speech",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/kelly20b_interspeech.html",
        "paper_authors": [
            "Amelia C. Kelly",
            "Eleni Karamichali",
            "Armin Saeb",
            "Karel Vesel\u00fd",
            "Nicholas Parslow",
            "Gloria Montoya Gomez",
            "Agape Deng",
            "Arnaud Letondor",
            "Niall Mullally",
            "Adrian Hempel",
            "Robert O'Regan",
            "Qiru Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CATOTRON - A Neural Text-to-Speech System in Catalan",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/kulebi20_interspeech.html",
        "paper_authors": [
            "Baybars K\u00fclebi",
            "Alp \u00d6ktem",
            "Alex Peir\u00f3 Lilja",
            "Santiago Pascual",
            "Mireia Farr\u00fas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Remote Patient Monitoring of Speech, Video, Cognitive and Respiratory Biomarkers Using Multimodal Dialog Technology",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/ramanarayanan20b_interspeech.html",
        "paper_authors": [
            "Vikram Ramanarayanan",
            "Oliver Roesler",
            "Michael Neumann",
            "David Pautler",
            "Doug Habberstad",
            "Andrew Cornish",
            "Hardik Kothare",
            "Vignesh Murali",
            "Jackson Liscombe",
            "Dirk Schnelle-Walka",
            "Patrick L. Lange",
            "David Suendermann-Oeft"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VoiceID on the Fly: A Speaker Recognition System that Learns from Scratch",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/lin20b_interspeech.html",
        "paper_authors": [
            "Baihan Lin",
            "Xinxin Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Transferability of Black-Box Adversarial Attacks via Lifelong Learning for Speech Emotion Recognition Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1869",
        "paper_authors": [
            "Zhao Ren",
            "Jing Han",
            "Nicholas Cummins",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Speech Emotion Recognition Combined with Acoustic-to-Word ASR Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1180",
        "paper_authors": [
            "Han Feng",
            "Sei Ueno",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Speech Emotion Recognition Using Graph Attentive Bi-Directional Gated Recurrent Unit Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1733",
        "paper_authors": [
            "Bo-Hao Su",
            "Chun-Min Chang",
            "Yun-Shao Lin",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Investigation of Cross-Cultural Semi-Supervised Learning for Continuous Affect Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2641",
        "paper_authors": [
            "Adria Mallol-Ragolta",
            "Nicholas Cummins",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ensemble of Students Taught by Probabilistic Teachers to Improve Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2694",
        "paper_authors": [
            "Kusha Sridhar",
            "Carlos Busso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Augmenting Generative Adversarial Networks for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3194",
        "paper_authors": [
            "Siddique Latif",
            "Muhammad Asim",
            "Rajib Rana",
            "Sara Khalifa",
            "Raja Jurdak",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion Recognition 'in the Wild' Using an Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1356",
        "paper_authors": [
            "Vipula Dissanayake",
            "Haimo Zhang",
            "Mark Billinghurst",
            "Suranga Nanayakkara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emotion Profile Refinery for Speech Emotion Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1771",
        "paper_authors": [
            "Shuiyang Mao",
            "Pak-Chung Ching",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Representation Learning for Emotion Recognition Using End-to-End ASR with Factorized Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2524",
        "paper_authors": [
            "Sung-Lin Yeh",
            "Yun-Shao Lin",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fast and Slow Acoustic Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2887",
        "paper_authors": [
            "Kshitiz Kumar",
            "Emilian Stoimenov",
            "Hosam Khalil",
            "Jian Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Distillation for Improving CTC-Transformer-Based ASR Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1223",
        "paper_authors": [
            "Takafumi Moriya",
            "Tsubasa Ochiai",
            "Shigeki Karita",
            "Hiroshi Sato",
            "Tomohiro Tanaka",
            "Takanori Ashihara",
            "Ryo Masumura",
            "Yusuke Shinohara",
            "Marc Delcroix"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Single Headed Attention Based Sequence-to-Sequence Model for State-of-the-Art Results on Switchboard",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1488",
        "paper_authors": [
            "Zolt\u00e1n T\u00fcske",
            "George Saon",
            "Kartik Audhkhasi",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Speech Recognition Using GAN-Based Speech Synthesis and Contrastive Unspoken Text Selection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1475",
        "paper_authors": [
            "Zhehuai Chen",
            "Andrew Rosenberg",
            "Yu Zhang",
            "Gary Wang",
            "Bhuvana Ramabhadran",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for End-to-End ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3053",
        "paper_authors": [
            "Yiwen Shao",
            "Yiming Wang",
            "Daniel Povey",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CAT: A CTC-CRF Based ASR Toolkit Bridging the Hybrid and the End-to-End Approaches Towards Data Efficiency and Low Latency",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2732",
        "paper_authors": [
            "Keyu An",
            "Hongyu Xiang",
            "Zhijian Ou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CTC-Synchronous Training for Monotonic Attention Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1069",
        "paper_authors": [
            "Hirofumi Inaguma",
            "Masato Mimura",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continual Learning for Multi-Dialect Acoustic Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1797",
        "paper_authors": [
            "Brady Houston",
            "Katrin Kirchhoff"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpecSwap: A Simple Data Augmentation Method for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2275",
        "paper_authors": [
            "Xingcheng Song",
            "Zhiyong Wu",
            "Yiheng Huang",
            "Dan Su",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RECOApy: Data Recording, Pre-Processing and Phonetic Transcription for End-to-End Speech-Based Applications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1184",
        "paper_authors": [
            "Adriana Stan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analyzing the Quality and Stability of a Streaming End-to-End On-Device Speech Recognizer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1194",
        "paper_authors": [
            "Yuan Shangguan",
            "Kate Knister",
            "Yanzhang He",
            "Ian McGraw",
            "Fran\u00e7oise Beaufays"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Statistical Testing on ASR Performance via Blockwise Bootstrap",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1338",
        "paper_authors": [
            "Zhe Liu",
            "Fuchun Peng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sentence Level Estimation of Psycholinguistic Norms Using Joint Multidimensional Annotations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1841",
        "paper_authors": [
            "Anil Ramakrishna",
            "Shrikanth Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Zero-Inflated Quality Estimation Model for Automatic Speech Recognition System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1881",
        "paper_authors": [
            "Kai Fan",
            "Bo Li",
            "Jiayi Wang",
            "Shiliang Zhang",
            "Boxing Chen",
            "Niyu Ge",
            "Zhijie Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Confidence Measures in Encoder-Decoder Models for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2215",
        "paper_authors": [
            "Alejandro Woodward",
            "Clara Bonn\u00edn",
            "Issey Masuda",
            "David Varas",
            "Elisenda Bou-Balust",
            "Juan Carlos Riveiro"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Word Error Rate Estimation Without ASR Output: e-WER2",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2357",
        "paper_authors": [
            "Ahmed Ali",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Evaluation of Manual and Semi-Automatic Laughter Annotation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2521",
        "paper_authors": [
            "Bogdan Ludusan",
            "Petra Wagner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding Racial Disparities in Automatic Speech Recognition: The Case of Habitual \"be\"",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2893",
        "paper_authors": [
            "Joshua L. Martin",
            "Kevin Tang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Secondary Phonetic Cues in the Production of the Nasal Short-a System in California English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1322",
        "paper_authors": [
            "Georgia Zellou",
            "Rebecca Scarborough",
            "Renee Kemp"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Properties of Strident Fricatives at the Edges: Implications for Consonant Discrimination",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2913",
        "paper_authors": [
            "Louis-Marie Lorin",
            "Lorenzo Maselli",
            "L\u00e9o Varnet",
            "Maria Giavazzi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Processes and Consequences of Co-Articulation in Mandarin V1N.(C2)V2 Context: Phonology and Phonetics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1041",
        "paper_authors": [
            "Mingqiong Luo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voicing Distinction of Obstruents in the Hangzhou Wu Chinese Dialect",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1259",
        "paper_authors": [
            "Yang Yue",
            "Fang Hu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Phonology and Phonetics of Kaifeng Mandarin Vowels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2375",
        "paper_authors": [
            "Lei Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Microprosodic Variability in Plosives in German and Austrian German",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2353",
        "paper_authors": [
            "Margaret Zellers",
            "Barbara Schuppler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Er-Suffixation in Southwestern Mandarin: An EMA and Ultrasound Study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2453",
        "paper_authors": [
            "Jing Huang",
            "Feng-fan Hsieh",
            "Yueh-Chin Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Electroglottographic-Phonetic Study on Korean Phonation Induced by Tripartite Plosives in Yanbian Korean",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2350",
        "paper_authors": [
            "Yinghao Li",
            "Jinghua Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling Global Body Configurations in American Sign Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2873",
        "paper_authors": [
            "Nicholas Wilkins",
            "Max Cordes Galbraith",
            "Ifeoma Nwogu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Augmenting Turn-Taking Prediction with Wearable Eye Activity During Conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3204",
        "paper_authors": [
            "Hang Li",
            "Siyuan Chen",
            "Julien Epps"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CAM: Uninteresting Speech Detector",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1192",
        "paper_authors": [
            "Weiyi Lu",
            "Yi Xu",
            "Peng Yang",
            "Belinda Zeng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mixed Case Contextual ASR Using Capitalization Masks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2367",
        "paper_authors": [
            "Diamantino Caseiro",
            "Pat Rondon",
            "Quoc-Nam Le The",
            "Petar S. Aleksic"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Recognition and Multi-Speaker Diarization of Long Conversations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3039",
        "paper_authors": [
            "Huanru Henry Mao",
            "Shuyang Li",
            "Julian J. McAuley",
            "Garrison W. Cottrell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of Data Augmentation Techniques for Disordered Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1161",
        "paper_authors": [
            "Mengzhe Geng",
            "Xurong Xie",
            "Shansong Liu",
            "Jianwei Yu",
            "Shoukang Hu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Real-Time Robot-Based Auxiliary System for Risk Evaluation of COVID-19 Infection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2105",
        "paper_authors": [
            "Wenqi Wei",
            "Jianzong Wang",
            "Jiteng Ma",
            "Ning Cheng",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Utterance Verification System for Word Naming Therapy in Aphasia",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2265",
        "paper_authors": [
            "David S. Barbera",
            "Mark A. Huckvale",
            "Victoria Fleming",
            "Emily Upton",
            "Henry Coley-Fisher",
            "Ian Shaw",
            "William H. Latham",
            "Alexander P. Leff",
            "Jenny Crinion"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploiting Cross-Domain Visual Feature Generation for Disordered Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2282",
        "paper_authors": [
            "Shansong Liu",
            "Xurong Xie",
            "Jianwei Yu",
            "Shoukang Hu",
            "Mengzhe Geng",
            "Rongfeng Su",
            "Shi-Xiong Zhang",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Prediction of Punctuation and Disfluency in Speech Transcripts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1277",
        "paper_authors": [
            "Binghuai Lin",
            "Liyuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Focal Loss for Punctuation Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1638",
        "paper_authors": [
            "Jiangyan Yi",
            "Jianhua Tao",
            "Zhengkun Tian",
            "Ye Bai",
            "Cunhang Fan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving X-Vector and PLDA for Text-Dependent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1188",
        "paper_authors": [
            "Zhuxin Chen",
            "Yue Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SdSV Challenge 2020: Large-Scale Evaluation of Short-Duration Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1485",
        "paper_authors": [
            "Hossein Zeinali",
            "Kong Aik Lee",
            "Jahangir Alam",
            "Luk\u00e1s Burget"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The XMUSPEECH System for Short-Duration Speaker Verification Challenge 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1704",
        "paper_authors": [
            "Tao Jiang",
            "Miao Zhao",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Text-Dependent Speaker Verification via Character-Level Information Preservation for the SdSV Challenge 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2183",
        "paper_authors": [
            "Sung Hwan Mun",
            "Woo Hyun Kang",
            "Min Hyun Han",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The TalTech Systems for the Short-Duration Speaker Verification Challenge 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2233",
        "paper_authors": [
            "Tanel Alum\u00e4e",
            "J\u00f6rgen Valk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of NICT Submission for Short-Duration Speaker Verification Challenge 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2351",
        "paper_authors": [
            "Peng Shen",
            "Xugang Lu",
            "Hisashi Kawai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype Mining and Language-Dependent Score Normalization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2662",
        "paper_authors": [
            "Jenthe Thienpondt",
            "Brecht Desplanques",
            "Kris Demuynck"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BUT Text-Dependent Speaker Verification System for SdSV Challenge 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2882",
        "paper_authors": [
            "Alicia Lozano-Diez",
            "Anna Silnova",
            "Bhargav Pulugundla",
            "Johan Rohdin",
            "Karel Vesel\u00fd",
            "Luk\u00e1s Burget",
            "Oldrich Plchot",
            "Ondrej Glembek",
            "Ondrej Novotn\u00fd",
            "Pavel Matejka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring the Use of an Unsupervised Autoregressive Model as a Shared Encoder for Text-Dependent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2957",
        "paper_authors": [
            "Vijay Ravi",
            "Ruchao Fan",
            "Amber Afshan",
            "Huanhua Lu",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recognition-Synthesis Based Non-Parallel Voice Conversion with Adversarial Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-36",
        "paper_authors": [
            "Jing-Xuan Zhang",
            "Zhen-Hua Ling",
            "Li-Rong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving the Speaker Identity of Non-Parallel Many-to-Many Voice Conversion with Adversarial Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1033",
        "paper_authors": [
            "Shaojin Ding",
            "Guanlong Zhao",
            "Ricardo Gutierrez-Osuna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Parallel Many-to-Many Voice Conversion with PSR-StarGAN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1310",
        "paper_authors": [
            "Yanping Li",
            "Dongxiang Xu",
            "Yan Zhang",
            "Yang Wang",
            "Binbin Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TTS Skins: Speaker Conversion via ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1416",
        "paper_authors": [
            "Adam Polyak",
            "Lior Wolf",
            "Yaniv Taigman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GAZEV: GAN-Based Zero-Shot Voice Conversion Over Non-Parallel Speech Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1710",
        "paper_authors": [
            "Zining Zhang",
            "Bingsheng He",
            "Zhenjie Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoken Content and Voice Factorization for Few-Shot Speaker Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1745",
        "paper_authors": [
            "Tao Wang",
            "Jianhua Tao",
            "Ruibo Fu",
            "Jiangyan Yi",
            "Zhengqi Wen",
            "Rongxiu Zhong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Cross-Domain Singing Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1862",
        "paper_authors": [
            "Adam Polyak",
            "Lior Wolf",
            "Yossi Adi",
            "Yaniv Taigman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention-Based Speaker Embeddings for One-Shot Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2512",
        "paper_authors": [
            "Tatsuma Ishihara",
            "Daisuke Saito"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2530",
        "paper_authors": [
            "Jian Cong",
            "Shan Yang",
            "Lei Xie",
            "Guoqiao Yu",
            "Guanglu Wan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gated Multi-Head Attention Pooling for Weakly Labelled Audio Tagging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1197",
        "paper_authors": [
            "Sixin Hong",
            "Yuexian Zou",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Environmental Sound Classification with Parallel Temporal-Spectral Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1219",
        "paper_authors": [
            "Helin Wang",
            "Yuexian Zou",
            "Dading Chong",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contrastive Predictive Coding of Audio with an Adversary",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1891",
        "paper_authors": [
            "Luyu Wang",
            "Kazuya Kawakami",
            "A\u00e4ron van den Oord"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Memory Controlled Sequential Self Attention for Sound Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1953",
        "paper_authors": [
            "Arjun Pankajakshan",
            "Helen L. Bear",
            "Vinod Subramanian",
            "Emmanouil Benetos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual Stage Learning Based Dynamic Time-Frequency Mask Generation for Audio Event Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2152",
        "paper_authors": [
            "Donghyeon Kim",
            "Jaihyun Park",
            "David K. Han",
            "Hanseok Ko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Effective Perturbation Based Semi-Supervised Learning Method for Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2329",
        "paper_authors": [
            "Xu Zheng",
            "Yan Song",
            "Jie Yan",
            "Li-Rong Dai",
            "Ian McLoughlin",
            "Lin Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Joint Framework for Audio Tagging and Weakly Supervised Acoustic Event Detection Using DenseNet with Global Average Pooling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2791",
        "paper_authors": [
            "Chieh-Chi Kao",
            "Bowen Shi",
            "Ming Sun",
            "Chao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intra-Utterance Similarity Preserving Knowledge Distillation for Audio Tagging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2835",
        "paper_authors": [
            "Chun-Chieh Chang",
            "Chieh-Chi Kao",
            "Ming Sun",
            "Chao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Two-Stage Polyphonic Sound Event Detection Based on Faster R-CNN-LSTM with Multi-Token Connectionist Temporal Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3097",
        "paper_authors": [
            "In Young Park",
            "Hong Kook Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeechMix - Augmenting Deep Sound Recognition Using Hidden Space Interpolations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3147",
        "paper_authors": [
            "Amit Jindal",
            "Narayanan Elavathur Ranganatha",
            "Aniket Didolkar",
            "Arijit Ghosh Chowdhury",
            "Di Jin",
            "Ramit Sawhney",
            "Rajiv Ratn Shah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Neural Transformer Based Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1963",
        "paper_authors": [
            "Martin Radfar",
            "Athanasios Mouchtaris",
            "Siegfried Kunzmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Jointly Encoding Word Confusion Network and Dialogue Context with BERT for Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1632",
        "paper_authors": [
            "Chen Liu",
            "Su Zhu",
            "Zijian Zhao",
            "Ruisheng Cao",
            "Lu Chen",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech to Semantics: Improve ASR and NLU Jointly via All-Neural Interfaces",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2976",
        "paper_authors": [
            "Milind Rao",
            "Anirudh Raju",
            "Pranav Dheram",
            "Bach Bui",
            "Ariya Rastrow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pretrained Semantic Speech Embeddings for End-to-End Spoken Language Understanding via Cross-Modal Teacher-Student Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2456",
        "paper_authors": [
            "Pavel Denisov",
            "Ngoc Thang Vu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Context Dependent RNNLM for Automatic Transcription of Conversations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1813",
        "paper_authors": [
            "Srikanth Raj Chetupalli",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving End-to-End Speech-to-Intent Classification with Reptile",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1160",
        "paper_authors": [
            "Yusheng Tian",
            "Philip John Gorinski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech to Text Adaptation: Towards an Efficient Cross-Modal Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1246",
        "paper_authors": [
            "Won-Ik Cho",
            "Donghyun Kwak",
            "Ji Won Yoon",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards an ASR Error Robust Spoken Language Understanding System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2844",
        "paper_authors": [
            "Weitong Ruan",
            "Yaroslav Nechaev",
            "Luoxin Chen",
            "Chengwei Su",
            "Imre Kiss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Spoken Language Understanding Without Full Transcripts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2924",
        "paper_authors": [
            "Hong-Kwang Jeff Kuo",
            "Zolt\u00e1n T\u00fcske",
            "Samuel Thomas",
            "Yinghui Huang",
            "Kartik Audhkhasi",
            "Brian Kingsbury",
            "Gakuto Kurata",
            "Zvi Kons",
            "Ron Hoory",
            "Luis A. Lastras"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Are Neural Open-Domain Dialog Systems Robust to Speech Recognition Errors in the Dialog History? An Empirical Study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1508",
        "paper_authors": [
            "Karthik Gopalakrishnan",
            "Behnam Hedayatnia",
            "Longshaokan Wang",
            "Yang Liu",
            "Dilek Hakkani-T\u00fcr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AutoSpeech: Neural Architecture Search for Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1258",
        "paper_authors": [
            "Shaojin Ding",
            "Tianlong Chen",
            "Xinyu Gong",
            "Weiwei Zha",
            "Zhangyang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Densely Connected Time Delay Neural Network for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1275",
        "paper_authors": [
            "Ya-Qi Yu",
            "Wu-Jun Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetically-Aware Coupled Network For Short Duration Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1306",
        "paper_authors": [
            "Siqi Zheng",
            "Yun Lei",
            "Hongbin Suo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Task Network for Noise-Robust Keyword Spotting and Speaker Verification Using CTC-Based Soft VAD and Global Query Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1420",
        "paper_authors": [
            "Myunghun Jung",
            "Youngmoon Jung",
            "Jahyun Goo",
            "Hoirin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vector-Based Attentive Pooling for Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1422",
        "paper_authors": [
            "Yanfeng Wu",
            "Chenkai Guo",
            "Hongcan Gao",
            "Xiaolei Hou",
            "Jing Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Attention Encoding and Pooling for Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1446",
        "paper_authors": [
            "Pooyan Safari",
            "Miquel India",
            "Javier Hernando"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ARET: Aggregated Residual Extended Time-Delay Neural Networks for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1626",
        "paper_authors": [
            "Ruiteng Zhang",
            "Jianguo Wei",
            "Wenhuan Lu",
            "Longbiao Wang",
            "Meng Liu",
            "Lin Zhang",
            "Jiayu Jin",
            "Junhai Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Separation Network for Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1966",
        "paper_authors": [
            "Hanyi Zhang",
            "Longbiao Wang",
            "Yunchun Zhang",
            "Meng Liu",
            "Kong Aik Lee",
            "Jianguo Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text-Independent Speaker Verification with Dual Attention Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2031",
        "paper_authors": [
            "Jingyu Li",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evolutionary Algorithm Enhanced Neural Architecture Search for Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3057",
        "paper_authors": [
            "Xiaoyang Qu",
            "Jianzong Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Minimum Bayes Risk Training of RNN-Transducer for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1221",
        "paper_authors": [
            "Chao Weng",
            "Chengzhu Yu",
            "Jia Cui",
            "Chunlei Zhang",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantic Mask for Transformer Based End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1778",
        "paper_authors": [
            "Chengyi Wang",
            "Yu Wu",
            "Yujiao Du",
            "Jinyu Li",
            "Shujie Liu",
            "Liang Lu",
            "Shuo Ren",
            "Guoli Ye",
            "Sheng Zhao",
            "Ming Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Faster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1995",
        "paper_authors": [
            "Frank Zhang",
            "Yongqiang Wang",
            "Xiaohui Zhang",
            "Chunxi Liu",
            "Yatharth Saraf",
            "Geoffrey Zweig"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Federated Approach in Training Acoustic Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1791",
        "paper_authors": [
            "Dimitrios Dimitriadis",
            "Ken'ichi Kumatani",
            "Robert Gmyr",
            "Yashesh Gaur",
            "Sefik Emre Eskimez"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Semi-Supervised LF-MMI Training of Acoustic Models with Limited Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2242",
        "paper_authors": [
            "Imran A. Sheikh",
            "Emmanuel Vincent",
            "Irina Illina"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Front-End Gain Invariant Modeling for Wake Word Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1992",
        "paper_authors": [
            "Yixin Gao",
            "Noah D. Stein",
            "Chieh-Chi Kao",
            "Yunliang Cai",
            "Ming Sun",
            "Tao Zhang",
            "Shiv Naga Prasad Vitaladevuni"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Regularization-Based Adaptive Training for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1689",
        "paper_authors": [
            "Fenglin Ding",
            "Wu Guo",
            "Bin Gu",
            "Zhen-Hua Ling",
            "Jun Du"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Robustness and Training Dynamics of Raw Waveform Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-17",
        "paper_authors": [
            "Erfan Loweimi",
            "Peter Bell",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Iterative Pseudo-Labeling for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1800",
        "paper_authors": [
            "Qiantong Xu",
            "Tatiana Likhomanenko",
            "Jacob Kahn",
            "Awni Y. Hannun",
            "Gabriel Synnaeve",
            "Ronan Collobert"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Smart Tube: A Biofeedback System for Vocal Training and Therapy Through Tube Phonation",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/kawamura20_interspeech.html",
        "paper_authors": [
            "Naoko Kawamura",
            "Tatsuya Kitamura",
            "Kenta Hamada"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VCTUBE : A Library for Automatic Speech Data Annotation",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/choi20_interspeech.html",
        "paper_authors": [
            "Seong Choi",
            "Seunghoon Jeong",
            "Jeewoo Yoon",
            "Migyeong Yang",
            "Minsam Ko",
            "Eunil Park",
            "Jinyoung Han",
            "Munyoung Lee",
            "Seonghee Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Mandarin L2 Learning APP with Mispronunciation Detection and Feedback",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/xie20_interspeech.html",
        "paper_authors": [
            "Yanlu Xie",
            "Xiaoli Feng",
            "Boxue Li",
            "Jinsong Zhang",
            "Yujia Jin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rapid Enhancement of NLP Systems by Acquisition of Data in Correlated Domains",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/udayakumar20_interspeech.html",
        "paper_authors": [
            "Tejas Udayakumar",
            "Kinnera Saranu",
            "Mayuresh Sanjay Oak",
            "Ajit Ashok Saunshikhar",
            "Sandip Shriram Bapat"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Computer-Assisted Language Learning System: Automatic Speech Evaluation for Children Learning Malay and Tamil",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/shi20_interspeech.html",
        "paper_authors": [
            "Ke Shi",
            "Kye Min Tan",
            "Richeng Duan",
            "Siti Umairah Md. Salleh",
            "Nur Farah Ain Suhaimi",
            "Rajan Vellu",
            "Ngoc Thuy Huong Helen Thai",
            "Nancy F. Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time, Full-Band, Online DNN-Based Voice Conversion System Using a Single CPU",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/saeki20_interspeech.html",
        "paper_authors": [
            "Takaaki Saeki",
            "Yuki Saito",
            "Shinnosuke Takamichi",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Dynamic 3D Pronunciation Teaching Model Based on Pronunciation Attributes and Anatomy",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/feng20b_interspeech.html",
        "paper_authors": [
            "Xiaoli Feng",
            "Yanlu Xie",
            "Yayue Deng",
            "Boxue Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Deep Learning Speech Recognition Model for Silent Speech Challenge",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/kimura20_interspeech.html",
        "paper_authors": [
            "Naoki Kimura",
            "Zixiong Su",
            "Takaaki Saeki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Autosegmental Neural Nets: Should Phones and Tones be Synchronous or Asynchronous?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1834",
        "paper_authors": [
            "Jialu Li",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Development of Multilingual ASR Using GlobalPhone for Less-Resourced Languages: The Case of Ethiopian Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2827",
        "paper_authors": [
            "Martha Yifiru Tachbelie",
            "Solomon Teferra Abate",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large-Scale End-to-End Multilingual Speech Recognition and Language Identification with Multi-Task Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2164",
        "paper_authors": [
            "Wenxin Hou",
            "Yue Dong",
            "Bairong Zhuang",
            "Longfei Yang",
            "Jiatong Shi",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2488",
        "paper_authors": [
            "Xinyuan Zhou",
            "Emre Yilmaz",
            "Yanhua Long",
            "Yijie Li",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multilingual Acoustic and Language Modeling for Ethio-Semitic Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2856",
        "paper_authors": [
            "Solomon Teferra Abate",
            "Martha Yifiru Tachbelie",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multilingual Jointly Trained Acoustic and Written Word Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2828",
        "paper_authors": [
            "Yushi Hu",
            "Shane Settle",
            "Karen Livescu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Code-Switching Language Modeling with Artificially Generated Texts Using Cycle-Consistent Adversarial Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2177",
        "paper_authors": [
            "Chia-Yu Li",
            "Ngoc Thang Vu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation for Code-Switch Language Modeling by Fusing Multiple Text Generation Methods",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2219",
        "paper_authors": [
            "Xinhui Hu",
            "Qi Zhang",
            "Lei Yang",
            "Binbin Gu",
            "Xinkang Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A 43 Language Multilingual Punctuation Prediction Neural Network Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2052",
        "paper_authors": [
            "Xinxing Li",
            "Edward Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Lexicon-Free Modeling Units for End-to-End Korean and Korean-English Code-Switching Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2440",
        "paper_authors": [
            "Jisung Wang",
            "Jihwan Kim",
            "Sangki Kim",
            "Yeha Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Task Siamese Neural Network for Improving Replay Attack Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-86",
        "paper_authors": [
            "Patrick von Platen",
            "Fei Tao",
            "G\u00f6khan T\u00fcr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "POCO: A Voice Spoofing and Liveness Detection Corpus Based on Pop Noise",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1243",
        "paper_authors": [
            "Kosuke Akimoto",
            "Seng Pei Liew",
            "Sakiko Mishima",
            "Ryo Mizushima",
            "Kong Aik Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual-Adversarial Domain Adaptation for Generalized Replay Attack Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1255",
        "paper_authors": [
            "Hongji Wang",
            "Heinrich Dinkel",
            "Shuai Wang",
            "Yanmin Qian",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Pre-Training with Acoustic Configurations for Replay Spoofing Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1345",
        "paper_authors": [
            "Hye-jin Shim",
            "Hee-Soo Heo",
            "Jee-weon Jung",
            "Ha-Jin Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Competency Evaluation in Voice Mimicking Using Acoustic Cues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1790",
        "paper_authors": [
            "Abhijith Girish",
            "Adharsh Sabu",
            "Akshay Prasannan Latha",
            "Rajeev Rajan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Light Convolutional Neural Network with Feature Genuinization for Detection of Synthetic Speech Attacks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1810",
        "paper_authors": [
            "Zhenzong Wu",
            "Rohan Kumar Das",
            "Jichen Yang",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoofing Attack Detection Using the Non-Linear Fusion of Sub-Band Classifiers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1844",
        "paper_authors": [
            "Hemlata Tak",
            "Jose Patino",
            "Andreas Nautsch",
            "Nicholas W. D. Evans",
            "Massimiliano Todisco"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Light-ResNet Architecture for Spoofing Detection Under Mismatched Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2039",
        "paper_authors": [
            "Prasanth Parasu",
            "Julien Epps",
            "Kaavya Sriskandaraja",
            "Gajan Suthokumar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Siamese Convolutional Neural Network Using Gaussian Probability Feature for Spoofing Speech Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2723",
        "paper_authors": [
            "Zhenchun Lei",
            "Yingen Yang",
            "Changhong Liu",
            "Jihua Ye"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lightweight Online Noise Reduction on Embedded Devices Using Hierarchical Recurrent Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1131",
        "paper_authors": [
            "Hendrik Schr\u00f6ter",
            "Tobias Rosenkranz",
            "Alberto N. Escalante-B.",
            "Pascal Zobel",
            "Andreas Maier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SEANet: A Multi-Modal Speech Enhancement Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1563",
        "paper_authors": [
            "Marco Tagliasacchi",
            "Yunpeng Li",
            "Karolis Misiunas",
            "Dominik Roblek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lite Audio-Visual Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1617",
        "paper_authors": [
            "Shang-Yi Chuang",
            "Yu Tsao",
            "Chen-Chou Lo",
            "Hsin-Min Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ORCA-CLEAN: A Deep Denoising Toolkit for Killer Whale Communication",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1316",
        "paper_authors": [
            "Christian Bergler",
            "Manuel Schmitt",
            "Andreas Maier",
            "Simeon Smeele",
            "Volker Barth",
            "Elmar N\u00f6th"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep Learning Approach to Active Noise Control",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1768",
        "paper_authors": [
            "Hao Zhang",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Speech Intelligibility Through Speaker Dependent and Independent Spectral Style Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-54",
        "paper_authors": [
            "Tuan Dinh",
            "Alexander Kain",
            "Kris Tjaden"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Speech Intelligibility Prediction Using Time-Domain Fully Convolutional Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1740",
        "paper_authors": [
            "Mathias Bach Pedersen",
            "Morten Kolb\u00e6k",
            "Asger Heidemann Andersen",
            "S\u00f8ren Holdt Jensen",
            "Jesper Jensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Intelligibility of Enhanced Speech Using Posteriors Derived from DNN-Based ASR System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1591",
        "paper_authors": [
            "Kenichi Arai",
            "Shoko Araki",
            "Atsunori Ogawa",
            "Keisuke Kinoshita",
            "Tomohiro Nakatani",
            "Toshio Irino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Estimation of Intelligibility Measure for Consonants in Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2121",
        "paper_authors": [
            "Ali Abavisani",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large Scale Evaluation of Importance Maps in Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2883",
        "paper_authors": [
            "Viet Anh Trinh",
            "Michael I. Mandel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Architecture Search on Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-57",
        "paper_authors": [
            "Jixiang Li",
            "Chuming Liang",
            "Bo Zhang",
            "Zhao Wang",
            "Fei Xiang",
            "Xiangxiang Chu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Scene Classification Using Audio Tagging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-992",
        "paper_authors": [
            "Jee-weon Jung",
            "Hye-jin Shim",
            "Ju-ho Kim",
            "Seung-bin Kim",
            "Ha-Jin Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ATReSN-Net: Capturing Attentive Temporal Relations in Semantic Neighborhood for Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1151",
        "paper_authors": [
            "Liwen Zhang",
            "Jiqing Han",
            "Ziqiang Shi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Environment Sound Classification Using Multiple Feature Channels and Attention Based Deep Convolutional Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1303",
        "paper_authors": [
            "Jivitesh Sharma",
            "Ole-Christoffer Granmo",
            "Morten Goodwin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Scene Analysis with Multi-Head Attention Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1342",
        "paper_authors": [
            "Weimin Wang",
            "Weiran Wang",
            "Ming Sun",
            "Chao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relational Teacher Student Learning with Neural Label Embedding for Device Adaptation in Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2038",
        "paper_authors": [
            "Hu Hu",
            "Sabato Marco Siniscalchi",
            "Yannan Wang",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Acoustic Segment Model Based Segment Unit Selection Approach to Acoustic Scene Classification with Partial Utterances",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2044",
        "paper_authors": [
            "Hu Hu",
            "Sabato Marco Siniscalchi",
            "Yannan Wang",
            "Xue Bai",
            "Jun Du",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention-Driven Projections for Soundscape Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2476",
        "paper_authors": [
            "Dhanunjaya Varma Devalraju",
            "H. Muralikrishna",
            "Padmanabhan Rajan",
            "Dileep Aroor Dinesh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Computer Audition for Continuous Rainforest Occupancy Monitoring: The Case of Bornean Gibbons' Call Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2655",
        "paper_authors": [
            "Panagiotis Tzirakis",
            "Alexander Shiarella",
            "Robert M. Ewers",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Learning Based Open Set Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3092",
        "paper_authors": [
            "Zuzanna Kwiatkowska",
            "Beniamin Kalinowski",
            "Michal Kosmider",
            "Krzysztof Rykaczewski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Singing Synthesis: With a Little Help from my Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1399",
        "paper_authors": [
            "Orazio Angelini",
            "Alexis Moinet",
            "Kayoko Yanagisawa",
            "Thomas Drugman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Peking Opera Synthesis via Duration Informed Attention Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1724",
        "paper_authors": [
            "Yusong Wu",
            "Shengchen Li",
            "Chengzhu Yu",
            "Heng Lu",
            "Chao Weng",
            "Liqiang Zhang",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DurIAN-SC: Duration Informed Attention Network Based Singing Voice Conversion System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1789",
        "paper_authors": [
            "Liqiang Zhang",
            "Chengzhu Yu",
            "Heng Lu",
            "Chao Weng",
            "Chunlei Zhang",
            "Yusong Wu",
            "Xiang Xie",
            "Zijin Li",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning for Improving Singing-Voice Detection in Polyphonic Instrumental Music",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1806",
        "paper_authors": [
            "Yuanbo Hou",
            "Frank K. Soong",
            "Jian Luan",
            "Shengchen Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Channel-Wise Subband Input for Better Voice and Accompaniment Separation on High Resolution Music",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2555",
        "paper_authors": [
            "Haohe Liu",
            "Lei Xie",
            "Jian Wu",
            "Geng Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continual Learning in Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2962",
        "paper_authors": [
            "Samik Sadhu",
            "Hynek Hermansky"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Adaptive Training for Speech Recognition Based on Attention-Over-Attention Mechanism",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1727",
        "paper_authors": [
            "Genshun Wan",
            "Jia Pan",
            "Qingran Wang",
            "Jianqing Gao",
            "Zhongfu Ye"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rapid RNN-T Adaptation Using Personalized Speech Synthesis and Neural Language Generator",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1290",
        "paper_authors": [
            "Yan Huang",
            "Jinyu Li",
            "Lei He",
            "Wenning Wei",
            "William Gale",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Transformer with Speaker Aware Persistent Memory",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1281",
        "paper_authors": [
            "Yingzhu Zhao",
            "Chongjia Ni",
            "Cheung-Chi Leung",
            "Shafiq R. Joty",
            "Eng Siong Chng",
            "Bin Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Speaker Normalization for CTC-Based Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1390",
        "paper_authors": [
            "Fenglin Ding",
            "Wu Guo",
            "Bin Gu",
            "Zhen-Hua Ling",
            "Jun Du"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Domain Adaptation Under Label Space Mismatch for Speech Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1861",
        "paper_authors": [
            "Akhil Mathur",
            "Nadia Berthouze",
            "Nicholas D. Lane"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Fast Adaptation on Cross-Accented Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-45",
        "paper_authors": [
            "Genta Indra Winata",
            "Samuel Cahyawijaya",
            "Zihan Liu",
            "Zhaojiang Lin",
            "Andrea Madotto",
            "Peng Xu",
            "Pascale Fung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Black-Box Adaptation of ASR for Accented Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3162",
        "paper_authors": [
            "Kartik Khandelwal",
            "Preethi Jyothi",
            "Abhijeet Awasthi",
            "Sunita Sarawagi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Achieving Multi-Accent ASR via Unsupervised Acoustic Model Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2742",
        "paper_authors": [
            "M. A. Tugtekin Turan",
            "Emmanuel Vincent",
            "Denis Jouvet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Frame-Wise Online Unsupervised Adaptation of DNN-HMM Acoustic Model from Perspective of Robust Adaptive Filtering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1301",
        "paper_authors": [
            "Ryu Takeda",
            "Kazunori Komatani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarially Trained Multi-Singer Sequence-to-Sequence Singing Synthesizer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1109",
        "paper_authors": [
            "Jie Wu",
            "Jian Luan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prediction of Head Motion from Speech Waveforms with a Canonical-Correlation-Constrained Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1218",
        "paper_authors": [
            "JinHong Lu",
            "Hiroshi Shimodaira"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1410",
        "paper_authors": [
            "Peiling Lu",
            "Jie Wu",
            "Jian Luan",
            "Xu Tan",
            "Li Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Talking Face Generation Using Latent Distribution Matching",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1823",
        "paper_authors": [
            "Ravindra Yadav",
            "Ashish Sardana",
            "Vinay P. Namboodiri",
            "Rajesh M. Hegde"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech-to-Singing Conversion Based on Boundary Equilibrium GAN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1984",
        "paper_authors": [
            "Da-Yi Wu",
            "Yi-Hsuan Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Face2Speech: Towards Multi-Speaker Text-to-Speech Synthesis Using an Embedding Vector Predicted from a Face Image",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2136",
        "paper_authors": [
            "Shunsuke Goto",
            "Kotaro Onishi",
            "Yuki Saito",
            "Kentaro Tachibana",
            "Koichiro Mori"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Driven Talking Head Generation via Attentional Landmarks Based Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2304",
        "paper_authors": [
            "Wentao Wang",
            "Yan Wang",
            "Jianqing Sun",
            "Qingsong Liu",
            "Jiaen Liang",
            "Teng Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimization and Evaluation of an Intelligibility-Improving Signal Processing Approach (IISPA) for the Hurricane Challenge 2.0 with FADE",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-93",
        "paper_authors": [
            "Marc Ren\u00e9 Sch\u00e4dler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "iMetricGAN: Intelligibility Enhancement for Speech-in-Noise Using Generative Adversarial Network-Based Metric Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1016",
        "paper_authors": [
            "Haoyu Li",
            "Szu-Wei Fu",
            "Yu Tsao",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intelligibility-Enhancing Speech Modifications - The Hurricane Challenge 2.0",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1641",
        "paper_authors": [
            "Jan Rennies",
            "Henning F. Schepker",
            "Cassia Valentini-Botinhao",
            "Martin Cooke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Listeners' Speech Rate Preferences",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1832",
        "paper_authors": [
            "Olympia Simantiraki",
            "Martin Cooke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Compressive Onset-Enhancement for Improved Speech Intelligibility in Noise and Reverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2640",
        "paper_authors": [
            "Felicitas Bederna",
            "Henning F. Schepker",
            "Christian Rollwage",
            "Simon Doclo",
            "Arne Pusch",
            "J\u00f6rg Bitzer",
            "Jan Rennies"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Sound Engineering Approach to Near End Listening Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2748",
        "paper_authors": [
            "Carol Chermaz",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Speech Intelligibility in Text-To-Speech Synthesis Using Speaking Style Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2793",
        "paper_authors": [
            "Dipjyoti Paul",
            "P. V. Muhammed Shifas",
            "Yannis Pantazis",
            "Yannis Stylianou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Two Different Mechanisms of Movable Mandible for Vocal-Tract Model with Flexible Tongue",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1159",
        "paper_authors": [
            "Takayuki Arai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving the Performance of Acoustic-to-Articulatory Inversion by Removing the Training Loss of Noncritical Portions of Articulatory Channels Dynamically",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1187",
        "paper_authors": [
            "Qiang Fang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Conditioned Acoustic-to-Articulatory Inversion Using x-Vectors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1222",
        "paper_authors": [
            "Aravind Illa",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coarticulation as Synchronised Sequential Target Approximation: An EMA Study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1432",
        "paper_authors": [
            "Zirui Liu",
            "Yi Xu",
            "Feng-fan Hsieh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Model for Vocal Folds with a Polyp with Potential Application",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3049",
        "paper_authors": [
            "J\u00f4natas Santos",
            "Jugurta Montalv\u00e3o",
            "Israel Santos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Regional Resonance of the Lower Vocal Tract and its Contribution to Speaker Characteristics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2024",
        "paper_authors": [
            "Lin Zhang",
            "Kiyoshi Honda",
            "Jianguo Wei",
            "Seiji Adachi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Air-Tissue Boundary Segmentation in Real Time Magnetic Resonance Imaging Video Using 3-D Convolutional Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2241",
        "paper_authors": [
            "Renuka Mannem",
            "Navaneetha Gaddam",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Investigation of the Virtual Lip Trajectories During the Production of Bilabial Stops and Nasal at Different Speaking Rates",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2709",
        "paper_authors": [
            "Tilak Purohit",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpEx+: A Complete Time Domain Speaker Extraction Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1397",
        "paper_authors": [
            "Meng Ge",
            "Chenglin Xu",
            "Longbiao Wang",
            "Eng Siong Chng",
            "Jianwu Dang",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Atss-Net: Target Speaker Separation via Attention-Based Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1436",
        "paper_authors": [
            "Tingle Li",
            "Qingjian Lin",
            "Yuanyuan Bao",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Target Speech Separation with Voice and Face References",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1697",
        "paper_authors": [
            "Leyuan Qu",
            "Cornelius Weber",
            "Stefan Wermter"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "X-TaSNet: Robust and Accurate Time-Domain Speaker Extraction Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1706",
        "paper_authors": [
            "Zining Zhang",
            "Bingsheng He",
            "Zhenjie Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Listen, Watch and Understand at the Cocktail Party: Audio-Visual-Contextual Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2028",
        "paper_authors": [
            "Chenda Li",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified Framework for Low-Latency Speaker Extraction in Cocktail Party Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2085",
        "paper_authors": [
            "Yunzhe Hao",
            "Jiaming Xu",
            "Jing Shi",
            "Peng Zhang",
            "Lei Qin",
            "Bo Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Time-Domain Target-Speaker Speech Separation with Waveform-Based Speaker Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2108",
        "paper_authors": [
            "Jianshu Zhao",
            "Shengzhou Gao",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Listen to What You Want: Neural Network-Based Universal Sound Selector",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2210",
        "paper_authors": [
            "Tsubasa Ochiai",
            "Marc Delcroix",
            "Yuma Koizumi",
            "Hiroaki Ito",
            "Keisuke Kinoshita",
            "Shoko Araki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Crossmodal Sound Retrieval Based on Specific Target Co-Occurrence Denoted with Weak Labels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2445",
        "paper_authors": [
            "Masahiro Yasuda",
            "Yasunori Ohishi",
            "Yuma Koizumi",
            "Noboru Harada"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Aware Monaural Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2483",
        "paper_authors": [
            "Jiahao Xu",
            "Kun Hu",
            "Chang Xu",
            "Tran Duc Chung",
            "Zhiyong Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Brain networks enabling speech perception in everyday settings",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/shinncunningham20_interspeech.html",
        "paper_authors": [
            "Barbara G. Shinn-Cunningham"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A DNN-HMM-DNN Hybrid Model for Discovering Word-Like Units from Spoken Captions and Image Regions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1148",
        "paper_authors": [
            "Liming Wang",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Wait-k Models for Simultaneous Machine Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1241",
        "paper_authors": [
            "Maha Elbayad",
            "Laurent Besacier",
            "Jakob Verbeek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Self-Supervised Pre-Training for End-to-End Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1835",
        "paper_authors": [
            "Ha Nguyen",
            "Fethi Bougares",
            "Natalia A. Tomashenko",
            "Yannick Est\u00e8ve",
            "Laurent Besacier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextualized Translation of Automatically Segmented Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2860",
        "paper_authors": [
            "Marco Gaido",
            "Mattia Antonino Di Gangi",
            "Matteo Negri",
            "Mauro Cettolo",
            "Marco Turchi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Training for End-to-End Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2938",
        "paper_authors": [
            "Juan Miguel Pino",
            "Qiantong Xu",
            "Xutai Ma",
            "Mohammad Javad Dousti",
            "Yun Tang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating and Optimizing Prosodic Alignment for Automatic Dubbing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2983",
        "paper_authors": [
            "Marcello Federico",
            "Yogesh Virkar",
            "Robert Enyedi",
            "Roberto Barra-Chicote"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pair Expansion for Learning Multilingual Semantic Embeddings Using Disjoint Visually-Grounded Speech Audio Datasets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3078",
        "paper_authors": [
            "Yasunori Ohishi",
            "Akisato Kimura",
            "Takahito Kawanishi",
            "Kunio Kashino",
            "David Harwath",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Representations Improve End-to-End Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3094",
        "paper_authors": [
            "Anne Wu",
            "Changhan Wang",
            "Juan Miguel Pino",
            "Jiatao Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved RawNet with Feature Map Scaling for Text-Independent Speaker Verification Using Raw Waveforms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1011",
        "paper_authors": [
            "Jee-weon Jung",
            "Seung-bin Kim",
            "Hye-jin Shim",
            "Ju-ho Kim",
            "Ha-Jin Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Multi-Scale Aggregation Using Feature Pyramid Module for Robust Speaker Verification of Variable-Duration Utterances",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1025",
        "paper_authors": [
            "Youngmoon Jung",
            "Seong Min Kye",
            "Yeunju Choi",
            "Myunghun Jung",
            "Hoirin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Adaptive X-Vector Model for Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1071",
        "paper_authors": [
            "Bin Gu",
            "Wu Guo",
            "Fenglin Ding",
            "Zhen-Hua Ling",
            "Jun Du"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Shouted Speech Compensation for Speaker Verification Robust to Vocal Effort Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1402",
        "paper_authors": [
            "Santi Prieto",
            "Alfonso Ortega Gim\u00e9nez",
            "Iv\u00e1n L\u00f3pez-Espejo",
            "Eduardo Lleida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sum-Product Networks for Robust Automatic Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1501",
        "paper_authors": [
            "Aaron Nicolson",
            "Kuldip K. Paliwal"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Segment Aggregation for Short Utterances Speaker Verification Using Raw Waveforms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1564",
        "paper_authors": [
            "Seung-bin Kim",
            "Jee-weon Jung",
            "Hye-jin Shim",
            "Ju-ho Kim",
            "Ha-Jin Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Siamese X-Vector Reconstruction for Domain Adapted Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1742",
        "paper_authors": [
            "Shai Rozenberg",
            "Hagai Aronowitz",
            "Ron Hoory"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Re-Identification with Speaker Dependent Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1772",
        "paper_authors": [
            "Yanpei Shi",
            "Qiang Huang",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Blind Speech Signal Quality Estimation for Speaker Verification Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1826",
        "paper_authors": [
            "Galina Lavrentyeva",
            "Marina Volkova",
            "Anastasia Avdeeva",
            "Sergey Novoselov",
            "Artem Gorlanov",
            "Tseren Andzhukaev",
            "Artem Ivanov",
            "Alexander Kozlov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Robustness of Adversarial Samples Detection for Automatic Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2441",
        "paper_authors": [
            "Xu Li",
            "Na Li",
            "Jinghua Zhong",
            "Xixin Wu",
            "Xunying Liu",
            "Dan Su",
            "Dong Yu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling ASR Ambiguity for Neural Dialogue State Tracking",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1783",
        "paper_authors": [
            "Vaishali Pal",
            "Fabien Guillot",
            "Manish Shrivastava",
            "Jean-Michel Renders",
            "Laurent Besacier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR Error Correction with Augmented Transformer for Entity Retrieval",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1753",
        "paper_authors": [
            "Haoyu Wang",
            "Shuyan Dong",
            "Yue Liu",
            "James Logan",
            "Ashish Kumar Agrawal",
            "Yang Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large-Scale Transfer Learning for Low-Resource Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-59",
        "paper_authors": [
            "Xueli Jia",
            "Jianzong Wang",
            "Zhiyong Zhang",
            "Ning Cheng",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Balancing for Boosting Performance of Low-Frequency Classes in Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1676",
        "paper_authors": [
            "Judith Gaspers",
            "Quynh Ngoc Thi Do",
            "Fabian Triefenbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Interactive Adversarial Reward Learning-Based Spoken Language Understanding System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2967",
        "paper_authors": [
            "Yu Wang",
            "Yilin Shen",
            "Hongxia Jin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Style Attuned Pre-Training and Parameter Efficient Fine-Tuning for Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2907",
        "paper_authors": [
            "Jin Cao",
            "Jun Wang",
            "Wael Hamza",
            "Kelly Vanee",
            "Shang-Wen Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Domain Adaptation for Dialogue Sequence Labeling Based on Hierarchical Adversarial Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2010",
        "paper_authors": [
            "Shota Orihashi",
            "Mana Ihori",
            "Tomohiro Tanaka",
            "Ryo Masumura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep F-Measure Maximization for End-to-End Speech Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1949",
        "paper_authors": [
            "Leda Sari",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Effective Domain Adaptive Post-Training Method for BERT in Response Selection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2153",
        "paper_authors": [
            "Taesun Whang",
            "Dongyub Lee",
            "Chanhee Lee",
            "Kisu Yang",
            "Dongsuk Oh",
            "Heuiseok Lim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Confidence Measure for Speech-to-Concept End-to-End Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2298",
        "paper_authors": [
            "Antoine Caubri\u00e8re",
            "Yannick Est\u00e8ve",
            "Antoine Laurent",
            "Emmanuel Morin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention to Indexical Information Improves Voice Recall",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3042",
        "paper_authors": [
            "Grant L. McGuire",
            "Molly Babel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Categorization of Whistled Consonants by French Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2683",
        "paper_authors": [
            "Ana\u00efs Tran Ngoc",
            "Julien Meyer",
            "Fanny Meunier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Whistled Vowel Identification by French Listeners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2697",
        "paper_authors": [
            "Ana\u00efs Tran Ngoc",
            "Julien Meyer",
            "Fanny Meunier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "F0 Slope and Mean: Cues to Speech Segmentation in French",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2509",
        "paper_authors": [
            "Maria del Mar Cordero",
            "Fanny Meunier",
            "Nicolas Grimault",
            "St\u00e9phane Pota",
            "Elsa Spinelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Does French Listeners' Ability to Use Accentual Information at the Word Level Depend on the Ear of Presentation?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1263",
        "paper_authors": [
            "Amandine Michelas",
            "Sophie Dufour"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Perceptual Study of the Five Level Tones in Hmu (Xinzhai Variety)",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-56",
        "paper_authors": [
            "Wen Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mandarin and English Adults' Cue-Weighting of Lexical Stress",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2612",
        "paper_authors": [
            "Zhen Zeng",
            "Karen Mattock",
            "Liquan Liu",
            "Varghese Peter",
            "Alba Tuninetti",
            "Feng-Ming Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Age-Related Differences of Tone Perception in Mandarin-Speaking Seniors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2194",
        "paper_authors": [
            "Yan Feng",
            "Gang Peng",
            "William Shi-Yuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Social and Functional Pressures in Vocal Alignment: Differences for Human and Voice-AI Interlocutors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1335",
        "paper_authors": [
            "Georgia Zellou",
            "Michelle Cohn"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identifying Important Time-Frequency Locations in Continuous Speech Utterances",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2637",
        "paper_authors": [
            "Hassan Salami Kavaki",
            "Michael I. Mandel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Raw Sign and Magnitude Spectra for Multi-Head Acoustic Modelling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-18",
        "paper_authors": [
            "Erfan Loweimi",
            "Peter Bell",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Raw Waveform Speech Recognition Using Relevance Weighted Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2301",
        "paper_authors": [
            "Purvi Agrawal",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep 2D Convolutional Network for Waveform-Based Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1870",
        "paper_authors": [
            "Dino Oglic",
            "Zoran Cvetkovic",
            "Peter Bell",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lightweight End-to-End Speech Recognition from Raw Audio Data Using Sinc-Convolutions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1392",
        "paper_authors": [
            "Ludwig K\u00fcrzinger",
            "Nicolas Lindae",
            "Palle Klewitz",
            "Gerhard Rigoll"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Alternative to MFCCs for ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2690",
        "paper_authors": [
            "Pegah Ghahramani",
            "Hossein Hadian",
            "Daniel Povey",
            "Hynek Hermansky",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phase Based Spectro-Temporal Features for Building a Robust ASR System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2258",
        "paper_authors": [
            "Anirban Dutta",
            "Ashishkumar Prabhakar Gudmalwar",
            "Ch. V. Rama Rao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Scattering Power Spectrum Features for Robust Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2656",
        "paper_authors": [
            "Neethu M. Joy",
            "Dino Oglic",
            "Zoran Cvetkovic",
            "Peter Bell",
            "Steve Renals"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FusionRNN: Shared Neural Parameters for Multi-Channel Distant Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2102",
        "paper_authors": [
            "Titouan Parcollet",
            "Xinchi Qiu",
            "Nicholas D. Lane"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bandpass Noise Generation and Augmentation for Unified ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2904",
        "paper_authors": [
            "Kshitiz Kumar",
            "Bo Ren",
            "Yifan Gong",
            "Jian Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Learning Based Dereverberation of Temporal Envelopes for Robust Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2283",
        "paper_authors": [
            "Anurenjan Purushothaman",
            "Anirudh Sreeram",
            "Rohit Kumar",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Introducing the VoicePrivacy Initiative",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1333",
        "paper_authors": [
            "Natalia A. Tomashenko",
            "Brij Mohan Lal Srivastava",
            "Xin Wang",
            "Emmanuel Vincent",
            "Andreas Nautsch",
            "Junichi Yamagishi",
            "Nicholas W. D. Evans",
            "Jose Patino",
            "Jean-Fran\u00e7ois Bonastre",
            "Paul-Gauthier No\u00e9",
            "Massimiliano Todisco"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Privacy ZEBRA: Zero Evidence Biometric Recognition Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1815",
        "paper_authors": [
            "Andreas Nautsch",
            "Jose Patino",
            "Natalia A. Tomashenko",
            "Junichi Yamagishi",
            "Paul-Gauthier No\u00e9",
            "Jean-Fran\u00e7ois Bonastre",
            "Massimiliano Todisco",
            "Nicholas W. D. Evans"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "X-Vector Singular Value Modification and Statistical-Based Decomposition with Ensemble Regression Modeling for Speaker Anonymization System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1887",
        "paper_authors": [
            "Candy Olivia Mawalim",
            "Kasorn Galajit",
            "Jessada Karnjana",
            "Masashi Unoki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparative Study of Speech Anonymization Metrics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2248",
        "paper_authors": [
            "Mohamed Maouche",
            "Brij Mohan Lal Srivastava",
            "Nathalie Vauquier",
            "Aur\u00e9lien Bellet",
            "Marc Tommasi",
            "Emmanuel Vincent"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Design Choices for X-Vector Based Speaker Anonymization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2692",
        "paper_authors": [
            "Brij Mohan Lal Srivastava",
            "Natalia A. Tomashenko",
            "Xin Wang",
            "Emmanuel Vincent",
            "Junichi Yamagishi",
            "Mohamed Maouche",
            "Aur\u00e9lien Bellet",
            "Marc Tommasi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Pseudonymisation Assessment Using Voice Similarity Matrices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2720",
        "paper_authors": [
            "Paul-Gauthier No\u00e9",
            "Jean-Fran\u00e7ois Bonastre",
            "Driss Matrouf",
            "Natalia A. Tomashenko",
            "Andreas Nautsch",
            "Nicholas W. D. Evans"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1094",
        "paper_authors": [
            "Kyubyong Park",
            "Seanie Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Mask-Based Model for Mandarin Chinese Polyphone Disambiguation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1142",
        "paper_authors": [
            "Haiteng Zhang",
            "Huashan Pan",
            "Xiulin Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perception of Concatenative vs. Neural Text-To-Speech (TTS): Differences in Intelligibility in Noise and Language Attitudes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1336",
        "paper_authors": [
            "Michelle Cohn",
            "Georgia Zellou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Sequence-to-Sequence Text-to-Speech with Morphology",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1547",
        "paper_authors": [
            "Jason Taylor",
            "Korin Richmond"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2111",
        "paper_authors": [
            "Yeunju Choi",
            "Youngmoon Jung",
            "Hoirin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Learning Based Assessment of Synthetic Speech Naturalness",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2382",
        "paper_authors": [
            "Gabriel Mittag",
            "Sebastian M\u00f6ller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distant Supervision for Polyphone Disambiguation in Mandarin Chinese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2427",
        "paper_authors": [
            "Jiawen Zhang",
            "Yuanyuan Zhao",
            "Jiaqi Zhu",
            "Jinba Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Unsupervised Method to Select a Speaker Subset from Large Multi-Speaker Speech Synthesis Datasets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2567",
        "paper_authors": [
            "Pilar Oplustil Gallegos",
            "Jennifer Williams",
            "Joanna Rownicka",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding the Effect of Voice Quality and Accent on Talker Similarity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2910",
        "paper_authors": [
            "Anurag Das",
            "Guanlong Zhao",
            "John Levis",
            "Evgeny Chukharev-Hudilainen",
            "Ricardo Gutierrez-Osuna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Beam Search for Encoder-Decoder Attention Based Speech Recognition Without Length Bias",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1958",
        "paper_authors": [
            "Wei Zhou",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer with Bidirectional Decoder for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2677",
        "paper_authors": [
            "Xi Chen",
            "Songyang Zhang",
            "Dandan Song",
            "Peng Ouyang",
            "Shouyi Yin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Investigation of Phone-Based Subword Units for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1873",
        "paper_authors": [
            "Weiran Wang",
            "Guangsen Wang",
            "Aadyot Bhatnagar",
            "Yingbo Zhou",
            "Caiming Xiong",
            "Richard Socher"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Combination of End-to-End and Hybrid Models for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2141",
        "paper_authors": [
            "Jeremy Heng Meng Wong",
            "Yashesh Gaur",
            "Rui Zhao",
            "Liang Lu",
            "Eric Sun",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evolved Speech-Transformer: Applying Neural Architecture Search to End-to-End Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1233",
        "paper_authors": [
            "Jihwan Kim",
            "Jisung Wang",
            "Sangki Kim",
            "Yeha Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical Multi-Stage Word-to-Grapheme Named Entity Corrector for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3174",
        "paper_authors": [
            "Abhinav Garg",
            "Ashutosh Gupta",
            "Dhananjaya Gowda",
            "Shatrughan Singh",
            "Chanwoo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LVCSR with Transformer Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1164",
        "paper_authors": [
            "Eugen Beck",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition and Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1315",
        "paper_authors": [
            "Yi-Chen Chen",
            "Jui-Yang Hsu",
            "Cheng-Kuang Lee",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Uncertainty-Aware Machine Support for Paper Reviewing on the Interspeech 2019 Submission Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2862",
        "paper_authors": [
            "Lukas Stappen",
            "Georgios Rizos",
            "Madina Hasan",
            "Thomas Hain",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Individual Variation in Language Attitudes Toward Voice-AI: The Role of Listeners' Autistic-Like Traits",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1339",
        "paper_authors": [
            "Michelle Cohn",
            "Melina Sarian",
            "Kristin Predeck",
            "Georgia Zellou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Differences in Gradient Emotion Perception: Human vs. Alexa Voices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1938",
        "paper_authors": [
            "Michelle Cohn",
            "Eran Raveh",
            "Kristin Predeck",
            "Iona Gessinger",
            "Bernd M\u00f6bius",
            "Georgia Zellou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The MSP-Conversation Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2444",
        "paper_authors": [
            "Luz Martinez-Lucas",
            "Mohammed Abdelwahab",
            "Carlos Busso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spotting the Traces of Depression in Read Speech: An Approach Based on Computational Paralinguistics and Social Signal Processing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2888",
        "paper_authors": [
            "Fuxiang Tao",
            "Anna Esposito",
            "Alessandro Vinciarelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Sentiment and Customer Satisfaction Estimation in Socialbot Conversations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2890",
        "paper_authors": [
            "Yelin Kim",
            "Joshua Levy",
            "Yang Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pardon the Interruption: An Analysis of Gender and Turn-Taking in U.S. Supreme Court Oral Arguments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2964",
        "paper_authors": [
            "Haley Lepp",
            "Gina-Anne Levow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Are Germans Better Haters Than Danes? Language-Specific Implicit Prosodies of Types of Hate Speech and How They Relate to Perceived Severity and Societal Rules",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1611",
        "paper_authors": [
            "Jana Neitsch",
            "Oliver Niebuhr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Objective Voice Gender Scoring System and Identification of the Salient Acoustic Measures",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1627",
        "paper_authors": [
            "Fuling Chen",
            "Roberto Togneri",
            "Murray Maybery",
            "Diana Tan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How Ordinal Are Your Data?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2030",
        "paper_authors": [
            "Sadari Jayawardena",
            "Julien Epps",
            "Zhaocheng Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Correlating Cepstra with Formant Frequencies: Implications for Phonetically-Informed Forensic Voice Comparison",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2216",
        "paper_authors": [
            "Vincent Hughes",
            "Frantz Clermont",
            "Philip Harrison"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosody and Breathing: A Comparison Between Rhetorical and Information-Seeking Questions in German and Brazilian Portuguese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1607",
        "paper_authors": [
            "Jana Neitsch",
            "Pl\u00ednio A. Barbosa",
            "Oliver Niebuhr"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scaling Processes of Clause Chains in Pitjantjatjara",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2101",
        "paper_authors": [
            "Rebecca Defina",
            "Catalina Torres",
            "Hywel Stoakes"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neutralization of Voicing Distinction of Stops in Tohoku Dialects of Japanese: Field Work and Acoustic Measurements",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3191",
        "paper_authors": [
            "Ai Mizoguchi",
            "Ayako Hashimoto",
            "Sanae Matsui",
            "Setsuko Imatomi",
            "Ryunosuke Kobayashi",
            "Mafuyu Kitahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Correlation Between Prosody and Pragmatics: Case Study of Discourse Markers in French and English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2204",
        "paper_authors": [
            "Lou Lee",
            "Denis Jouvet",
            "Katarina Bartkova",
            "Yvon Keromnes",
            "Mathilde Dargnat"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Analysis of Prosodic Prominence Cues to Information Structure in Egyptian Arabic",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2322",
        "paper_authors": [
            "Dina El Zarka",
            "Anneliese Kelterer",
            "Barbara Schuppler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lexical Stress in Urdu",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2942",
        "paper_authors": [
            "Benazir Mumtaz",
            "Tina B\u00f6gel",
            "Miriam Butt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vocal Markers from Sustained Phonation in Huntington's Disease",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1057",
        "paper_authors": [
            "Rachid Riad",
            "Hadrien Titeux",
            "Laurie Lemoine",
            "Justine Montillot",
            "Jennifer Hamet Bagnou",
            "Xuan-Nga Cao",
            "Emmanuel Dupoux",
            "Anne-Catherine Bachoud-L\u00e9vi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How Rhythm and Timbre Encode Moor\u00e9 Language in Bendr\u00e9 Drummed Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2532",
        "paper_authors": [
            "Laure Dentel",
            "Julien Meyer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Doing Something we Never could with Spoken Language Technologies-from early days to the era of deep learning",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/lee20_interspeech.html",
        "paper_authors": [
            "Lin-Shan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interaction of Tone and Voicing in Mizo",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2695",
        "paper_authors": [
            "Wendy Lalhminghlui",
            "Priyankoo Sarmah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mandarin Lexical Tones: A Corpus-Based Study of Word Length, Syllable Position and Prosodic Position on Duration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1614",
        "paper_authors": [
            "Yaru Wu",
            "Martine Adda-Decker",
            "Lori Lamel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Investigation of the Target Approximation Model for Tone Modeling and Recognition in Continuous Mandarin Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2823",
        "paper_authors": [
            "Yingming Gao",
            "Xinyu Zhang",
            "Yi Xu",
            "Jinsong Zhang",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Integrating the Application and Realization of Mandarin 3rd Tone Sandhi in the Resolution of Sentence Ambiguity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2073",
        "paper_authors": [
            "Wei Lai",
            "Aini Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neutral Tone in Changde Mandarin",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1257",
        "paper_authors": [
            "Zhenrui Zhang",
            "Fang Hu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pitch Declination and Final Lowering in Northeastern Mandarin",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1987",
        "paper_authors": [
            "Ping Cui",
            "Jianjing Kuang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variation in Spectral Slope and Interharmonic Noise in Cantonese Tones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1954",
        "paper_authors": [
            "Phil Rose"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Acoustic Realization of Mandarin Tones in Fast Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1274",
        "paper_authors": [
            "Ping Tang",
            "Shanpeng Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Do Face Masks Introduce Bias in Speech Technologies? The Case of Automated Scoring of Speaking Proficiency",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1264",
        "paper_authors": [
            "Anastassia Loukina",
            "Keelan Evanini",
            "Matthew Mulholland",
            "Ian Blood",
            "Klaus Zechner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Low Latency ASR-Free End to End Spoken Language Understanding System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1449",
        "paper_authors": [
            "Mohamed Mhiri",
            "Samuel Myer",
            "Vikrant Singh Tomar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Audio-Based Wakeword-Independent Verification System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1843",
        "paper_authors": [
            "Joe Wang",
            "Rajath Kumar",
            "Mike Rodehorst",
            "Brian Kulis",
            "Shiv Naga Prasad Vitaladevuni"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learnable Spectro-Temporal Receptive Fields for Robust Voice Type Discrimination",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1878",
        "paper_authors": [
            "Tyler Vuong",
            "Yangyang Xia",
            "Richard M. Stern"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low Latency Speech Recognition Using End-to-End Prefetching",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1898",
        "paper_authors": [
            "Shuo-Yiin Chang",
            "Bo Li",
            "David Rybach",
            "Yanzhang He",
            "Wei Li",
            "Tara N. Sainath",
            "Trevor Strohman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AutoSpeech 2020: The Second Automated Machine Learning Challenge for Speech Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1986",
        "paper_authors": [
            "Jingsong Wang",
            "Tom Ko",
            "Zhen Xu",
            "Xiawei Guo",
            "Souxiang Liu",
            "Wei-Wei Tu",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Building a Robust Word-Level Wakeword Verification Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2018",
        "paper_authors": [
            "Rajath Kumar",
            "Mike Rodehorst",
            "Joe Wang",
            "Jiacheng Gu",
            "Brian Kulis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Transformer-Based Audio Captioning Model with Keyword Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2087",
        "paper_authors": [
            "Yuma Koizumi",
            "Ryo Masumura",
            "Kyosuke Nishida",
            "Masahiro Yasuda",
            "Shoichiro Saito"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Architecture Search for Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3132",
        "paper_authors": [
            "Tong Mo",
            "Yakun Yu",
            "Mohammad Salameh",
            "Di Niu",
            "Shangling Jui"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Small-Footprint Keyword Spotting with Multi-Scale Temporal Convolution",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3177",
        "paper_authors": [
            "Ximin Li",
            "Xiaodong Wei",
            "Xiaowei Qin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Cyclic Noise as the Source Signal for Neural Source-Filter-Based Speech Waveform Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1018",
        "paper_authors": [
            "Xin Wang",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1137",
        "paper_authors": [
            "Jen-Yu Liu",
            "Yu-Hua Chen",
            "Yin-Cheng Yeh",
            "Yi-Hsuan Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Complex-Valued Variational Autoencoder: A Novel Deep Generative Model for Direct Representation of Complex Spectra",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1964",
        "paper_authors": [
            "Toru Nakashika"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attentron: Few-Shot Text-to-Speech Utilizing Attention-Based Variable-Length Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2096",
        "paper_authors": [
            "Seungwoo Choi",
            "Seungju Han",
            "Dongyoung Kim",
            "Sungjoo Ha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reformer-TTS: Neural Speech Synthesis with Reformer Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2189",
        "paper_authors": [
            "Hyeong Rae Ihm",
            "Joun Yeop Lee",
            "Byoung Jin Choi",
            "Sung Jun Cheon",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CycleGAN-VC3: Examining and Improving CycleGAN-VCs for Mel-Spectrogram Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2280",
        "paper_authors": [
            "Takuhiro Kaneko",
            "Hirokazu Kameoka",
            "Kou Tanaka",
            "Nobukatsu Hojo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "High Quality Streaming Speech Synthesis with Low, Sentence-Length-Independent Latency",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2464",
        "paper_authors": [
            "Nikolaos Ellinas",
            "Georgios Vamvoukakis",
            "Konstantinos Markopoulos",
            "Aimilios Chalamandaris",
            "Georgia Maniati",
            "Panos Kakoulidis",
            "Spyros Raptis",
            "June Sig Sung",
            "Hyoungmin Park",
            "Pirros Tsiakoulis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DurIAN: Duration Informed Attention Network for Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2968",
        "paper_authors": [
            "Chengzhu Yu",
            "Heng Lu",
            "Na Hu",
            "Meng Yu",
            "Chao Weng",
            "Kun Xu",
            "Peng Liu",
            "Deyi Tuo",
            "Shiyin Kang",
            "Guangzhi Lei",
            "Dan Su",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Speaker Text-to-Speech Synthesis Using Deep Gaussian Processes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3167",
        "paper_authors": [
            "Kentaro Mitsui",
            "Tomoki Koriyama",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Hybrid HMM-Waveglow Based Text-to-Speech Synthesizer Using Histogram Equalization for Low Resource Indian Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3180",
        "paper_authors": [
            "Mano Ranjith Kumar M.",
            "Sudhanshu Srivastava",
            "Anusha Prakash",
            "Hema A. Murthy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The INTERSPEECH 2020 Computational Paralinguistics Challenge: Elderly Emotion, Breathing & Masks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-32",
        "paper_authors": [
            "Bj\u00f6rn W. Schuller",
            "Anton Batliner",
            "Christian Bergler",
            "Eva-Maria Messner",
            "Antonia F. de C. Hamilton",
            "Shahin Amiriparian",
            "Alice Baird",
            "Georgios Rizos",
            "Maximilian Schmitt",
            "Lukas Stappen",
            "Harald Baumeister",
            "Alexis Deighton MacIntyre",
            "Simone Hantke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Higher Representations from Pre-Trained Deep Models with Data Augmentation for the COMPARE 2020 Challenge Mask Task",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1552",
        "paper_authors": [
            "Tomoya Koike",
            "Kun Qian",
            "Bj\u00f6rn W. Schuller",
            "Yoshiharu Yamamoto"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Surgical Mask Detection with Convolutional Neural Networks and Data Augmentations on Spectrograms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1692",
        "paper_authors": [
            "Steffen Illium",
            "Robert M\u00fcller",
            "Andreas Sedlmeier",
            "Claudia Linnhoff-Popien"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Surgical Mask Detection with Deep Recurrent Phonetic Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1723",
        "paper_authors": [
            "Philipp Klumpp",
            "Tom\u00e1s Arias-Vergara",
            "Juan Camilo V\u00e1squez-Correa",
            "Paula Andrea P\u00e9rez-Toro",
            "Florian H\u00f6nig",
            "Elmar N\u00f6th",
            "Juan Rafael Orozco-Arroyave"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic, Frame Clustering and Intelligibility Analyses for the INTERSPEECH 2020 ComParE Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2243",
        "paper_authors": [
            "Claude Montaci\u00e9",
            "Marie-Jos\u00e9 Caraty"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Text and Audio Embeddings for Multi-Dimension Elderly Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2290",
        "paper_authors": [
            "Mariana Juli\u00e3o",
            "Alberto Abad",
            "Helena Moniz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ensembling End-to-End Deep Models for Computational Paralinguistics Tasks: ComParE 2020 Mask and Breathing Sub-Challenges",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2666",
        "paper_authors": [
            "Maxim Markitantov",
            "Denis Dresvyanskiy",
            "Danila Mamontov",
            "Heysem Kaya",
            "Wolfgang Minker",
            "Alexey Karpov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analyzing Breath Signals for the Interspeech 2020 ComParE Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2778",
        "paper_authors": [
            "John Mendon\u00e7a",
            "Francisco Teixeira",
            "Isabel Trancoso",
            "Alberto Abad"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Attentive End-to-End Continuous Breath Sensing from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2832",
        "paper_authors": [
            "Alexis Deighton MacIntyre",
            "Georgios Rizos",
            "Anton Batliner",
            "Alice Baird",
            "Shahin Amiriparian",
            "Antonia F. de C. Hamilton",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Paralinguistic Classification of Mask Wearing by Image Classifiers and Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2857",
        "paper_authors": [
            "Jeno Szep",
            "Salim Hariri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploration of Acoustic and Lexical Cues for the INTERSPEECH 2020 Computational Paralinguistic Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2999",
        "paper_authors": [
            "Ziqing Yang",
            "Zifan An",
            "Zehao Fan",
            "Chengye Jing",
            "Houwei Cao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Is Everything Fine, Grandma? Acoustic and Linguistic Modeling for Robust Elderly Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3160",
        "paper_authors": [
            "Gizem Sogancioglu",
            "Oxana Verkholyak",
            "Heysem Kaya",
            "Dmitrii Fedotov",
            "Tobias Cad\u00e8e",
            "Albert Ali Salah",
            "Alexey Karpov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Are you Wearing a Mask? Improving Mask Detection from Speech Using Augmentation by Cycle-Consistent GANs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1329",
        "paper_authors": [
            "Nicolae-Catalin Ristea",
            "Radu Tudor Ionescu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "1-D Row-Convolution LSTM: Fast Streaming ASR at Accuracy Parity with LC-BLSTM",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2894",
        "paper_authors": [
            "Kshitiz Kumar",
            "Chaojun Liu",
            "Yifan Gong",
            "Jian Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low Latency End-to-End Streaming Speech Recognition with a Scout Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1292",
        "paper_authors": [
            "Chengyi Wang",
            "Yu Wu",
            "Liang Lu",
            "Shujie Liu",
            "Jinyu Li",
            "Guoli Ye",
            "Ming Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation from Offline to Streaming RNN Transducer for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2442",
        "paper_authors": [
            "Gakuto Kurata",
            "George Saon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parallel Rescoring with Transformer for Streaming On-Device Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2875",
        "paper_authors": [
            "Wei Li",
            "James Qin",
            "Chung-Cheng Chiu",
            "Ruoming Pang",
            "Yanzhang He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Hybrid Streaming ASR with Transformer Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2770",
        "paper_authors": [
            "Pau Baquero-Arnal",
            "Javier Jorge",
            "Adri\u00e0 Gim\u00e9nez",
            "Joan Albert Silvestre-Cerd\u00e0",
            "Javier Iranzo-S\u00e1nchez",
            "Albert Sanch\u00eds",
            "Jorge Civera",
            "Alfons Juan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Transformer-Based Acoustic Models Using Self-Attention with Augmented Memory",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2079",
        "paper_authors": [
            "Chunyang Wu",
            "Yongqiang Wang",
            "Yangyang Shi",
            "Ching-Feng Yeh",
            "Frank Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Monotonic Multihead Attention for Streaming ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1780",
        "paper_authors": [
            "Hirofumi Inaguma",
            "Masato Mimura",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Chunk-Aware Multihead Attention for Online End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1972",
        "paper_authors": [
            "Shiliang Zhang",
            "Zhifu Gao",
            "Haoneng Luo",
            "Ming Lei",
            "Jie Gao",
            "Zhijie Yan",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "High Performance Sequence-to-Sequence Model for Streaming Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1863",
        "paper_authors": [
            "Thai-Son Nguyen",
            "Ngoc-Quan Pham",
            "Sebastian St\u00fcker",
            "Alex Waibel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning Approaches for Streaming End-to-End Speech Recognition System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2345",
        "paper_authors": [
            "Vikas Joshi",
            "Rui Zhao",
            "Rupesh R. Mehta",
            "Kshitiz Kumar",
            "Jinyu Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tackling the ADReSS Challenge: A Multimodal Approach to the Automated Recognition of Alzheimer's Dementia",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2202",
        "paper_authors": [
            "Matej Martinc",
            "Senja Pollak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Disfluencies and Fine-Tuning Pre-Trained Language Models for Detection of Alzheimer's Disease",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2516",
        "paper_authors": [
            "Jiahong Yuan",
            "Yuchen Bian",
            "Xingyu Cai",
            "Jiaji Huang",
            "Zheng Ye",
            "Kenneth Church"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "To BERT or not to BERT: Comparing Speech and Language-Based Approaches for Alzheimer's Disease Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2557",
        "paper_authors": [
            "Aparna Balagopalan",
            "Benjamin Eyre",
            "Frank Rudzicz",
            "Jekaterina Novikova"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alzheimer's Dementia Recognition Through Spontaneous Speech: The ADReSS Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2571",
        "paper_authors": [
            "Saturnino Luz",
            "Fasih Haider",
            "Sofia de la Fuente",
            "Davida Fromm",
            "Brian MacWhinney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using State of the Art Speaker Recognition and Natural Language Processing Technologies to Detect Alzheimer's Disease and Assess its Severity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2587",
        "paper_authors": [
            "Raghavendra Pappagari",
            "Jaejin Cho",
            "Laureano Moro-Vel\u00e1zquez",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparison of Acoustic and Linguistics Methodologies for Alzheimer's Dementia Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2635",
        "paper_authors": [
            "Nicholas Cummins",
            "Yilin Pan",
            "Zhao Ren",
            "Julian Fritsch",
            "Venkata Srikanth Nallanthighal",
            "Heidi Christensen",
            "Daniel Blackburn",
            "Bj\u00f6rn W. Schuller",
            "Mathew Magimai-Doss",
            "Helmer Strik",
            "Aki H\u00e4rm\u00e4"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Modal Fusion with Gating Using Audio, Lexical and Disfluency Features for Alzheimer's Dementia Recognition from Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2721",
        "paper_authors": [
            "Morteza Rohanian",
            "Julian Hough",
            "Matthew Purver"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparing Natural Language Processing Techniques for Alzheimer's Dementia Prediction in Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2729",
        "paper_authors": [
            "Thomas Searle",
            "Zina M. Ibrahim",
            "Richard J. B. Dobson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multiscale System for Alzheimer's Dementia Recognition Through Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2781",
        "paper_authors": [
            "Erik Edwards",
            "Charles Dognin",
            "Bajibabu Bollepalli",
            "Maneesh Kumar Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The INESC-ID Multi-Modal System for the ADReSS 2020 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2833",
        "paper_authors": [
            "Anna Pompili",
            "Thomas Rolland",
            "Alberto Abad"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring MMSE Score Prediction Using Verbal and Non-Verbal Cues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3085",
        "paper_authors": [
            "Shahla Farzana",
            "Natalie Parde"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Inductive Transfer Learning for Detection of Alzheimer's Dementia and its Severity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3137",
        "paper_authors": [
            "Utkarsh Sarawgi",
            "Wazeer Zulfikar",
            "Nouran Soliman",
            "Pattie Maes"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploiting Multi-Modal Features from Pre-Trained Networks for Alzheimer's Dementia Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3153",
        "paper_authors": [
            "Junghyun Koo",
            "Jie Hwan Lee",
            "Jaewoo Pyo",
            "Yujin Jo",
            "Kyogu Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automated Screening for Alzheimer's Dementia Through Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3158",
        "paper_authors": [
            "Muhammad Shehram Shah Syed",
            "Zafi Sherhan Syed",
            "Margaret Lech",
            "Elena Pirogova"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NEC-TT Speaker Verification System for SRE'19 CTS Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1132",
        "paper_authors": [
            "Kong Aik Lee",
            "Koji Okabe",
            "Hitoshi Yamamoto",
            "Qiongqiong Wang",
            "Ling Guo",
            "Takafumi Koshinaka",
            "Jiacen Zhang",
            "Keisuke Ishikawa",
            "Koichi Shinoda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "THUEE System for NIST SRE19 CTS Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1245",
        "paper_authors": [
            "Ruyun Li",
            "Tianyu Liang",
            "Dandan Song",
            "Yi Liu",
            "Yangcheng Wu",
            "Can Xu",
            "Peng Ouyang",
            "Xianwei Zhang",
            "Xianhong Chen",
            "Weiqiang Zhang",
            "Shouyi Yin",
            "Liang He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Quality Assessment for Audio-Visual Verification Systems. The LOVe Submission to NIST SRE Challenge 2019",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1434",
        "paper_authors": [
            "Grigory Antipov",
            "Nicolas Gengembre",
            "Olivier Le Blouch",
            "Ga\u00ebl Le Lan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Speaker Recognition with a Cross-Modal Discriminative Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1814",
        "paper_authors": [
            "Ruijie Tao",
            "Rohan Kumar Das",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Association for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1996",
        "paper_authors": [
            "Suwon Shon",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Modality Matters: A Performance Leap on VoxCeleb",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2229",
        "paper_authors": [
            "Zhengyang Chen",
            "Shuai Wang",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Domain Adaptation with Discrepancy Minimization for Text-Independent Forensic Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2738",
        "paper_authors": [
            "Zhenyu Wang",
            "Wei Xia",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Open-Set Short Utterance Forensic Speaker Verification Using Teacher-Student Network with Explicit Inductive Bias",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2868",
        "paper_authors": [
            "Mufan Sang",
            "Wei Xia",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "JukeBox: A Multilingual Singer Recognition Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2972",
        "paper_authors": [
            "Anurag Chowdhury",
            "Austin Cozzo",
            "Arun Ross"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Identification for Household Scenarios with Self-Attention and Adversarial Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3025",
        "paper_authors": [
            "Ruirui Li",
            "Jyun-Yu Jiang",
            "Xian Wu",
            "Chu-Cheng Hsieh",
            "Andreas Stolcke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Keyword Spotting on Mobile Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1003",
        "paper_authors": [
            "Oleg Rybakov",
            "Natasha Kononenko",
            "Niranjan Subrahmanya",
            "Mirk\u00f3 Visontai",
            "Stella Laurenzo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Metadata-Aware End-to-End Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1262",
        "paper_authors": [
            "Hongyi Liu",
            "Apurva Abhyankar",
            "Yuriy Mishchenko",
            "Thibaud S\u00e9n\u00e9chal",
            "Gengshen Fu",
            "Brian Kulis",
            "Noah D. Stein",
            "Anish Shah",
            "Shiv Naga Prasad Vitaladevuni"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Audio: A New Information Hiding Method",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1294",
        "paper_authors": [
            "Yehao Kong",
            "Jiliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "S2IGAN: Speech-to-Image Generation via Adversarial Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1759",
        "paper_authors": [
            "Xinsheng Wang",
            "Tingting Qiao",
            "Jihua Zhu",
            "Alan Hanjalic",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Speech Recognition Benchmark for Air-Traffic Communications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2173",
        "paper_authors": [
            "Juan Zuluaga-Gomez",
            "Petr Motl\u00edcek",
            "Qingran Zhan",
            "Karel Vesel\u00fd",
            "Rudolf A. Braun"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Whisper Augmented End-to-End/Hybrid Speech Recognition System - CycleGAN Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2639",
        "paper_authors": [
            "Prithvi R. R. Gudepu",
            "Gowtham P. Vadisetti",
            "Abhishek Niranjan",
            "Kinnera Saranu",
            "Raghava Sarma",
            "M. Ali Basha Shaik",
            "Periyasamy Paramasivam"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Risk Forecasting from Earnings Calls Acoustics and Network Correlations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2649",
        "paper_authors": [
            "Ramit Sawhney",
            "Arshiya Aggarwal",
            "Piyush Khanna",
            "Puneet Mathur",
            "Taru Jain",
            "Rajiv Ratn Shah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpecMark: A Spectral Watermarking Framework for IP Protection of Speech Recognition Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2787",
        "paper_authors": [
            "Huili Chen",
            "Bita Darvish Rouhani",
            "Farinaz Koushanfar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating Automatically Generated Phoneme Captions for Images",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2870",
        "paper_authors": [
            "Justin van der Hout",
            "Zolt\u00e1n D'Haese",
            "Mark Hasegawa-Johnson",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Efficient Temporal Modeling Approach for Speech Emotion Recognition by Mapping Varied Duration Sentences into Fixed Number of Chunks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2636",
        "paper_authors": [
            "Wei-Cheng Lin",
            "Carlos Busso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Architecture Enhancing Robustness to Noise, Adversarial Attacks, and Cross-Corpus Setting for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3190",
        "paper_authors": [
            "Siddique Latif",
            "Rajib Rana",
            "Sara Khalifa",
            "Raja Jurdak",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Meta-Learning for Speech Emotion Recognition Considering Ambiguity of Emotion Labels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1082",
        "paper_authors": [
            "Takuya Fujioka",
            "Takeshi Homma",
            "Kenji Nagamatsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Temporal Attention Convolutional Network for Speech Emotion Recognition with Latent Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1520",
        "paper_authors": [
            "Jiaxing Liu",
            "Zhilei Liu",
            "Longbiao Wang",
            "Yuan Gao",
            "Lili Guo",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reconciliation of Multiple Corpora for Speech Emotion Recognition by Multiple Classifiers with an Adversarial Corpus Discriminator",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1618",
        "paper_authors": [
            "Zhi Zhu",
            "Yoshinao Sato"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conversational Emotion Recognition Using Self-Attention Mechanisms and Graph Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1703",
        "paper_authors": [
            "Zheng Lian",
            "Jianhua Tao",
            "Bin Liu",
            "Jian Huang",
            "Zhanlei Yang",
            "Rongjun Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EigenEmo: Spectral Utterance Representation Using Dynamic Mode Decomposition for Speech Emotion Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1762",
        "paper_authors": [
            "Shuiyang Mao",
            "P. C. Ching",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Advancing Multiple Instance Learning with Attention Modeling for Categorical Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1779",
        "paper_authors": [
            "Shuiyang Mao",
            "P. C. Ching",
            "C.-C. Jay Kuo",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Effect of Language Proficiency on the Perception of Segmental Foreign Accent",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1023",
        "paper_authors": [
            "Rub\u00e9n P\u00e9rez Ram\u00f3n",
            "Mar\u00eda Luisa Garc\u00eda Lecumberri",
            "Martin Cooke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Effect of Language Dominance on the Selective Attention of Segments and Tones in Urdu-Cantonese Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1678",
        "paper_authors": [
            "Yi Liu",
            "Jinghong Ning"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Effect of Input on the Production of English Tense and Lax Vowels by Chinese Learners: Evidence from an Elementary School in China",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2595",
        "paper_authors": [
            "Mengrou Li",
            "Ying Chen",
            "Jie Cui"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring the Use of an Artificial Accent of English to Assess Phonetic Learning in Monolingual and Bilingual Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2783",
        "paper_authors": [
            "Laura Spinu",
            "Jiwon Hwang",
            "Nadya Pincus",
            "Mariana Vasilita"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Dialectal Code-Switching on Speech Modules: A Study Using Egyptian Arabic Broadcast Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2271",
        "paper_authors": [
            "Shammur A. Chowdhury",
            "Younes Samih",
            "Mohamed Eldesouki",
            "Ahmed Ali"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bilingual Acoustic Voice Variation is Similarly Structured Across Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3095",
        "paper_authors": [
            "Khia A. Johnson",
            "Molly Babel",
            "Robert A. Fuhrman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Monolingual Data Selection Analysis for English-Mandarin Hybrid Code-Switching Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1582",
        "paper_authors": [
            "Haobo Zhang",
            "Haihua Xu",
            "Van Tung Pham",
            "Hao Huang",
            "Eng Siong Chng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perception and Production of Mandarin Initial Stops by Native Urdu Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1921",
        "paper_authors": [
            "Dan Du",
            "Xianjin Zhu",
            "Zhu Li",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Now You're Speaking My Language: Visual Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2921",
        "paper_authors": [
            "Triantafyllos Afouras",
            "Joon Son Chung",
            "Andrew Zisserman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Different Enhancement Roles of Covarying Cues in Thai and Mandarin Tones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1685",
        "paper_authors": [
            "Nari Rhee",
            "Jianjing Kuang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Singing Voice Extraction with Attention-Based Spectrograms Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1043",
        "paper_authors": [
            "Hao Shi",
            "Longbiao Wang",
            "Sheng Li",
            "Chenchen Ding",
            "Meng Ge",
            "Nan Li",
            "Jianwu Dang",
            "Hiroshi Seki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incorporating Broad Phonetic Information for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1400",
        "paper_authors": [
            "Yen-Ju Lu",
            "Chien-Feng Liao",
            "Xugang Lu",
            "Jeih-weih Hung",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Recursive Network with Dynamic Attention for Monaural Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1513",
        "paper_authors": [
            "Andong Li",
            "Chengshi Zheng",
            "Cunhang Fan",
            "Renhua Peng",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Constrained Ratio Mask for Speech Enhancement Using DNN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1920",
        "paper_authors": [
            "Hongjiang Yu",
            "Wei-Ping Zhu",
            "Yuhong Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SERIL: Noise Adaptive Speech Enhancement Using Regularization-Based Incremental Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2213",
        "paper_authors": [
            "Chi-Chang Lee",
            "Yu-Chen Lin",
            "Hsuan-Tien Lin",
            "Hsin-Min Wang",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Neural Speech Enhancement with a Denoising Variational Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2291",
        "paper_authors": [
            "Yoshiaki Bando",
            "Kouhei Sekiguchi",
            "Kazuyoshi Yoshii"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-Latency Single Channel Speech Dereverberation Using U-Net Convolutional Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2421",
        "paper_authors": [
            "Ahmet Emin Bulut",
            "Kazuhito Koishida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Single-Channel Speech Enhancement by Subspace Affinity Minimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2982",
        "paper_authors": [
            "Dung N. Tran",
            "Kazuhito Koishida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Noise Tokens: Learning Neural Noise Templates for Environment-Aware Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1030",
        "paper_authors": [
            "Haoyu Li",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NAAGN: Noise-Aware Attention-Gated Network for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1133",
        "paper_authors": [
            "Feng Deng",
            "Tao Jiang",
            "Xiaorui Wang",
            "Chen Zhang",
            "Yan Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Monaural Speech Enhancement Using Delayed Subband LSTM",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2091",
        "paper_authors": [
            "Xiaofei Li",
            "Radu Horaud"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "INTERSPEECH 2020 Deep Noise Suppression Challenge: A Fully Convolutional Recurrent Network (FCRN) for Joint Dereverberation and Denoising",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2439",
        "paper_authors": [
            "Maximilian Strake",
            "Bruno Defraene",
            "Kristoff Fluyt",
            "Wouter Tirry",
            "Tim Fingscheidt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2537",
        "paper_authors": [
            "Yanxin Hu",
            "Yun Liu",
            "Shubo Lv",
            "Mengtao Xing",
            "Shimin Zhang",
            "Yihui Fu",
            "Jian Wu",
            "Bihong Zhang",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual-Signal Transformation LSTM Network for Real-Time Noise Suppression",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2631",
        "paper_authors": [
            "Nils L. Westhausen",
            "Bernd T. Meyer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Perceptually-Motivated Approach for Low-Complexity, Real-Time Enhancement of Fullband Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2730",
        "paper_authors": [
            "Jean-Marc Valin",
            "Umut Isik",
            "Neerad Phansalkar",
            "Ritwik Giri",
            "Karim Helwani",
            "Arvindh Krishnaswamy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings, Semi-Supervised Conversational Data, and Biased Loss",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3027",
        "paper_authors": [
            "Umut Isik",
            "Ritwik Giri",
            "Neerad Phansalkar",
            "Jean-Marc Valin",
            "Karim Helwani",
            "Arvindh Krishnaswamy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3038",
        "paper_authors": [
            "Chandan K. A. Reddy",
            "Vishak Gopal",
            "Ross Cutler",
            "Ebrahim Beyrami",
            "Roger Cheng",
            "Harishchandra Dubey",
            "Sergiy Matusevych",
            "Robert Aichner",
            "Ashkan Aazami",
            "Sebastian Braun",
            "Puneet Rana",
            "Sriram Srinivasan",
            "Johannes Gehrke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Implication of Sound Level on Spatial Selective Auditory Attention for Cochlear Implant Users: Behavioral and Electrophysiological Measurement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2836",
        "paper_authors": [
            "Sara Akbarzadeh",
            "Sungmin Lee",
            "Chin-Tuan Tan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing the Interaural Time Difference of Bilateral Cochlear Implants with the Temporal Limits Encoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2507",
        "paper_authors": [
            "Yangyang Wan",
            "Huali Zhou",
            "Qinglin Meng",
            "Nengheng Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Clarity Improvement by Vocal Self-Training Using a Hearing Impairment Simulator and its Correlation with an Auditory Modulation Index",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1081",
        "paper_authors": [
            "Toshio Irino",
            "Soichi Higashiyama",
            "Hanako Yoshigi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of Phase Distortion on Perceived Speech Quality for Hearing-Impaired Listeners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1481",
        "paper_authors": [
            "Zhuohuang Zhang",
            "Donald S. Williamson",
            "Yi Shen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EEG-Based Short-Time Auditory Attention Detection Using Multi-Task Deep Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2013",
        "paper_authors": [
            "Zhuo Zhang",
            "Gaoyan Zhang",
            "Jianwu Dang",
            "Shuang Wu",
            "Di Zhou",
            "Longbiao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Interpreting Deep Learning Models to Understand Loss of Speech Intelligibility in Speech Disorders - Step 1: CNN Model-Based Phone Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2239",
        "paper_authors": [
            "Sondes Abderrazek",
            "Corinne Fredouille",
            "Alain Ghio",
            "Muriel Lalain",
            "Christine Meunier",
            "Virginie Woisard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Cognitive Impairment Classification by Generative Neural Network-Based Feature Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2433",
        "paper_authors": [
            "Bahman Mirheidari",
            "Daniel Blackburn",
            "Ronan O'Malley",
            "Annalena Venneri",
            "Traci Walker",
            "Markus Reuber",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UncommonVoice: A Crowdsourced Dataset of Dysphonic Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3093",
        "paper_authors": [
            "Meredith Moore",
            "Piyush Papreja",
            "Michael Saxon",
            "Visar Berisha",
            "Sethuraman Panchanathan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Automatic Assessment of Voice Disorders: A Clinical Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2160",
        "paper_authors": [
            "Purva Barche",
            "Krishna Gurugubelli",
            "Anil Kumar Vuppala"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BlaBla: Linguistic Feature Extraction for Clinical Analysis in Multiple Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2880",
        "paper_authors": [
            "Abhishek Shivkumar",
            "Jack Weston",
            "Raphael Lenain",
            "Emil Fristed"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Depthwise Separable Convolutional ResNet with Squeeze-and-Excitation Blocks for Small-Footprint Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1045",
        "paper_authors": [
            "Menglong Xu",
            "Xiao-Lei Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Detection Filters for Small Footprint Open-Vocabulary Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1186",
        "paper_authors": [
            "Th\u00e9odore Bluche",
            "Thibault Gisselbrecht"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Convolutional Spiking Neural Networks for Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1230",
        "paper_authors": [
            "Emre Yilmaz",
            "\u00d6zg\u00fcr Bora Gevrek",
            "Jibin Wu",
            "Yuxiang Chen",
            "Xuanbo Meng",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Aware Training for Far-Field Small-Footprint Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1412",
        "paper_authors": [
            "Haiwei Wu",
            "Yan Jia",
            "Yuanfei Nie",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Re-Weighted Interval Loss for Handling Data Imbalance Problem of End-to-End Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1644",
        "paper_authors": [
            "Kun Zhang",
            "Zhiyong Wu",
            "Daode Yuan",
            "Jian Luan",
            "Jia Jia",
            "Helen Meng",
            "Binheng Song"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Template Matching for Small-Footprint and Configurable Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1761",
        "paper_authors": [
            "Peng Zhang",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Scale Convolution for Robust Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2185",
        "paper_authors": [
            "Chen Yang",
            "Xue Wen",
            "Liming Song"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Investigation of Few-Shot Learning in Spoken Term Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2568",
        "paper_authors": [
            "Yangbin Chen",
            "Tom Ko",
            "Lifeng Shang",
            "Xiao Chen",
            "Xin Jiang",
            "Qing Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Keyword Search Based on Attention and Energy Scorer for Low Resource Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2613",
        "paper_authors": [
            "Zeyu Zhao",
            "Weiqiang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stacked 1D Convolutional Networks for End-to-End Small Footprint Voice Trigger Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2763",
        "paper_authors": [
            "Takuya Higuchi",
            "Mohammad Ghasemzadeh",
            "Kisun You",
            "Chandra Dhir"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Statistical and Neural Network Based Speech Activity Detection in Non-Stationary Acoustic Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1252",
        "paper_authors": [
            "Jens Heitkaemper",
            "Joerg Schmalenstroeer",
            "Reinhold Haeb-Umbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Diarization System Based on DPCA Algorithm for Fearless Steps Challenge Phase-2",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1666",
        "paper_authors": [
            "Xueshuai Zhang",
            "Wenchao Wang",
            "Pengyuan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The DKU Speech Activity Detection and Speaker Identification Systems for Fearless Steps Challenge Phase-02",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1915",
        "paper_authors": [
            "Qingjian Lin",
            "Tingle Li",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "\"This is Houston. Say again, please\". The Behavox System for the Apollo-11 Fearless Steps Challenge (Phase II)",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2822",
        "paper_authors": [
            "Arseniy Gorin",
            "Daniil Kulko",
            "Steven Grima",
            "Alex Glasman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FEARLESS STEPS Challenge (FS-2): Supervised Learning with Massive Naturalistic Apollo Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3054",
        "paper_authors": [
            "Aditya Joglekar",
            "John H. L. Hansen",
            "Meena Chandra Shekhar",
            "Abhijeet Sangwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Separating Varying Numbers of Sources with Auxiliary Autoencoding Loss",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-34",
        "paper_authors": [
            "Yi Luo",
            "Nima Mesgarani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Synthesis for Supervised Monaural Speech Separation in Time Domain",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1150",
        "paper_authors": [
            "Jingjing Chen",
            "Qirong Mao",
            "Dong Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Better Speech Representations by Worsening Interference",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1545",
        "paper_authors": [
            "Jun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Asteroid: The PyTorch-Based Audio Source Separation Toolkit for Researchers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1673",
        "paper_authors": [
            "Manuel Pariente",
            "Samuele Cornell",
            "Joris Cosentino",
            "Sunit Sivasankaran",
            "Efthymios Tzinis",
            "Jens Heitkaemper",
            "Michel Olvera",
            "Fabian-Robert St\u00f6ter",
            "Mathieu Hu",
            "Juan M. Mart\u00edn-Do\u00f1as",
            "David Ditter",
            "Ariel Frank",
            "Antoine Deleforge",
            "Emmanuel Vincent"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2205",
        "paper_authors": [
            "Jingjing Chen",
            "Qirong Mao",
            "Dong Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conv-TasSAN: Separative Adversarial Network Based on Conv-TasNet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2371",
        "paper_authors": [
            "Chengyun Deng",
            "Yi Zhang",
            "Shiqian Ma",
            "Yongtao Sha",
            "Hui Song",
            "Xiangang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Path RNN for Hierarchical Modeling of Long Sequential Data and its Application to Speaker Stream Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2388",
        "paper_authors": [
            "Keisuke Kinoshita",
            "Thilo von Neumann",
            "Marc Delcroix",
            "Tomohiro Nakatani",
            "Reinhold Haeb-Umbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Audio Source Separation Using Generative Priors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3115",
        "paper_authors": [
            "Vivek Sivaraman Narayanaswamy",
            "Jayaraman J. Thiagarajan",
            "Rushil Anirudh",
            "Andreas Spanias"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Latent Representation Learning for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1593",
        "paper_authors": [
            "Yuanhang Qiu",
            "Ruili Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An NMF-HMM Speech Enhancement Method Based on Kullback-Leibler Divergence",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1047",
        "paper_authors": [
            "Yang Xiang",
            "Liming Shi",
            "Jesper Lisby H\u00f8jvang",
            "Morten H\u00f8jfeldt Rasmussen",
            "Mads Gr\u00e6sb\u00f8ll Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Scale TCN: Exploring Better Temporal DNN Model for Causal Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1104",
        "paper_authors": [
            "Lu Zhang",
            "Mingjiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1193",
        "paper_authors": [
            "Quan Wang",
            "Ignacio L\u00f3pez-Moreno",
            "Mert Saglam",
            "Kevin W. Wilson",
            "Alan Chiao",
            "Renjie Liu",
            "Yanzhang He",
            "Wei Li",
            "Jason Pelecanos",
            "Marily Nika",
            "Alexander Gruenstein"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Separation Based on Multi-Stage Elaborated Dual-Path Deep BiLSTM with Auxiliary Identity Loss",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1537",
        "paper_authors": [
            "Ziqiang Shi",
            "Rujie Liu",
            "Jiqing Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sub-Band Knowledge Distillation Framework for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1539",
        "paper_authors": [
            "Xiang Hao",
            "Shixue Wen",
            "Xiangdong Su",
            "Yun Liu",
            "Guanglai Gao",
            "Xiaofei Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep Learning-Based Kalman Filter for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1551",
        "paper_authors": [
            "Sujan Kumar Roy",
            "Aaron Nicolson",
            "Kuldip K. Paliwal"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Subband Kalman Filtering with DNN Estimated Parameters for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1913",
        "paper_authors": [
            "Hongjiang Yu",
            "Wei-Ping Zhu",
            "Beno\u00eet Champagne"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bidirectional LSTM Network with Ordered Neurons for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2245",
        "paper_authors": [
            "Xiaoqi Li",
            "Yaxing Li",
            "Yuanjie Dong",
            "Shan Xu",
            "Zhihui Zhang",
            "Dan Wang",
            "Shengwu Xiong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Conditional Chain Model for Speech Separation and Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2418",
        "paper_authors": [
            "Jing Shi",
            "Jiaming Xu",
            "Yusuke Fujita",
            "Shinji Watanabe",
            "Bo Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised vs. Transfer Learning for Multimodal One-Shot Matching of Speech and Images",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-87",
        "paper_authors": [
            "Leanne Nortje",
            "Herman Kamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Speech Emotion Recognition Using Cross Attention with Aligned Audio and Text",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2312",
        "paper_authors": [
            "Yoonhyung Lee",
            "Seunghyun Yoon",
            "Kyomin Jung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Dependent Articulatory-to-Acoustic Mapping Using Real-Time MRI of the Vocal Tract",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-15",
        "paper_authors": [
            "Tam\u00e1s G\u00e1bor Csap\u00f3"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ultrasound-Based Articulatory-to-Acoustic Mapping with WaveGlow Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1031",
        "paper_authors": [
            "Tam\u00e1s G\u00e1bor Csap\u00f3",
            "Csaba Zaink\u00f3",
            "L\u00e1szl\u00f3 T\u00f3th",
            "G\u00e1bor Gosztolya",
            "Alexandra Mark\u00f3"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Subword Modeling Using Autoregressive Pretraining and Cross-Lingual Phone-Aware Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1170",
        "paper_authors": [
            "Siyuan Feng",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generative Adversarial Training Data Adaptation for Very Low-Resource Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1195",
        "paper_authors": [
            "Kohei Matsuura",
            "Masato Mimura",
            "Shinsuke Sakai",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Speech Completion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2110",
        "paper_authors": [
            "Kazuki Tsunematsu",
            "Johanes Effendi",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Unsupervised Sparsespeech Acoustic Models with Categorical Reparameterization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2629",
        "paper_authors": [
            "Benjamin Milde",
            "Chris Biemann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Sign Language Recognition via Temporal Deformable Convolutional Sequence Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2691",
        "paper_authors": [
            "Katerina Papadimitriou",
            "Gerasimos Potamianos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MLS: A Large-Scale Multilingual Dataset for Speech Research",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2826",
        "paper_authors": [
            "Vineel Pratap",
            "Qiantong Xu",
            "Anuroop Sriram",
            "Gabriel Synnaeve",
            "Ronan Collobert"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Combining Audio and Brain Activity for Predicting Speech Quality",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1559",
        "paper_authors": [
            "Ivan Halim Parmonangan",
            "Hiroki Tanaka",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The \"Sound of Silence\" in EEG - Cognitive Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2383",
        "paper_authors": [
            "Rini A. Sharon",
            "Hema A. Murthy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low Latency Auditory Attention Detection with Common Spatial Pattern Analysis of EEG Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2496",
        "paper_authors": [
            "Siqi Cai",
            "Enze Su",
            "Yonghao Song",
            "Longhan Xie",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Spectrogram Estimation from Intracranial Brain Activity Using a Quantization Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2946",
        "paper_authors": [
            "Miguel Angrick",
            "Christian Herff",
            "Garett D. Johnson",
            "Jerry J. Shih",
            "Dean J. Krusienski",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Speech Decoding for Amyotrophic Lateral Sclerosis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3071",
        "paper_authors": [
            "Debadatta Dash",
            "Paul Ferrari",
            "Angel W. Hernandez-Mulero",
            "Daragh Heitzman",
            "Sara G. Austin",
            "Jun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised ASR by End-to-End Self-Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1280",
        "paper_authors": [
            "Yang Chen",
            "Weiran Wang",
            "Chao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Training Strategies for End-to-End Speech Recognition in Digital Voice Assistants",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2036",
        "paper_authors": [
            "Hitesh Tulsiani",
            "Ashtosh Sapru",
            "Harish Arsikere",
            "Surabhi Punjabi",
            "Sri Garimella"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Serialized Output Training for End-to-End Overlapped Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-999",
        "paper_authors": [
            "Naoyuki Kanda",
            "Yashesh Gaur",
            "Xiaofei Wang",
            "Zhong Meng",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised Learning with Data Augmentation for End-to-End ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1337",
        "paper_authors": [
            "Felix Weninger",
            "Franco Mana",
            "Roberto Gemello",
            "Jes\u00fas Andr\u00e9s-Ferrer",
            "Puming Zhan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Minimum Word Error Rate Training of RNN-Transducer for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1557",
        "paper_authors": [
            "Jinxi Guo",
            "Gautam Tiwari",
            "Jasha Droppo",
            "Maarten Van Segbroeck",
            "Che-Wei Huang",
            "Andreas Stolcke",
            "Roland Maas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A New Training Pipeline for an Improved Neural Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1855",
        "paper_authors": [
            "Albert Zeyer",
            "Andr\u00e9 Merboldt",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Noisy Student Training for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1470",
        "paper_authors": [
            "Daniel S. Park",
            "Yu Zhang",
            "Ye Jia",
            "Wei Han",
            "Chung-Cheng Chiu",
            "Bo Li",
            "Yonghui Wu",
            "Quoc V. Le"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phoneme-to-Grapheme Conversion Based Large-Scale Pre-Training for End-to-End Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1930",
        "paper_authors": [
            "Ryo Masumura",
            "Naoki Makishima",
            "Mana Ihori",
            "Akihiko Takashima",
            "Tomohiro Tanaka",
            "Shota Orihashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Utterance Invariant Training for Hybrid Two-Pass End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3230",
        "paper_authors": [
            "Dhananjaya Gowda",
            "Ankur Kumar",
            "Kwangyoun Kim",
            "Hejung Yang",
            "Abhinav Garg",
            "Sachin Singh",
            "Jiyeon Kim",
            "Mehul Kumar",
            "Sichen Jin",
            "Shatrughan Singh",
            "Chanwoo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SCADA: Stochastic, Consistent and Adversarial Data Augmentation to Improve ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2920",
        "paper_authors": [
            "Gary Wang",
            "Andrew Rosenberg",
            "Zhehuai Chen",
            "Yu Zhang",
            "Bhuvana Ramabhadran",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fundamental Frequency Model for Postfiltering at Low Bitrates in a Transform-Domain Speech and Audio Codec",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1067",
        "paper_authors": [
            "Sneha Das",
            "Tom B\u00e4ckstr\u00f6m",
            "Guillaume Fuchs"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hearing-Impaired Bio-Inspired Cochlear Models for Real-Time Auditory Applications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2818",
        "paper_authors": [
            "Arthur Van Den Broucke",
            "Deepak Baby",
            "Sarah Verhulst"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Opus Low Bit Rate Quality with Neural Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2939",
        "paper_authors": [
            "Jan Skoglund",
            "Jean-Marc Valin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Differentiable Perceptual Audio Metric Learned from Just Noticeable Differences",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1191",
        "paper_authors": [
            "Pranay Manocha",
            "Adam Finkelstein",
            "Richard Zhang",
            "Nicholas J. Bryan",
            "Gautham J. Mysore",
            "Zeyu Jin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "StoRIR: Stochastic Room Impulse Response Generation for Audio Data Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2261",
        "paper_authors": [
            "Piotr Masztalski",
            "Mateusz Matuszewski",
            "Karol Piaskowski",
            "Michal Romaniuk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Open Source Implementation of ITU-T Recommendation P.808 with Validation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2665",
        "paper_authors": [
            "Babak Naderi",
            "Ross Cutler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DNN No-Reference PSTN Speech Quality Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2760",
        "paper_authors": [
            "Gabriel Mittag",
            "Ross Cutler",
            "Yasaman Hosseinkashi",
            "Michael Revow",
            "Sriram Srinivasan",
            "Naglakshmi Chande",
            "Robert Aichner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Intrusive Diagnostic Monitoring of Fullband Speech Quality",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1125",
        "paper_authors": [
            "Sebastian M\u00f6ller",
            "Tobias H\u00fcbschen",
            "Thilo Michael",
            "Gabriel Mittag",
            "Gerhard Schmidt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning of Articulatory Information Through Phone Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1139",
        "paper_authors": [
            "Abdolreza Sabzi Shahrebabaki",
            "Negar Olfati",
            "Sabato Marco Siniscalchi",
            "Giampiero Salvi",
            "Torbj\u00f8rn Svendsen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sequence-to-Sequence Articulatory Inversion Through Time Convolution of Sub-Band Frequency Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1140",
        "paper_authors": [
            "Abdolreza Sabzi Shahrebabaki",
            "Sabato Marco Siniscalchi",
            "Giampiero Salvi",
            "Torbj\u00f8rn Svendsen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discriminative Singular Spectrum Analysis for Bioacoustic Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2134",
        "paper_authors": [
            "Bernardo B. Gatto",
            "Eulanda Miranda dos Santos",
            "Juan Gabriel Colonna",
            "Naoya Sogi",
            "Lincon Sales de Souza",
            "Kazuhiro Fukui"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Rate Task-Specific Representation Learning from Acoustic-Articulatory Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2259",
        "paper_authors": [
            "Renuka Mannem",
            "Hima Jyothi R.",
            "Aravind Illa",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dysarthria Detection and Severity Assessment Using Rhythm-Based Metrics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2354",
        "paper_authors": [
            "Abner Hernandez",
            "Eun Jung Yeo",
            "Sunhee Kim",
            "Minhwa Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LungRN+NL: An Improved Adventitious Lung Sound Classification Using Non-Local Block ResNet Neural Network with Mixup Data Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2487",
        "paper_authors": [
            "Yi Ma",
            "Xinzi Xu",
            "Yongfu Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention and Encoder-Decoder Based Models for Transforming Articulatory Movements at Different Speaking Rates",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2708",
        "paper_authors": [
            "Abhayjeet Singh",
            "Aravind Illa",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adventitious Respiratory Classification Using Attentive Residual Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2790",
        "paper_authors": [
            "Zijiang Yang",
            "Shuo Liu",
            "Meishu Song",
            "Emilia Parada-Cabaleiro",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Surfboard: Audio Feature Extraction for Modern Machine Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2879",
        "paper_authors": [
            "Raphael Lenain",
            "Jack Weston",
            "Abhishek Shivkumar",
            "Emil Fristed"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Whisper Activity Detection Using CNN-LSTM Based Attention Pooling Network Trained for a Speaker Identification Task",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3217",
        "paper_authors": [
            "Abinay Reddy Naini",
            "Malla Satyapriya",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Natural Bilingual and Code-Switched Speech Synthesis Based on Mix of Monolingual Recordings and Cross-Lingual Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1163",
        "paper_authors": [
            "Shengkui Zhao",
            "Trung Hieu Nguyen",
            "Hao Wang",
            "Bin Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Lingual Multi-Speaker Text-to-Speech Synthesis for Voice Cloning with Online Speaker Enrollment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1464",
        "paper_authors": [
            "Zhaoyu Liu",
            "Brian Mak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Soft Windowing and Language Dependent Style Token for Code-Switching End-to-End Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1754",
        "paper_authors": [
            "Ruibo Fu",
            "Jianhua Tao",
            "Zhengqi Wen",
            "Jiangyan Yi",
            "Chunyu Qiang",
            "Tao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonological Features for 0-Shot Multilingual Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1821",
        "paper_authors": [
            "Marlene Staib",
            "Tian Huey Teh",
            "Alexandra Torresquintero",
            "Devang S. Ram Mohan",
            "Lorenzo Foglianti",
            "Raphael Lenain",
            "Jiameng Gao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Lingual Text-To-Speech Synthesis via Domain Adaptation and Perceptual Similarity Regression in Speaker Space",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2070",
        "paper_authors": [
            "Detai Xin",
            "Yuki Saito",
            "Shinnosuke Takamichi",
            "Tomoki Koriyama",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tone Learning in Low-Resource Bilingual TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2180",
        "paper_authors": [
            "Ruolan Liu",
            "Xue Wen",
            "Chunhui Lu",
            "Xiao Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Improving Code Mixed Speech Synthesis with Mixlingual Grapheme-to-Phoneme Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2654",
        "paper_authors": [
            "Shubham Bansal",
            "Arijit Mukherjee",
            "Sandeepkumar Satpal",
            "Rupesh Kumar Mehta"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generic Indic Text-to-Speech Synthesisers with Rapid Adaptation in an End-to-End Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2663",
        "paper_authors": [
            "Anusha Prakash",
            "Hema A. Murthy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Neural Speech Synthesis for Low-Resource Languages Through Multilingual Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2664",
        "paper_authors": [
            "Marcel de Korte",
            "Jaebok Kim",
            "Esther Klabbers"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One Model, Many Languages: Meta-Learning for Multilingual Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2679",
        "paper_authors": [
            "Tom\u00e1s Nekvinda",
            "Ondrej Dusek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "In Defence of Metric Learning for Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1064",
        "paper_authors": [
            "Joon Son Chung",
            "Jaesung Huh",
            "Seongkyu Mun",
            "Minjae Lee",
            "Hee-Soo Heo",
            "Soyeon Choe",
            "Chiheon Ham",
            "Sunghwan Jung",
            "Bong-Jin Lee",
            "Icksang Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Meta-Learning for Short Utterance Speaker Recognition with Imbalance Length Pairs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1283",
        "paper_authors": [
            "Seong Min Kye",
            "Youngmoon Jung",
            "Haebeom Lee",
            "Sung Ju Hwang",
            "Hoirin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Segment-Level Effects of Gender, Nationality and Emotion Information on Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1700",
        "paper_authors": [
            "Kai Li",
            "Masato Akagi",
            "Yibo Wu",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly Supervised Training of Hierarchical Attention Networks for Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1774",
        "paper_authors": [
            "Yanpei Shi",
            "Qiang Huang",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Task Learning for Voice Related Recognition Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1857",
        "paper_authors": [
            "Ana Montalvo",
            "Jos\u00e9 R. Calvo",
            "Jean-Fran\u00e7ois Bonastre"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Training of Siamese Networks for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1882",
        "paper_authors": [
            "Umair Khan",
            "Javier Hernando"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Effective Speaker Recognition Method Based on Joint Identification and Verification Supervisions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1922",
        "paper_authors": [
            "Ying Liu",
            "Yan Song",
            "Yiheng Jiang",
            "Ian McLoughlin",
            "Lin Liu",
            "Li-Rong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Aware Linear Discriminant Analysis in Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2061",
        "paper_authors": [
            "Naijun Zheng",
            "Xixin Wu",
            "Jinghua Zhong",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Domain Adaptation for Speaker Verification Using Partially Shared Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2226",
        "paper_authors": [
            "Zhengyang Chen",
            "Shuai Wang",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Scoring at Multi-Granularity for L2 Pronunciation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1282",
        "paper_authors": [
            "Binghuai Lin",
            "Liyuan Wang",
            "Xiaoli Feng",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Effective End-to-End Modeling Approach for Mispronunciation Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1605",
        "paper_authors": [
            "Tien-Hong Lo",
            "Shi-Yan Weng",
            "Hsiu-Jui Chang",
            "Berlin Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An End-to-End Mispronunciation Detection System for L2 English Speech Leveraging Novel Anti-Phone Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1616",
        "paper_authors": [
            "Bi-Cheng Yan",
            "Meng-Che Wu",
            "Hsiao-Tsung Hung",
            "Berlin Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Feature Adaptation Using Adversarial Multi-Task Training for Automatic Evaluation of Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1657",
        "paper_authors": [
            "Richeng Duan",
            "Nancy F. Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pronunciation Erroneous Tendency Detection with Language Adversarial Represent Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2033",
        "paper_authors": [
            "Longfei Yang",
            "Kaiqi Fu",
            "Jinsong Zhang",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR-Free Pronunciation Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2623",
        "paper_authors": [
            "Sitong Cheng",
            "Zhixin Liu",
            "Lantian Li",
            "Zhiyuan Tang",
            "Dong Wang",
            "Thomas Fang Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection of Accent and Lexical Pronunciation Errors in Spontaneous Non-Native English Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2881",
        "paper_authors": [
            "Konstantinos Kyriakopoulos",
            "Kate M. Knill",
            "Mark J. F. Gales"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Context-Aware Goodness of Pronunciation for Computer-Assisted Pronunciation Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2953",
        "paper_authors": [
            "Jiatong Shi",
            "Nan Huo",
            "Qin Jin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recognize Mispronunciations to Improve Non-Native Acoustic Modeling Through a Phone Decoder Built from One Edit Distance Finite State Automaton",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3109",
        "paper_authors": [
            "Wei Chu",
            "Yang Liu",
            "Jianwei Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Partial AUC Optimisation Using Recurrent Neural Networks for Music Detection with Limited Training Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1108",
        "paper_authors": [
            "Pablo Gimeno",
            "Victoria Mingote",
            "Alfonso Ortega Gim\u00e9nez",
            "Antonio Miguel",
            "Eduardo Lleida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Open-Source Voice Type Classifier for Child-Centered Daylong Recordings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1690",
        "paper_authors": [
            "Marvin Lavechin",
            "Ruben Bousbib",
            "Herv\u00e9 Bredin",
            "Emmanuel Dupoux",
            "Alejandrina Cristi\u00e0"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Competing Speaker Count Estimation on the Fusion of the Spectral and Spatial Embedding Space",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1781",
        "paper_authors": [
            "Chao Peng",
            "Xihong Wu",
            "Tianshu Qu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Multi-Speaker Tracking Based on the GLMB Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1969",
        "paper_authors": [
            "Shoufeng Lin",
            "Xinyuan Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Speech Robustness for Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2365",
        "paper_authors": [
            "Shuo Liu",
            "Andreas Triantafyllopoulos",
            "Zhao Ren",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identify Speakers in Cocktail Parties with End-to-End Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2430",
        "paper_authors": [
            "Junzhe Zhu",
            "Mark Hasegawa-Johnson",
            "Leda Sari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Talker ASR for an Unknown Number of Sources: Joint Training of Source Counting, Separation and ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2519",
        "paper_authors": [
            "Thilo von Neumann",
            "Christoph B\u00f6ddeker",
            "Lukas Drude",
            "Keisuke Kinoshita",
            "Marc Delcroix",
            "Tomohiro Nakatani",
            "Reinhold Haeb-Umbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attentive Convolutional Recurrent Neural Network Using Phoneme-Level Acoustic Representation for Rare Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2585",
        "paper_authors": [
            "Shreya G. Upadhyay",
            "Bo-Hao Su",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting and Counting Overlapping Speakers in Distant Speech Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2671",
        "paper_authors": [
            "Samuele Cornell",
            "Maurizio Omologo",
            "Stefano Squartini",
            "Emmanuel Vincent"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "All-in-One Transformer: Unifying Speech Recognition, Audio Tagging, and Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2757",
        "paper_authors": [
            "Niko Moritz",
            "Gordon Wichern",
            "Takaaki Hori",
            "Jonathan Le Roux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Silent Paralinguistics: Deriving Speaking Mode and Speaker ID from Electromyographic Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2848",
        "paper_authors": [
            "Lorenz Diener",
            "Shahin Amiriparian",
            "Catarina Botelho",
            "Kevin Scheck",
            "Dennis K\u00fcster",
            "Isabel Trancoso",
            "Bj\u00f6rn W. Schuller",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Collaborative Task Performance Using Graph Interlocutor Acoustic Network in Small Group Interaction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1698",
        "paper_authors": [
            "Shun-Chang Zhong",
            "Bo-Hao Su",
            "Wei Huang",
            "Yi-Ching Liu",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Very Short-Term Conflict Intensity Estimation Using Fisher Vectors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2349",
        "paper_authors": [
            "G\u00e1bor Gosztolya"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gaming Corpus for Studying Social Screams",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2553",
        "paper_authors": [
            "Hiroki Mori",
            "Yuki Kikuchi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Discrimination in Humans and Machines: Effects of Speaking Style Variability",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3004",
        "paper_authors": [
            "Amber Afshan",
            "Jody Kreiman",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Prediction of Confidence Level from Children's Oral Reading Recordings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2276",
        "paper_authors": [
            "Kamini Sabu",
            "Preeti Rao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards a Comprehensive Assessment of Speech Intelligibility for Pathological Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2693",
        "paper_authors": [
            "Wei Xue",
            "Viviana Mendoza Ramos",
            "Wieke Harmsen",
            "Catia Cucchiarini",
            "R. W. N. M. van Hout",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Communication Channels and Actor's Gender on Emotion Identification by Native Mandarin Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1498",
        "paper_authors": [
            "Yi Lin",
            "Hongwei Ding"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detection of Voicing and Place of Articulation of Fricatives with Deep Learning in a Virtual Speech and Language Therapy Tutor",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2821",
        "paper_authors": [
            "Ivo Anjos",
            "Maxine Esk\u00e9nazi",
            "Nuno Marques",
            "Margarida Grilo",
            "Isabel Guimar\u00e3es",
            "Jo\u00e3o Magalh\u00e3es",
            "Sofia Cavaco"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Learning for Sequence-to-Sequence Text-to-Speech for Low-Resource Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1403",
        "paper_authors": [
            "Haitong Zhang",
            "Yue Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conditional Spoken Digit Generation with StyleGAN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1461",
        "paper_authors": [
            "Kasperi Palkama",
            "Lauri Juvela",
            "Alexander Ilin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Universal Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1590",
        "paper_authors": [
            "Jingzhou Yang",
            "Lei He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Independent Mel-Cepstrum Estimation from Articulator Movements Using D-Vector Input",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1630",
        "paper_authors": [
            "Kouichi Katsurada",
            "Korin Richmond"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Monotonicity for Robust Autoregressive Transformer TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1751",
        "paper_authors": [
            "Xiangyu Liang",
            "Zhiyong Wu",
            "Runnan Li",
            "Yanqing Liu",
            "Sheng Zhao",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incremental Text to Speech for Neural Sequence-to-Sequence Models Using Reinforcement Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1822",
        "paper_authors": [
            "Devang S. Ram Mohan",
            "Raphael Lenain",
            "Lorenzo Foglianti",
            "Tian Huey Teh",
            "Marlene Staib",
            "Alexandra Torresquintero",
            "Jiameng Gao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised Learning for Multi-Speaker Text-to-Speech Synthesis Using Discrete Speech Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1824",
        "paper_authors": [
            "Tao Tu",
            "Yuan-Jui Chen",
            "Alexander H. Liu",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Joint Articulatory-Acoustic Representations with Normalizing Flows",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2004",
        "paper_authors": [
            "Pramit Saha",
            "Sidney S. Fels"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Effective Additional Contextual Factors in DNN-Based Spontaneous Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2469",
        "paper_authors": [
            "Yuki Yamashita",
            "Tomoki Koriyama",
            "Yuki Saito",
            "Shinnosuke Takamichi",
            "Yusuke Ijima",
            "Ryo Masumura",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hider-Finder-Combiner: An Adversarial Architecture for General Speech Signal Modification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2558",
        "paper_authors": [
            "Jacob J. Webber",
            "Olivier Perrotin",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Wav2Spk: A Simple DNN Architecture for Learning Speaker Embeddings from Waveforms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1287",
        "paper_authors": [
            "Wei-Wei Lin",
            "Man-Wai Mak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How Does Label Noise Affect the Quality of Speaker Embeddings?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1395",
        "paper_authors": [
            "Minh Pham",
            "Zeqian Li",
            "Jacob Whitehill"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparative Re-Assessment of Feature Extractors for Deep Speaker Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1765",
        "paper_authors": [
            "Xuechen Liu",
            "Md. Sahidullah",
            "Tomi Kinnunen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Representation Learning Using Global Context Guided Channel and Time-Frequency Transformations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1845",
        "paper_authors": [
            "Wei Xia",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intra-Class Variation Reduction of Speaker Representation in Disentanglement Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2075",
        "paper_authors": [
            "Yoohwan Kwon",
            "Soo-Whan Chung",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Compact Speaker Embedding: lrx-Vector",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2106",
        "paper_authors": [
            "Munir Georges",
            "Jonathan Huang",
            "Tobias Bocklet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cosine-Distance Virtual Adversarial Training for Semi-Supervised Speaker-Discriminative Acoustic Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2270",
        "paper_authors": [
            "Florian L. Kreyssig",
            "Philip C. Woodland"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Speaker Embedding with Long Short Term Centroid Learning for Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2470",
        "paper_authors": [
            "Junyi Peng",
            "Rongzhi Gu",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Discriminant Analysis for Deep Speaker Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2542",
        "paper_authors": [
            "Lantian Li",
            "Dong Wang",
            "Thomas Fang Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Speaker Embedding from Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2970",
        "paper_authors": [
            "Jaejin Cho",
            "Piotr Zelasko",
            "Jes\u00fas Villalba",
            "Shinji Watanabe",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Noisy-Reverberant Speech Enhancement Using DenseUNet with Time-Frequency Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2952",
        "paper_authors": [
            "Yan Zhao",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Loss Functions and Recurrency Training for GAN-Based Speech Enhancement Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1169",
        "paper_authors": [
            "Zhuohuang Zhang",
            "Chengyun Deng",
            "Yi Shen",
            "Donald S. Williamson",
            "Yongtao Sha",
            "Yi Zhang",
            "Hui Song",
            "Xiangang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Adversarial Multi-Task Learning for Vocoder-Based Monaural Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1496",
        "paper_authors": [
            "Zhihao Du",
            "Ming Lei",
            "Jiqing Han",
            "Shiliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Speech Inpainting of Time-Frequency Masks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1532",
        "paper_authors": [
            "Mikolaj Kegler",
            "Pierre Beckmann",
            "Milos Cernak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time Single-Channel Deep Neural Network-Based Speech Enhancement on Edge Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1901",
        "paper_authors": [
            "Nikhil Shankar",
            "Gautam Shreedhar Bhat",
            "Issa M. S. Panahi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Speech Enhancement Using a Time-Domain GAN with Mask Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1946",
        "paper_authors": [
            "Ju Lin",
            "Sufeng Niu",
            "Adriaan J. de Lind van Wijngaarden",
            "Jerome L. McClendon",
            "Melissa C. Smith",
            "Kuang-Ching Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real Time Speech Enhancement in the Waveform Domain",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2409",
        "paper_authors": [
            "Alexandre D\u00e9fossez",
            "Gabriel Synnaeve",
            "Yossi Adi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2443",
        "paper_authors": [
            "Michal Romaniuk",
            "Piotr Masztalski",
            "Karol Piaskowski",
            "Mateusz Matuszewski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Stream Attention-Based BLSTM with Feature Segmentation for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1199",
        "paper_authors": [
            "Yuya Chiba",
            "Takashi Nose",
            "Akinori Ito"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Microphone Array Post-Filter for Target Speech Enhancement Without a Prior Information of Point Interferers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1351",
        "paper_authors": [
            "Guanjun Li",
            "Shan Liang",
            "Shuai Nie",
            "Wenju Liu",
            "Zhanlei Yang",
            "Longshuai Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Similarity-and-Independence-Aware Beamformer: Method for Target Source Extraction Using Magnitude Spectrogram as Reference",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1365",
        "paper_authors": [
            "Atsuo Hiroe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Method of Random Directions Optimization for Stereo Audio Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1409",
        "paper_authors": [
            "Oleg Golokolenko",
            "Gerald Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gated Recurrent Fusion of Spatial and Spectral Features for Multi-Channel Speech Separation with Deep Embedding Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1548",
        "paper_authors": [
            "Cunhang Fan",
            "Jianhua Tao",
            "Bin Liu",
            "Jiangyan Yi",
            "Zhengqi Wen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Minimal Distortion Principle for Blind Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2158",
        "paper_authors": [
            "Robin Scheibler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Lightweight Model Based on Separable Convolution for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2408",
        "paper_authors": [
            "Ying Zhong",
            "Ying Hu",
            "Hao Huang",
            "Wushour Silamu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Meta Multi-Task Learning for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2624",
        "paper_authors": [
            "Ruichu Cai",
            "Kaibin Guo",
            "Boyan Xu",
            "Xiaoyan Yang",
            "Zhenjie Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GEV Beamforming Supported by DOA-Based Masks Generated on Pairs of Microphones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2687",
        "paper_authors": [
            "Fran\u00e7ois Grondin",
            "Jean-Samuel Lauzon",
            "Jonathan Vincent",
            "Fran\u00e7ois Michaud"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Accurate Detection of Wake Word Start and End Using a CNN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1491",
        "paper_authors": [
            "Christin Jose",
            "Yuriy Mishchenko",
            "Thibaud S\u00e9n\u00e9chal",
            "Anish Shah",
            "Alex Escott",
            "Shiv Naga Prasad Vitaladevuni"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hybrid Transformer/CTC Networks for Hardware Efficient Voice Triggering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1330",
        "paper_authors": [
            "Saurabh Adya",
            "Vineet Garg",
            "Siddharth Sigtia",
            "Pramod Simha",
            "Chandra Dhir"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MatchboxNet: 1D Time-Channel Separable Convolutional Neural Network Architecture for Speech Commands Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1058",
        "paper_authors": [
            "Somshubra Majumdar",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Iterative Compression of End-to-End ASR Model Using AutoML",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1894",
        "paper_authors": [
            "Abhinav Mehrotra",
            "Lukasz Dudziak",
            "Jinsu Yeo",
            "Young-Yoon Lee",
            "Ravichander Vipperla",
            "Mohamed S. Abdelfattah",
            "Sourav Bhattacharya",
            "Samin Ishtiaq",
            "Alberto Gil C. P. Ramos",
            "SangJeong Lee",
            "Daehyun Kim",
            "Nicholas D. Lane"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Quantization Aware Training with Absolute-Cosine Regularization for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1991",
        "paper_authors": [
            "Hieu Duy Nguyen",
            "Anastasios Alexandridis",
            "Athanasios Mouchtaris"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming On-Device End-to-End ASR System for Privacy-Sensitive Voice-Typing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3172",
        "paper_authors": [
            "Abhinav Garg",
            "Gowtham P. Vadisetti",
            "Dhananjaya Gowda",
            "Sichen Jin",
            "Aditya Jayasimha",
            "Youngho Han",
            "Jiyeon Kim",
            "Junmo Park",
            "Kwangyoun Kim",
            "Sooyeon Kim",
            "Young-Yoon Lee",
            "Kyungbo Min",
            "Chanwoo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scaling Up Online Speech Recognition Using ConvNets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2840",
        "paper_authors": [
            "Vineel Pratap",
            "Qiantong Xu",
            "Jacob Kahn",
            "Gilad Avidov",
            "Tatiana Likhomanenko",
            "Awni Y. Hannun",
            "Vitaliy Liptchinsky",
            "Gabriel Synnaeve",
            "Ronan Collobert"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Listen Attentively, and Spell Once: Whole Sentence Generation via a Non-Autoregressive Architecture for Low-Latency Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1600",
        "paper_authors": [
            "Ye Bai",
            "Jiangyan Yi",
            "Jianhua Tao",
            "Zhengkun Tian",
            "Zhengqi Wen",
            "Shuai Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rescore in a Flash: Compact, Cache Efficient Hashing Data Structures for n-Gram Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1939",
        "paper_authors": [
            "Grant P. Strimel",
            "Ariya Rastrow",
            "Gautam Tiwari",
            "Adrien Pi\u00e9rard",
            "Jon Webb"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Speaker Emotion Conversion via Latent Variable Regularization and a Chained Encoder-Decoder-Predictor Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1323",
        "paper_authors": [
            "Ravi Shankar",
            "Hsi-Wei Hsieh",
            "Nicolas Charon",
            "Archana Venkataraman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Parallel Emotion Conversion Using a Deep-Generative Hybrid Network and an Adversarial Pair Discriminator",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1325",
        "paper_authors": [
            "Ravi Shankar",
            "Jacob Sager",
            "Archana Venkataraman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Laughter Synthesis: Combining Seq2seq Modeling with Transfer Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1423",
        "paper_authors": [
            "No\u00e9 Tits",
            "Kevin El Haddad",
            "Thierry Dutoit"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nonparallel Emotional Speech Conversion Using VAE-GAN",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1647",
        "paper_authors": [
            "Yuexin Cao",
            "Zhengchen Liu",
            "Minchuan Chen",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Principal Style Components: Expressive Style Control and Cross-Speaker Transfer in Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1854",
        "paper_authors": [
            "Alexander Sorin",
            "Slava Shechtman",
            "Ron Hoory"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2014",
        "paper_authors": [
            "Kun Zhou",
            "Berrak Sisman",
            "Mingyang Zhang",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Controlling the Strength of Emotions in Speech-Like Emotional Sound Generated by WaveNet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2064",
        "paper_authors": [
            "Kento Matsumoto",
            "Sunao Hara",
            "Masanobu Abe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Syllable-Level Discrete Prosodic Representation for Expressive Speech Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2228",
        "paper_authors": [
            "Guangyan Zhang",
            "Ying Qin",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simultaneous Conversion of Speaker Identity and Emotion Based on Multiple-Domain Adaptive RBM",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2262",
        "paper_authors": [
            "Takuya Kishida",
            "Shin Tsukamoto",
            "Toru Nakashika"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploiting Deep Sentential Context for Expressive End-to-End Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2423",
        "paper_authors": [
            "Fengyu Yang",
            "Shan Yang",
            "Qinghua Wu",
            "Yujun Wang",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical Multi-Grained Generative Model for Expressive Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2477",
        "paper_authors": [
            "Yukiya Hono",
            "Kazuna Tsuboi",
            "Kei Sawada",
            "Kei Hashimoto",
            "Keiichiro Oura",
            "Yoshihiko Nankaku",
            "Keiichi Tokuda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GAN-Based Data Generation for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2898",
        "paper_authors": [
            "Sefik Emre Eskimez",
            "Dimitrios Dimitriadis",
            "Robert Gmyr",
            "Kenichi Kumanati"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Phonetic Bases of Vocal Expressed Emotion: Natural versus Acted",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3046",
        "paper_authors": [
            "Hira Dhamyal",
            "Shahan Ali Memon",
            "Bhiksha Raj",
            "Rita Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The INTERSPEECH 2020 Far-Field Speaker Verification Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1249",
        "paper_authors": [
            "Xiaoyi Qin",
            "Ming Li",
            "Hui Bu",
            "Wei Rao",
            "Rohan Kumar Das",
            "Shrikanth Narayanan",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Embedding Learning for Text-Dependent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1354",
        "paper_authors": [
            "Peng Zhang",
            "Peng Hu",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "STC-Innovation Speaker Recognition Systems for Far-Field Speaker Verification Challenge 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2580",
        "paper_authors": [
            "Aleksei Gusev",
            "Vladimir Volokhov",
            "Alisa Vinogradova",
            "Tseren Andzhukaev",
            "Andrey Shulipa",
            "Sergey Novoselov",
            "Timur Pekhovsky",
            "Alexander Kozlov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NPU Speaker Verification System for INTERSPEECH 2020 Far-Field Speaker Verification Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2688",
        "paper_authors": [
            "Li Zhang",
            "Jian Wu",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The JD AI Speaker Verification System for the FFSVC 2020 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3062",
        "paper_authors": [
            "Ying Tong",
            "Wei Xue",
            "Shanluo Huang",
            "Lu Fan",
            "Chao Zhang",
            "Guohong Ding",
            "Xiaodong He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FaceFilter: Audio-Visual Speech Separation Using Still Images",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1065",
        "paper_authors": [
            "Soo-Whan Chung",
            "Soyeon Choe",
            "Joon Son Chung",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Seeing Voices and Hearing Voices: Learning Discriminative Embeddings Using Cross-Modal Self-Supervision",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1113",
        "paper_authors": [
            "Soo-Whan Chung",
            "Hong-Goo Kang",
            "Joon Son Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fusion Architectures for Word-Based Audiovisual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2117",
        "paper_authors": [
            "Michael Wand",
            "J\u00fcrgen Schmidhuber"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Multi-Channel Recognition of Overlapped Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2346",
        "paper_authors": [
            "Jianwei Yu",
            "Bo Wu",
            "Rongzhi Gu",
            "Shi-Xiong Zhang",
            "Lianwu Chen",
            "Yong Xu",
            "Meng Yu",
            "Dan Su",
            "Dong Yu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TMT: A Transformer-Based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-Aware Dialog",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2359",
        "paper_authors": [
            "Wubo Li",
            "Dongwei Jiang",
            "Wei Zou",
            "Xiangang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Should we Hard-Code the Recurrence Concept or Learn it Instead ? Exploring the Transformer Architecture for Audio-Visual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2480",
        "paper_authors": [
            "George Sterpu",
            "Christian Saam",
            "Naomi Harte"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Resource-Adaptive Deep Learning for Visual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3003",
        "paper_authors": [
            "Alexandros Koumparoulis",
            "Gerasimos Potamianos",
            "Samuel Thomas",
            "Edmilson da Silva Morais"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech-Image Semantic Alignment Does Not Depend on Any Prior Classification Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3024",
        "paper_authors": [
            "Masood S. Mortazavi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lip Graph Assisted Audio-Visual Speech Recognition Using Bidirectional Synchronous Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3146",
        "paper_authors": [
            "Hong Liu",
            "Zhan Chen",
            "Bing Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Caption Alignment for Low Resource Audio-Visual Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3157",
        "paper_authors": [
            "Vighnesh Reddy Konda",
            "Mayur Warialani",
            "Rakesh Prasanth Achari",
            "Varad Bhatnagar",
            "Jayaprakash Akula",
            "Preethi Jyothi",
            "Ganesh Ramakrishnan",
            "Gholamreza Haffari",
            "Pankaj Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Successes, Challenges and Opportunities for Speech Technology in Conversational Agents",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2020/mevawalla20_interspeech.html",
        "paper_authors": [
            "Shehzad Mevawalla"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vocoder-Based Speech Synthesis from Silent Videos",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1026",
        "paper_authors": [
            "Daniel Michelsanti",
            "Olga Slizovskaia",
            "Gloria Haro",
            "Emilia G\u00f3mez",
            "Zheng-Hua Tan",
            "Jesper Jensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Quasi-Periodic Parallel WaveGAN Vocoder: A Non-Autoregressive Pitch-Dependent Dilated Convolution Model for Parametric Speech Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1070",
        "paper_authors": [
            "Yi-Chiao Wu",
            "Tomoki Hayashi",
            "Takuma Okamoto",
            "Hisashi Kawai",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Cyclical Post-Filtering Approach to Mismatch Refinement of Neural Vocoder for Text-to-Speech Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1072",
        "paper_authors": [
            "Yi-Chiao Wu",
            "Patrick Lumban Tobing",
            "Kazuki Yasuhara",
            "Noriyuki Matsunaga",
            "Yamato Ohtani",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio Dequantization for High Fidelity Audio Generation in Flow-Based Neural Vocoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1226",
        "paper_authors": [
            "Hyun-Wook Yoon",
            "Sang-Hoon Lee",
            "Hyeong-Rae Noh",
            "Seong-Whan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "StrawNet: Self-Training WaveNet for TTS in Low-Data Regimes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1437",
        "paper_authors": [
            "Manish Sharma",
            "Tom Kenter",
            "Rob Clark"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Efficient Subband Linear Prediction for LPCNet-Based Neural Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1463",
        "paper_authors": [
            "Yang Cui",
            "Xi Wang",
            "Lei He",
            "Frank K. Soong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reverberation Modeling for Source-Filter-Based Neural Vocoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1613",
        "paper_authors": [
            "Yang Ai",
            "Xin Wang",
            "Junichi Yamagishi",
            "Zhen-Hua Ling"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bunched LPCNet: Vocoder for Low-Cost Neural Text-To-Speech Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2041",
        "paper_authors": [
            "Ravichander Vipperla",
            "Sangjun Park",
            "Kihyun Choo",
            "Samin Ishtiaq",
            "Kyoungbo Min",
            "Sourav Bhattacharya",
            "Abhinav Mehrotra",
            "Alberto Gil C. P. Ramos",
            "Nicholas D. Lane"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Text-to-Speech with a Modeling-by-Generation Excitation Vocoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2116",
        "paper_authors": [
            "Eunwoo Song",
            "Min-Jae Hwang",
            "Ryuichi Yamamoto",
            "Jin-Seob Kim",
            "Ohsung Kwon",
            "Jae-Min Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeedySpeech: Efficient Neural Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2867",
        "paper_authors": [
            "Jan Vainer",
            "Ondrej Dusek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised End-to-End ASR via Teacher-Student Learning with Conditional Posterior Distribution",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1574",
        "paper_authors": [
            "Zi-qiang Zhang",
            "Yan Song",
            "Jian-Shu Zhang",
            "Ian McLoughlin",
            "Li-Rong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Unlabeled Speech for Sequence Discriminative Training of Acoustic Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2056",
        "paper_authors": [
            "Ashtosh Sapru",
            "Sri Garimella"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Developing RNN-T Models Surpassing High-Performance Hybrid Models with Customization Capability",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3016",
        "paper_authors": [
            "Jinyu Li",
            "Rui Zhao",
            "Zhong Meng",
            "Yanqing Liu",
            "Wenning Wei",
            "Sarangarajan Parthasarathy",
            "Vadim Mazalov",
            "Zhenghao Wang",
            "Lei He",
            "Sheng Zhao",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End ASR with Adaptive Span Self-Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2816",
        "paper_authors": [
            "Xuankai Chang",
            "Aswin Shanmugam Subramanian",
            "Pengcheng Guo",
            "Shinji Watanabe",
            "Yuya Fujita",
            "Motoi Omachi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Subword Regularization: An Analysis of Scalability and Generalization for End-to-End Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1569",
        "paper_authors": [
            "Egor Lakomkin",
            "Jahn Heymann",
            "Ilya Sklyar",
            "Simon Wiesler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Early Stage LM Integration Using Local and Global Log-Linear Combination",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2675",
        "paper_authors": [
            "Wilfried Michel",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2059",
        "paper_authors": [
            "Wei Han",
            "Zhengdong Zhang",
            "Yu Zhang",
            "Jiahui Yu",
            "Chung-Cheng Chiu",
            "James Qin",
            "Anmol Gulati",
            "Ruoming Pang",
            "Yonghui Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emitting Word Timings with End-to-End Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1059",
        "paper_authors": [
            "Tara N. Sainath",
            "Ruoming Pang",
            "David Rybach",
            "Basi Garc\u00eda",
            "Trevor Strohman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-Latency Sequence-to-Sequence Speech Recognition and Translation by Partial Hypothesis Selection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2897",
        "paper_authors": [
            "Danni Liu",
            "Gerasimos Spanakis",
            "Jan Niehues"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Language Modeling with Implicit Cache Pointers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3020",
        "paper_authors": [
            "Ke Li",
            "Daniel Povey",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Finnish ASR with Deep Transformer Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1784",
        "paper_authors": [
            "Abhilash Jain",
            "Aku Rouhe",
            "Stig-Arne Gr\u00f6nroos",
            "Mikko Kurimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distilling the Knowledge of BERT for Sequence-to-Sequence ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1179",
        "paper_authors": [
            "Hayato Futami",
            "Hirofumi Inaguma",
            "Sei Ueno",
            "Masato Mimura",
            "Shinsuke Sakai",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Convolutional Recurrent Networks for Language Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1493",
        "paper_authors": [
            "Jen-Tzung Chien",
            "Yu-Min Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of Large-Margin Softmax in Neural Language Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1849",
        "paper_authors": [
            "Jingjing Huo",
            "Yingbo Gao",
            "Weiyue Wang",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextualizing ASR Lattice Rescoring with Hybrid Pointer Network Language Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1344",
        "paper_authors": [
            "Da-Rong Liu",
            "Chunxi Liu",
            "Frank Zhang",
            "Gabriel Synnaeve",
            "Yatharth Saraf",
            "Geoffrey Zweig"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2404",
        "paper_authors": [
            "Yosuke Higuchi",
            "Shinji Watanabe",
            "Nanxin Chen",
            "Tetsuji Ogawa",
            "Tetsunori Kobayashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Insertion-Based Modeling for End-to-End Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1619",
        "paper_authors": [
            "Yuya Fujita",
            "Shinji Watanabe",
            "Motoi Omachi",
            "Xuankai Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Activity Detection in the Wild via Weakly Supervised Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-995",
        "paper_authors": [
            "Yefei Chen",
            "Heinrich Dinkel",
            "Mengyue Wu",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual Attention in Time and Frequency Domain for Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-997",
        "paper_authors": [
            "Joohyung Lee",
            "Youngmoon Jung",
            "Hoirin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Polishing the Classical Likelihood Ratio Test by Supervised Learning for Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1177",
        "paper_authors": [
            "Tianjiao Xu",
            "Hui Zhang",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Noise Robust Technique for Detecting Vowels in Speech Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1204",
        "paper_authors": [
            "Avinash Kumar",
            "S. Shahnawazuddin",
            "Waquar Ahmad"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Domain-Adversarial Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2285",
        "paper_authors": [
            "Marvin Lavechin",
            "Marie-Philippe Gill",
            "Ruben Bousbib",
            "Herv\u00e9 Bredin",
            "Leibny Paola Garc\u00eda-Perera"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VOP Detection in Variable Speech Rate Condition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2326",
        "paper_authors": [
            "Ayush Agarwal",
            "Jagabandhu Mishra",
            "S. R. Mahadeva Prasanna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MLNET: An Adaptive Multiple Receptive-Field Attention Neural Network for Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2392",
        "paper_authors": [
            "Zhenpeng Zheng",
            "Jianzong Wang",
            "Ning Cheng",
            "Jian Luo",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2398",
        "paper_authors": [
            "Felix Kreuk",
            "Joseph Keshet",
            "Yossi Adi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "That Sounds Familiar: An Analysis of Phonetic Representations Transfer Across Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2513",
        "paper_authors": [
            "Piotr Zelasko",
            "Laureano Moro-Vel\u00e1zquez",
            "Mark Hasegawa-Johnson",
            "Odette Scharenborg",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analyzing Read Aloud Speech by Primary School Pupils: Insights for Research and Development",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2804",
        "paper_authors": [
            "S. Limonard",
            "Catia Cucchiarini",
            "R. W. N. M. van Hout",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discovering Articulatory Speech Targets from Synthesized Random Babble",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3186",
        "paper_authors": [
            "Heikki Rasilo",
            "Yannick Jadoul"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Dependent Acoustic-to-Articulatory Inversion Using Real-Time MRI of the Vocal Tract",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-16",
        "paper_authors": [
            "Tam\u00e1s G\u00e1bor Csap\u00f3"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic-to-Articulatory Inversion with Deep Autoregressive Articulatory-WaveNet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1875",
        "paper_authors": [
            "Narjes Bozorg",
            "Michael T. Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Silence MR Image to Synthesise Dynamic MRI Vocal Tract Data of CV",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1173",
        "paper_authors": [
            "Ioannis K. Douros",
            "Ajinkya Kulkarni",
            "Chrysanthi Dourou",
            "Yu Xie",
            "Jacques Felblinger",
            "Karyna Isaieva",
            "Pierre-Andr\u00e9 Vuissoz",
            "Yves Laprie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Quantification of Transducer Misalignment in Ultrasound Tongue Imaging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1672",
        "paper_authors": [
            "Tam\u00e1s G\u00e1bor Csap\u00f3",
            "Kele Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Independent and Automatic Evaluation of Speaker-Independent Acoustic-to-Articulatory Reconstruction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1746",
        "paper_authors": [
            "Maud Parrot",
            "Juliette Millet",
            "Ewan Dunbar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CSL-EMG_Array: An Open Access Corpus for EMG-to-Speech Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2859",
        "paper_authors": [
            "Lorenz Diener",
            "Mehrdad Roustay Vishkasougheh",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Links Between Production and Perception of Glottalisation in Individual Australian English Speaker/Listeners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1175",
        "paper_authors": [
            "Joshua Penney",
            "Felicity Cox",
            "Anita Szakay"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Jointly Fine-Tuning \"BERT-Like\" Self Supervised Models to Improve Multimodal Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1212",
        "paper_authors": [
            "Shamane Siriwardhana",
            "Andrew Reis",
            "Rivindu Weerasekera",
            "Suranga Nanayakkara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vector-Quantized Autoregressive Predictive Coding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1228",
        "paper_authors": [
            "Yu-An Chung",
            "Hao Tang",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech-XLNet: Unsupervised Acoustic Model Pretraining for Self-Attention Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1511",
        "paper_authors": [
            "Xingchen Song",
            "Guangsen Wang",
            "Yiheng Huang",
            "Zhiyong Wu",
            "Dan Su",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large Scale Weakly and Semi-Supervised Learning for Low-Resource Video ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1917",
        "paper_authors": [
            "Kritika Singh",
            "Vimal Manohar",
            "Alex Xiao",
            "Sergey Edunov",
            "Ross B. Girshick",
            "Vitaliy Liptchinsky",
            "Christian Fuegen",
            "Yatharth Saraf",
            "Geoffrey Zweig",
            "Abdelrahman Mohamed"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sequence-Level Self-Learning with Multiple Hypotheses",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2020",
        "paper_authors": [
            "Ken'ichi Kumatani",
            "Dimitrios Dimitriadis",
            "Yashesh Gaur",
            "Robert Gmyr",
            "Sefik Emre Eskimez",
            "Jinyu Li",
            "Michael Zeng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Defense for Black-Box Attacks on Anti-Spoofing Models by Self-Supervised Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2026",
        "paper_authors": [
            "Haibin Wu",
            "Andy T. Liu",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding Self-Attention of Self-Supervised Audio Transformers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2231",
        "paper_authors": [
            "Shu-Wen Yang",
            "Andy T. Liu",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Convolutional Deep Markov Model for Unsupervised Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3084",
        "paper_authors": [
            "Sameer Khurana",
            "Antoine Laurent",
            "Wei-Ning Hsu",
            "Jan Chorowski",
            "Adrian Lancucki",
            "Ricard Marxer",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Speech Recognition for ILSE-Interviews: Longitudinal Conversational Speech Recordings Covering Aging and Cognitive Decline",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2829",
        "paper_authors": [
            "Ayimunishagu Abulimiti",
            "Jochen Weiner",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Margin Softmax Loss for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1106",
        "paper_authors": [
            "Dao Zhou",
            "Longbiao Wang",
            "Kong Aik Lee",
            "Yibo Wu",
            "Meng Liu",
            "Jianwu Dang",
            "Jianguo Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Parameter Adaptation in Softmax-Based Cross-Entropy Loss for Improved Convergence Speed and Accuracy in DNN-Based Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2264",
        "paper_authors": [
            "Magdalena Rybicka",
            "Konrad Kowalczyk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training Speaker Enrollment Models by Network Optimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2325",
        "paper_authors": [
            "Victoria Mingote",
            "Antonio Miguel",
            "Alfonso Ortega Gim\u00e9nez",
            "Eduardo Lleida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Supervised Domain Adaptation for Text-Independent Speaker Verification Using Limited Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2342",
        "paper_authors": [
            "Seyyed Saeed Sarfjoo",
            "Srikanth R. Madikeri",
            "Petr Motl\u00edcek",
            "S\u00e9bastien Marcel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Angular Margin Centroid Loss for Text-Independent Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2538",
        "paper_authors": [
            "Yuheng Wei",
            "Junzhao Du",
            "Hui Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain-Invariant Speaker Vector Projection by Model-Agnostic Meta-Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2562",
        "paper_authors": [
            "Jiawen Kang",
            "Ruiqi Liu",
            "Lantian Li",
            "Yunqi Cai",
            "Dong Wang",
            "Thomas Fang Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2650",
        "paper_authors": [
            "Brecht Desplanques",
            "Jenthe Thienpondt",
            "Kris Demuynck"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Length- and Noise-Aware Training Techniques for Short-Utterance Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2872",
        "paper_authors": [
            "Wenda Chen",
            "Jonathan Huang",
            "Tobias Bocklet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoken Language 'Grammatical Error Correction'",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1852",
        "paper_authors": [
            "Yiting Lu",
            "Mark J. F. Gales",
            "Yu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mixtures of Deep Neural Experts for Automated Speech Scoring",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1055",
        "paper_authors": [
            "Sara Papi",
            "Edmondo Trentin",
            "Roberto Gretter",
            "Marco Matassoni",
            "Daniele Falavigna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Targeted Content Feedback in Spoken Language Learning and Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1766",
        "paper_authors": [
            "Xinhao Wang",
            "Klaus Zechner",
            "Christopher Hamill"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Universal Adversarial Attacks on Spoken Language Assessment Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1890",
        "paper_authors": [
            "Vyas Raina",
            "Mark J. F. Gales",
            "Kate M. Knill"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ensemble Approaches for Uncertainty in Spoken Language Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2238",
        "paper_authors": [
            "Xixin Wu",
            "Kate M. Knill",
            "Mark J. F. Gales",
            "Andrey Malinin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Shadowability Annotation with Fine Granularity on L2 Utterances and its Improvement with Native Listeners' Script-Shadowing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2550",
        "paper_authors": [
            "Zhenchao Lin",
            "Ryo Takashima",
            "Daisuke Saito",
            "Nobuaki Minematsu",
            "Noriko Nakanishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR-Based Evaluation and Feedback for Individualized Reading Practice",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2842",
        "paper_authors": [
            "Yu Bai",
            "Ferdy Hubers",
            "Catia Cucchiarini",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Adversarial Neural Networks for Dysarthric Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2845",
        "paper_authors": [
            "Dominika Woszczyk",
            "Stavros Petridis",
            "David E. Millard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Estimation of Pathological Voice Quality Based on Recurrent Neural Network Using Amplitude and Phase Spectrogram",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3228",
        "paper_authors": [
            "Shunsuke Hidaka",
            "Yogaku Lee",
            "Kohei Wakamiya",
            "Takashi Nakagawa",
            "Tokihiko Kaburagi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Curiosity Exploration for Dialogue Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1313",
        "paper_authors": [
            "Jen-Tzung Chien",
            "Po-Chien Hsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conditional Response Augmentation for Dialogue Using Knowledge Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1968",
        "paper_authors": [
            "Myeongho Jeong",
            "Seungtaek Choi",
            "Hojae Han",
            "Kyungho Kim",
            "Seung-won Hwang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prototypical Q Networks for Automatic Conversational Diagnosis and Few-Shot New Disease Adaption",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1865",
        "paper_authors": [
            "Hongyin Luo",
            "Shang-Wen Li",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Task-Oriented Dialog System Through Template Slot Value Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2011",
        "paper_authors": [
            "Teakgyu Hong",
            "Oh-Woog Kwon",
            "Young-Kil Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Task-Oriented Dialog Generation with Enhanced Entity Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1037",
        "paper_authors": [
            "Zhenhao He",
            "Jiachun Wang",
            "Jian Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Speech-to-Dialog-Act Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1062",
        "paper_authors": [
            "Viet-Trung Dang",
            "Tianyu Zhao",
            "Sei Ueno",
            "Hirofumi Inaguma",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discriminative Transfer Learning for Optimizing ASR and Semantic Labeling in Task-Oriented Spoken Dialog",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1962",
        "paper_authors": [
            "Yao Qian",
            "Yu Shi",
            "Michael Zeng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Datasets and Benchmarks for Task-Oriented Log Dialogue Ranking Task",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1341",
        "paper_authors": [
            "Xinnuo Xu",
            "Yizhe Zhang",
            "Lars Liden",
            "Sungjin Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Semi-Blind Source Separation Approach for Speech Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1307",
        "paper_authors": [
            "Ziteng Wang",
            "Yueyue Na",
            "Zhang Liu",
            "Yun Li",
            "Biao Tian",
            "Qiang Fu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Virtual Acoustic Channel Expansion Based on Neural Networks for Weighted Prediction Error-Based Speech Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1553",
        "paper_authors": [
            "Joon-Young Yang",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SkipConvNet: Skip Convolutional Neural Network for Speech Dereverberation Using Optimally Smoothed Spectral Mapping",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2048",
        "paper_authors": [
            "Vinay Kothapally",
            "Wei Xia",
            "Shahram Ghorbani",
            "John H. L. Hansen",
            "Wei Xue",
            "Jing Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Robust and Cascaded Acoustic Echo Cancellation Based on Deep Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1260",
        "paper_authors": [
            "Chenggang Zhang",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generative Adversarial Network Based Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1454",
        "paper_authors": [
            "Yi Zhang",
            "Chengyun Deng",
            "Shiqian Ma",
            "Yongtao Sha",
            "Hui Song",
            "Xiangang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nonlinear Residual Echo Suppression Using a Recurrent Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1473",
        "paper_authors": [
            "Lukas Pfeifenberger",
            "Franz Pernkopf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Independent Echo Path Modeling for Stereophonic Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2131",
        "paper_authors": [
            "Yi Gao",
            "Ian Liu",
            "J. Zheng",
            "Cheng Luo",
            "Bin Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nonlinear Residual Echo Suppression Based on Multi-Stream Conv-TasNet",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2234",
        "paper_authors": [
            "Hongsheng Chen",
            "Teng Xiang",
            "Kai Chen",
            "Jing Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Partition-Block-Based Acoustic Echo Canceler in Under-Modeling Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2479",
        "paper_authors": [
            "Wenzhi Fan",
            "Jing Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention Wave-U-Net for Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3200",
        "paper_authors": [
            "Jung-Hee Kim",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "From Speaker Verification to Multispeaker Speech Synthesis, Deep Transfer with Feedback Constraint",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1032",
        "paper_authors": [
            "Zexin Cai",
            "Chuxiong Zhang",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1229",
        "paper_authors": [
            "Erica Cooper",
            "Cheng-I Lai",
            "Yusuke Yasuda",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Autoregressive End-to-End TTS with Coarse-to-Fine Decoding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1662",
        "paper_authors": [
            "Tao Wang",
            "Xuefei Liu",
            "Jianhua Tao",
            "Jiangyan Yi",
            "Ruibo Fu",
            "Zhengqi Wen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bi-Level Speaker Supervision for One-Shot Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1737",
        "paper_authors": [
            "Tao Wang",
            "Jianhua Tao",
            "Ruibo Fu",
            "Jiangyan Yi",
            "Zhengqi Wen",
            "Chunyu Qiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Naturalness Enhancement with Linguistic Information in End-to-End TTS Using Unsupervised Parallel Encoding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1788",
        "paper_authors": [
            "Alex Peir\u00f3 Lilja",
            "Mireia Farr\u00fas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MoBoAligner: A Neural Alignment Model for Non-Autoregressive TTS with Monotonic Boundary Search",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1976",
        "paper_authors": [
            "Naihan Li",
            "Shujie Liu",
            "Yanqing Liu",
            "Sheng Zhao",
            "Ming Liu",
            "Ming Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "JDI-T: Jointly Trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2123",
        "paper_authors": [
            "Dan Lim",
            "Won Jang",
            "Gyeonghwan O",
            "Heayoung Park",
            "Bongwan Kim",
            "Jaesam Yoon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Text-to-Speech Synthesis with Unaligned Multiple Language Units Based on Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2347",
        "paper_authors": [
            "Masashi Aso",
            "Shinnosuke Takamichi",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention Forcing for Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2520",
        "paper_authors": [
            "Qingyun Dou",
            "Joshua Efiong",
            "Mark J. F. Gales"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Testing the Limits of Representation Mixing for Pronunciation Correction in End-to-End Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2618",
        "paper_authors": [
            "Jason Fong",
            "Jason Taylor",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MultiSpeech: Multi-Speaker Text to Speech with Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3139",
        "paper_authors": [
            "Mingjian Chen",
            "Xu Tan",
            "Yi Ren",
            "Jin Xu",
            "Hao Sun",
            "Sheng Zhao",
            "Tao Qin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploiting Conic Affinity Measures to Design Speech Enhancement Systems Operating in Unseen Noise Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1269",
        "paper_authors": [
            "Pavlos Papadopoulos",
            "Shrikanth Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Dictionary Learning for Monaural Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2500",
        "paper_authors": [
            "Yunyun Ji",
            "Longting Xu",
            "Wei-Ping Zhu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised Self-Produced Speech Enhancement and Suppression Based on Joint Source Modeling of Air- and Body-Conducted Signals Using Variational Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2055",
        "paper_authors": [
            "Shogo Seki",
            "Moe Takada",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spatial Covariance Matrix Estimation for Reverberant Speech with Application to Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2224",
        "paper_authors": [
            "Ran Weisman",
            "Vladimir Tourbabin",
            "Paul Calamia",
            "Boaz Rafaely"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Cross-Channel Attention-Based Wave-U-Net for Multi-Channel Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2548",
        "paper_authors": [
            "Minh Tri Ho",
            "Jinyoung Lee",
            "Bong-Ki Lee",
            "Dong Hoon Yi",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1864",
        "paper_authors": [
            "Igor Fedorov",
            "Marko Stamenovic",
            "Carl Jensen",
            "Li-Chia Yang",
            "Ari Mandell",
            "Yiming Gan",
            "Matthew Mattina",
            "Paul N. Whatmough"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intelligibility Enhancement Based on Speech Waveform Modification Using Hearing Impairment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2062",
        "paper_authors": [
            "Shu Hikosaka",
            "Shogo Seki",
            "Tomoki Hayashi",
            "Kazuhiro Kobayashi",
            "Kazuya Takeda",
            "Hideki Banno",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker and Phoneme-Aware Speech Bandwidth Extension with Residual Dual-Path Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1994",
        "paper_authors": [
            "Nana Hou",
            "Chenglin Xu",
            "Van Tung Pham",
            "Joey Tianyi Zhou",
            "Eng Siong Chng",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Task Learning for End-to-End Noise-Robust Bandwidth Extension",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2022",
        "paper_authors": [
            "Nana Hou",
            "Chenglin Xu",
            "Joey Tianyi Zhou",
            "Eng Siong Chng",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phase-Aware Music Super-Resolution Using Generative Adversarial Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2605",
        "paper_authors": [
            "Shichao Hu",
            "Bin Zhang",
            "Beici Liang",
            "Ethan Zhao",
            "Simon Lui"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Utterance-Level Representations with Label Smoothing for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1391",
        "paper_authors": [
            "Jian Huang",
            "Jianhua Tao",
            "Bin Liu",
            "Zheng Lian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Removing Bias with Residual Mixture of Multi-View Attention for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3005",
        "paper_authors": [
            "Md Asif Jalal",
            "Rosanna Milner",
            "Thomas Hain",
            "Roger K. Moore"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Domain-Aware Representation Learning for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2572",
        "paper_authors": [
            "Weiquan Fan",
            "Xiangmin Xu",
            "Xiaofen Xing",
            "Dongyan Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion Recognition with Discriminative Feature Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2237",
        "paper_authors": [
            "Huan Zhou",
            "Kai Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Speech Enhancement Preprocessing for Speech Emotion Recognition in Realistic Noisy Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2472",
        "paper_authors": [
            "Hengshun Zhou",
            "Jun Du",
            "Yanhui Tu",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison of Glottal Source Parameter Values in Emotional Vowels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1536",
        "paper_authors": [
            "Yongwei Li",
            "Jianhua Tao",
            "Bin Liu",
            "Donna Erickson",
            "Masato Akagi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to Recognize Per-Rater's Emotion Perception Using Co-Rater Training Strategy with Soft and Hard Labels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1714",
        "paper_authors": [
            "Huang-Cheng Chou",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Empirical Interpretation of Speech Emotion Perception with Attention Based Model for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3007",
        "paper_authors": [
            "Md. Asif Jalal",
            "Rosanna Milner",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic Accommodation of L2 German Speakers to the Virtual Language Learning Tutor Mirabella",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2701",
        "paper_authors": [
            "Iona Gessinger",
            "Bernd M\u00f6bius",
            "Bistra Andreeva",
            "Eran Raveh",
            "Ingmar Steiner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Characterization of Singaporean Children's English: Comparisons to American and British Counterparts Using Archetypal Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3166",
        "paper_authors": [
            "Yuling Gu",
            "Nancy F. Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rhythmic Convergence in Canadian French Varieties?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2963",
        "paper_authors": [
            "Svetlana Kaminska\u00efa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Malayalam-English Code-Switched: Grapheme to Phoneme System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1936",
        "paper_authors": [
            "Sreeja Manghat",
            "Sreeram Manghat",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ongoing Phonologization of Word-Final Voicing Alternations in Two Romance Languages: Romanian and French",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1460",
        "paper_authors": [
            "Mathilde Hutin",
            "Ad\u00e8le Jatteau",
            "Ioana Vasilescu",
            "Lori Lamel",
            "Martine Adda-Decker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cues for Perception of Gender in Synthetic Voices and the Role of Identity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2657",
        "paper_authors": [
            "Maxwell Hope",
            "Jason Lilley"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic Entrainment in Cooperative Dialogues: A Case of Russian",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2696",
        "paper_authors": [
            "Alla Menshikova",
            "Daniil Kocharov",
            "Tatiana Kachkovskaia"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosodic Characteristics of Genuine and Mock (Im)polite Mandarin Utterances",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3231",
        "paper_authors": [
            "Chengwei Xu",
            "Wentao Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tone Variations in Regionally Accented Mandarin",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1235",
        "paper_authors": [
            "Yanping Li",
            "Catherine T. Best",
            "Michael D. Tyler",
            "Denis Burnham"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "F0 Patterns in Mandarin Statements of Mandarin and Cantonese Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2549",
        "paper_authors": [
            "Yike Yang",
            "Si Chen",
            "Xi Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeechBERT: An Audio-and-Text Jointly Learned Language Model for End-to-End Spoken Question Answering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1570",
        "paper_authors": [
            "Yung-Sung Chuang",
            "Chi-Liang Liu",
            "Hung-yi Lee",
            "Lin-Shan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Audio-Enriched BERT-Based Framework for Spoken Multiple-Choice Question Answering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1763",
        "paper_authors": [
            "Chia-Chih Kuo",
            "Shang-Bao Luo",
            "Kuan-Yu Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Entity Linking for Short Text Using Structured Knowledge Graph via Multi-Grained Text Matching",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1934",
        "paper_authors": [
            "Binxuan Huang",
            "Han Wang",
            "Tong Wang",
            "Yue Liu",
            "Yang Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sound-Image Grounding Based Focusing Mechanism for Efficient Automatic Spoken Language Acquisition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2027",
        "paper_authors": [
            "Mingxin Zhang",
            "Tomohiro Tanaka",
            "Wenxin Hou",
            "Shengzhou Gao",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised Learning for Character Expression of Spoken Dialogue Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2293",
        "paper_authors": [
            "Kenta Yamamoto",
            "Koji Inoue",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dimensional Emotion Prediction Based on Interactive Context in Conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1820",
        "paper_authors": [
            "Xiaohan Shi",
            "Sixia Li",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HRI-RNN: A User-Robot Dynamics-Oriented RNN for Engagement Decrease Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1261",
        "paper_authors": [
            "Asma Atamna",
            "Chlo\u00e9 Clavel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Representations of Dialogical History for Improving Upcoming Turn Acoustic Parameters Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2785",
        "paper_authors": [
            "Simone Fuscone",
            "Beno\u00eet Favre",
            "Laurent Pr\u00e9vot"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Domain-Specific Credibility and Expertise in Text and Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1518",
        "paper_authors": [
            "Shengli Hu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Attacker's Perspective on Automatic Speaker Verification: An Overview",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1052",
        "paper_authors": [
            "Rohan Kumar Das",
            "Xiaohai Tian",
            "Tomi Kinnunen",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extrapolating False Alarm Rates in Automatic Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1090",
        "paper_authors": [
            "Alexey Sholokhov",
            "Tomi Kinnunen",
            "Ville Vestman",
            "Kong Aik Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Spoofing Audio Detection Scheme",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1760",
        "paper_authors": [
            "Ziyue Jiang",
            "Hongcheng Zhu",
            "Li Peng",
            "Wenbing Ding",
            "Yanzhen Ren"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Inaudible Adversarial Perturbations for Targeted Attack in Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1955",
        "paper_authors": [
            "Qing Wang",
            "Pengcheng Guo",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "x-Vectors Meet Adversarial Attacks: Benchmarking Adversarial Robustness in Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2458",
        "paper_authors": [
            "Jes\u00fas Villalba",
            "Yuekai Zhang",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Black-Box Attacks on Spoofing Countermeasures Using Transferability of Adversarial Examples",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2834",
        "paper_authors": [
            "Yuekai Zhang",
            "Ziyan Jiang",
            "Jes\u00fas Villalba",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Emotion Recognition Using Cross-Modal Attention and 1D Convolutional Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1190",
        "paper_authors": [
            "Krishna D. N",
            "Ankita Patil"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Abstractive Spoken Document Summarization Using Hierarchical Model with Multi-Stage Attention Diversity Optimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1683",
        "paper_authors": [
            "Potsawee Manakul",
            "Mark J. F. Gales",
            "Linlin Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Learning of Word Embeddings with Word Definitions and Semantic Injection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1702",
        "paper_authors": [
            "Yichi Zhang",
            "Yinpei Dai",
            "Zhijian Ou",
            "Huixin Wang",
            "Junlan Feng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Wake Word Detection with Alignment-Free Lattice-Free MMI",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1811",
        "paper_authors": [
            "Yiming Wang",
            "Hang Lv",
            "Daniel Povey",
            "Lei Xie",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Vietnamese Named Entity Recognition from Speech Using Word Capitalization and Punctuation Recovery Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1896",
        "paper_authors": [
            "Thai Binh Nguyen",
            "Quang Minh Nguyen",
            "Thi Thu Hien Nguyen",
            "Quoc Truong Do",
            "Luong Chi Mai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Named Entity Recognition from English Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2482",
        "paper_authors": [
            "Hemant Yadav",
            "Sreyan Ghosh",
            "Yi Yu",
            "Rajiv Ratn Shah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantic Complexity in End-to-End Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2929",
        "paper_authors": [
            "Joseph P. McKenna",
            "Samridhi Choudhary",
            "Michael Saxon",
            "Grant P. Strimel",
            "Athanasios Mouchtaris"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis of Disfluency in Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3037",
        "paper_authors": [
            "Trang Tran",
            "Morgan Tinkler",
            "Gary Yeung",
            "Abeer Alwan",
            "Mari Ostendorf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Representation Based Meta-Learning for Few-Shot Spoken Intent Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3208",
        "paper_authors": [
            "Ashish R. Mittal",
            "Samarth Bharadwaj",
            "Shreya Khare",
            "Saneem A. Chemmengath",
            "Karthik Sankaranarayanan",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Complementary Language Model and Parallel Bi-LRNN for False Trigger Mitigation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3238",
        "paper_authors": [
            "Rishika Agarwal",
            "Xiaochuan Niu",
            "Pranay Dighe",
            "Srikanth Vishnubhotla",
            "Sameer Badaskar",
            "Devang Naik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Utterance Dual Attention for Speaker and Utterance Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1818",
        "paper_authors": [
            "Tianchi Liu",
            "Rohan Kumar Das",
            "Maulik C. Madhavi",
            "Shengmei Shen",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Separation and Adaptation Network for Far-Field Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2372",
        "paper_authors": [
            "Lu Yi",
            "Man-Wai Mak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MIRNet: Learning Multiple Identities Representations in Overlapped Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2076",
        "paper_authors": [
            "Hyewon Han",
            "Soo-Whan Chung",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Strategies for End-to-End Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2092",
        "paper_authors": [
            "Weiwei Lin",
            "Man-Wai Mak",
            "Jen-Tzung Chien"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Why Did the x-Vector System Miss a Target Speaker? Impact of Acoustic Mismatch Upon Target Score on VoxCeleb Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2715",
        "paper_authors": [
            "Rosa Gonz\u00e1lez Hautam\u00e4ki",
            "Tomi Kinnunen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variable Frame Rate-Based Data Augmentation to Handle Speaking-Style Variability for Automatic Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3006",
        "paper_authors": [
            "Amber Afshan",
            "Jinxi Guo",
            "Soo Jin Park",
            "Vijay Ravi",
            "Alan McCree",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Machine of Few Words: Interactive Speaker Recognition with Reinforcement Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2892",
        "paper_authors": [
            "Mathieu Seurin",
            "Florian Strub",
            "Philippe Preux",
            "Olivier Pietquin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving On-Device Speaker Verification Using Federated Learning with Privacy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2944",
        "paper_authors": [
            "Filip Granqvist",
            "Matt Seigel",
            "Rogier C. van Dalen",
            "\u00c1ine Cahill",
            "Stephen Shum",
            "Matthias Paulik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural PLDA Modeling for End-to-End Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2699",
        "paper_authors": [
            "Shreyas Ramoji",
            "Prashant Krishnan V",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "State Sequence Pooling Training of Acoustic Models for Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2722",
        "paper_authors": [
            "Kuba Lopatka",
            "Tobias Bocklet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training Keyword Spotting Models on Non-IID Data with Federated Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3023",
        "paper_authors": [
            "Andrew Hard",
            "Kurt Partridge",
            "Cameron Nguyen",
            "Niranjan Subrahmanya",
            "Aishanee Shah",
            "Pai Zhu",
            "Ignacio L\u00f3pez-Moreno",
            "Rajiv Mathews"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Class LM and Word Mapping for Contextual Biasing in End-to-End ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1787",
        "paper_authors": [
            "Rongqing Huang",
            "Ossama Abdel-Hamid",
            "Xinwei Li",
            "Gunnar Evermann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Do End-to-End Speech Recognition Models Care About Context?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1750",
        "paper_authors": [
            "Lasse Borgholt",
            "Jakob D. Havtorn",
            "Zeljko Agic",
            "Anders S\u00f8gaard",
            "Lars Maal\u00f8e",
            "Christian Igel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Utterance Confidence Measure for End-to-End Speech Recognition with Applications to Distributed Speech Recognition Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3216",
        "paper_authors": [
            "Ankur Kumar",
            "Sachin Singh",
            "Dhananjaya Gowda",
            "Abhinav Garg",
            "Shatrughan Singh",
            "Chanwoo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Code Based Speaker Adaptive Training Using Model Agnostic Meta-Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2296",
        "paper_authors": [
            "Huaxin Wu",
            "Genshun Wan",
            "Jia Pan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Adaptation Using Class Similarity for Robust Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3087",
        "paper_authors": [
            "Han Zhu",
            "Jiangjiang Zhao",
            "Yuling Ren",
            "Li Wang",
            "Pengyuan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incremental Machine Speech Chain Towards Enabling Listening While Speaking in Real-Time",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2034",
        "paper_authors": [
            "Sashi Novitasari",
            "Andros Tjandra",
            "Tomoya Yanagita",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Context-Dependent Acoustic Modeling Without Explicit Phone Clustering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1244",
        "paper_authors": [
            "Tina Raissi",
            "Eugen Beck",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Conversion Based Data Augmentation to Improve Children's Speech Recognition in Limited Data Scenario",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1112",
        "paper_authors": [
            "S. Shahnawazuddin",
            "Nagaraj Adiga",
            "Kunal Kumar",
            "Aayushi Poddar",
            "Waquar Ahmad"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1251",
        "paper_authors": [
            "Sri Karlapati",
            "Alexis Moinet",
            "Arnaud Joly",
            "Viacheslav Klimkov",
            "Daniel S\u00e1ez-Trigueros",
            "Thomas Drugman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Detection of Sentence Stress and Phrase Boundary for Prosody",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1284",
        "paper_authors": [
            "Binghuai Lin",
            "Liyuan Wang",
            "Xiaoli Feng",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning of the Expressivity Using FLOW Metric Learning in Multispeaker Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1297",
        "paper_authors": [
            "Ajinkya Kulkarni",
            "Vincent Colotte",
            "Denis Jouvet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaking Speed Control of End-to-End Speech Synthesis Using Sentence-Level Conditioning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1361",
        "paper_authors": [
            "Jae-Sung Bae",
            "Hanbin Bae",
            "Young-Sun Joo",
            "Junmo Lee",
            "Gyeong-Hoon Lee",
            "Hoon-Young Cho"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Prosody Generation for Speech Synthesis Using Linguistics-Driven Acoustic Embedding Selection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1411",
        "paper_authors": [
            "Shubhi Tyagi",
            "Marco Nicolis",
            "Jonas Rohnke",
            "Thomas Drugman",
            "Jaime Lorenzo-Trueba"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving the Prosody of RNN-Based English Text-To-Speech Synthesis by Incorporating a BERT Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1430",
        "paper_authors": [
            "Tom Kenter",
            "Manish Sharma",
            "Rob Clark"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Prosody from Learned F0 Codebook Representations for VQ-VAE Speech Waveform Reconstruction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1615",
        "paper_authors": [
            "Yi Zhao",
            "Haoyu Li",
            "Cheng-I Lai",
            "Jennifer Williams",
            "Erica Cooper",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosody Learning Mechanism for Speech Synthesis System Without Text Length Limit",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2053",
        "paper_authors": [
            "Zhen Zeng",
            "Jianzong Wang",
            "Ning Cheng",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discriminative Method to Extract Coarse Prosodic Structure and its Application for Statistical Phrase/Accent Command Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2566",
        "paper_authors": [
            "Yuma Shirahata",
            "Daisuke Saito",
            "Nobuaki Minematsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Controllable Neural Text-to-Speech Synthesis Using Intuitive Prosodic Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2861",
        "paper_authors": [
            "Tuomo Raitio",
            "Ramya Rasipuram",
            "Dan Castellani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Controllable Neural Prosody Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2918",
        "paper_authors": [
            "Max Morrison",
            "Zeyu Jin",
            "Justin Salamon",
            "Nicholas J. Bryan",
            "Gautham J. Mysore"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Reference Neural TTS Stylization with Adversarial Cycle Consistency",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2985",
        "paper_authors": [
            "Matt Whitehill",
            "Shuang Ma",
            "Daniel McDuff",
            "Yale Song"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interactive Text-to-Speech System via Joint Style Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3069",
        "paper_authors": [
            "Yang Gao",
            "Weiyi Zheng",
            "Zhaojun Yang",
            "Thilo K\u00f6hler",
            "Christian Fuegen",
            "Qing He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mobile-Assisted Prosody Training for Limited English Proficiency: Learner Background and Speech Learning Pattern",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2901",
        "paper_authors": [
            "Kevin Hirschi",
            "Okim Kang",
            "Catia Cucchiarini",
            "John H. L. Hansen",
            "Keelan Evanini",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Finding Intelligible Consonant-Vowel Sounds Using High-Quality Articulatory Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2545",
        "paper_authors": [
            "Daniel R. van Niekerk",
            "Anqi Xu",
            "Branislav Gerazov",
            "Paul Konstantin Krug",
            "Peter Birkholz",
            "Yi Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audiovisual Correspondence Learning in Humans and Machines",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2674",
        "paper_authors": [
            "Venkat Krishnamohan",
            "Akshara Soman",
            "Anshul Gupta",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perception of English Fricatives and Affricates by Advanced Chinese Learners of English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1120",
        "paper_authors": [
            "Yizhou Lan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perception of Japanese Consonant Length by Native Speakers of Korean Differing in Japanese Learning Experience",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1068",
        "paper_authors": [
            "Kimiko Tsukada",
            "Joo-Yeon Kim",
            "Jeong-Im Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection of Phonological Errors in Child Speech Using Siamese Recurrent Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2145",
        "paper_authors": [
            "Si Ioi Ng",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparison of English Rhythm Produced by Native American Speakers and Mandarin ESL Primary School Learners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2207",
        "paper_authors": [
            "Hongwei Ding",
            "Binghuai Lin",
            "Liyuan Wang",
            "Hui Wang",
            "Ruomei Fang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Linguistic Interaction Between Phonological Categorization and Orthography Predicts Prosodic Effects in the Acquisition of Portuguese Liquids by L1-Mandarin Learners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2689",
        "paper_authors": [
            "Chao Zhou",
            "Silke Hamann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Linguistic Perception of Utterances with Willingness and Reluctance in Mandarin by Korean L2 Learners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1640",
        "paper_authors": [
            "Wenqian Li",
            "Jung-Yueh Tu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Enhancement Based on Beamforming and Post-Filtering by Combining Phase Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-990",
        "paper_authors": [
            "Rui Cheng",
            "Changchun Bao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Noise-Aware Memory-Attention Network Architecture for Regression-Based Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2037",
        "paper_authors": [
            "Yu-Xuan Wang",
            "Jun Du",
            "Li Chai",
            "Chin-Hui Lee",
            "Jia Pan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HiFi-GAN: High-Fidelity Denoising and Dereverberation Based on Speech Deep Features in Adversarial Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2143",
        "paper_authors": [
            "Jiaqi Su",
            "Zeyu Jin",
            "Adam Finkelstein"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Complex Spectral Mapping for Speech Enhancement with Improved Cross-Corpus Generalization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2561",
        "paper_authors": [
            "Ashutosh Pandey",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Enhancement with Stochastic Temporal Convolutional Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2588",
        "paper_authors": [
            "Julius Richter",
            "Guillaume Carbajal",
            "Timo Gerkmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visual Speech In Real Noisy Environments (VISION): A Novel Benchmark Dataset and Deep Learning-Based Baseline System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2935",
        "paper_authors": [
            "Mandar Gogate",
            "Kia Dashtipour",
            "Amir Hussain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sparse Mixture of Local Experts for Efficient Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2989",
        "paper_authors": [
            "Aswin Sivaraman",
            "Minje Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Speech Enhancement Using TCN with Multiple Encoder-Decoder Layers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3122",
        "paper_authors": [
            "Vinith Kishore",
            "Nitya Tiwari",
            "Periyasamy Paramasivam"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Training for Simultaneous Speech Denoising and Dereverberation with Deep Embedding Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1225",
        "paper_authors": [
            "Cunhang Fan",
            "Jianhua Tao",
            "Bin Liu",
            "Jiangyan Yi",
            "Zhengqi Wen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Robust Speech Enhancement Based on Alpha-Stable Fast Multichannel Nonnegative Matrix Factorization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3202",
        "paper_authors": [
            "Mathieu Fontaine",
            "Kouhei Sekiguchi",
            "Aditya Arie Nugraha",
            "Kazuyoshi Yoshii"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Squeeze for Sneeze: Compact Neural Networks for Cold and Flu Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2531",
        "paper_authors": [
            "Merlin Albes",
            "Zhao Ren",
            "Bj\u00f6rn W. Schuller",
            "Nicholas Cummins"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extended Study on the Use of Vocal Tract Variables to Quantify Neuromotor Coordination in Depression",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2758",
        "paper_authors": [
            "Nadee Seneviratne",
            "James R. Williamson",
            "Adam C. Lammert",
            "Thomas F. Quatieri",
            "Carol Y. Espy-Wilson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Affective Conditioning on Hierarchical Attention Networks Applied to Depression Detection from Transcribed Clinical Interviews",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2819",
        "paper_authors": [
            "Danai Xezonaki",
            "Georgios Paraskevopoulos",
            "Alexandros Potamianos",
            "Shrikanth Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Adaptation for Enhancing Speech-Based Depression Detection in Natural Environmental Conditions Using Dilated CNNs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3135",
        "paper_authors": [
            "Zhaocheng Huang",
            "Julien Epps",
            "Dale Joachim",
            "Brian Stasak",
            "James R. Williamson",
            "Thomas F. Quatieri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Making a Distinction Between Schizophrenia and Bipolar Disorder Based on Temporal Parameters in Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-49",
        "paper_authors": [
            "G\u00e1bor Gosztolya",
            "Anita Bagi",
            "Szilvia Szal\u00f3ki",
            "Istv\u00e1n Szendi",
            "Ildik\u00f3 Hoffmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prediction of Sleepiness Ratings from Voice by Man and Machine",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1601",
        "paper_authors": [
            "Mark A. Huckvale",
            "Andr\u00e1s Beke",
            "Mirei Ikushima"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tongue and Lip Motion Patterns in Alaryngeal Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2854",
        "paper_authors": [
            "Kristin J. Teplansky",
            "Alan Wisler",
            "Beiming Cao",
            "Wendy Liang",
            "Chad W. Whited",
            "Ted Mau",
            "Jun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Autoencoder Bottleneck Features with Multi-Task Optimisation for Improved Continuous Dysarthric Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2746",
        "paper_authors": [
            "Zhengjun Yue",
            "Heidi Christensen",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Raw Speech Waveform Based Classification of Patients with ALS, Parkinson's Disease and Healthy Controls Using CNN-BLSTM",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2221",
        "paper_authors": [
            "Jhansi Mallela",
            "Aravind Illa",
            "Yamini Belur",
            "Atchayaram Nalini",
            "Ravi Yadav",
            "Pradeep Reddy",
            "Dipanjan Gope",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Assessment of Parkinson's Disease Medication State Through Automatic Speech Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2726",
        "paper_authors": [
            "Anna Pompili",
            "Rub\u00e9n Solera-Ure\u00f1a",
            "Alberto Abad",
            "Rita Cardoso",
            "Isabel Guimar\u00e3es",
            "Margherita Fabbri",
            "Isabel P. Martins",
            "Joaquim J. Ferreira"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Replay Detection System with Channel Consistency DenseNeXt for the ASVspoof 2019 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1044",
        "paper_authors": [
            "Chao Zhang",
            "Junjie Cheng",
            "Yanmei Gu",
            "Huacan Wang",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Subjective Quality Evaluation of Speech Signals Transmitted via BPL-PLC Wired System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1077",
        "paper_authors": [
            "Przemyslaw Falkowski-Gilski",
            "Grzegorz Debita",
            "Marcin Habrych",
            "Bogdan Miedzinski",
            "Przemyslaw Jedlikowski",
            "Bartosz Polnik",
            "Jan Wandzio",
            "Xin Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the Visual Lombard Effect with Gabor Based Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1291",
        "paper_authors": [
            "Waito Chiu",
            "Yan Xu",
            "Andrew Abel",
            "Chun Lin",
            "Zhengzheng Tu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploration of Audio Quality Assessment and Anomaly Localisation Using Attention Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1885",
        "paper_authors": [
            "Qiang Huang",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Development of a Speech Quality Database Under Uncontrolled Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1899",
        "paper_authors": [
            "Alessandro Ragano",
            "Emmanouil Benetos",
            "Andrew Hines"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating the Reliability of Acoustic Speech Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2362",
        "paper_authors": [
            "Robin Algayres",
            "Mohamed Salah Za\u00efem",
            "Beno\u00eet Sagot",
            "Emmanuel Dupoux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Frame-Level Signal-to-Noise Ratio Estimation Using Deep Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2475",
        "paper_authors": [
            "Hao Li",
            "DeLiang Wang",
            "Xueliang Zhang",
            "Guanglai Gao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Pyramid Recurrent Network for Predicting Crowdsourced Speech-Quality Ratings of Real-World Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2809",
        "paper_authors": [
            "Xuan Dong",
            "Donald S. Williamson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effect of Spectral Complexity Reduction and Number of Instruments on Musical Enjoyment with Cochlear Implants",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3034",
        "paper_authors": [
            "Avamarie Brueggeman",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spectrum Correction: Acoustic Scene Classification with Mismatched Recording Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3088",
        "paper_authors": [
            "Michal Kosmider"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distributed Summation Privacy for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1977",
        "paper_authors": [
            "Matthew O'Connor",
            "W. Bastiaan Kleijn"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perception of Privacy Measured in the Crowd - Paired Comparison on the Effect of Background Noises",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2299",
        "paper_authors": [
            "Anna Leschanowsky",
            "Sneha Das",
            "Tom B\u00e4ckstr\u00f6m",
            "Pablo P\u00e9rez Zarazaga"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hide and Speak: Towards Deep Neural Networks for Speech Steganography",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2380",
        "paper_authors": [
            "Felix Kreuk",
            "Yossi Adi",
            "Bhiksha Raj",
            "Rita Singh",
            "Joseph Keshet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Adversarial Examples for Speech Recognition via Uncertainty Quantification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2734",
        "paper_authors": [
            "Sina D\u00e4ubener",
            "Lea Sch\u00f6nherr",
            "Asja Fischer",
            "Dorothea Kolossa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Privacy Guarantees for De-Identifying Text Transformations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2208",
        "paper_authors": [
            "David Ifeoluwa Adelani",
            "Ali Davody",
            "Thomas Kleinbauer",
            "Dietrich Klakow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Audio Attacks on ASR Systems with Dropout Uncertainty",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1846",
        "paper_authors": [
            "Tejas Jayashankar",
            "Jonathan Le Roux",
            "Pierre Moulin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1066",
        "paper_authors": [
            "Wen-Chin Huang",
            "Tomoki Hayashi",
            "Yi-Chiao Wu",
            "Hirokazu Kameoka",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nonparallel Training of Exemplar-Based Voice Conversion System Using INCA-Based Alignment Technique",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1232",
        "paper_authors": [
            "Hitoshi Suda",
            "Gaku Kotani",
            "Daisuke Saito"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Intelligibility of Dysarthric Speech Using Gated Convolutional-Based Voice Conversion System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1367",
        "paper_authors": [
            "Chen-Yu Chen",
            "Wei-Zhong Zheng",
            "Syu-Siang Wang",
            "Yu Tsao",
            "Pei-Chun Li",
            "Ying-Hui Lai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net Architecture",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1443",
        "paper_authors": [
            "Da-Yi Wu",
            "Yen-Hao Chen",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion Without Parallel Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1542",
        "paper_authors": [
            "Seung Won Park",
            "Doo-young Kim",
            "Myun-chul Joe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Speaker Representations Adjustment and Decoder Factorization for Speaker Adaptation in End-to-End Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1623",
        "paper_authors": [
            "Ruibo Fu",
            "Jianhua Tao",
            "Zhengqi Wen",
            "Jiangyan Yi",
            "Tao Wang",
            "Chunyu Qiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ARVC: An Auto-Regressive Voice Conversion System Without Parallel Training Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1715",
        "paper_authors": [
            "Zheng Lian",
            "Zhengqi Wen",
            "Xinyong Zhou",
            "Songbai Pu",
            "Shengkai Zhang",
            "Jianhua Tao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Zero-Shot Voice Conversion Using Explicit Conditioning Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1889",
        "paper_authors": [
            "Shahan Nercessian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Parallel Voice Conversion with Fewer Labeled Data by Conditional Generative Adversarial Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2162",
        "paper_authors": [
            "Minchuan Chen",
            "Weijian Hou",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transferring Source Style in Non-Parallel Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2412",
        "paper_authors": [
            "Songxiang Liu",
            "Yuewen Cao",
            "Shiyin Kang",
            "Na Hu",
            "Xunying Liu",
            "Dan Su",
            "Dong Yu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Conversion Using Speech-to-Speech Neuro-Style Transfer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3056",
        "paper_authors": [
            "Ehab A. AlBadawy",
            "Siwei Lyu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Cross-Lingual Transfer Learning for End-to-End Speech Recognition with Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2955",
        "paper_authors": [
            "Changhan Wang",
            "Juan Miguel Pino",
            "Jiatao Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transliteration Based Data Augmentation for Training Multilingual ASR Acoustic Models in Low Resource Settings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2593",
        "paper_authors": [
            "Samuel Thomas",
            "Kartik Audhkhasi",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multilingual Speech Recognition with Self-Attention Structured Parameterization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2847",
        "paper_authors": [
            "Yun Zhu",
            "Parisa Haghani",
            "Anshuman Tripathi",
            "Bhuvana Ramabhadran",
            "Brian Farris",
            "Hainan Xu",
            "Han Lu",
            "Hasim Sak",
            "Isabel Leal",
            "Neeraj Gaur",
            "Pedro J. Moreno",
            "Qian Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lattice-Free Maximum Mutual Information Training of Multilingual Speech Recognition Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2919",
        "paper_authors": [
            "Srikanth R. Madikeri",
            "Banriskhem K. Khonglah",
            "Sibo Tong",
            "Petr Motl\u00edcek",
            "Herv\u00e9 Bourlard",
            "Daniel Povey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2831",
        "paper_authors": [
            "Vineel Pratap",
            "Anuroop Sriram",
            "Paden Tomasello",
            "Awni Y. Hannun",
            "Vitaliy Liptchinsky",
            "Gabriel Synnaeve",
            "Ronan Collobert"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multilingual Speech Recognition Using Language-Specific Phoneme Recognition as Auxiliary Task for Indian Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2739",
        "paper_authors": [
            "Hardik B. Sailor",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Style Variation as a Vantage Point for Code-Switching",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2574",
        "paper_authors": [
            "Khyathi Raghavi Chandu",
            "Alan W. Black"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bi-Encoder Transformer Network for Mandarin-English Code-Switching Speech Recognition Using Mixture of Experts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2485",
        "paper_authors": [
            "Yizhou Lu",
            "Mingkun Huang",
            "Hao Li",
            "Jiaqi Guo",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Low Resource Code-Switched ASR Using Augmented Code-Switched TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2402",
        "paper_authors": [
            "Yash Sharma",
            "Basil Abraham",
            "Karan Taneja",
            "Preethi Jyothi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Context-Aware End-to-End Code-Switching Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1980",
        "paper_authors": [
            "Zimeng Qiu",
            "Yiyuan Li",
            "Xinjian Li",
            "Florian Metze",
            "William M. Campbell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Increasing the Intelligibility and Naturalness of Alaryngeal Speech Using Voice Conversion and Synthetic Fundamental Frequency",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1196",
        "paper_authors": [
            "Tuan Dinh",
            "Alexander Kain",
            "Robin Samlan",
            "Beiming Cao",
            "Jun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Assessment of Dysarthric Severity Level Using Audio-Video Cross-Modal Approach in Deep Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1997",
        "paper_authors": [
            "Han Tong",
            "Hamid R. Sharifzadeh",
            "Ian McLoughlin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Staged Knowledge Distillation for End-to-End Dysarthric Speech Recognition and Speech Attribute Transcription",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1755",
        "paper_authors": [
            "Yuqin Lin",
            "Longbiao Wang",
            "Sheng Li",
            "Jianwu Dang",
            "Chenchen Ding"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dysarthric Speech Recognition Based on Deep Metric Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2267",
        "paper_authors": [
            "Yuki Takashima",
            "Ryoichi Takashima",
            "Tetsuya Takiguchi",
            "Yasuo Ariki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Glottis Detection and Segmentation in Stroboscopic Videos Using Convolutional Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2599",
        "paper_authors": [
            "Divya Degala",
            "M. V. Achuth Rao",
            "Rahul Krishnamurthy",
            "Pebbili Gopikishore",
            "Veeramani Priyadharshini",
            "Prakash T. K.",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Feature Extraction with Interpretable Deep Neural Network for Neurodegenerative Related Disorder Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2684",
        "paper_authors": [
            "Yilin Pan",
            "Bahman Mirheidari",
            "Zehai Tu",
            "Ronan O'Malley",
            "Traci Walker",
            "Annalena Venneri",
            "Markus Reuber",
            "Daniel Blackburn",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coswara - A Database of Breathing, Cough, and Voice Sounds for COVID-19 Diagnosis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2768",
        "paper_authors": [
            "Neeraj Kumar Sharma",
            "Prashant Krishnan V",
            "Rohit Kumar",
            "Shreyas Ramoji",
            "Srikanth Raj Chetupalli",
            "Nirmala R.",
            "Prasanta Kumar Ghosh",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic-Based Articulatory Phenotypes of Amyotrophic Lateral Sclerosis and Parkinson's Disease: Towards an Interpretable, Hypothesis-Driven Framework of Motor Control",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1459",
        "paper_authors": [
            "Hannah P. Rowe",
            "Sarah E. Gutz",
            "Marc F. Maffei",
            "Jordan R. Green"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recognising Emotions in Dysarthric Speech Using Typical Speech Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1825",
        "paper_authors": [
            "Lubna Alhinti",
            "Stuart P. Cunningham",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting and Analysing Spontaneous Oral Cancer Speech in the Wild",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1598",
        "paper_authors": [
            "Bence Mark Halpern",
            "Rob van Son",
            "Michiel W. M. van den Brekel",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Zero Resource Speech Challenge 2020: Discovering Discrete Subword and Word Units",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2743",
        "paper_authors": [
            "Ewan Dunbar",
            "Julien Karadayi",
            "Mathieu Bernard",
            "Xuan-Nga Cao",
            "Robin Algayres",
            "Lucas Ondel",
            "Laurent Besacier",
            "Sakriani Sakti",
            "Emmanuel Dupoux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vector-Quantized Neural Networks for Acoustic Unit Discovery in the ZeroSpeech 2020 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1693",
        "paper_authors": [
            "Benjamin van Niekerk",
            "Leanne Nortje",
            "Herman Kamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploration of End-to-End Synthesisers for Zero Resource Speech Challenge 2020",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2731",
        "paper_authors": [
            "Karthik Pandia D. S",
            "Anusha Prakash",
            "Mano Ranjith Kumar M.",
            "Hema A. Murthy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vector Quantized Temporally-Aware Correspondence Sparse Autoencoders for Zero-Resource Acoustic Unit Discovery",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2765",
        "paper_authors": [
            "Batuhan G\u00fcndogdu",
            "Bolaji Yusuf",
            "Mansur Yesilbursa",
            "Murat Saraclar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer VQ-VAE for Unsupervised Unit Discovery and Speech Synthesis: ZeroSpeech 2020 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3033",
        "paper_authors": [
            "Andros Tjandra",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring TTS Without T Using Biologically/Psychologically Motivated Neural Network Modules (ZeroSpeech 2020)",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3127",
        "paper_authors": [
            "Takashi Morita",
            "Hiroki Koda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cyclic Spectral Modeling for Unsupervised Unit Discovery into Voice Conversion with Excitation and Waveform Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2559",
        "paper_authors": [
            "Patrick Lumban Tobing",
            "Tomoki Hayashi",
            "Yi-Chiao Wu",
            "Kazuhiro Kobayashi",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Acoustic Unit Representation Learning for Voice Conversion Using WaveNet Auto-Encoders",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1785",
        "paper_authors": [
            "Mingjie Chen",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Discovery of Recurring Speech Patterns Using Probabilistic Adaptive Metrics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1738",
        "paper_authors": [
            "Okko R\u00e4s\u00e4nen",
            "Mar\u00eda Andrea Cruz Bland\u00f3n"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Expressing Autoencoders for Unsupervised Spoken Term Discovery",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3000",
        "paper_authors": [
            "Saurabhchand Bhati",
            "Jes\u00fas Villalba",
            "Piotr Zelasko",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perceptimatic: A Human Speech Perception Benchmark for Unsupervised Subword Modelling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1671",
        "paper_authors": [
            "Juliette Millet",
            "Ewan Dunbar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decoding Imagined, Heard, and Spoken Speech: Classification and Regression of EEG Using a 14-Channel Dry-Contact Mobile Headset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2745",
        "paper_authors": [
            "Jonathan Clayton",
            "Scott Wellington",
            "Cassia Valentini-Botinhao",
            "Oliver Watts"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Glottal Closure Instants Detection from EGG Signal by Classification Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1189",
        "paper_authors": [
            "Gurunath Reddy M.",
            "K. Sreenivasa Rao",
            "Partha Pratim Das"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Classify Imaginary Mandarin Tones with Cortical EEG Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1248",
        "paper_authors": [
            "Hua Li",
            "Fei Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Augmenting Images for ASR and TTS Through Single-Loop and Dual-Loop Multimodal Chain Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2001",
        "paper_authors": [
            "Johanes Effendi",
            "Andros Tjandra",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Punctuation Prediction in Spontaneous Conversations: Can We Mitigate ASR Errors with Retrofitted Word Embeddings?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1250",
        "paper_authors": [
            "Lukasz Augustyniak",
            "Piotr Szymanski",
            "Mikolaj Morzy",
            "Piotr Zelasko",
            "Adrian Szymczak",
            "Jan Mizgajski",
            "Yishay Carmiel",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Semi-Supervised Learning Framework for Punctuation Prediction in Conversational Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3074",
        "paper_authors": [
            "Monica Sunkara",
            "Srikanth Ronanki",
            "Dhanush Bekal",
            "Sravan Bodapati",
            "Katrin Kirchhoff"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient MDI Adaptation for n-Gram Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2909",
        "paper_authors": [
            "Ruizhe Huang",
            "Ke Li",
            "Ashish Arora",
            "Daniel Povey",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Tail Performance of a Deliberation E2E ASR Model Using a Large Text Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1465",
        "paper_authors": [
            "Cal Peyser",
            "Sepand Mavandadi",
            "Tara N. Sainath",
            "James Apfel",
            "Ruoming Pang",
            "Shankar Kumar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language Model Data Augmentation Based on Text Domain Transfer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1524",
        "paper_authors": [
            "Atsunori Ogawa",
            "Naohiro Tawara",
            "Marc Delcroix"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contemporary Polish Language Model (Version 2) Using Big Data and Sub-Word Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1207",
        "paper_authors": [
            "Krzysztof Wolk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Speech Recognition of Compound-Rich Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2514",
        "paper_authors": [
            "Prabhat Pandey",
            "Volker Leutnant",
            "Simon Wiesler",
            "Jahn Heymann",
            "Daniel Willett"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language Modeling for Speech Analytics in Under-Resourced Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1586",
        "paper_authors": [
            "Simone Wills",
            "Pieter Uys",
            "Charl Johannes van Heerden",
            "Etienne Barnard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Early Study on Intelligent Analysis of Speech Under COVID-19: Severity, Sleep Quality, Fatigue, and Anxiety",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2223",
        "paper_authors": [
            "Jing Han",
            "Kun Qian",
            "Meishu Song",
            "Zijiang Yang",
            "Zhao Ren",
            "Shuo Liu",
            "Juan Liu",
            "Huaiyuan Zheng",
            "Wei Ji",
            "Tomoya Koike",
            "Xiao Li",
            "Zixing Zhang",
            "Yoshiharu Yamamoto",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Evaluation of the Effect of Anxiety on Speech - Computational Prediction of Anxiety from Sustained Vowels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1801",
        "paper_authors": [
            "Alice Baird",
            "Nicholas Cummins",
            "Sebastian Schnieder",
            "Jarek Krajewski",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hybrid Network Feature Extraction for Depression Assessment from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2396",
        "paper_authors": [
            "Ziping Zhao",
            "Qifei Li",
            "Nicholas Cummins",
            "Bin Liu",
            "Haishuai Wang",
            "Jianhua Tao",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Detection of Alzheimer's Disease Using Automatic Speech Recognition to Identify High-Quality Segments for More Robust Feature Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2698",
        "paper_authors": [
            "Yilin Pan",
            "Bahman Mirheidari",
            "Markus Reuber",
            "Annalena Venneri",
            "Daniel Blackburn",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Classification of Manifest Huntington Disease Using Vowel Distortion Measures",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2724",
        "paper_authors": [
            "Amrit Romana",
            "John Bandon",
            "Noelle Carlozzi",
            "Angela Roberts",
            "Emily Mower Provost"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parkinson's Disease Detection from Speech Using Single Frequency Filtering Cepstral Coefficients",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3197",
        "paper_authors": [
            "Sudarsana Reddy Kadiri",
            "Rashmi Kethireddy",
            "Paavo Alku"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Prediction of Speech Intelligibility Based on X-Vectors in the Context of Head and Neck Cancer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1431",
        "paper_authors": [
            "Sebasti\u00e3o Quintas",
            "Julie Mauclair",
            "Virginie Woisard",
            "Julien Pinquier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spectral Moment and Duration of Burst of Plosives in Speech of Children with Hearing Impairment and Typically Developing Children - A Comparative Study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1805",
        "paper_authors": [
            "Ajish K. Abraham",
            "M. Pushpavathi",
            "N. Sreedevi",
            "A. Navya",
            "Vikram C. Mathad",
            "S. R. Mahadeva Prasanna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Aphasic Speech Recognition Using a Mixture of Speech Intelligibility Experts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2049",
        "paper_authors": [
            "Matthew Perez",
            "Zakaria Aldeneh",
            "Emily Mower Provost"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Discrimination of Apraxia of Speech and Dysarthria Using a Minimalistic Set of Handcrafted Features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2253",
        "paper_authors": [
            "Ina Kodrasi",
            "Michaela Pernon",
            "Marina Laganaro",
            "Herv\u00e9 Bourlard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weak-Attention Suppression for Transformer Based Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1363",
        "paper_authors": [
            "Yangyang Shi",
            "Yongqiang Wang",
            "Chunyang Wu",
            "Christian Fuegen",
            "Frank Zhang",
            "Duc Le",
            "Ching-Feng Yeh",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conv-Transformer Transducer: Low Latency, Low Frame Rate, Streamable End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2361",
        "paper_authors": [
            "Wenyong Huang",
            "Wenchao Hu",
            "Yu Ting Yeung",
            "Xiao Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Transformer-Based Speech Recognition with Unsupervised Pre-Training and Multi-Task Semantic Knowledge Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2007",
        "paper_authors": [
            "Song Li",
            "Lin Li",
            "Qingyang Hong",
            "Lingling Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer-Based Long-Context End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2928",
        "paper_authors": [
            "Takaaki Hori",
            "Niko Moritz",
            "Chiori Hori",
            "Jonathan Le Roux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-and-Mixed Attention Decoder with Deep Acoustic Structure for Transformer-Based LVCSR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2556",
        "paper_authors": [
            "Xinyuan Zhou",
            "Grandee Lee",
            "Emre Yilmaz",
            "Yanhua Long",
            "Jiaen Liang",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Universal Speech Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1716",
        "paper_authors": [
            "Yingzhu Zhao",
            "Chongjia Ni",
            "Cheung-Chi Leung",
            "Shafiq R. Joty",
            "Eng Siong Chng",
            "Bin Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2086",
        "paper_authors": [
            "Zhengkun Tian",
            "Jiangyan Yi",
            "Jianhua Tao",
            "Ye Bai",
            "Shuai Zhang",
            "Zhengqi Wen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross Attention with Monotonic Alignment for Speech Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1198",
        "paper_authors": [
            "Yingzhu Zhao",
            "Chongjia Ni",
            "Cheung-Chi Leung",
            "Shafiq R. Joty",
            "Eng Siong Chng",
            "Bin Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conformer: Convolution-augmented Transformer for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-3015",
        "paper_authors": [
            "Anmol Gulati",
            "James Qin",
            "Chung-Cheng Chiu",
            "Niki Parmar",
            "Yu Zhang",
            "Jiahui Yu",
            "Wei Han",
            "Shibo Wang",
            "Zhengdong Zhang",
            "Yonghui Wu",
            "Ruoming Pang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Transformers for Large-Scale Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2638",
        "paper_authors": [
            "Liang Lu",
            "Changliang Liu",
            "Jinyu Li",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sparseness-Aware DOA Estimation with Majorization Minimization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1168",
        "paper_authors": [
            "Masahito Togami",
            "Robin Scheibler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spatial Resolution of Early Reflection for Speech and White Noise",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1220",
        "paper_authors": [
            "Xiaoli Zhong",
            "Hao Song",
            "Xuejie Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effect of Microphone Position Measurement Error on RIR and its Impact on Speech Intelligibility and Quality",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-1578",
        "paper_authors": [
            "Aditya Raikar",
            "Karan Nathwani",
            "Ashish Panda",
            "Sunil Kumar Kopparapu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Blind Reverberation Time Estimation Using CRNNs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2156",
        "paper_authors": [
            "Shuwen Deng",
            "Wolfgang Mack",
            "Emanu\u00ebl A. P. Habets"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Single-Channel Blind Direct-to-Reverberation Ratio Estimation Using Masking",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2171",
        "paper_authors": [
            "Wolfgang Mack",
            "Shuwen Deng",
            "Emanu\u00ebl A. P. Habets"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Importance of Time-Frequency Averaging for Binaural Speaker Localization in Reverberant Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2256",
        "paper_authors": [
            "Hanan Beit-On",
            "Vladimir Tourbabin",
            "Boaz Rafaely"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Signal Enhancement Using Relative Harmonic Coefficients: Spherical Harmonics Domain Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2316",
        "paper_authors": [
            "Yonggang Hu",
            "Prasanga N. Samarasinghe",
            "Thushara D. Abhayapala"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Instantaneous Time Delay Estimation of Broadband Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2462",
        "paper_authors": [
            "B. H. V. S. Narayana Murthy",
            "J. V. Satyanarayana",
            "Nivedita Chennupati",
            "B. Yegnanarayana"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "U-Net Based Direct-Path Dominance Test for Robust Direction-of-Arrival Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2493",
        "paper_authors": [
            "Hao Wang",
            "Kai Chen",
            "Jing Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sound Event Localization and Detection Based on Multiple DOA Beamforming and Multi-Task Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2020-2759",
        "paper_authors": [
            "Wei Xue",
            "Ying Tong",
            "Chao Zhang",
            "Guohong Ding",
            "Xiaodong He",
            "Bowen Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    }
]