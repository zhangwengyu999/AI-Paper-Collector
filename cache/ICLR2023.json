[
    {
        "paper_name": "TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis",
        "paper_url": "https://openreview.net/pdf?id=ju_Uqw384Oq",
        "paper_authors": [
            "Haixu Wu",
            "Tengge Hu",
            "Yong Liu",
            "Hang Zhou",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "paper_abstract": "Time series analysis is of immense importance in extensive applications, such as weather forecasting, anomaly detection, and action recognition. This paper focuses on temporal variation modeling, which is the common key problem of extensive analysis tasks. Previous methods attempt to accomplish this directly from the 1D time series, which is extremely challenging due to the intricate temporal patterns. Based on the observation of multi-periodicity in time series, we ravel out the complex temporal variations into the multiple intraperiod- and interperiod-variations. To tackle the limitations of 1D time series in representation capability, we extend the analysis of temporal variations into the 2D space by transforming the 1D time series into a set of 2D tensors based on multiple periods. This transformation can embed the intraperiod- and interperiod-variations into the columns and rows of the 2D tensors respectively, making the 2D-variations to be easily modeled by 2D kernels. Technically, we propose the TimesNet with TimesBlock as a task-general backbone for time series analysis. TimesBlock can discover the multi-periodicity adaptively and extract the complex temporal variations from transformed 2D tensors by a parameter-efficient inception block. Our proposed TimesNet achieves consistent state-of-the-art in five mainstream time series analysis tasks, including short- and long-term forecasting, imputation, classification, and anomaly detection. Code is available at this repository: https://github.com/thuml/TimesNet.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning without Prejudices: Continual Unbiased Learning via Benign and Malignant Forgetting",
        "paper_url": "https://openreview.net/pdf?id=gfPUokHsW-",
        "paper_authors": [
            "Myeongho Jeon",
            "Hyoje Lee",
            "Yedarm Seong",
            "Myungjoo Kang"
        ],
        "paper_abstract": "Although machine learning algorithms have achieved state-of-the-art status in image classification, recent studies have substantiated that the ability of the models to learn several tasks in sequence, termed continual learning (CL), often suffers from abrupt degradation of performance from previous tasks.  A large body of CL frameworks has been devoted to alleviating this issue. However, we observe that forgetting phenomena in CL are not always unfavorable, especially when there is bias (spurious correlation) in training data. We term such type of forgetting benign forgetting, and categorize detrimental forgetting as malignant forgetting. Based on this finding, our objective in this study is twofold:  (a) to discourage malignant forgetting by generating previous representations, and (b) encourage benign forgetting by employing contrastive learning in conjunction with feature-level augmentation. Extensive evaluations of biased experimental setups demonstrate that our proposed method, Learning without Prejudices, is effective for continual unbiased learning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities",
        "paper_url": "https://openreview.net/pdf?id=tLScKVhcCR",
        "paper_authors": [
            "Takashi Matsubara",
            "Takaharu Yaguchi"
        ],
        "paper_abstract": "Many real-world dynamical systems are associated with first integrals (a.k.a. invariant quantities), which are quantities that remain unchanged over time. The discovery and understanding of first integrals are fundamental and important topics both in the natural sciences and in industrial applications. First integrals arise from the conservation laws of system energy, momentum, and mass, and from constraints on states; these are typically related to specific geometric structures of the governing equations. Existing neural networks designed to ensure such first integrals have shown excellent accuracy in modeling from data. However, these models incorporate the underlying structures, and in most situations where neural networks learn unknown systems, these structures are also unknown. This limitation needs to be overcome for scientific discovery and modeling of unknown systems. To this end, we propose first integral-preserving neural differential equation (FINDE). By leveraging the projection method and the discrete gradient method, FINDE finds and preserves first integrals from data, even in the absence of prior knowledge about underlying structures. Experimental results demonstrate that FINDE can predict future states of target systems much longer and find various quantities consistent with well-known first integrals in a unified manner.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Approximate Vanishing Ideal Computations at Scale",
        "paper_url": "https://openreview.net/pdf?id=3ZPESALKXO",
        "paper_authors": [
            "Elias Samuel Wirth",
            "Hiroshi Kera",
            "Sebastian Pokutta"
        ],
        "paper_abstract": "The vanishing ideal of a set of points $X = \\{\\mathbf{x}_1, \\ldots, \\mathbf{x}_m\\}\\subseteq \\mathbb{R}^n$ is the set of polynomials that evaluate to $0$ over all points $\\mathbf{x} \\in X$ and admits an efficient representation by a finite subset of generators. In practice, to accommodate noise in the data, algorithms that construct generators of the approximate vanishing ideal are widely studied but their computational complexities remain expensive. In this paper, we scale up the oracle approximate vanishing ideal algorithm (OAVI), the only generator-constructing algorithm with known learning guarantees. We prove that the computational complexity of OAVI is not superlinear, as previously claimed, but linear in the number of samples $m$. In addition, we propose two modifications that accelerate OAVI's training time: Our analysis reveals that replacing the pairwise conditional gradients algorithm, one of the solvers used in OAVI, with the faster blended pairwise conditional gradients algorithm leads to an exponential speed-up in the number of features $n$. Finally, using a new inverse Hessian boosting approach, intermediate convex optimization problems can be solved almost instantly, improving OAVI's training time by multiple orders of magnitude in a variety of numerical experiments.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Selective Annotation Makes Language Models Better Few-Shot Learners",
        "paper_url": "https://openreview.net/pdf?id=qY1hlv7gwg",
        "paper_authors": [
            "Hongjin SU",
            "Jungo Kasai",
            "Chen Henry Wu",
            "Weijia Shi",
            "Tianlu Wang",
            "Jiayi Xin",
            "Rui Zhang",
            "Mari Ostendorf",
            "Luke Zettlemoyer",
            "Noah A. Smith",
            "Tao Yu"
        ],
        "paper_abstract": "Many recent approaches to natural language tasks are built on the remarkable abilities of large language models. Large language models can perform in-context learning, where they learn a new task from a few task demonstrations, without any parameter updates. This work examines the implications of in-context learning for the creation of datasets for new natural language tasks. Departing from recent in-context learning methods, we formulate an annotation-efficient, two-step framework: selective annotation that chooses a pool of examples to annotate from unlabeled data in advance, followed by prompt retrieval that retrieves task examples from the annotated pool at test time. Based on this framework, we propose an unsupervised, graph-based selective annotation method, voke-k, to select diverse, representative examples to annotate. Extensive experiments on 10 datasets (covering classification, commonsense reasoning, dialogue, and text/code generation) demonstrate that our selective annotation method improves the task performance by a large margin. On average, vote-k achieves a 12.9%/11.4% relative gain under an annotation budget of 18/100, as compared to randomly selecting examples to annotate. Compared to state-of-the-art supervised finetuning approaches, it yields similar performance with 10-100x less annotation cost across 10 tasks. We further analyze the effectiveness of our framework in various scenarios: language models with varying sizes, alternative selective annotation methods, and cases where there is a test data domain shift. We hope that our studies will serve as a basis for data annotations as large language models are increasingly applied to new tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Switch-NeRF: Learning Scene Decomposition with Mixture of Experts for Large-scale Neural Radiance Fields",
        "paper_url": "https://openreview.net/pdf?id=PQ2zoIZqvm",
        "paper_authors": [
            "Zhenxing MI",
            "Dan Xu"
        ],
        "paper_abstract": "The Neural Radiance Fields (NeRF) have been recently applied to reconstruct building-scale and even city-scale scenes. To model a large-scale scene efficiently, a dominant strategy is to employ a divide-and-conquer paradigm via performing scene decomposition, which decomposes a complex scene into parts that are further processed by different sub-networks. Existing large-scale NeRFs mainly use heuristic hand-crafted scene decomposition, with regular 3D-distance-based or physical-street-block-based schemes. Although achieving promising results, the hand-crafted schemes limit the capabilities of NeRF in large-scale scene modeling in several aspects. Manually designing a universal scene decomposition rule for different complex scenes is challenging, leading to adaptation issues for different scenarios. The decomposition procedure is not learnable, hindering the network from jointly optimizing the scene decomposition and the radiance fields in an end-to-end manner.  The different sub-networks are typically optimized independently, and thus hand-crafted rules are required to composite them to achieve a better consistency.  To tackle these issues, we propose Switch-NeRF, a novel end-to-end large-scale NeRF with learning-based scene decomposition. We design a gating network to dispatch 3D points to different NeRF sub-networks. The gating network can be optimized together with the NeRF sub-networks for different scene partitions, by a design with the Sparsely Gated Mixture of Experts (MoE). The outputs from different sub-networks can also be fused in a learnable way in the unified framework to effectively guarantee the consistency of the whole scene. Furthermore, the proposed MoE-based Switch-NeRF model is carefully implemented and optimized to achieve both high-fidelity scene reconstruction and efficient computation. Our method establishes clear state-of-the-art performances on several large-scale datasets. To the best of our knowledge, we are the first to propose an applicable end-to-end sparse NeRF network  with learning-based decomposition for large-scale scenes. Codes are released at https://github.com/MiZhenxing/Switch-NeRF.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NORM: Knowledge Distillation via N-to-One Representation Matching",
        "paper_url": "https://openreview.net/pdf?id=CRNwGauQpb6",
        "paper_authors": [
            "Xiaolong Liu",
            "LUKING LI",
            "Chao Li",
            "Anbang Yao"
        ],
        "paper_abstract": "Existing feature distillation methods commonly adopt the One-to-one Representation Matching between any pre-selected teacher-student layer pair. In this paper, we present $N$-to-$O$ne $R$epresentation $M$atching (NORM), a new two-stage knowledge distillation method, which relies on a simpleFeature Transform (FT) module consisting of two linear layers. In view of preserving the intact information learnt by the teacher network, during training, our FT module is merely inserted after the last convolutional layer of the student network. The first linear layer projects the student representation to a feature space having $N$ times feature channels than the teacher representation from the last convolutional layer, and the second linear layer contracts the expanded output back to the original feature space. By sequentially splitting the expanded student representation into $N$ non-overlapping feature segments having the same number of feature channels as the teacher's, they can be readily forced to approximate the intact teacher representation simultaneously, formulating a novel many-to-one representation matching mechanism conditioned on a single teacher-student layer pair. After training, such an FT module will be naturally merged into the subsequent fully connected layer thanks to its linear property, introducing no extra parameters or architectural modifications to the student network at inference. Extensive experiments on different visual recognition benchmarks demonstrate the leading performance of our method. For instance, the ResNet18|MobileNet|ResNet50-1/4 model trained by NORM reaches 72.14%|74.26%|68.03% top-1 accuracy on the ImageNet dataset when using a pre-trained ResNet34|ResNet50|ResNet50 model as the teacher, achieving an absolute improvement of 2.01%|4.63%|3.03% against the individually trained counterpart. Code is available at https://github.com/OSVAI/NORM.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Critic Sequential Monte Carlo",
        "paper_url": "https://openreview.net/pdf?id=ObtGcyKmwna",
        "paper_authors": [
            "Vasileios Lioutas",
            "Jonathan Wilder Lavington",
            "Justice Sefas",
            "Matthew Niedoba",
            "Yunpeng Liu",
            "Berend Zwartsenberg",
            "Setareh Dabiri",
            "Frank Wood",
            "Adam Scibior"
        ],
        "paper_abstract": "We introduce CriticSMC, a new algorithm for planning as inference built from a composition of sequential Monte Carlo with learned Soft-Q function heuristic factors. These heuristic factors, obtained from parametric approximations of the marginal likelihood ahead, more effectively guide SMC towards the desired target distribution, which is particularly helpful for planning in environments with hard constraints placed sparsely in time. Compared with previous work, we modify the placement of such heuristic factors, which allows us to cheaply propose and evaluate large numbers of putative action particles, greatly increasing inference and planning efficiency. CriticSMC is compatible with informative priors, whose density function need not be known, and can be used as a model-free control algorithm. Our experiments on collision avoidance in a high-dimensional simulated driving task show that CriticSMC significantly reduces collision rates at a low computational cost while maintaining realism and diversity of driving behaviors across vehicles and environment scenarios.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image Transformers Help 3D Representation Learning?",
        "paper_url": "https://openreview.net/pdf?id=8Oun8ZUVe8N",
        "paper_authors": [
            "Runpei Dong",
            "Zekun Qi",
            "Linfeng Zhang",
            "Junbo Zhang",
            "Jianjian Sun",
            "Zheng Ge",
            "Li Yi",
            "Kaisheng Ma"
        ],
        "paper_abstract": "The success of deep learning heavily relies on large-scale data with comprehensive labels, which is more expensive and time-consuming to fetch in 3D compared to 2D images or natural languages. This promotes the potential of utilizing models pretrained with data more than 3D as teachers for cross-modal knowledge transferring. In this paper, we revisit masked modeling in a unified fashion of knowledge distillation, and we show that foundational Transformers pretrained with 2D images or natural languages can help self-supervised 3D representation learning through training Autoencoders as Cross-Modal Teachers (ACT). The pretrained Transformers are transferred as cross-modal 3D teachers using discrete variational autoencoding self-supervision, during which the Transformers are frozen with prompt tuning for better knowledge inheritance. The latent features encoded by the 3D teachers are used as the target of masked point modeling, wherein the dark knowledge is distilled to the 3D Transformer students as foundational geometry understanding. Our ACT pretrained 3D learner achieves state-of-the-art generalization capacity across various downstream benchmarks, e.g., 88.21% overall accuracy on ScanObjectNN. Codes have been released at https://github.com/RunpeiDong/ACT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?",
        "paper_url": "https://openreview.net/pdf?id=0Q9H_Pgx132",
        "paper_authors": [
            "Kaiqi Zhang",
            "Yu-Xiang Wang"
        ],
        "paper_abstract": "We study the theory of neural network (NN) from the lens of classical nonparametric regression problems with a focus on NN\u2019s ability to adaptively estimate functions with heterogeneous smoothness \u2014 a property of functions in Besov or Bounded Variation (BV) classes. Existing work on this problem requires tuning the NN architecture based on the function spaces and sample sizes. We consider a \u201cParallel NN\u201d variant of deep ReLU networks and show that the standard weight decay is equivalent to promoting the \u2113p -sparsity (0 < p < 1) of the coefficient vector of an end-to-end learned function bases, i.e., a dictionary. Using this equivalence, we further establish that by tuning only the weight decay, such Parallel NN achieves an estimation error arbitrarily close to the minimax rates for both the Besov and BV classes. Notably, it gets exponentially closer to minimax optimal as the NN gets deeper. Our research sheds new lights on why depth matters and how NNs are more powerful than kernel methods",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sparse Token Transformer with Attention Back Tracking",
        "paper_url": "https://openreview.net/pdf?id=VV0hSE8AxCw",
        "paper_authors": [
            "Heejun Lee",
            "Minki Kang",
            "Youngwan Lee",
            "Sung Ju Hwang"
        ],
        "paper_abstract": "Despite the success of Transformers in various applications from text, vision, and speech domains, they are yet to become standard architectures for mobile and edge device applications due to their heavy memory and computational requirements. While there exist many different approaches to reduce the complexities of the Transformers, such as the pruning of the weights/attentions/tokens, quantization, and distillation, we focus on token pruning, which reduces not only the complexity of the attention operations, but also the linear layers, which have non-negligible computational costs. However, previous token pruning approaches often remove tokens during the feed-forward stage without consideration of their impact on later layers' attentions, which has a potential risk of dropping out important tokens for the given task. To tackle this issue, we propose an attention back-tracking method that tracks the importance of each attention in a Transformer architecture from the outputs to the inputs, to preserve the tokens that have a large impact on the final predictions. We experimentally validate the effectiveness of the method on both NLP and CV benchmarks, using Transformer architectures for both domains, and the results show that the proposed attention back-tracking allows the model to better retain the full models' performance even at high sparsity rates, significantly outperforming all baselines. Qualitative analysis of the examples further shows that our method does preserve semantically meaningful tokens.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Active Distillation",
        "paper_url": "https://openreview.net/pdf?id=ALDM5SN2r7M",
        "paper_authors": [
            "Cenk Baykal",
            "Khoa Trinh",
            "Fotis Iliopoulos",
            "Gaurav Menghani",
            "Erik Vee"
        ],
        "paper_abstract": "Distilling knowledge from a large teacher model to a lightweight one is a widely successful approach for generating compact, powerful models in the semi-supervised learning setting where a limited amount of labeled data is available. In large-scale applications, however, the teacher tends to provide a large number of incorrect soft-labels that impairs student performance. The sheer size of the teacher additionally constrains the number of soft-labels that can be queried due to prohibitive computational and/or financial costs. The difficulty in achieving simultaneous \\emph{efficiency} (i.e., minimizing soft-label queries) and \\emph{robustness} (i.e., avoiding student inaccuracies due to incorrect labels) hurts the widespread application of knowledge distillation to many modern tasks. In this paper, we present a parameter-free approach with provable guarantees to query the soft-labels of points that are simultaneously informative and correctly labeled by the teacher. At the core of our work lies a game-theoretic formulation that explicitly considers the inherent trade-off between the informativeness and correctness of input instances. We establish bounds on the expected performance of our approach that hold even in worst-case distillation instances. We present empirical evaluations on popular benchmarks that demonstrate the improved distillation performance enabled by our work relative to that of state-of-the-art active learning and active distillation methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Kernel Neural Optimal Transport",
        "paper_url": "https://openreview.net/pdf?id=Zuc_MHtUma4",
        "paper_authors": [
            "Alexander Korotin",
            "Daniil Selikhanovych",
            "Evgeny Burnaev"
        ],
        "paper_abstract": "We study the Neural Optimal Transport (NOT) algorithm which uses the general optimal transport formulation and learns stochastic transport plans. We show that NOT with the weak quadratic cost may learn fake plans which are not optimal. To resolve this issue, we introduce kernel weak quadratic costs. We show that they provide improved theoretical guarantees and practical performance. We test NOT with kernel costs on the unpaired image-to-image translation task.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SeaFormer: Squeeze-enhanced Axial Transformer for Mobile Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=-qg8MQNrxZw",
        "paper_authors": [
            "Qiang Wan",
            "Zilong Huang",
            "Jiachen Lu",
            "Gang YU",
            "Li Zhang"
        ],
        "paper_abstract": "Since the introduction of Vision Transformers, the landscape of many computer vision tasks (e.g., semantic segmentation), which has been overwhelmingly dominated by CNNs, recently has significantly revolutionized. However, the computational cost and memory requirement render these methods unsuitable on the mobile device, especially for the high resolution per-pixel semantic segmentation task. In this paper, we introduce a new method squeeze-enhanced Axial Transformer (SeaFormer) for mobile semantic segmentation. Specifically, we design a generic attention block characterized by the formulation of squeeze Axial and spatial enhancement. It can be further used to create a family of backbone architectures with superior cost-effectiveness. Coupled with a light segmentation head, we demonstrate state-of-the-art results on the ADE20K, Pascal Context and COCO-stuff datasets. Critically, we beat both the mobile-friendly rivals and Transformer-based counterparts with better performance and lower latency without bells and whistles. Beyond semantic segmentation, we further apply the proposed SeaFormer architecture to image classification problem, demonstrating the potentials of serving as a versatile mobile-friendly backbone.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=4UldFtZ_CVF",
        "paper_authors": [
            "Shuai Zhang",
            "Meng Wang",
            "Pin-Yu Chen",
            "Sijia Liu",
            "Songtao Lu",
            "Miao Liu"
        ],
        "paper_abstract": "Due to the significant computational challenge of training large-scale graph neural networks (GNNs), various sparse learning techniques have been exploited to reduce memory and storage costs. Examples include graph sparsification that samples a subgraph to reduce the amount of data aggregation and model sparsification that prunes the neural network to reduce the number of trainable weights. Despite the empirical successes in reducing the training cost while maintaining the test accuracy, the theoretical generalization analysis of sparse learning for GNNs remains elusive. To the best of our knowledge, this paper provides the first theoretical characterization of joint edge-model sparse learning from the perspective of sample complexity and convergence rate in achieving zero generalization error. It proves analytically that both sampling important nodes and pruning neurons with lowest-magnitude can reduce the sample complexity and improve convergence without compromising the test accuracy. Although the analysis is centered on two-layer GNNs with structural constraints on data, the insights are applicable to more general setups and justified by both synthetic and practical citation datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Sparse and Low-Rank Priors for Image Recovery via Iterative Reweighted Least Squares Minimization",
        "paper_url": "https://openreview.net/pdf?id=TXPN6MtdSE4",
        "paper_authors": [
            "Stamatios Lefkimmiatis",
            "Iaroslav Sergeevich Koshelev"
        ],
        "paper_abstract": "In this work we introduce a novel optimization algorithm for image recovery under learned sparse and low-rank constraints, which are parameterized with weighted extensions of the $\\ell_p^p$-vector and $\\mathcal{S}_p^p$ Schatten-matrix quasi-norms for $0\\!<p\\!\\le1$, respectively. Our proposed algorithm generalizes the Iteratively Reweighted Least Squares (IRLS) method, used for signal recovery under $\\ell_1$ and nuclear-norm constrained minimization. Further, we interpret our overall minimization approach as a recurrent network that we then employ to deal with inverse low-level computer vision problems. Thanks to the convergence guarantees that our IRLS strategy offers, we are able to train the derived reconstruction networks using a memory-efficient implicit back-propagation scheme, which does not pose any restrictions on their effective depth. To assess our networks' performance, we compare them against other existing reconstruction methods on several inverse problems, namely image deblurring, super-resolution, demosaicking and sparse recovery. Our reconstruction results are shown to be very competitive and in many cases outperform those of existing unrolled networks, whose number of parameters is orders of magnitude higher than that of our learned models. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spherical Sliced-Wasserstein",
        "paper_url": "https://openreview.net/pdf?id=jXQ0ipgMdU",
        "paper_authors": [
            "Cl\u00e9ment Bonet",
            "Paul Berg",
            "Nicolas Courty",
            "Fran\u00e7ois Septier",
            "Lucas Drumetz",
            "Minh Tan Pham"
        ],
        "paper_abstract": "Many variants of the Wasserstein distance have been introduced to reduce its original computational burden. In particular the Sliced-Wasserstein distance (SW), which leverages one-dimensional projections for which a closed-form solution of the Wasserstein distance is available, has received a lot of interest. Yet, it is restricted to data living in Euclidean spaces, while the Wasserstein distance has been studied and used recently on manifolds. We focus more specifically on the sphere, for which we define a novel SW discrepancy, which we call spherical Sliced-Wasserstein, making a first step towards defining SW discrepancies on manifolds. Our construction is notably based on closed-form solutions of the Wasserstein distance on the circle, together with a new spherical Radon transform. Along with efficient algorithms and the corresponding implementations, we illustrate its properties in several machine learning use cases where spherical representations of data are at stake: sampling on the sphere, density estimation on real eath data or hyperspherical auto-encoders.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning",
        "paper_url": "https://openreview.net/pdf?id=m6ahb1mpwwX",
        "paper_authors": [
            "Zhuoran Yu",
            "Yin Li",
            "Yong Jae Lee"
        ],
        "paper_abstract": "Recent state-of-the-art methods in imbalanced semi-supervised learning (SSL) rely on confidence-based pseudo-labeling with consistency regularization. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted.  However, it has been shown that softmax-based confidence scores in deep networks can be arbitrarily high for samples far from the training data, and thus, the pseudo-labels for even high-confidence unlabeled samples may still be unreliable.  In this work, we present a new perspective of pseudo-labeling for imbalanced SSL. Without relying on model confidence, we propose to measure whether an unlabeled sample is likely to be \"in-distribution''; i.e., close to the current training data. To decide whether an unlabeled sample is \"in-distribution'' or \"out-of-distribution'', we adopt the energy score from out-of-distribution detection literature. As training progresses and more unlabeled samples become in-distribution and contribute to training, the combined labeled and pseudo-labeled data can better approximate the true class distribution to improve the model. Experiments demonstrate that our energy-based pseudo-labeling method, InPL, albeit conceptually simple, significantly outperforms confidence-based methods on imbalanced SSL benchmarks. For example, it produces a 4-6% absolute accuracy improvement on CIFAR10-LT when the imbalance ratio is higher than 50. When combined with state-of-the-art long-tailed SSL methods, further improvements are attained. In particular, in one of the most challenging scenarios, InPL achieves a 6.9% accuracy improvement over the best competitor.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam",
        "paper_url": "https://openreview.net/pdf?id=-CefY2EOupj",
        "paper_authors": [
            "Yucheng Lu",
            "Conglong Li",
            "Minjia Zhang",
            "Christopher De Sa",
            "Yuxiong He"
        ],
        "paper_abstract": "1-bit gradient compression and local steps are two representative techniques that enable drastic communication reduction in distributed SGD. Their benefits, however, remain an open question on Adam-based large model pre-training (e.g. BERT and GPT). In this paper, we demonstrate the non-linearity in Adam causes slow convergence even when 1-bit compression or local steps are individually applied. To alleviate this limitation, we propose \\textbf{0/1 Adam} that linearizes each Adam step via approximating its optimizer states using their stale estimates and linear correlation. \\textbf{0/1 Adam} performs an Adam-like step to preserve the adaptivity, while its linearity allows utilizing 1-bit compression and local steps simultaneously for wall-clock time speed up. We provide convergence guarantee for \\textbf{0/1 Adam} on smooth non-convex objectives. On various large-scale benchmarks such as BERT-Base, BERT-Large, GPT-2 pre-training and ImageNet, we demonstrate on up to 128 GPUs that \\textbf{0/1 Adam} is able to reduce up to 87\\% of data volume, 54\\% of communication rounds, and achieve up to 2$\\times$ higher training throughput and end-to-end training time reduction compared to the state-of-the-art baseline 1-bit Adam; while enjoying the same statistical convergence speed and end task model accuracy on GLUE dataset and ImageNet validation set. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Truthful Self-Play",
        "paper_url": "https://openreview.net/pdf?id=WVRb98rwbv9",
        "paper_authors": [
            "Shohei Ohsawa"
        ],
        "paper_abstract": "We present a general framework for evolutionary learning to emergent unbiased state representation without any supervision. Evolutionary frameworks such as self-play converge to bad local optima in case of multi-agent reinforcement learning in non-cooperative partially observable environments with communication due to information asymmetry.  Our proposed framework is a simple modification of self-play inspired by mechanism design, also known as {\\em reverse game theory}, to elicit truthful signals and make the agents cooperative. The key idea is to add imaginary rewards using the peer prediction method, i.e., a mechanism for evaluating the validity of information exchanged between agents in a decentralized environment. Numerical experiments with predator prey, traffic junction and StarCraft tasks demonstrate that the state-of-the-art performance of our framework.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Strategic Classification with Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=TuHkVOjSAR",
        "paper_authors": [
            "Itay Eilat",
            "Ben Finkelshtein",
            "Chaim Baskin",
            "Nir Rosenfeld"
        ],
        "paper_abstract": "Strategic classification studies learning in settings where users can modify their features to obtain favorable predictions. Most current works focus on simple classifiers that trigger independent user responses. Here we examine the implications of learning with more elaborate models that break the independence assumption. Motivated by the idea that applications of strategic classification are often social in nature, we focus on graph neural networks, which make use of social relations between users to improve predictions. Using a graph for learning introduces inter-user dependencies in prediction; our key point is that strategic users can exploit these to promote their goals. As we show through analysis and simulation, this can work either against the system---or for it. Based on this, we propose a differentiable framework for strategically-robust learning of graph-based classifiers. Experiments on several real networked datasets demonstrate the utility of our approach.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continual Transformers: Redundancy-Free Attention for Online Inference",
        "paper_url": "https://openreview.net/pdf?id=PolHquob8M7",
        "paper_authors": [
            "Lukas Hedegaard",
            "Arian Bakhtiarnia",
            "Alexandros Iosifidis"
        ],
        "paper_abstract": "Transformers in their common form are inherently limited to operate on whole token sequences rather than on one token at a time. Consequently, their use during online inference on time-series data entails considerable redundancy due to the overlap in successive token sequences. In this work, we propose novel formulations of the Scaled Dot-Product Attention, which enable Transformers to perform efficient online token-by-token inference on a continual input stream. Importantly, our modifications are purely to the order of computations, while the outputs and learned weights are identical to those of the original Transformer Encoder. We validate our Continual Transformer Encoder with experiments on the THUMOS14, TVSeries and GTZAN datasets with remarkable results: Our Continual one- and two-block architectures reduce the floating point operations per prediction by up to 63x and 2.6x, respectively, while retaining predictive performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Symbolic Models for Graph-structured Physical Mechanism",
        "paper_url": "https://openreview.net/pdf?id=f2wN4v_2__W",
        "paper_authors": [
            "Hongzhi Shi",
            "Jingtao Ding",
            "Yufan Cao",
            "quanming yao",
            "Li Liu",
            "Yong Li"
        ],
        "paper_abstract": "Graph-structured physical mechanisms are ubiquitous in real-world scenarios, thus revealing underneath formulas is of great importance for scientific discovery. However, classical symbolic regression methods fail on this task since they can only handle input-output pairs that are not graph-structured. In this paper, we propose a new approach that generalizes symbolic regression to graph-structured physical mechanisms. The essence of our method is to model the formula skeleton with a message-passing flow, which helps transform the discovery of the skeleton into the search for the message-passing flow. Such a transformation guarantees that we are able to search a message-passing flow, which is efficient and Pareto-optimal in terms of both accuracy and simplicity. Subsequently, the underneath formulas can be identified by interpreting component functions of the searched message-passing flow, reusing classical symbolic regression methods. We conduct extensive experiments on datasets from different physical domains, including mechanics, electricity, and thermology, and on real-world datasets of pedestrian dynamics without ground-truth formulas. The experimental results not only verify the rationale of our design but also demonstrate that the proposed method can automatically learn precise and interpretable formulas for graph-structured physical mechanisms. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=0v4VkCSkHNm",
        "paper_authors": [
            "Sasha Salter",
            "Kristian Hartikainen",
            "Walter Goodwin",
            "Ingmar Posner"
        ],
        "paper_abstract": "The ability to discover behaviours from past experience and transfer them to new tasks is a hallmark of intelligent agents acting sample-efficiently in the real world. Equipping embodied reinforcement learners with the same ability may be crucial for their successful deployment in robotics. While hierarchical and KL-regularized reinforcement learning individually hold promise here, arguably a hybrid approach could combine their respective benefits. Key to these fields is the use of information asymmetry across architectural modules to bias which skills are learnt. While asymmetry choice has a large influence on transferability, existing methods base their choice primarily on intuition in a domain-independent, potentially sub-optimal, manner. In this paper, we theoretically and empirically show the crucial expressivity-transferability trade-off of skills across sequential tasks, controlled by information asymmetry. Given this insight, we introduce Attentive Priors for Expressive and Transferable Skills (APES), a hierarchical KL-regularized method, heavily benefiting from both priors and hierarchy. Unlike existing approaches, APES automates the choice of asymmetry by learning it in a data-driven, domain-dependent, way based on our expressivity-transferability theorems. Experiments over complex transfer domains of varying levels of extrapolation and sparsity, such as robot block stacking, demonstrate the criticality of the correct asymmetric choice, with APES drastically outperforming previous methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Set Representation Learning for Unsupervised Meta-Learning",
        "paper_url": "https://openreview.net/pdf?id=kIAx30hYi_p",
        "paper_authors": [
            "Dong Bok Lee",
            "Seanie Lee",
            "Kenji Kawaguchi",
            "Yunji Kim",
            "Jihwan Bang",
            "Jung-Woo Ha",
            "Sung Ju Hwang"
        ],
        "paper_abstract": "Unsupervised meta-learning (UML) essentially shares the spirit of self-supervised learning (SSL) in that their goal aims at learning models without any human supervision so that the models can be adapted to downstream tasks. Further, the learning objective of self-supervised learning, which pulls positive pairs closer and repels negative pairs, also resembles metric-based meta-learning. Metric-based meta-learning is one of the most successful meta-learning methods, which learns to minimize the distance between representations from the same class. \nOne notable aspect of metric-based meta-learning, however, is that it is widely interpreted as a set-level problem since the inference of discriminative class prototypes (or set representations) from few examples is crucial for the performance of downstream tasks. Motivated by this, we propose Set-SimCLR, a novel self-supervised set representation learning framework for targeting UML problem. Specifically, our Set-SimCLR learns a set encoder on top of instance representations to maximize the agreement between two sets of augmented samples, which are generated by applying stochastic augmentations to a given image. We theoretically analyze how our proposed set representation learning can potentially improve the generalization performance at the meta-test. We also empirically validate its effectiveness on various benchmark datasets, showing that Set-SimCLR largely outperforms both UML and instance-level self-supervised learning baselines.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems",
        "paper_url": "https://openreview.net/pdf?id=itZ6ggvMnzS",
        "paper_authors": [
            "Phillip Lippe",
            "Sara Magliacane",
            "Sindy L\u00f6we",
            "Yuki M Asano",
            "Taco Cohen",
            "Efstratios Gavves"
        ],
        "paper_abstract": "Causal representation learning is the task of identifying the underlying causal variables and their relations from high-dimensional observations, such as images. Recent work has shown that one can reconstruct the causal variables from temporal sequences of observations under the assumption that there are no instantaneous causal relations between them. In practical applications, however, our measurement or frame rate might be slower than many of the causal effects. This effectively creates ``instantaneous'' effects and invalidates previous identifiability results. To address this issue, we propose iCITRIS, a causal representation learning method that allows for instantaneous effects in intervened temporal sequences when intervention targets can be observed, e.g., as actions of an agent. iCITRIS identifies the potentially multidimensional causal variables from temporal observations, while simultaneously using a differentiable causal discovery method to learn their causal graph. In experiments on three datasets of interactive systems, iCITRIS accurately identifies the causal variables and their causal graph.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visual Imitation Learning with Patch Rewards",
        "paper_url": "https://openreview.net/pdf?id=OnM3R47KIiU",
        "paper_authors": [
            "Minghuan Liu",
            "Tairan He",
            "Weinan Zhang",
            "Shuicheng YAN",
            "Zhongwen Xu"
        ],
        "paper_abstract": "Visual imitation learning enables reinforcement learning agents to learn to behave from expert visual demonstrations such as videos or image sequences, without explicit, well-defined rewards. \nPrevious reseaches either adopt supervised learning techniques or induce simple and coarse scalar rewards from pixels, neglecting the dense information contained in the image demonstrations.\nIn this work, we propose to measure the expertise of various local regions of image samples, or called patches, and recover multi-dimensional patch rewards accordingly. \nPatch reward is a more precise rewarding characterization that serves as fine-grained expertise measurement and visual explainability tool.\nSpecifically, we present Adversarial Imitation Learning with Patch Rewards (PatchAIL), which employs a patch-based discriminator to measure the expertise of different local parts from given images and provide patch rewards.\nThe patch-based knowledge is also used to regularize the aggregated reward and stabilize the training.\nWe evaluate our method on the standard pixel-based benchmark DeepMind Control Suite. \nThe experiment results have demonstrated that PatchAIL outperforms baseline methods and provides valuable interpretations for visual demonstrations.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CodeT:  Code Generation with Generated Tests",
        "paper_url": "https://openreview.net/pdf?id=ktrw68Cmu9c",
        "paper_authors": [
            "Bei Chen",
            "Fengji Zhang",
            "Anh Nguyen",
            "Daoguang Zan",
            "Zeqi Lin",
            "Jian-Guang Lou",
            "Weizhu Chen"
        ],
        "paper_abstract": "The task of generating code solutions for a given programming problem can benefit from the use of pre-trained language models such as Codex, which can produce multiple diverse samples. However, a major challenge for this task is to select the most appropriate solution from the multiple samples generated by the pre-trained language models. A natural way to evaluate the quality and correctness of a code solution is to run it against a set of test cases, but the manual creation of such test cases is often costly and time-consuming. In this paper, we propose a novel method, CodeT, that leverages the same pre-trained language models to automatically generate test cases for the code samples, thus reducing the human effort and increasing the coverage of the test scenarios. CodeT then executes the code samples using the generated test cases, and performs a dual execution agreement, which considers both the consistency of the outputs against the generated test cases and the agreement of the outputs with other code samples. We conduct comprehensive experiments on four benchmarks, HumanEval, MBPP, APPS and CodeContests, using five different pre-trained language models with varying sizes and capabilities. Our results show that CodeT can significantly improve the performance of code solution selection over previous methods, achieving remarkable and consistent gains across different models and benchmarks. For instance, CodeT improves the pass@1 metric on HumanEval to 65.8%, which represents an absolute improvement of 18.8% over the code-davinci-002 model, and an absolute improvement of more than 20% over the previous state-of-the-art results.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to Generate Columns with Application to Vertex Coloring",
        "paper_url": "https://openreview.net/pdf?id=JHW30A4DXtO",
        "paper_authors": [
            "Yuan Sun",
            "Andreas T Ernst",
            "Xiaodong Li",
            "Jake Weiner"
        ],
        "paper_abstract": "We present a new column generation approach based on Machine Learning (ML) for solving combinatorial optimization problems. The aim of our method is to generate high-quality columns that belong to an optimal integer solution, in contrast to the traditional approach that aims at solving linear programming relaxations. To achieve this aim, we design novel features to characterize a column, and develop an effective ML model to predict whether a column belongs to an optimal integer solution. We then use the ML model as a filter to select high-quality columns generated from a sampling method and use the selected columns to construct an integer solution.  Our method is computationally fast compared to the traditional methods that generate columns by repeatedly solving a pricing problem. We demonstrate the efficacy of our method on the vertex coloring problem, by empirically showing that the columns selected by our ML model are significantly better, in terms of the integer solution that can be constructed from them, than those selected randomly or based only on their reduced cost. Further, we show that the columns generated by our method can be used as a warm start to boost the performance of a column generation-based heuristic.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EVC: Towards Real-Time Neural Image Compression with Mask Decay",
        "paper_url": "https://openreview.net/pdf?id=XUxad2Gj40n",
        "paper_authors": [
            "Wang Guo-Hua",
            "Jiahao Li",
            "Bin Li",
            "Yan Lu"
        ],
        "paper_abstract": "Neural image compression has surpassed state-of-the-art traditional codecs (H.266/VVC) for rate-distortion (RD) performance, but suffers from large complexity and separate models for different rate-distortion trade-offs. In this paper, we propose an Efficient single-model Variable-bit-rate Codec (EVC), which is able to run at 30 FPS with 768x512 input images and still outperforms VVC for the RD performance. By further reducing both encoder and decoder complexities, our small model even achieves 30 FPS with 1920x1080 input images. To bridge the performance gap between our different capacities models, we meticulously design the mask decay, which transforms the large model's parameters into the small model automatically. And a novel sparsity regularization loss is proposed to mitigate shortcomings of $L_p$ regularization. Our algorithm significantly narrows the performance gap by 50% and 30% for our medium and small models, respectively. At last, we advocate the scalable encoder for neural image compression. The encoding complexity is dynamic to meet different latency requirements. We propose decaying the large encoder multiple times to reduce the residual representation progressively. Both mask decay and residual representation learning greatly improve the RD performance of our scalable encoder. Our code is at https://github.com/microsoft/DCVC.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information",
        "paper_url": "https://openreview.net/pdf?id=ICYasJBlZNs",
        "paper_authors": [
            "Yulun Wu",
            "Rob Barton",
            "Zichen Wang",
            "Vassilis N. Ioannidis",
            "Carlo De Donno",
            "Layne C Price",
            "Luis F. Voloch",
            "George Karypis"
        ],
        "paper_abstract": "Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advantage of our approach over state-of-the-art deep learning models for individual response prediction.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor",
        "paper_url": "https://openreview.net/pdf?id=HmPOzJQhbwg",
        "paper_authors": [
            "Wanqi Xue",
            "Qingpeng Cai",
            "Ruohan Zhan",
            "Dong Zheng",
            "Peng Jiang",
            "Kun Gai",
            "Bo An"
        ],
        "paper_abstract": "Long-term engagement is preferred over immediate engagement in sequential recommendation as it directly affects product operational metrics such as daily active users (DAUs) and dwell time. Meanwhile, reinforcement learning (RL) is widely regarded as a promising framework for optimizing long-term engagement in sequential recommendation. However, due to expensive online interactions, it is very difficult for RL algorithms to perform state-action value estimation, exploration and feature extraction when optimizing long-term engagement. In this paper, we propose ResAct which seeks a policy that is close to, but better than, the online-serving policy. In this way, we can collect sufficient data near the learned policy so that state-action values can be properly estimated, and there is no need to perform online exploration. ResAct optimizes the policy by first reconstructing the online behaviors and then improving it via a Residual Actor. To extract long-term information, ResAct utilizes two information-theoretical regularizers to confirm the expressiveness and conciseness of features. We conduct experiments on a benchmark dataset and a large-scale industrial dataset which consists of tens of millions of recommendation requests. Experimental results show that our method significantly outperforms the state-of-the-art baselines in various long-term engagement optimization tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dataset Pruning: Reducing Training Data by Examining Generalization Influence",
        "paper_url": "https://openreview.net/pdf?id=4wZiAXD29TQ",
        "paper_authors": [
            "Shuo Yang",
            "Zeke Xie",
            "Hanyu Peng",
            "Min Xu",
            "Mingming Sun",
            "Ping Li"
        ],
        "paper_abstract": "The great success of deep learning heavily relies on increasingly larger training data, which comes at a price of huge computational and infrastructural costs. This poses crucial questions that, do all training data contribute to model's performance? How much does each individual training sample or a sub-training-set affect the model's generalization, and how to construct the smallest subset from the entire training data as a proxy training set without significantly sacrificing the model's performance? To answer these, we propose dataset pruning, an optimization-based sample selection method that can (1) examine the influence of removing a particular set of training samples on model's generalization ability with theoretical guarantee, and (2) construct the smallest subset of training data that yields strictly constrained generalization gap. The empirically observed generalization gap of dataset pruning is substantially consistent with our theoretical expectations. Furthermore, the proposed method prunes 40% training examples on the CIFAR-10 dataset, halves the convergence time with only 1.3% test accuracy decrease, which is superior to previous score-based sample selection methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training",
        "paper_url": "https://openreview.net/pdf?id=HE_75XY5Ljh",
        "paper_authors": [
            "Yuechen Yu",
            "Yulin Li",
            "Chengquan Zhang",
            "Xiaoqiang Zhang",
            "Zengyuan Guo",
            "Xiameng Qin",
            "Kun Yao",
            "Junyu Han",
            "Errui Ding",
            "Jingdong Wang"
        ],
        "paper_abstract": "In this paper, we present StrucTexTv2, an effective document image pre-training framework, by performing masked visual-textual prediction. It consists of two self-supervised pre-training tasks: masked image modeling and masked language modeling, based on text region-level image masking. The proposed method randomly masks some image regions according to the bounding box coordinates of text words. The objectives of our pre-training tasks are reconstructing the pixels of masked image regions and the corresponding masked tokens simultaneously. Hence the pre-trained encoder can capture more textual semantics in comparison to the masked image modeling that usually predicts the masked image patches. Compared to the masked multi-modal modeling methods for document image understanding that rely on both the image and text modalities, StrucTexTv2 models image-only input and potentially deals with more application scenarios free from OCR pre-processing. Extensive experiments on mainstream benchmarks of document image understanding demonstrate the effectiveness of StrucTexTv2. It achieves competitive or even new state-of-the-art performance in various downstream tasks such as image classification, layout analysis, table structure recognition, document OCR, and information extraction under the end-to-end scenario.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Plateau in Monotonic Linear Interpolation --- A \"Biased\" View of Loss Landscape for Deep Networks",
        "paper_url": "https://openreview.net/pdf?id=z289SIQOQna",
        "paper_authors": [
            "Xiang Wang",
            "Annie N. Wang",
            "Mo Zhou",
            "Rong Ge"
        ],
        "paper_abstract": "Monotonic linear interpolation (MLI) --- on the line connecting a random initialization with the minimizer it converges to, the loss and accuracy are monotonic --- is a phenomenon that is commonly observed in the training of neural networks. Such a  phenomenon may seem to suggest that optimization of neural networks is easy. In this paper, we show that the MLI property is not necessarily related to the hardness of optimization problems, and empirical observations on MLI for deep neural networks depend heavily on the biases. In particular, we show that interpolating both weights and biases linearly leads to very different influences on the final output, and when different classes have different last-layer biases on a deep network, there will be a long plateau in both the loss and accuracy interpolation (which existing theory of MLI cannot explain). We also show how the last-layer biases for different classes can be different even on a perfectly balanced dataset using a simple model. Empirically we demonstrate that similar intuitions hold on practical networks and realistic datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The KFIoU Loss for Rotated Object Detection",
        "paper_url": "https://openreview.net/pdf?id=qUKsCztWlKq",
        "paper_authors": [
            "Xue Yang",
            "Yue Zhou",
            "Gefan Zhang",
            "Jirui Yang",
            "Wentao Wang",
            "Junchi Yan",
            "XIAOPENG ZHANG",
            "Qi Tian"
        ],
        "paper_abstract": "Differing from the well-developed horizontal object detection area whereby the computing-friendly IoU based loss is readily adopted and well fits with the detection metrics, rotation detectors often involve a more complicated loss based on SkewIoU which is unfriendly to gradient-based training. In this paper, we propose an effective approximate SkewIoU loss based on Gaussian modeling and Gaussian product, which mainly consists of two items. The first term is a scale-insensitive center point loss, which is used to quickly narrow the distance between the center points of the two bounding boxes. In the distance-independent second term, the product of the Gaussian distributions is adopted to inherently mimic the mechanism of SkewIoU by its definition, and show its alignment with the SkewIoU loss at trend-level within a certain distance (i.e. within 9 pixels). This is in contrast to recent Gaussian modeling based rotation detectors e.g. GWD loss and KLD loss that involve a human-specified distribution distance metric which require additional hyperparameter tuning that vary across datasets and detectors. The resulting new loss called KFIoU loss is easier to implement and works better compared with exact SkewIoU loss, thanks to its full differentiability and ability to handle the non-overlapping cases. We further extend our technique to the 3-D case which also suffers from the same issues as 2-D. Extensive results on various datasets with different base detectors show the effectiveness of our approach. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BrainBERT: Self-supervised representation learning for intracranial recordings",
        "paper_url": "https://openreview.net/pdf?id=xmcYx_reUn6",
        "paper_authors": [
            "Christopher Wang",
            "Vighnesh Subramaniam",
            "Adam Uri Yaari",
            "Gabriel Kreiman",
            "Boris Katz",
            "Ignacio Cases",
            "Andrei Barbu"
        ],
        "paper_abstract": "We create a reusable Transformer, BrainBERT, for intracranial recordings bringing modern representation learning approaches to neuroscience. Much like in NLP and speech recognition, this Transformer enables classifying complex concepts, i.e., decoding neural data, with higher accuracy and with much less data by being pretrained in an unsupervised manner on a large corpus of unannotated neural recordings. Our approach generalizes to new subjects with electrodes in new positions and to unrelated tasks showing that the representations robustly disentangle the neural signal. Just like in NLP where one can study language by investigating what a language model learns, this approach opens the door to investigating the brain by what a model of the brain learns. As a first step along this path, we demonstrate a new analysis of the intrinsic dimensionality of the computations in different areas of the brain. To construct these representations, we combine a technique for producing super-resolution spectrograms of neural data with an approach designed for generating contextual representations of audio by masking. In the future, far more concepts will be decodable from neural recordings by using representation learning, potentially unlocking the brain like language models unlocked language.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "General Neural Gauge Fields",
        "paper_url": "https://openreview.net/pdf?id=XWkWK2UagFR",
        "paper_authors": [
            "Fangneng Zhan",
            "Lingjie Liu",
            "Adam Kortylewski",
            "Christian Theobalt"
        ],
        "paper_abstract": "The recent advance of neural fields, such as neural radiance fields, has significantly pushed the boundary of scene representation learning. Aiming to boost the computation ef\ufb01ciency and rendering quality of 3D scenes, a popular line of research maps the 3D coordinate system to another measuring system, e.g., 2D manifolds and hash tables, for modeling neural fields. The conversion of coordinate systems can be typically dubbed as \\emph{gauge transformation}, which is usually a pre-defined mapping function, e.g., orthogonal projection or spatial hash function. This begs a question: can we directly learn a desired gauge transformation along with the neural field in an end-to-end manner? In this work, we extend this problem to a general paradigm with a taxonomy of discrete and continuous cases, and develop an end-to-end learning framework to jointly optimize the gauge transformation and neural fields. To counter the problem that the learning of gauge transformations can collapse easily, we derive a general regularization mechanism from the principle of information conservation during the gauge transformation. To circumvent the high computation cost in gauge learning with regularization, we directly derive an information-invariant gauge transformation which allows to preserve scene information inherently and yield superior performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
        "paper_url": "https://openreview.net/pdf?id=fB0hRu9GZUS",
        "paper_authors": [
            "Wenhao Yu",
            "Dan Iter",
            "Shuohang Wang",
            "Yichong Xu",
            "Mingxuan Ju",
            "Soumya Sanyal",
            "Chenguang Zhu",
            "Michael Zeng",
            "Meng Jiang"
        ],
        "paper_abstract": "Knowledge-intensive tasks, such as open-domain question answering (QA), require access to a large amount of world or domain knowledge. A common approach for knowledge-intensive tasks is to employ a retrieve-then-read pipeline that first retrieves a handful of relevant contextual documents from an external corpus such as Wikipedia and then predicts an answer conditioned on the retrieved documents. In this paper, we present a novel perspective for solving knowledge-intensive tasks by replacing document retrievers with large language model generators. We call our method generate-then-read (GenRead), which first prompts a large language model to generate contextual documents based on a given question, and then reads the generated documents to produce the final answer. Furthermore, we propose a novel clustering-based prompting method that selects distinct prompts, in order to generate diverse documents that cover different perspectives, leading to better recall over acceptable answers. We conduct extensive experiments on three different knowledge-intensive tasks, including open-domain QA, fact checking, and dialogue system. Notably, GenRead achieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantly outperforming the state-of-the-art retrieve-then-read pipeline DPR-FiD by +4.0 and +3.9, without retrieving any documents from any external knowledge source. Lastly, we demonstrate the model performance can be further improved by combining retrieval and generation. Our code and generated documents can be found at https://github.com/wyu97/GenRead.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discovering Informative and Robust Positives for Video Domain Adaptation",
        "paper_url": "https://openreview.net/pdf?id=vk-j5pQY3Gv",
        "paper_authors": [
            "Chang Liu",
            "Kunpeng Li",
            "Michael Stopa",
            "Jun Amano",
            "Yun Fu"
        ],
        "paper_abstract": "Unsupervised domain adaptation for video recognition is challenging where the domain shift includes both spatial variations and temporal dynamics. Previous works have focused on exploring contrastive learning for cross-domain alignment. However, limited variations in intra-domain positives, false cross-domain positives, and false negatives hinder contrastive learning from fulfilling intra-domain discrimination and cross-domain closeness. This paper presents a non-contrastive learning framework without relying on negative samples for unsupervised video domain adaptation. To address the limited variations in intra-domain positives, we set unlabeled target videos as anchors and explored to mine \"informative intra-domain positives\" in the form of spatial/temporal augmentations and target nearest neighbors (NNs).\nTo tackle the false cross-domain positives led by noisy pseudo-labels, we reversely set source videos as anchors and sample the synthesized target videos as \"robust cross-domain positives\" from an estimated target distribution, which are naturally more robust to the pseudo-label noise. Our approach is demonstrated to be superior to state-of-the-art methods through extensive experiments on several cross-domain action recognition benchmarks.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding Why Generalized Reweighting Does Not Improve Over ERM",
        "paper_url": "https://openreview.net/pdf?id=ashPce_W8F-",
        "paper_authors": [
            "Runtian Zhai",
            "Chen Dan",
            "J Zico Kolter",
            "Pradeep Kumar Ravikumar"
        ],
        "paper_abstract": "Empirical risk minimization (ERM) is known to be non-robust in practice to distributional shift where the training and the test distributions are different. A suite of approaches, such as importance weighting, and variants of distributionally robust optimization (DRO), have been proposed to solve this problem. But a line of recent work has empirically shown that these approaches do not significantly improve over ERM in real applications with distribution shift. The goal of this work is to obtain a comprehensive theoretical understanding of this intriguing phenomenon. We first posit the class of Generalized Reweighting (GRW) algorithms, as a broad category of approaches that iteratively update model parameters based on iterative reweighting of the training samples. We show that when overparameterized models are trained under GRW, the resulting models are close to that obtained by ERM. We also show that adding small regularization which does not greatly affect the empirical training accuracy does not help. Together, our results show that a broad category of what we term GRW approaches are not able to achieve distributionally robust generalization. Our work thus has the following sobering takeaway: to make progress towards distributionally robust generalization, we either have to develop non-GRW approaches, or perhaps devise novel classification/regression loss functions that are adapted to GRW approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Linear Connectivity Reveals Generalization Strategies",
        "paper_url": "https://openreview.net/pdf?id=hY6M0JHl3uL",
        "paper_authors": [
            "Jeevesh Juneja",
            "Rachit Bansal",
            "Kyunghyun Cho",
            "Jo\u00e3o Sedoc",
            "Naomi Saphra"
        ],
        "paper_abstract": "In the mode connectivity literature, it is widely accepted that there are common circumstances in which two neural networks, trained similarly on the same data, will maintain loss when interpolated in the weight space. In particular, transfer learning is presumed to ensure the necessary conditions for linear mode connectivity across training runs. In contrast to existing results from image classification, we find that among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of finetuned models have large barriers of increasing loss on the linear paths between them. On each task, we find distinct clusters of models which are linearly connected on the test loss surface, but are disconnected from models outside the cluster---models that occupy separate basins on the surface. By measuring performance on specially-crafted diagnostic datasets, we find that these clusters correspond to different generalization strategies. For example, on MNLI, one cluster behaves like a bag of words model under domain shift, while another cluster uses syntactic heuristics. Our work demonstrates how the geometry of the loss surface can guide models towards different heuristic functions in standard finetuning settings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models",
        "paper_url": "https://openreview.net/pdf?id=9DZKk85Z4zA",
        "paper_authors": [
            "Meng Liu",
            "Haoran Liu",
            "Shuiwang Ji"
        ],
        "paper_abstract": "Learning energy-based models (EBMs) is known to be difficult especially on discrete data where gradient-based learning strategies cannot be applied directly. Although ratio matching is a sound method to learn discrete EBMs, it suffers from expensive computation and excessive memory requirements, thereby resulting in difficulties in learning EBMs on high-dimensional data. Motivated by these limitations, in this study, we propose ratio matching with gradient-guided importance sampling (RMwGGIS). Particularly, we use the gradient of the energy function w.r.t. the discrete data space to approximately construct the provably optimal proposal distribution, which is subsequently used by importance sampling to efficiently estimate the original ratio matching objective. We perform experiments on density modeling over synthetic discrete data, graph generation, and training Ising models to evaluate our proposed method. The experimental results demonstrate that our method can significantly alleviate the limitations of ratio matching, perform more effectively in practice, and scale to high-dimensional problems. Our implementation is available at https://github.com/divelab/RMwGGIS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Composing Ensembles of Pre-trained Models via Iterative Consensus",
        "paper_url": "https://openreview.net/pdf?id=gmwDKo-4cY",
        "paper_authors": [
            "Shuang Li",
            "Yilun Du",
            "Joshua B. Tenenbaum",
            "Antonio Torralba",
            "Igor Mordatch"
        ],
        "paper_abstract": "Large pre-trained models exhibit distinct and complementary capabilities dependent on the data they are trained on. Language models such as GPT-3 are capable of textual reasoning but cannot understand visual information, while vision models such as DALL-E can generate photorealistic photos but fail to understand complex language descriptions. In this work, we propose a unified framework for composing ensembles of different pre-trained models -- combining the strengths of each individual model to solve various multimodal problems in a zero-shot manner. We use pre-trained models as \"generators\" or \"scorers\" and compose them via closed-loop iterative consensus optimization. The generator constructs proposals and the scorers iteratively provide feedback to refine the generated result. Such closed-loop communication enables models to correct errors caused by other models, significantly boosting performance on downstream tasks, e.g. improving accuracy on grade school math problems by 7.5%, without requiring any model finetuning. We demonstrate that consensus achieved by an ensemble of scorers outperforms the feedback of a single scorer, by leveraging the strengths of each expert model. Results show that the proposed method can be used as a general purpose framework for a wide range of zero-shot multimodal tasks, such as image generation, video question answering, mathematical reasoning, and robotic manipulation. \n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automated Data Augmentations for Graph Classification",
        "paper_url": "https://openreview.net/pdf?id=vTb1JI0Gps_",
        "paper_authors": [
            "Youzhi Luo",
            "Michael Curtis McThrow",
            "Wing Yee Au",
            "Tao Komikado",
            "Kanji Uchino",
            "Koji Maruhashi",
            "Shuiwang Ji"
        ],
        "paper_abstract": "Data augmentations are effective in improving the invariance of learning machines. We argue that the core challenge of data augmentations lies in designing data transformations that preserve labels. This is relatively straightforward for images, but much more challenging for graphs. In this work, we propose GraphAug, a novel automated data augmentation method aiming at computing label-invariant augmentations for graph classification. Instead of using uniform transformations as in existing studies, GraphAug uses an automated augmentation model to avoid compromising critical label-related information of the graph, thereby producing label-invariant augmentations at most times. To ensure label-invariance, we develop a training method based on reinforcement learning to maximize an estimated label-invariance probability. Experiments show that GraphAug outperforms previous graph augmentation methods on various graph classification tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Riemannian Metric Learning via Optimal Transport",
        "paper_url": "https://openreview.net/pdf?id=v3y68gz-WEz",
        "paper_authors": [
            "Christopher Scarvelis",
            "Justin Solomon"
        ],
        "paper_abstract": "We introduce an optimal transport-based model for learning a metric tensor from cross-sectional samples of evolving probability measures on a common Riemannian manifold. We neurally parametrize the metric as a spatially-varying matrix field and efficiently optimize our model's objective using a simple alternating scheme. Using this learned metric, we can non-linearly interpolate between probability measures and compute geodesics on the manifold. We show that metrics learned using our method improve the quality of trajectory inference on scRNA and bird migration data at the cost of little additional cross-sectional data.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reliability of CKA as a Similarity Measure in Deep Learning",
        "paper_url": "https://openreview.net/pdf?id=8HRvyxc606",
        "paper_authors": [
            "MohammadReza Davari",
            "Stefan Horoi",
            "Amine Natik",
            "Guillaume Lajoie",
            "Guy Wolf",
            "Eugene Belilovsky"
        ],
        "paper_abstract": "Comparing learned neural representations in neural networks is a challenging but important problem, which has been approached in different ways. The Centered Kernel Alignment (CKA) similarity metric, particularly its linear variant, has recently become a popular approach and has been widely used to compare representations of a network's different layers, of architecturally similar networks trained differently, or of models with different architectures trained on the same data. A wide variety of claims about similarity and dissimilarity of these various representations have been made using CKA results. In this work we present analysis that formally characterizes CKA sensitivity to a large class of simple transformations, which can naturally occur in the context of modern machine learning. This provides a concrete explanation to CKA sensitivity to outliers, which has been observed in past works, and to transformations that preserve the linear separability of the data, an important generalization attribute. We empirically investigate several weaknesses of the CKA similarity metric, demonstrating situations in which it gives unexpected or counterintuitive results. Finally we study approaches for modifying representations to maintain functional behaviour while changing the CKA value. Our results illustrate that, in many cases, the CKA value can be easily manipulated without substantial changes to the functional behaviour of the models, and call for caution when leveraging activation alignment metrics.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fair Attribute Completion on Graph with Missing Attributes",
        "paper_url": "https://openreview.net/pdf?id=9vcXCMp9VEp",
        "paper_authors": [
            "Dongliang Guo",
            "Zhixuan Chu",
            "Sheng Li"
        ],
        "paper_abstract": "Tackling unfairness in graph learning models is a challenging task, as the unfairness issues on graphs involve both attributes and topological structures. Existing work on fair graph learning simply assumes that attributes of all nodes are available for model training and then makes fair predictions. In practice, however, the attributes of some nodes might not be accessible due to missing data or privacy concerns, which makes fair graph learning even more challenging. In this paper, we propose FairAC, a fair attribute completion method, to complement missing information and learn fair node embeddings for graphs with missing attributes. FairAC adopts an attention mechanism to deal with the attribute missing problem and meanwhile, it mitigates two types of unfairness, i.e., feature unfairness from attributes and topological unfairness due to attribute completion. FairAC can work on various types of homogeneous graphs and generate fair embeddings for them and thus can be applied to most downstream tasks to improve their fairness performance. To our best knowledge, FairAC is the first method that jointly addresses the graph attribution completion and graph unfairness problems. Experimental results on benchmark datasets show that our method achieves better fairness performance with less sacrifice in accuracy, compared with the state-of-the-art methods of fair graph learning. Code is available at: https://github.com/donglgcn/FairAC.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Ranking Ensembles for Hyperparameter Optimization",
        "paper_url": "https://openreview.net/pdf?id=_ruvo2KCL2x",
        "paper_authors": [
            "Abdus Salam Khazi",
            "Sebastian Pineda Arango",
            "Josif Grabocka"
        ],
        "paper_abstract": "Automatically optimizing the hyperparameters of Machine Learning algorithms is one of the primary open questions in AI. Existing work in Hyperparameter Optimization (HPO) trains surrogate models for approximating the response surface of hyperparameters as a regression task. In contrast, we hypothesize that the optimal strategy for training surrogates is to preserve the ranks of the performances of hyperparameter configurations as a Learning to Rank problem. As a result, we present a novel method that meta-learns neural network surrogates optimized for ranking the configurations' performances while modeling their uncertainty via ensembling. In a large-scale experimental protocol comprising 12 baselines, 16 HPO search spaces and 86 datasets/tasks, we demonstrate that our method achieves new state-of-the-art results in HPO.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robustness to corruption in pre-trained Bayesian neural networks",
        "paper_url": "https://openreview.net/pdf?id=kUI41mY8bHl",
        "paper_authors": [
            "Xi Wang",
            "Laurence Aitchison"
        ],
        "paper_abstract": "We develop ShiftMatch, a new training-data-dependent likelihood for robustness to corruption in Bayesian neural networks (BNNs). ShiftMatch is inspired by the training-data-dependent \u201cEmpCov\u201d priors from Izmailov et al. (2021a), and efficiently matches test-time spatial correlations to those at training time. Critically, ShiftMatch is designed to leave the neural network\u2019s training time likelihood unchanged, allowing it to use publicly available samples from pre-trained BNNs. Using pre-trained HMC samples, ShiftMatch gives strong performance improvements on CIFAR-10-C, outperforms EmpCov priors (though ShiftMatch uses extra information from a minibatch of corrupted test points), and is perhaps the first Bayesian method capable of convincingly outperforming plain deep ensembles.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning",
        "paper_url": "https://openreview.net/pdf?id=resApVNcqSB",
        "paper_authors": [
            "Bo Wan",
            "Yongfei Liu",
            "Desen Zhou",
            "Tinne Tuytelaars",
            "Xuming He"
        ],
        "paper_abstract": "Human object interaction (HOI) detection plays a crucial role in human-centric scene understanding and serves as a fundamental building block for many vision tasks. One generalizable and scalable strategy for HOI detection is to use weak supervision, learning from image-level annotations only. This is inherently challenging due to ambiguous human-object associations, large search space of detecting HOIs and highly noisy training signal. A promising strategy to address those challenges is to exploit knowledge from large-scale pretrained models (e.g., CLIP), but a direct knowledge distillation strategy does not perform well on the weakly-supervised setting. In contrast, we develop a CLIP-guided HOI representation capable of incorporating the prior knowledge at both image level and HOI instance level, and adopt a self-taught mechanism to prune incorrect human-object associations. Experimental results on HICO-DET and V-COCO\nshow that our method outperforms the previous works by a sizable margin, showing the efficacy of our HOI representation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction",
        "paper_url": "https://openreview.net/pdf?id=KXRSh0sdVTP",
        "paper_authors": [
            "Wenlin Chen",
            "Austin Tripp",
            "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
        ],
        "paper_abstract": "We propose Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for learning deep kernel Gaussian processes (GPs) by interpolating between meta-learning and conventional deep kernel learning. Our approach employs a bilevel optimization objective where we meta-learn generally useful feature representations across tasks, in the sense that task-specific GP models estimated on top of such features achieve the lowest possible predictive loss on average. We solve the resulting nested optimization problem using the implicit function theorem (IFT). We show that our ADKF-IFT framework contains previously proposed Deep Kernel Learning (DKL) and Deep Kernel Transfer (DKT) as special cases. Although ADKF-IFT is a completely general method, we argue that it is especially well-suited for drug discovery problems and demonstrate that it significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks and out-of-domain molecular property prediction and optimization tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation ",
        "paper_url": "https://openreview.net/pdf?id=FYZCHEtt6H0",
        "paper_authors": [
            "Jianye HAO",
            "Pengyi Li",
            "Hongyao Tang",
            "YAN ZHENG",
            "Xian Fu",
            "Zhaopeng Meng"
        ],
        "paper_abstract": "Deep Reinforcement Learning (Deep RL) and Evolutionary Algorithm (EA) are two major paradigms of policy optimization with distinct learning principles, i.e., gradient-based v.s. gradient-free. An appealing research direction is integrating Deep RL and EA to devise new methods by fusing their complementary advantages. However, existing works on combining Deep RL and EA have two common drawbacks:1) the RL agent and EA agents learn their policies individually, neglecting efficient sharing of useful common knowledge; 2) parameter-level policy optimization guarantees no semantic level of behavior evolution for the EA side. In this paper, we propose Evolutionary Reinforcement Learning with Two-scale State Representation and Policy Representation (ERL-Re$^2$), a novel solution to the aforementioned two drawbacks. The key idea of ERL-Re$^2$ is two-scale representation: all EA and RL policies share the same nonlinear state representation while maintaining individual linear policy representations. The state representation conveys expressive common features of the environment learned by all the agents collectively; the linear policy representation provides a favorable space for efficient policy optimization, where novel behavior-level crossover and mutation operations can be performed. Moreover, the linear policy representation allows convenient generalization of policy fitness with the help of Policy-extended Value Function Approximator (PeVFA), further improving the sample efficiency of fitness estimation. The experiments on a range of continuous control tasks show that ERL-Re$^2$ consistently outperforms advanced baselines and achieves the State Of The Art (SOTA). Our code is available on  https://github.com/yeshenpy/ERL-Re2.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
        "paper_url": "https://openreview.net/pdf?id=WZH7099tgfM",
        "paper_authors": [
            "Denny Zhou",
            "Nathanael Sch\u00e4rli",
            "Le Hou",
            "Jason Wei",
            "Nathan Scales",
            "Xuezhi Wang",
            "Dale Schuurmans",
            "Claire Cui",
            "Olivier Bousquet",
            "Quoc V Le",
            "Ed H. Chi"
        ],
        "paper_abstract": "Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split)  with an accuracy of at least 99\\% using just 14 exemplars, compared to only 16\\% accuracy with chain-of-thought prompting.  This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Ensembles for Graphs with Higher-order Dependencies",
        "paper_url": "https://openreview.net/pdf?id=hZftxQGJ4Re",
        "paper_authors": [
            "Steven Krieg",
            "William Burgis",
            "Patrick Soga",
            "Nitesh Chawla"
        ],
        "paper_abstract": "Graph neural networks (GNNs) continue to achieve state-of-the-art performance on many graph learning tasks, but rely on the assumption that a given graph is a sufficient approximation of the true neighborhood structure. In the presence of higher-order sequential dependencies, we show that the tendency of traditional graph representations to underfit each node's neighborhood causes existing GNNs to generalize poorly. To address this, we propose a novel Deep Graph Ensemble (DGE), which captures neighborhood variance by training an ensemble of GNNs on different neighborhood subspaces of the same node within a higher-order network structure. We show that DGE consistently outperforms existing GNNs on semisupervised and supervised tasks on six real-world data sets with known higher-order dependencies, even under a similar parameter budget. We demonstrate that learning diverse and accurate base classifiers is central to DGE's success, and discuss the implications of these findings for future work on GNNs.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Understanding Why Mask Reconstruction Pretraining Helps in Downstream Tasks",
        "paper_url": "https://openreview.net/pdf?id=PaEUQiY40Dk",
        "paper_authors": [
            "Jiachun Pan",
            "Pan Zhou",
            "Shuicheng YAN"
        ],
        "paper_abstract": "For unsupervised pretraining, mask-reconstruction pretraining (MRP) approaches, e.g. MAE and data2vec, randomly mask input patches and then reconstruct the pixels or semantic features of these masked patches via an auto-encoder. Then for a downstream task, supervised fine-tuning the pretrained encoder remarkably surpasses the conventional \"supervised learning\" (SL) trained from scratch. However, it is still unclear 1) how MRP performs semantic (feature) learning in the pretraining phase and 2) why it helps in downstream tasks.  To solve these problems, we first theoretically show that on an auto-encoder of a two/one-layered convolution encoder/decoder, MRP can capture all discriminative semantics of each potential semantic class in the pretraining dataset. Then considering the fact that the pretraining dataset is of huge size and high diversity and thus covers most semantics in downstream dataset, in fine-tuning phase, the pretrained encoder can capture as much semantics as it can in downstream datasets, and would not lost these semantics with theoretical guarantees.  In contrast, SL only randomly captures some semantics due to lottery ticket hypothesis. So  MRP provably achieves better performance than SL  on the classification tasks.   Experimental results testify to our data assumptions and also our theoretical implications. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance",
        "paper_url": "https://openreview.net/pdf?id=20GtJ6hIaPA",
        "paper_authors": [
            "Xueyi Liu",
            "Ji Zhang",
            "Ruizhen Hu",
            "Haibin Huang",
            "He Wang",
            "Li Yi"
        ],
        "paper_abstract": "Category-level articulated object pose estimation aims to estimate a hierarchy of articulation-aware object poses of an unseen articulated object from a known category. To reduce the heavy annotations needed for supervised learning methods, we present a novel self-supervised strategy that solves this problem without any human labels. Our key idea is to factorize canonical shapes and articulated object poses from input articulated shapes through part-level equivariant shape analysis. Specifically, we first introduce the concept of part-level SE(3) equivariance and devise a network to learn features of such property. Then, through a carefully designed fine-grained pose-shape disentanglement strategy, we expect that canonical spaces to support pose estimation could be induced automatically. Thus, we could further predict articulated object poses as per-part rigid transformations describing how parts transform from their canonical part spaces to the camera space. Extensive experiments demonstrate the effectiveness of our method on both complete and partial point clouds from synthetic and real articulated object datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations",
        "paper_url": "https://openreview.net/pdf?id=6orC5MvgPBK",
        "paper_authors": [
            "Ali Hummos"
        ],
        "paper_abstract": "Animals thrive in a constantly changing environment and leverage the temporal structure to learn well-factorized causal representations. In contrast, traditional neural networks suffer from forgetting in changing environments and many methods have been proposed to limit forgetting with different trade-offs. Inspired by the brain thalamocortical circuit, we introduce a simple algorithm that uses optimization at inference time to generate internal representations of the current task dynamically. The algorithm alternates between updating the model weights and a latent task embedding, allowing the agent to parse the stream of temporal experience into discrete events and organize learning about them. On a continual learning benchmark, it achieves competitive end average accuracy by mitigating forgetting, but importantly, the interaction between the weights dynamics and the latent dynamics organizes knowledge into flexible structures with a cognitive interface to control them. Tasks later in the sequence can be solved through knowledge transfer as they become reachable within the well-factorized latent space. The algorithm meets many of the desiderata of an ideal continually learning agent in open-ended environments, and its simplicity suggests fundamental computations in circuits with abundant feedback control loops such as the thalamocortical circuits in the brain",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Variational Implicit Processes",
        "paper_url": "https://openreview.net/pdf?id=8aeSJNbmbQq",
        "paper_authors": [
            "Luis A. Ortega",
            "Simon Rodriguez Santana",
            "Daniel Hern\u00e1ndez-Lobato"
        ],
        "paper_abstract": "Implicit processes (IPs) are a generalization of Gaussian processes (GPs). IPs may lack a closed-form expression but are easy to sample from. Examples include, among others, Bayesian neural networks or neural samplers. IPs can be used as priors over functions, resulting in flexible models with well-calibrated prediction uncertainty estimates. Methods based on IPs usually carry out function-space approximate inference, which overcomes some of the difficulties of parameter-space approximate inference. Nevertheless, the approximations employed often limit the expressiveness of the final model, resulting, e.g., in a Gaussian predictive distribution, which can be restrictive. We propose here a multi-layer generalization of IPs called the Deep Variational Implicit process (DVIP). This generalization is similar to that of deep GPs over GPs, but it is more flexible due to the use of IPs as the prior distribution over the latent functions. We describe a scalable variational inference algorithm for training DVIP and show that it outperforms previous IP-based methods and also deep GPs. We support these claims via extensive regression and classification experiments. We also evaluate DVIP on large datasets with up to several million data instances to illustrate its good scalability and performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Denoising Masked Autoencoders Help Robust Classification",
        "paper_url": "https://openreview.net/pdf?id=zDjtZZBZtqK",
        "paper_authors": [
            "QuanLin Wu",
            "Hang Ye",
            "Yuntian Gu",
            "Huishuai Zhang",
            "Liwei Wang",
            "Di He"
        ],
        "paper_abstract": "In this paper, we propose a new self-supervised method, which is called denoising masked autoencoders (DMAE), for learning certified robust classifiers of images. In DMAE, we corrupt each image by adding Gaussian noises to each pixel value and randomly masking several patches. A Transformer-based encoder-decoder model is then trained to reconstruct the original image from the corrupted one. In this learning paradigm, the encoder will learn to capture relevant semantics for the downstream tasks, which is also robust to Gaussian additive noises. We show that the pre-trained encoder can naturally be used as the base classifier in Gaussian smoothed models, where we can analytically compute the certified radius for any data point. Although the proposed method is simple, it yields significant performance improvement in downstream classification tasks. We show that the DMAE ViT-Base model, which just uses 1/10 parameters of the model developed in recent work (Carlini et al., 2022), achieves competitive or better certified accuracy in various settings. The DMAE ViT-Large model significantly surpasses all previous results, establishing a new state-of-the-art on ImageNet dataset. We further demonstrate that the pre-trained model has good transferability to the CIFAR-10 dataset, suggesting its wide adaptability. Models and code are available at\nhttps://github.com/quanlin-wu/dmae.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Estimating individual treatment effects under unobserved confounding using binary instruments",
        "paper_url": "https://openreview.net/pdf?id=ULsuEVQbV-9",
        "paper_authors": [
            "Dennis Frauen",
            "Stefan Feuerriegel"
        ],
        "paper_abstract": "Estimating conditional average treatment effects (CATEs) from observational data is relevant in many fields such as personalized medicine. However, in practice, the treatment assignment is usually confounded by unobserved variables and thus introduces bias. A remedy to remove the bias is the use of instrumental variables (IVs). Such settings are widespread in medicine (e.g., trials where the treatment assignment is used as binary IV). In this paper, we propose a novel, multiply robust machine learning framework, called MRIV, for estimating CATEs using binary IVs and thus yield an unbiased CATE estimator. Different from previous work for binary IVs, our framework estimates the CATE directly via a pseudo-outcome regression. (1)~We provide a theoretical analysis where we show that our framework yields multiple robust convergence rates: our CATE estimator achieves fast convergence even if several nuisance estimators converge slowly. (2)~We further show that our framework asymptotically outperforms state-of-the-art plug-in IV methods for CATE estimation, in the sense that it achieves a faster rate of convergence if the CATE is smoother than the individual outcome surfaces. (3)~We build upon our theoretical results and propose a tailored deep neural network architecture called MRIV-Net for CATE estimation using binary IVs. Across various computational experiments, we demonstrate empirically that our MRIV-Net achieves state-of-the-art performance. To the best of our knowledge, our MRIV is the first multiply robust machine learning framework tailored to estimating CATEs in the binary IV setting. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Approximate Bayesian Inference with Stein Functional Variational Gradient Descent",
        "paper_url": "https://openreview.net/pdf?id=a2-aoqmeYM4",
        "paper_authors": [
            "Tobias Pielok",
            "Bernd Bischl",
            "David R\u00fcgamer"
        ],
        "paper_abstract": "We propose a general-purpose variational algorithm that forms a natural analogue of Stein variational gradient descent (SVGD) in function space. While SVGD successively updates a set of particles to match a target density, the method introduced here of Stein functional variational gradient descent (SFVGD) updates a set of particle functions to match a target stochastic process (SP). The update step is found by minimizing the functional derivative of the Kullback-Leibler divergence between SPs. SFVGD can either be used to train Bayesian neural networks (BNNs) or for ensemble gradient boosting. We show the efficacy of training BNNs with SFVGD on various real-world datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SCoMoE: Efficient Mixtures of Experts with Structured Communication",
        "paper_url": "https://openreview.net/pdf?id=s-c96mSU0u5",
        "paper_authors": [
            "zhiyuan zeng",
            "Deyi Xiong"
        ],
        "paper_abstract": "  Mixture-of-Experts (MoE) models are promising architectures for massively multilingual neural machine translation and large language models due to the advantage of sublinear scaling. However, the training of large MoE models is usually bottlenecked by the all-to-all communication (Lepikhin et al., 2020). To reduce the communication cost, we propose SCoMoE, an MoE architecture with structured all-to-all communication, inspired by the hierarchical architecture of the communication topology. SCoMoE encourages data to be communicated across devices through fast intra-accelerator/node communication channels, reducing communication throughput in the slow inter-node communication channel. We slice the data on the sequence dimension (SCoMoE-Seq) into three communication groups and project the data on the feature dimension (SCoMoE-Feat) into low-dimensional representations. To compensate the potential performance drop caused by the routing locality in SCoMoE, we further propose a token clustering approach to aggregating related tokens from different devices before the MoE layers. The sigmoid gating in the balanced router used in the token clustering is substituted with the softmax gating with differential sorting. Experiments on bilingual and massively multilingual machine translation demonstrate that SCoMoE achieves a speedup of 1.44x over GShard with comparable performance, and substantially outperforms Gshard (2.8 BLEU) on OPUS-100 with a speedup of 1.25x.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Additive Instance-Wise Approach to Multi-class Model Interpretation",
        "paper_url": "https://openreview.net/pdf?id=5OygDd-4Eeh",
        "paper_authors": [
            "Vy Vo",
            "Van Nguyen",
            "Trung Le",
            "Quan Hung Tran",
            "Reza Haf",
            "Seyit Camtepe",
            "Dinh Phung"
        ],
        "paper_abstract": "Interpretable machine learning offers insights into what factors drive a certain prediction of a black-box system. A large number of interpreting methods focus on identifying explanatory input features, which generally fall into two main categories: attribution and selection. A popular attribution-based approach is to exploit local neighborhoods for learning instance-specific explainers in an additive manner. The process is thus inefficient and susceptible to poorly-conditioned samples. Meanwhile, many selection-based methods directly optimize local feature distributions in an instance-wise training framework, thereby being capable of leveraging global information from other inputs. However, they can only interpret single-class predictions and many suffer from inconsistency across different settings, due to a strict reliance on a pre-defined number of features selected. This work exploits the strengths of both methods and proposes a framework for learning local explanations simultaneously for multiple target classes. Our model explainer significantly outperforms additive and instance-wise counterparts on faithfulness with more compact and comprehensible explanations. We also demonstrate the capacity to select stable and important features through extensive experiments on various data sets and black-box model architectures.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LDMIC: Learning-based Distributed Multi-view Image Coding",
        "paper_url": "https://openreview.net/pdf?id=ILQVw4cA5F9",
        "paper_authors": [
            "Xinjie Zhang",
            "Jiawei Shao",
            "Jun Zhang"
        ],
        "paper_abstract": "Multi-view image compression plays a critical role in 3D-related applications. Existing methods adopt a predictive coding architecture, which requires joint encoding to compress the corresponding disparity as well as residual information. This demands collaboration among cameras and enforces the epipolar geometric constraint between different views, which makes it challenging to deploy these methods in distributed camera systems with randomly overlapping fields of view. Meanwhile, distributed source coding theory indicates that efficient data compression of correlated sources can be achieved by independent encoding and joint decoding, which motivates us to design a learning-based distributed multi-view image coding (LDMIC) framework. With independent encoders, LDMIC introduces a simple yet effective joint context transfer module based on the cross-attention mechanism at the decoder to effectively capture the global inter-view correlations, which is insensitive to the geometric relationships between images. Experimental results show that LDMIC significantly outperforms both traditional and learning-based MIC methods while enjoying fast encoding speed. Code is released at https://github.com/Xinjie-Q/LDMIC.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sound Randomized Smoothing in Floating-Point Arithmetic",
        "paper_url": "https://openreview.net/pdf?id=HaHCoGcpV9",
        "paper_authors": [
            "Vaclav Voracek",
            "Matthias Hein"
        ],
        "paper_abstract": "Randomized smoothing is sound when using infinite precision. However, we show that randomized smoothing is no longer sound for limited floating-point precision. We present a simple example where randomized smoothing certifies a radius of $1.26$ around a point, even though there is an adversarial example in the distance $0.8$ and show how this can be abused to give false certificates for CIFAR10. We discuss the implicit assumptions of randomized smoothing and show that they do not apply to generic image classification models whose smoothed versions are commonly  certified.  In order to overcome this problem, we propose a sound approach to randomized smoothing when using floating-point precision with essentially  equal speed for quantized input. It yields sound certificates or image classifiers which for the ones tested so far are very similar to the unsound practice of randomized smoothing.  Our only assumption is that we have  access to a fair coin.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Collaborative Pure Exploration in Kernel Bandit",
        "paper_url": "https://openreview.net/pdf?id=hLbeJ6jObDD",
        "paper_authors": [
            "Yihan Du",
            "Wei Chen",
            "Yuko Kuroki",
            "Longbo Huang"
        ],
        "paper_abstract": "In this paper, we propose a novel Collaborative Pure Exploration in Kernel Bandit model (CoPE-KB), where multiple agents collaborate to complete different but related tasks with limited communication. Our model generalizes prior CoPE formulation with the single-task and classic MAB setting to allow multiple tasks and general reward structures. We propose a novel communication scheme with an efficient kernelized estimator, and design optimal algorithms CoKernelFC and CoKernelFB for CoPE-KB with fixed-confidence  and fixed-budget objectives, respectively. Nearly matching upper and lower bounds in both sampling and communication complexity are established to demonstrate the optimality of our algorithms. Our theoretical results explicitly quantify how task similarities influence learning speedup, and only depend on the effective dimension of feature space. Our novel techniques including an efficient kernelized estimator and linear structured instance transformation, which overcome the communication difficulty in high-dimensional feature space and derive communication round lower bounds, can be of independent interests. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Provably Efficient Risk-Sensitive Reinforcement Learning: Iterated CVaR and Worst Path",
        "paper_url": "https://openreview.net/pdf?id=Yn0xg-kHNW-",
        "paper_authors": [
            "Yihan Du",
            "Siwei Wang",
            "Longbo Huang"
        ],
        "paper_abstract": "In this paper, we study a novel episodic risk-sensitive Reinforcement Learning (RL) problem, named Iterated CVaR RL, which aims to maximize the tail of the reward-to-go at each step, and focuses on tightly controlling the risk of getting into catastrophic situations at each stage. This formulation is applicable to real-world tasks that demand strong risk avoidance throughout the decision process, such as autonomous driving, clinical treatment planning and robotics. We investigate two performance metrics under Iterated CVaR RL, i.e., Regret Minimization  and Best Policy Identification. For both metrics, we design efficient algorithms ICVaR-RM and ICVaR-BPI, respectively, and provide nearly matching upper and lower bounds with respect to the number of episodes $K$. We also investigate an interesting limiting case of Iterated CVaR RL, called Worst Path RL, where the objective becomes to maximize the minimum possible cumulative reward. For Worst Path RL, we propose an efficient algorithm with constant upper and lower bounds. Finally, the techniques we develop for bounding the change of CVaR due to the value function shift and decomposing the regret via a distorted visitation distribution are novel, and can find applications in other risk-sensitive online learning problems. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Test-Time Robust Personalization for Federated Learning",
        "paper_url": "https://openreview.net/pdf?id=3aBuJEza5sq",
        "paper_authors": [
            "Liangze Jiang",
            "Tao Lin"
        ],
        "paper_abstract": "Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalization on FL models additionally adapts the global model to different clients, achieving promising results on consistent local training & test distributions. However, for real-world personalized FL applications, it is crucial to go one step further: robustifying FL models under the evolving local test set during deployment, where various types of distribution shifts can arise. In this work, we identify the pitfalls of existing works under test-time distribution shifts and propose Federated Test-time Head Ensemble plus tuning (FedTHE+), which personalizes FL models with robustness to various test-time distribution shifts. We illustrate the advancement of FedTHE+ (and its degraded computationally efficient variant FedTHE) over strong competitors, for training various neural architectures (CNN, ResNet, and Transformer) on CIFAR10 and ImageNet and evaluating on diverse test distributions. Along with this, we build a benchmark for assessing the performance and robustness of personalized FL methods during deployment. Code: \\url{https://github.com/LINs-lab/FedTHE}.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to Linearize Deep Neural Networks  for Secure and Efficient Private Inference",
        "paper_url": "https://openreview.net/pdf?id=BGF9IeDfmlH",
        "paper_authors": [
            "Souvik Kundu",
            "Shunlin Lu",
            "Yuke Zhang",
            "Jacqueline Tiffany Liu",
            "Peter Anthony Beerel"
        ],
        "paper_abstract": "The large number of ReLU non-linearity operations in existing deep neural networks makes them ill-suited for latency-efficient private inference (PI). Existing techniques to reduce ReLU operations often involve manual effort and sacrifice significant accuracy. In this paper, we first present a novel measure of non-linearity layers\u2019 ReLU sensitivity, enabling mitigation of the time-consuming manual efforts in identifying the same. Based on this sensitivity, we then present SENet, a three-stage training method that for a given ReLU budget, automatically assigns per-layer ReLU counts, decides the ReLU locations for each layer\u2019s activation map, and trains a model with significantly fewer ReLUs to potentially yield latency and communication efficient PI. Experimental evaluations with multiple models on various datasets show SENet\u2019s superior performance both in terms of reduced ReLUs and improved classification accuracy compared to existing alternatives. In particular, SENet can yield models that require up to \u223c2\u00d7 fewer ReLUs while yielding similar accuracy. For a similar ReLU budget SENet can yield models with \u223c2.32% improved classification accuracy, evaluated on CIFAR-100.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Meta Knowledge Condensation for Federated Learning",
        "paper_url": "https://openreview.net/pdf?id=TDf-XFAwc79",
        "paper_authors": [
            "Ping Liu",
            "Xin Yu",
            "Joey Tianyi Zhou"
        ],
        "paper_abstract": "Existing federated learning paradigms usually extensively exchange distributed models, rather than original data, at a central solver to achieve a more powerful model. However, this would incur severe communication burden between a server and multiple clients especially when data distributions are heterogeneous. As a result, current federated learning methods often require plenty of communication rounds in training. Unlike existing paradigms, we introduce an alternative perspective to significantly decrease the federate learning communication cost without leaking original data. In this work, we first present a meta knowledge representation method that extracts meta knowledge from distributed clients.  The extracted meta knowledge encodes essential information that can be used to improve the current model. As the training progresses, the contributions of the same training samples to a federated model should also vary. Thus, we introduce a dynamic weight assignment mechanism that enables informative samples to contribute adaptively to the current model update. Then, informative meta knowledge from all active clients is sent to the server for model update. Training model on the combined meta knowledge that is regarded as a condense form of original data can significantly mitigate the heterogeneity issues. Moreover, to further ameliorate data heterogeneity, we also exchange meta knowledge among clients as conditional initialisation for meta knowledge extraction. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method. Remarkably, our method outperforms the state-of-the-art by a large margin (from $74.07\\%$ to $92.95\\%$) on MNIST with a restricted communication budget (\\textit{i.e.}, 10 rounds).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Masked Frequency Modeling for Self-Supervised Visual Pre-Training",
        "paper_url": "https://openreview.net/pdf?id=9-umxtNPx5E",
        "paper_authors": [
            "Jiahao Xie",
            "Wei Li",
            "Xiaohang Zhan",
            "Ziwei Liu",
            "Yew-Soon Ong",
            "Chen Change Loy"
        ],
        "paper_abstract": "We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain. Specifically, MFM first masks out a portion of frequency components of the input image and then predicts the missing frequencies on the frequency spectrum. Our key insight is that predicting masked components in the frequency domain is more ideal to reveal underlying image patterns rather than predicting masked patches in the spatial domain, due to the heavy spatial redundancy. Our findings suggest that with the right configuration of mask-and-predict strategy, both the structural information within high-frequency components and the low-level statistics among low-frequency counterparts are useful in learning good representations. For the first time, MFM demonstrates that, for both ViT and CNN, a simple non-Siamese framework can learn meaningful representations even using none of the following: (i) extra data, (ii) extra model, (iii) mask token. Experimental results on image classification and semantic segmentation, as well as several robustness benchmarks show the competitive performance and advanced robustness of MFM compared with recent masked image modeling approaches. Furthermore, we also comprehensively investigate the effectiveness of classical image restoration tasks for representation learning from a unified frequency perspective and reveal their intriguing relations with our MFM approach. Project page: https://www.mmlab-ntu.com/project/mfm/index.html.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning",
        "paper_url": "https://openreview.net/pdf?id=DHyHRBwJUTN",
        "paper_authors": [
            "Pan Lu",
            "Liang Qiu",
            "Kai-Wei Chang",
            "Ying Nian Wu",
            "Song-Chun Zhu",
            "Tanmay Rajpurohit",
            "Peter Clark",
            "Ashwin Kalyan"
        ],
        "paper_abstract": "Mathematical reasoning, a core ability of human intelligence, presents unique challenges for machines in abstract thinking and logical reasoning. Recent large pre-trained language models such as GPT-3 have achieved remarkable progress on mathematical reasoning tasks written in text form, such as math word problems (MWP). However, it is unknown if the models can handle more complex problems that involve math reasoning over heterogeneous information, such as tabular data. To fill the gap, we present Tabular Math Word Problems (TabMWP), a new dataset containing 38,431 open-domain grade-level problems that require mathematical reasoning on both textual and tabular data. Each question in TabMWP is aligned with a tabular context, which is presented as an image, semi-structured text, and a structured table. There are two types of questions: free-text and multi-choice, and each problem is annotated with gold solutions to reveal the multi-step reasoning process. We evaluate different pre-trained models on TabMWP, including the GPT-3 model in a few-shot setting. As earlier studies suggest, since few-shot GPT-3 relies on the selection of in-context examples, its performance is unstable and can degrade to near chance. The unstable issue is more severe when handling complex problems like TabMWP. To mitigate this, we further propose a novel approach, PromptPG, which utilizes policy gradient to learn to select in-context examples from a small amount of training data and then constructs the corresponding prompt for the test example. Experimental results show that our method outperforms the best baseline by 5.31% on the accuracy metric and reduces the prediction variance significantly compared to random selection, which verifies its effectiveness in selecting in-context examples. The data and code are available at https://promptpg.github.io.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Object-Language Alignments for Open-Vocabulary Object Detection",
        "paper_url": "https://openreview.net/pdf?id=mjHlitXvReu",
        "paper_authors": [
            "Chuang Lin",
            "Peize Sun",
            "Yi Jiang",
            "Ping Luo",
            "Lizhen Qu",
            "Gholamreza Haffari",
            "Zehuan Yuan",
            "Jianfei Cai"
        ],
        "paper_abstract": "Existing object detection methods are bounded in a fixed-set vocabulary by costly labeled data. When dealing with novel categories, the model has to be retrained with more bounding box annotations. Natural language supervision is an attractive alternative for its annotation-free attributes and broader object concepts. However, learning open-vocabulary object detection from language is challenging since image-text pairs do not contain fine-grained object-language alignments.  Previous solutions rely on either expensive grounding annotations or distilling classification-oriented vision models. In this paper, we propose a novel open-vocabulary object detection framework directly learning from image-text pair data. We formulate object-language alignment as a set matching problem between a set of image region features and a set of word embeddings. It enables us to train an open-vocabulary object detector on image-text pairs in a much simple and effective way. Extensive experiments on two benchmark datasets, COCO and LVIS, demonstrate our superior performance over the competing approaches on novel categories, e.g. achieving  32.0% mAP on COCO and 21.7% mask mAP on LVIS. Code will be released.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phase transition for detecting a small community in a large network",
        "paper_url": "https://openreview.net/pdf?id=iN3Lh-Vy2TH",
        "paper_authors": [
            "Jiashun Jin",
            "Tracy Ke",
            "Paxton Turner",
            "Anru Zhang"
        ],
        "paper_abstract": "How to detect a small community in a large network is an interesting problem, including clique detection as a special case, where a naive degree-based $\\chi^2$-test was shown to be powerful in the presence of an Erd\u00f6s-Renyi (ER) background. Using Sinkhorn's theorem, we show that the signal captured by the $\\chi^2$-test may be a modeling artifact, and it may disappear once we replace the Erd\u00f6s-Renyi model by a broader network model.  We show that the recent SgnQ test is more appropriate for such a setting. The test is optimal in detecting communities with sizes comparable to the whole network, but has never been studied for our setting, which is substantially different and more challenging.  Using a degree-corrected block model (DCBM), we establish phase transitions of this testing problem concerning the size of the small community and the edge densities in small and large communities.  When the size of the small community is larger than $\\sqrt{n}$, the SgnQ test is optimal  for it attains the computational lower bound (CLB), the information lower bound for methods allowing polynomial computation time. When the size of the small community is smaller than $\\sqrt{n}$, we establish the parameter regime where the SgnQ test has full power and make some conjectures of the CLB. We also study the classical information lower bound (LB) and show that there is always a gap between the CLB and LB in our range of interest. \t",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme",
        "paper_url": "https://openreview.net/pdf?id=b4t9_XASt6G",
        "paper_authors": [
            "Ryo Ueda",
            "Taiga Ishii",
            "Yusuke Miyao"
        ],
        "paper_abstract": "This paper shows that emergent languages in signaling games lack meaningful word boundaries in terms of Harris's Articulation Scheme (HAS), a universal property of natural language. Emergent Languages are artificial communication protocols arising among agents. However, it is not obvious whether such a simulated language would have the same properties as natural language. In this paper, we test if they satisfy HAS. HAS states that word boundaries can be obtained solely from phonemes in natural language. We adopt HAS-based word segmentation and verify whether emergent languages have meaningful word segments. The experiment suggested they do not have, although they meet some preconditions for HAS. We discovered a gap between emergent and natural languages to be bridged, indicating that the standard signaling game satisfies prerequisites but is still missing some necessary ingredients.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TempCLR: Temporal Alignment Representation with Contrastive Learning",
        "paper_url": "https://openreview.net/pdf?id=CIFOsnhZvON",
        "paper_authors": [
            "Yuncong Yang",
            "Jiawei Ma",
            "Shiyuan Huang",
            "Long Chen",
            "Xudong Lin",
            "Guangxing Han",
            "Shih-Fu Chang"
        ],
        "paper_abstract": "Video representation learning has been successful in video-text pre-training for zero-shot transfer, where each sentence is trained to be close to the paired video clips in a common feature space. For long videos, given a paragraph of description where the sentences describe different segments of the video, by matching all sentence-clip pairs,  the paragraph and the full video are aligned implicitly. However, such unit-level similarity measure may ignore the global temporal context over a long time span, which inevitably limits the generalization ability. In this paper, we propose a contrastive learning framework TempCLR to compare the full video and the paragraph explicitly. As the video/paragraph is formulated as a sequence of clips/sentences, under the constraint of their temporal order, we use dynamic time warping to compute the minimum cumulative cost over sentence-clip pairs as the sequence-level distance. To explore the temporal dynamics, we break the consistency of temporal order by shuffling the video clips or sentences according to the temporal granularity. In this way, we obtain the representations for clips/sentences, which perceive the temporal information and thus facilitate the sequence alignment. In addition to pre-training on the video and paragraph, our approach can also generalize on the matching between different video instances. We evaluate our approach on video retrieval, action step localization, and few-shot action recognition, and achieve consistent performance gain over all three tasks. Detailed ablation studies are provided to justify the approach design. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bort: Towards Explainable Neural Networks with Bounded Orthogonal Constraint",
        "paper_url": "https://openreview.net/pdf?id=My57qBufZWs",
        "paper_authors": [
            "Borui Zhang",
            "Wenzhao Zheng",
            "Jie Zhou",
            "Jiwen Lu"
        ],
        "paper_abstract": "Deep learning has revolutionized human society, yet the black-box nature of deep neural networks hinders further application to reliability-demanded industries. In the attempt to unpack them, many works observe or impact internal variables to improve the comprehensibility and invertibility of the black-box models. However, existing methods rely on intuitive assumptions and lack mathematical guarantees. To bridge this gap, we introduce Bort, an optimizer for improving model explainability with boundedness and orthogonality constraints on model parameters, derived from the sufficient conditions of model comprehensibility and invertibility. We perform reconstruction and backtracking on the model representations optimized by Bort and observe a clear improvement in model explainability. Based on Bort, we are able to synthesize explainable adversarial samples without additional parameters and training. Surprisingly, we find Bort constantly improves the classification accuracy of various architectures including ResNet and DeiT on MNIST, CIFAR-10, and ImageNet. Code: https://github.com/zbr17/Bort.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Power of Regularization in Solving Extensive-Form Games",
        "paper_url": "https://openreview.net/pdf?id=bPiHuNUNv_R",
        "paper_authors": [
            "Mingyang Liu",
            "Asuman E. Ozdaglar",
            "Tiancheng Yu",
            "Kaiqing Zhang"
        ],
        "paper_abstract": "In this paper, we investigate the power of {\\it regularization},  a common technique in reinforcement learning and optimization, in solving extensive-form games (EFGs). We propose a series of new algorithms based on regularizing the payoff functions of the game, and establish a set of convergence results that strictly improve over the existing ones, with either weaker assumptions or stronger convergence guarantees. In particular, we first show that dilated optimistic mirror descent (DOMD),  an efficient variant of OMD for solving EFGs, with adaptive regularization can achieve a fast $\\tilde O(1/T)$  last-iterate convergence in terms of duality gap and distance to the set of Nash equilibrium (NE) without uniqueness assumption of the NE. Second, we show that regularized counterfactual regret minimization  (\\texttt{Reg-CFR}), with a variant of optimistic mirror descent algorithm as regret-minimizer, can achieve $O(1/T^{1/4})$ best-iterate,  and $O(1/T^{3/4})$ average-iterate convergence rate for finding NE in EFGs. Finally, we show that \\texttt{Reg-CFR} can achieve asymptotic last-iterate convergence, and optimal $O(1/T)$ average-iterate convergence rate, for finding the NE of perturbed EFGs, which is useful for finding approximate  extensive-form perfect equilibria (EFPE). To  the best of our knowledge, they constitute the first last-iterate convergence results  for CFR-type  algorithms, while matching the state-of-the-art average-iterate convergence rate in finding NE for non-perturbed EFGs. We also provide numerical results to corroborate the advantages of our algorithms.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization",
        "paper_url": "https://openreview.net/pdf?id=P8YIphWNEGO",
        "paper_authors": [
            "Xiaotian Han",
            "Tong Zhao",
            "Yozen Liu",
            "Xia Hu",
            "Neil Shah"
        ],
        "paper_abstract": "Training graph neural networks (GNNs) on large graphs is complex and extremely time consuming. This is attributed to overheads caused by sparse matrix multiplication, which are sidestepped when training multi-layer perceptrons (MLPs) with only node features. MLPs, by ignoring graph context, are simple and faster for graph data, however they usually sacrifice prediction accuracy, limiting their applications for graph data. We observe that for most message passing-based GNNs, we can trivially derive an analog MLP (we call this a PeerMLP) with an equivalent weight space, by setting the trainable parameters with the same shapes, making us curious about how do GNNs using weights from a fully trained PeerMLP perform? Surprisingly, we find that GNNs initialized with such weights significantly outperform their PeerMLPs, motivating us to use PeerMLP training as a precursor, initialization step to GNN training. To this end, we propose an embarrassingly simple, yet hugely effective initialization method for GNN training acceleration, called \\mlpinit. Our extensive experiments on multiple large-scale graph datasets with diverse GNN architectures validate that MLPInit can accelerate the training of GNNs (up to 33\u00d7 speedup on OGB-Products) and often improve prediction performance (e.g., up to $7.97\\%$ improvement for GraphSAGE across $7$ datasets for node classification, and up to $17.81\\%$ improvement across $4$ datasets for link prediction on metric Hits@10). The code is available at https://github.com/snap-research/MLPInit-for-GNNs.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Progressively Compressed Auto-Encoder for Self-supervised Representation Learning",
        "paper_url": "https://openreview.net/pdf?id=8T4qmZbTkW7",
        "paper_authors": [
            "Jin Li",
            "Yaoming Wang",
            "XIAOPENG ZHANG",
            "Yabo Chen",
            "Dongsheng Jiang",
            "Wenrui Dai",
            "Chenglin Li",
            "Hongkai Xiong",
            "Qi Tian"
        ],
        "paper_abstract": "As a typical self-supervised learning strategy, Masked Image Modeling (MIM) is driven by recovering all masked patches from visible ones. However, patches from the same image are highly correlated and it is redundant to reconstruct all the masked patches. We find that this redundancy is neglected by existing MIM based methods and causes non-negligible overheads in computation that do not necessarily benefit self-supervised representation. In this paper, we present a novel approach named PCAE, short for Progressively Compressed AutoEncoder, to address the redundant reconstruction issue by progressively compacting tokens and only retaining necessary information for forward propagation and reconstruction. In particular, we identify those redundant tokens in an image via a simple yet effective similarity metric between each token with the mean of the token sequence. Those redundant tokens that other ones can probably represent are progressively dropped accordingly during the forward propagation, and importantly, we only focus on reconstructing these retained tokens. As a result, we are able to achieve a better trade-off between performance and efficiency for pre-training. Besides, benefitting from the flexible strategy, PCAE can be also directly employed for downstream fine-tuning tasks and enable scalable deployment. Experiments show that PCAE achieves comparable performance to MAE with only 1/8 GPU days. The code is available at https://github.com/caddyless/PCAE/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "S-NeRF: Neural Radiance Fields for Street Views",
        "paper_url": "https://openreview.net/pdf?id=gx2yJS-ENqI",
        "paper_authors": [
            "Ziyang Xie",
            "Junge Zhang",
            "Wenye Li",
            "Feihu Zhang",
            "Li Zhang"
        ],
        "paper_abstract": "Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, \"floaters\" and other artifacts on  street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers.   Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7\uff5e40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": " Cycle-consistent Masked AutoEncoder for Unsupervised Domain Generalization",
        "paper_url": "https://openreview.net/pdf?id=wC98X1qpDBA",
        "paper_authors": [
            "Haiyang Yang",
            "Xiaotong Li",
            "SHIXIANG TANG",
            "Feng Zhu",
            "Yizhou Wang",
            "Meilin Chen",
            "LEI BAI",
            "Rui Zhao",
            "Wanli Ouyang"
        ],
        "paper_abstract": "Self-supervised learning methods undergo undesirable performance drops when there exists a significant domain gap between training and testing scenarios. Therefore, unsupervised domain generalization (UDG) is proposed to tackle the problem, which requires the model to be trained on several different domains without supervision and generalize well on unseen test domains. Existing methods either rely on a cross-domain and semantically consistent image pair in contrastive methods or the reconstruction pair in generative methods, while the precious image pairs are not available without semantic labels. In this paper, we propose a cycle cross-domain reconstruction task for unsupervised domain generalization in the absence of paired images. The cycle cross-domain reconstruction task converts a masked image from one domain to another domain and then reconstructs the original image from the converted images. To preserve the divergent domain knowledge of decoders in the cycle reconstruction task, we propose a novel domain-contrastive loss to regularize the domain information in reconstructed images encoded with the desirable domain style. Qualitative results on extensive datasets illustrate our method improves the state-of-the-art unsupervised domain generalization methods by average $\\textbf{+5.59\\%}, \\textbf{+4.52\\%}, \\textbf{+4.22\\%}, \\textbf{+7.02\\%}$ on $1\\%, 5\\%, 10\\%, 100\\%$ PACS, and $\\textbf{+5.08\\%}, \\textbf{+6.49\\%}, \\textbf{+1.79\\%}, \\textbf{+0.53\\%}$ on $1\\%, 5\\%, 10\\%, 100\\%$ DomainNet, respectively.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CFlowNets: Continuous Control with Generative Flow Networks",
        "paper_url": "https://openreview.net/pdf?id=yAYHho4fATa",
        "paper_authors": [
            "Yinchuan Li",
            "Shuang Luo",
            "Haozhi Wang",
            "Jianye HAO"
        ],
        "paper_abstract": "Generative flow networks (GFlowNets), as an emerging technique, can be used as an alternative to reinforcement learning for exploratory control tasks. GFlowNets aims to sample actions with a probability proportional to the reward, similar to sampling different candidates in an active learning fashion. However, existing GFlowNets cannot adapt to continuous control tasks because GFlowNets need to form a DAG and compute the flow matching loss by traversing the inflows and outflows of each node in the trajectory. In this paper, we propose generative continuous flow networks (CFlowNets) that can be applied to continuous control tasks. First, we present the theoretical formulation of CFlowNets. Then, a training framework for CFlowNets is proposed, including the action selection process, the flow approximation algorithm, and the continuous flow matching loss function. Afterward, we theoretically prove the error bound of the flow approximation. The error decreases rapidly as the number of flow samples increases. Finally, experimental results on continuous control tasks demonstrate the performance advantages of CFlowNets compared to many reinforcement learning methods, especially regarding exploration ability.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models",
        "paper_url": "https://openreview.net/pdf?id=OXP9Ns0gnIq",
        "paper_authors": [
            "Dongzhuo Li"
        ],
        "paper_abstract": "Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the desired high-dimensional standard Gaussian distribution during inversion, particularly in the presence of data noise and inaccurate forward models, leading to low-fidelity solutions. To address this issue, we propose to reparameterize and Gaussianize the latent tensors using novel differentiable data-dependent layers wherein custom operators are defined by solving optimization problems. These proposed layers constrain inverse problems to obtain high-fidelity in-distribution solutions. We validate our technique on three inversion tasks: compressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear PDE-constrained inverse problem) using two representative deep generative models: StyleGAN2 and Glow. Our approach achieves state-of-the-art performance in terms of accuracy and consistency.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection",
        "paper_url": "https://openreview.net/pdf?id=ZccFLU-Yk65",
        "paper_authors": [
            "Jinrong Yang",
            "Lin Song",
            "Songtao Liu",
            "Weixin Mao",
            "Zeming Li",
            "Xiaoping Li",
            "Hongbin Sun",
            "Jian Sun",
            "Nanning Zheng"
        ],
        "paper_abstract": "Many point-based 3D detectors adopt point-feature sampling strategies to drop some points for efficient inference. These strategies are typically based on fixed and handcrafted rules, making it difficult to handle complicated scenes. Different from them, we propose a Dynamic Ball Query (DBQ) network to adaptively select a subset of input points according to the input features, and assign the feature transform with a suitable receptive field for each selected point. It can be embedded into some state-of-the-art 3D detectors and trained in an end-to-end manner, which significantly reduces the computational cost. Extensive experiments demonstrate that our method can reduce latency by 30%-100% on KITTI, Waymo, and ONCE datasets. Specifically, the inference speed of our detector can reach 162 FPS on KITTI scene, and 30 FPS on Waymo and ONCE scenes without performance degradation. Due to skipping the redundant points, some evaluation metrics show significant improvements.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Low-Rank Property in Multiple Instance Learning for Whole Slide Image Classification",
        "paper_url": "https://openreview.net/pdf?id=01KmhBsEPFO",
        "paper_authors": [
            "Jinxi Xiang",
            "Jun Zhang"
        ],
        "paper_abstract": "The classification of gigapixel-sized whole slide images (WSIs) with slide-level labels can be formulated as a multiple-instance-learning (MIL) problem. State-of-the-art models often consist of two decoupled parts: local feature embedding with a pre-trained model followed by a global feature aggregation network for classification. We leverage the properties of the apparent similarity in high-resolution WSIs, which essentially exhibit \\textit{low-rank} structures in the data manifold, to develop a novel MIL with a boost in both feature embedding and feature aggregation. We extend the contrastive learning with a pathology-specific Low-Rank Constraint  (LRC) for feature embedding to pull together samples (i.e., patches) belonging to the same pathological tissue in the low-rank subspace and simultaneously push apart those from different latent subspaces. At the feature aggregation stage, we introduce an iterative low-rank attention MIL (ILRA-MIL) model to aggregate features with low-rank learnable latent vectors to model global interactions among all instances. We highlight the importance of instance correlation modeling but refrain from directly using the transformer encoder considering the $O(n^2)$ complexity. ILRA-MIL with LRC pre-trained features achieves strong empirical results across various benchmarks, including (i) 96.49\\% AUC on the CAMELYON16 for binary metastasis classification, (ii) 97.63\\% AUC on the TCGA-NSCLC for lung cancer subtyping, and (iii) 0.6562 kappa on the large-scale PANDA dataset for prostate cancer classification. The code is available at https://github.com/jinxixiang/low_rank_wsi.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Causal Balancing for Domain Generalization",
        "paper_url": "https://openreview.net/pdf?id=F91SROvVJ_6",
        "paper_authors": [
            "Xinyi Wang",
            "Michael Saxon",
            "Jiachen Li",
            "Hongyang Zhang",
            "Kun Zhang",
            "William Yang Wang"
        ],
        "paper_abstract": "While machine learning models rapidly advance the state-of-the-art on various real-world tasks, out-of-domain (OOD) generalization remains a challenging problem given the vulnerability of these models to spurious correlations. We propose a balanced mini-batch sampling strategy to transform a biased data distribution into a spurious-free balanced distribution, based on the invariance of the underlying causal mechanisms for the data generation process. We argue that the Bayes optimal classifiers trained on such balanced distribution are minimax optimal across a diverse enough environment space. We also provide an identifiability guarantee of the latent variable model of the proposed data generation process, when utilizing enough train environments. Experiments are conducted on DomainBed, demonstrating empirically that our method obtains the best performance across 20 baselines reported on the benchmark.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Addressing Label Skews in One-Shot Federated Learning",
        "paper_url": "https://openreview.net/pdf?id=rzrqh85f4Sc",
        "paper_authors": [
            "Yiqun Diao",
            "Qinbin Li",
            "Bingsheng He"
        ],
        "paper_abstract": "Federated learning (FL) has been a popular research area, where multiple clients collaboratively train a model without sharing their local raw data. Among existing FL solutions, one-shot FL is a promising and challenging direction, where the clients conduct FL training with a single communication round. However, while label skew is a common real-world scenario where some clients may have few or no data of some classes, existing one-shot FL approaches that conduct voting on the local models are not able to produce effective global models. Due to the limited number of classes in each party, the local models misclassify the data from unseen classes into seen classes, which leads to very ineffective global models from voting. To address the label skew issue in one-shot FL, we propose a novel approach named FedOV which generates diverse outliers and introduces them as an additional unknown class in local training to improve the voting performance. Specifically, based on open-set recognition, we propose novel outlier generation approaches by corrupting the original features and further develop adversarial learning to enhance the outliers. Our extensive experiments show that FedOV can significantly improve the test accuracy compared to state-of-the-art approaches in various label skew settings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Breaking Correlation Shift via Conditional Invariant Regularizer",
        "paper_url": "https://openreview.net/pdf?id=-jTaz3CMk72",
        "paper_authors": [
            "Mingyang Yi",
            "Ruoyu Wang",
            "Jiacheng Sun",
            "Zhenguo Li",
            "Zhi-Ming Ma"
        ],
        "paper_abstract": "Recently, generalization on out-of-distribution (OOD) data with correlation shift has attracted great attentions. The correlation shift is caused by the spurious attributes that correlate to the class label, as the correlation between them may vary in training and test data. For such a problem, we show that given the class label, the models that are conditionally independent of spurious attributes are OOD generalizable. Based on this, a metric Conditional Spurious Variation (CSV) which controls the OOD generalization error, is proposed to measure such conditional independence. To improve the OOD generalization, we regularize the training process with the proposed CSV. Under mild assumptions, our training objective can be formulated as a nonconvex-concave mini-max problem. An algorithm with a provable convergence rate is proposed to solve the problem. Extensive empirical results verify our algorithm's efficacy in improving OOD generalization.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards One-shot Neural Combinatorial Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case",
        "paper_url": "https://openreview.net/pdf?id=h21yJhdzbwz",
        "paper_authors": [
            "Runzhong Wang",
            "Li Shen",
            "Yiting Chen",
            "Xiaokang Yang",
            "Dacheng Tao",
            "Junchi Yan"
        ],
        "paper_abstract": "One-shot non-autoregressive neural networks, different from RL-based ones, have been actively adopted for solving combinatorial optimization (CO) problems, which can be trained by the objective score in a self-supervised manner. Such methods have shown their superiority in efficiency (e.g. by parallelization) and potential for tackling predictive CO problems for decision-making under uncertainty. While the discrete constraints often become a bottleneck for gradient-based neural solvers, as currently handled in three typical ways: 1) adding a soft penalty in the objective, where a bounded violation of the constraints cannot be guaranteed, being critical to many constraint-sensitive scenarios; 2) perturbing the input to generate an approximate gradient in a black-box manner, though the constraints are exactly obeyed while the approximate gradients can hurt the performance on the objective score; 3) a compromise by developing soft algorithms whereby the output of neural networks obeys a relaxed constraint, and there can still occur an arbitrary degree of constraint-violation. Towards the ultimate goal of establishing a general framework for neural CO solver with the ability to control an arbitrary-small degree of constraint violation, in this paper, we focus on a more achievable and common setting: the cardinality constraints, which in fact can be readily encoded by a differentiable optimal transport (OT) layer. Based on this observation, we propose OT-based cardinality constraint encoding for end-to-end CO problem learning with two variants: Sinkhorn and Gumbel-Sinkhorn, whereby their violation of the constraints can be exactly characterized and bounded by our theoretical results. On synthetic and real-world CO problem instances, our methods surpass the state-of-the-art CO network and are comparable to (if not superior to) the commercial solver Gurobi. In particular, we further showcase a case study of applying our approach to the predictive portfolio optimization task on real-world asset price data, improving the Sharpe ratio from 1.1 to 2.0 of a strong LSTM+Gurobi baseline under the classic predict-then-optimize paradigm.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Block and Subword-Scaling Floating-Point (BSFP) : An Efficient Non-Uniform Quantization For Low Precision Inference",
        "paper_url": "https://openreview.net/pdf?id=VWm4o4l3V9e",
        "paper_authors": [
            "Yun-Chen Lo",
            "Tse-Kuang Lee",
            "Ren-Shuo Liu"
        ],
        "paper_abstract": "In this paper, we propose Block and Subword-Scaling Floating-Point (BSFP), a non-uniform quantization scheme for the skewed and non-uniform distribution of weight vectors in neural networks. By quantizing each weight vector as the superposition of multiple subword vectors (in two's complement) with scaling factors (in Low-bit Floating-Point, LBFP), BSFP can effectively fit the distribution of weight vectors while maintaining high computation efficiency. Furthermore, we present a grid search-based MSE-optimal quantization flow and a scaled serial processing engine to complete the quantization pipeline and the infrastructure. \n\nThe experimental results on the ImageNet classification task show that our proposed method outperforms state-of-the-art Microsoft Floating Point (MSFP) by up to 20.56% top-1 accuracy at the same weight precision and reduces up to 10.3% model size. Furthermore, BSFP outperforms MSFP by up to 2.0$\\times$ computing throughput and up to 5.3$\\times$ energy efficiency under the same silicon area budget.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning",
        "paper_url": "https://openreview.net/pdf?id=0qmwFNJyxCL",
        "paper_authors": [
            "Rundong Luo",
            "Yifei Wang",
            "Yisen Wang"
        ],
        "paper_abstract": "Recent works have shown that self-supervised learning can achieve remarkable robustness when integrated with adversarial training (AT). However, the robustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT) remains significant. Motivated by this observation, we revisit existing self-AT methods and discover an inherent dilemma that affects self-AT robustness: either strong or weak data augmentations are harmful to self-AT, and a medium strength is insufficient to bridge the gap. To resolve this dilemma, we propose a simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In particular, we propose an augmentation schedule that gradually anneals from a strong augmentation to a weak one to benefit from both extreme cases. Besides, we adopt a fast post-processing stage for adapting it to downstream tasks. Through extensive experiments, we show that DYNACL can improve state-of-the-art self-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can even outperform vanilla supervised adversarial training for the first time. Our code is available at \\url{https://github.com/PKU-ML/DYNACL}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-supervised Community Detection via Structural Similarity Metrics",
        "paper_url": "https://openreview.net/pdf?id=cxvEGLCHpgl",
        "paper_authors": [
            "Yicong Jiang",
            "Tracy Ke"
        ],
        "paper_abstract": "Motivated by the interests of social network analysis and network-based recommendation systems, we consider a semi-supervised community detection problem, where the goal is to estimate the community label of a new node by leveraging on the network structure and partially observed community labels of existing nodes. \nWe model the network with a degree-corrected stochastic block model, which allows for severe degree heterogeneity and potentially non-assortative communities. \nWe propose a fast algorithm that computes a `structural similarity metric' between the new node and each of the $K$ communities, aggregating information in labeled and unlabeled data. The estimated label of the new node is equal to the value of $k$  that maximizes this similarity metric. Our method is computationally fast and compares favorably with existing semi-supervised algorithms on numerical performance. In theory, we derive explicit bounds for the misclassification error and show the efficiency of our method by comparing it with an ideal classifier. To our best knowledge, our results provide the first semi-supervised community detection algorithm with theoretical guarantees.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models",
        "paper_url": "https://openreview.net/pdf?id=0vqjc50HfcC",
        "paper_authors": [
            "Tiange Xiang",
            "Mahmut Yurt",
            "Ali B Syed",
            "Kawin Setsompop",
            "Akshay Chaudhari"
        ],
        "paper_abstract": "Magnetic resonance imaging (MRI) is a common and life-saving medical imaging technique. However, acquiring high signal-to-noise ratio MRI scans requires long scan times, resulting in increased costs and patient discomfort, and decreased throughput. Thus, there is great interest in denoising MRI scans, especially for the subtype of diffusion MRI scans that are severely SNR-limited. While most prior MRI denoising methods are supervised in nature, acquiring supervised training datasets for the multitude of anatomies, MRI scanners, and scan parameters proves impractical. Here, we propose Denoising Diffusion Models for Denoising Diffusion MRI (DDM^2), a self-supervised denoising method for MRI denoising using diffusion denoising generative models. Our three-stage framework integrates statistic-based denoising theory into diffusion models and performs denoising through conditional generation. During inference, we represent input noisy measurements as a sample from an intermediate posterior distribution within the diffusion Markov chain. We conduct experiments on 4 real-world in-vivo diffusion MRI datasets and show that our DDM^2 demonstrates superior denoising performances ascertained with clinically-relevant visual qualitative and quantitative metrics.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multivariate Time-series Imputation with Disentangled Temporal Representations",
        "paper_url": "https://openreview.net/pdf?id=rdjeCNUS6TG",
        "paper_authors": [
            "SHUAI LIU",
            "Xiucheng Li",
            "Gao Cong",
            "Yile Chen",
            "YUE JIANG"
        ],
        "paper_abstract": "Multivariate time series often faces the problem of missing value. Many time series imputation methods have been developed in the literature. However, these methods all rely on an entangled representation to model dynamics of time series, which may fail to fully exploit the multiple factors (e.g., periodic patterns) contained in the time series. Moreover, the entangled representation usually has no semantic meaning, and thus they often lack interpretability. In addition, many recent models are proposed to deal with the whole time series to capture cross-channel correlations and identify temporal dynamics, but they are not scalable to large-scale datasets. Different from existing approaches, we propose TIDER, a novel matrix factorization-based method with disentangled temporal representations that account for multiple factors, namely trend, seasonality, and local bias, to model complex dynamics. The learned disentanglement makes the imputation process more reliable and offers explainability for imputation results. Moreover, TIDER is scalable to large datasets. Empirical results show that our method not only outperforms existing approaches by notable margins on three real-world datasets, but also scales well to large datasets on which existing deep learning based methods struggle. Disentanglement validation experiments further demonstrate the robustness of our model in obtaining accurate and explainable disentangled components.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization",
        "paper_url": "https://openreview.net/pdf?id=FvevdI0aA_h",
        "paper_authors": [
            "Zonghan Yang",
            "Xiaoyuan Yi",
            "Peng Li",
            "Yang Liu",
            "Xing Xie"
        ],
        "paper_abstract": "Recently pre-trained language models (PLMs) have prospered in various natural language generation (NLG) tasks due to their ability to generate fairly fluent text. Nevertheless, these models are observed to capture and reproduce harmful contents in training corpora, typically toxic language and social biases, raising severe moral issues. Prior works on ethical NLG tackle detoxifying and debiasing separately, which is problematic since we find debiased models still exhibit toxicity while detoxified ones even exacerbate biases. To address such a challenge, we propose the first unified framework of detoxifying and debiasing called UDDIA, which jointly formalizes these two problems as rectifying the output space. We theoretically interpret our framework as learning a text distribution mixing weighted attributes. Besides, UDDIA conducts adaptive optimization of only a few parameters during decoding based on a parameter-efficient tuning schema without any training data. This leads to minimal generation quality loss and improved rectification performance with acceptable computational cost. Experimental results demonstrate that compared to several strong baselines, UDDIA achieves debiasing and detoxifying simultaneously and better balances efficiency and effectiveness, taking a further step towards practical ethical NLG.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automating Nearest Neighbor Search Configuration with Constrained Optimization",
        "paper_url": "https://openreview.net/pdf?id=KfptQCEKVW4",
        "paper_authors": [
            "Philip Sun",
            "Ruiqi Guo",
            "Sanjiv Kumar"
        ],
        "paper_abstract": "The approximate nearest neighbor (ANN) search problem is fundamental to efficiently serving many real-world machine learning applications. A number of techniques have been developed for ANN search that are efficient, accurate, and scalable. However, such techniques typically have a number of parameters that affect the speed-recall tradeoff, and exhibit poor performance when such parameters aren't properly set. Tuning these parameters has traditionally been a manual process, demanding in-depth knowledge of the underlying search algorithm. This is becoming an increasingly unrealistic demand as ANN search grows in popularity. To tackle this obstacle to ANN adoption, this work proposes a constrained optimization-based approach to tuning quantization-based ANN algorithms. Our technique takes just a desired search cost or recall as input, and then generates tunings that, empirically, are very close to the speed-recall Pareto frontier and give leading performance on standard benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders",
        "paper_url": "https://openreview.net/pdf?id=HDxgaKk956l",
        "paper_authors": [
            "Huangjie Zheng",
            "Pengcheng He",
            "Weizhu Chen",
            "Mingyuan Zhou"
        ],
        "paper_abstract": "Employing a forward diffusion chain to gradually map the data to a  noise distribution, diffusion-based generative models learn how to generate the data by inferring a reverse diffusion chain. However, this approach is slow and costly because it needs many forward and reverse steps. We propose a faster and cheaper approach that adds noise not until the data become pure random noise, but until they reach a hidden noisy data distribution that we can confidently learn. Then, we use fewer reverse steps to generate data by starting from this hidden distribution that is made similar to the noisy data. We reveal that the proposed model can be cast as an adversarial auto-encoder empowered by both the diffusion process and a learnable implicit prior. Experimental results show even with a significantly smaller number of reverse diffusion steps, the proposed truncated diffusion probabilistic models can provide consistent improvements over the non-truncated ones in terms of performance in both unconditional and text-guided image generations.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NTK-SAP: Improving neural network pruning by aligning training dynamics",
        "paper_url": "https://openreview.net/pdf?id=-5EWhW_4qWP",
        "paper_authors": [
            "Yite Wang",
            "Dawei Li",
            "Ruoyu Sun"
        ],
        "paper_abstract": "Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a  certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK. Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK. This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart. However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase. We further propose to sample multiple realizations of random weights to estimate the NTK spectrum. Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent. In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well. We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP). Empirically, our method achieves better performance than all baselines on multiple datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effective Self-supervised Pre-training on Low-compute Networks without Distillation",
        "paper_url": "https://openreview.net/pdf?id=cbpRzMy-UZH",
        "paper_authors": [
            "Fuwen Tan",
            "Fatemeh Sadat Saleh",
            "Brais Martinez"
        ],
        "paper_abstract": "Despite the impressive progress of self-supervised learning (SSL), its applicability to low-compute networks has received limited attention. Reported performance has trailed behind standard supervised pre-training by a large margin, barring self-supervised learning from making an impact on models that are deployed on device. Most prior works attribute this poor performance to the capacity bottleneck of the low-compute networks and opt to bypass the problem through the use of knowledge distillation (KD). In this work, we revisit SSL for efficient neural networks, taking a closer at what are the detrimental factors causing the practical limitations, and whether they are intrinsic to the self-supervised low-compute setting. We find that, contrary to accepted knowledge, there is no intrinsic architectural bottleneck, we diagnose that the performance bottleneck is related to the model complexity vs regularization strength trade-off. In particular, we start by empirically observing that the use of local views can have a dramatic impact on the effectiveness of the SSL methods. This hints at view sampling being one of the performance bottlenecks for SSL on low-capacity networks. We hypothesize that the view sampling strategy for large neural networks, which requires matching views in very diverse spatial scales and contexts, is too demanding for low-capacity architectures. We systematize the design of the view sampling mechanism, leading to a new training methodology that consistently improves the performance across different SSL methods (e.g. MoCo-v2, SwAV or DINO), different low-size networks (convolution-based networks, e.g. MobileNetV2, ResNet18, ResNet34 and vision transformer, e.g. ViT-Ti), and different tasks (linear probe, object detection, instance segmentation and semi-supervised learning). Our best models establish new state-of-the-art for SSL methods on low-compute networks despite not using a KD loss term. Code is publicly available at github.com/saic-fi/SSLight.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CoRTX: Contrastive Framework for Real-time Explanation",
        "paper_url": "https://openreview.net/pdf?id=L2MUOUp0beo",
        "paper_authors": [
            "Yu-Neng Chuang",
            "Guanchu Wang",
            "Fan Yang",
            "Quan Zhou",
            "Pushkar Tripathi",
            "Xuanting Cai",
            "Xia Hu"
        ],
        "paper_abstract": "Recent advancements in explainable machine learning provide effective and faithful solutions for interpreting model behaviors. However, many explanation methods encounter efficiency issues, which largely limit their deployments in practical scenarios. Real-time explainer (RTX) frameworks have thus been proposed to accelerate the model explanation process by learning an one-feed-forward explainer. Existing RTX frameworks typically build the explainer under the supervised learning paradigm, which requires large amounts of explanation labels as the ground truth. Considering that accurate explanation labels are usually hard to obtain, due to constrained computational resources and limited human efforts, effective explainer training is still challenging in practice. In this work, we propose a COntrastive Real-Time eXplanation (CoRTX) framework to learn the explanation-oriented representation and relieve the intensive dependence of explainer training on explanation labels. Specifically, we design a synthetic strategy to select positive and negative instances for explanation representation learning. Theoretical analysis show that our selection strategy can benefit the contrastive learning process on explanation tasks. Experimental results on three real-world datasets further demonstrate the efficiency and efficacy of our proposed CoRTX framework.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OTOv2: Automatic, Generic, User-Friendly",
        "paper_url": "https://openreview.net/pdf?id=7ynoX1ojPMt",
        "paper_authors": [
            "Tianyi Chen",
            "Luming Liang",
            "Tianyu DING",
            "Zhihui Zhu",
            "Ilya Zharkov"
        ],
        "paper_abstract": "The existing model compression methods via structured pruning typically require complicated multi-stage procedures. Each individual stage necessitates numerous engineering efforts and domain-knowledge from the end-users which prevent their wider applications onto broader scenarios. We propose the second generation of Only-Train-Once (OTOv2), which first automatically trains and compresses a general DNN only once from scratch to produce a more compact model with competitive performance without fine-tuning. OTOv2 is automatic and pluggable into various deep learning applications, and requires almost minimal engineering efforts from the users. Methodologically, OTOv2 proposes two major improvements: (i) Autonomy: automatically exploits the dependency of general DNNs, partitions the trainable variables into Zero-Invariant Groups (ZIGs), and constructs the compressed model; and (ii) Dual Half-Space Projected Gradient (DHSPG): a novel optimizer to more reliably solve structured-sparsity problems. Numerically, we demonstrate the generality and autonomy of OTOv2 on a variety of model architectures such as VGG, ResNet, CARN, ConvNeXt, DenseNet and StackedUnets, the majority of which cannot be handled by other methods without extensive handcrafting efforts. Together with benchmark datasets including CIFAR10/100, DIV2K, Fashion-MNIST, SVNH and ImageNet, its effectiveness is validated by performing competitively or even better than the state-of-the-arts. The source code is available at https://github.com/tianyic/only_train_once.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Filter-Recovery Network for Multi-Speaker Audio-Visual Speech Separation",
        "paper_url": "https://openreview.net/pdf?id=fiB2RjmgwQ6",
        "paper_authors": [
            "Haoyue Cheng",
            "Zhaoyang Liu",
            "Wayne Wu",
            "Limin Wang"
        ],
        "paper_abstract": "In this paper, we systematically study the audio-visual speech separation task in a multi-speaker scenario. Given the facial information of each speaker, the goal of this task is to separate the corresponding speech from the mixed speech. The existing works are designed for speech separation in a controlled setting with a fixed number of speakers (mostly 2 or 3 speakers), which seems to be impractical for real applications. As a result, we try to utilize a single model to separate the voices with a variable number of speakers. Based on the observation, there are two prominent issues for multi-speaker separation: 1) There are some noisy voice pieces belonging to other speakers in the separation results; 2) Part of the target speech is missing after separation. Accordingly, we propose \\textbf{BFRNet}, including a {\\bf B}asic audio-visual speech separator and a Filter-Recovery Network (\\textbf{FRNet}). FRNet can refine the coarse audio separated by basic audio-visual speech separator. To have fair comparisons, we build a comprehensive benchmark for multi-speaker audio-visual speech separation to verify the performance of various methods. Experimental results show that our method is able to achieve the state-of-the-art performance. Furthermore, we also find that FRNet can boost the performance of other off-the-shelf speech separators, which exhibits its ability of generalization.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Can discrete information extraction prompts generalize across language models?",
        "paper_url": "https://openreview.net/pdf?id=sbWVtxq8-zE",
        "paper_authors": [
            "Nathana\u00ebl Carraz Rakotonirina",
            "Roberto Dessi",
            "Fabio Petroni",
            "Sebastian Riedel",
            "Marco Baroni"
        ],
        "paper_abstract": "We study whether automatically-induced prompts that effectively extract information from a language model can also be used, out-of-the-box, to probe other language models for the same information. After confirming that discrete prompts induced with the AutoPrompt algorithm outperform manual and semi-manual prompts on the slot-filling task, we demonstrate a drop in performance for AutoPrompt prompts learned on a model and tested on another. We introduce a way to induce prompts by mixing language models at training time that results in prompts that generalize well across models. We conduct an extensive analysis of the induced prompts, finding that the more general prompts include a larger proportion of existing English words and have a less order-dependent and more uniform distribution of information across their component tokens. Our work provides preliminary evidence that it's possible to generate discrete prompts that can be induced once and used with a number of different models, and gives insights on the properties characterizing such prompts.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions,  benefit from negative momenta.",
        "paper_url": "https://openreview.net/pdf?id=bzaPGEllsjE",
        "paper_authors": [
            "Maksim Velikanov",
            "Denis Kuznedelev",
            "Dmitry Yarotsky"
        ],
        "paper_abstract": "Mini-batch SGD with momentum is a fundamental algorithm for learning large predictive models. In this paper we develop a new analytic framework to analyze noise-averaged properties of mini-batch SGD for linear models at constant learning rates, momenta and sizes of batches. Our key idea is to consider the dynamics of the second moments of model parameters for a special family of \"Spectrally Expressible\" approximations. This allows to obtain an explicit expression for the generating function of the sequence of loss values. By analyzing this generating function, we find, in particular, that 1) the SGD dynamics exhibits several convergent and divergent regimes depending on the spectral distributions of the problem; 2) the convergent regimes admit explicit stability conditions, and explicit loss asymptotics in the case of power-law spectral distributions; 3) the optimal convergence rate can be achieved at negative momenta. We verify our theoretical predictions by extensive experiments with MNIST and synthetic problems, and find a good quantitative agreement.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bridging the Gap between ANNs and SNNs by Calibrating Offset Spikes",
        "paper_url": "https://openreview.net/pdf?id=PFbzoWZyZRX",
        "paper_authors": [
            "Zecheng Hao",
            "Jianhao Ding",
            "Tong Bu",
            "Tiejun Huang",
            "Zhaofei Yu"
        ],
        "paper_abstract": "Spiking Neural Networks (SNNs) have attracted great attention due to their distinctive characteristics of low power consumption and temporal information processing. ANN-SNN conversion, as the most commonly used training method for applying SNNs, can ensure that converted SNNs achieve comparable performance to ANNs on large-scale datasets. However, the performance degrades severely under low quantities of time-steps, which hampers the practical applications of SNNs to neuromorphic chips. \nIn this paper, instead of evaluating different conversion errors and then eliminating these errors, we define an offset spike to measure the degree of deviation between actual and desired SNN firing rates. We perform a detailed analysis of offset spike and note that the firing of one additional (or one less) spike is the main cause of conversion errors. Based on this, we propose an optimization strategy based on shifting the initial membrane potential and we theoretically prove the corresponding optimal shifting distance for calibrating the spike. In addition, we also note that our method has a unique iterative property that enables further reduction of conversion errors. The experimental results show that our proposed method achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet datasets. For example, we reach a top-1 accuracy of 67.12% on ImageNet when using 6 time-steps. To the best of our knowledge, this is the first time an ANN-SNN conversion has been shown to simultaneously achieve high accuracy and ultralow latency on complex datasets. Code is available at https://github.com/hzc1208/ANN2SNN_COS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure",
        "paper_url": "https://openreview.net/pdf?id=bHW9njOSON",
        "paper_authors": [
            "Hee Suk Yoon",
            "Joshua Tian Jin Tee",
            "Eunseop Yoon",
            "Sunjae Yoon",
            "Gwangsu Kim",
            "Yingzhen Li",
            "Chang D. Yoo"
        ],
        "paper_abstract": "Studies have shown that modern neural networks tend to be poorly calibrated due to over-confident predictions. Traditionally, post-processing methods have been used to calibrate the model after training. In recent years, various trainable calibration measures have been proposed to incorporate them directly into the training process. However, these methods all incorporate internal hyperparameters, and the performance of these calibration objectives relies on tuning these hyperparameters, incurring more computational costs as the size of neural networks and datasets become larger. As such, we present Expected Squared Difference (ESD), a tuning-free (i.e., hyperparameter-free) trainable calibration objective loss, where we view the calibration error from the perspective of the squared difference between the two expectations. With extensive experiments on several architectures (CNNs, Transformers) and datasets, we demonstrate that (1) incorporating ESD into the training improves model calibration in various batch size settings without the need for internal hyperparameter tuning, (2) ESD yields the best-calibrated results compared with previous approaches, and (3) ESD drastically improves the computational costs required for calibration during training due to the absence of internal hyperparameter. The code is publicly accessible at https://github.com/hee-suk-yoon/ESD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interactive Portrait Harmonization",
        "paper_url": "https://openreview.net/pdf?id=AP0iZoaRaS",
        "paper_authors": [
            "Jeya Maria Jose Valanarasu",
            "HE Zhang",
            "Jianming Zhang",
            "Yilin Wang",
            "Zhe Lin",
            "Jose Echevarria",
            "Yinglan Ma",
            "Zijun Wei",
            "Kalyan Sunkavalli",
            "Vishal Patel"
        ],
        "paper_abstract": "Current image harmonization methods consider the entire background as the guidance for harmonization. However, this may limit the capability for user to choose any specific object/person in the background to guide the harmonization. To enable flexible interaction between user and harmonization, we introduce interactive harmonization, a new setting where the harmonization is performed with respect to a selected region in the reference image instead of the entire background. A new flexible framework that allows users to pick certain regions of the background image and use it to guide the harmonization is proposed. Inspired by professional portrait harmonization users, we also introduce a new luminance matching loss to optimally match the color/luminance conditions between the composite foreground and select reference region. This framework provides more control to the image harmonization pipeline achieving visually pleasing portrait edits. Furthermore, we also introduce a new dataset carefully curated for validating portrait harmonization. Extensive experiments on both synthetic and real-world datasets show that the proposed approach is efficient and robust compared to previous harmonization baselines, especially for portraits.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Distillation for Further Pre-training of Transformers",
        "paper_url": "https://openreview.net/pdf?id=kj6oK_Hj40",
        "paper_authors": [
            "Seanie Lee",
            "Minki Kang",
            "Juho Lee",
            "Sung Ju Hwang",
            "Kenji Kawaguchi"
        ],
        "paper_abstract": "Pre-training a large transformer model on a massive amount of unlabeled data and fine-tuning it on labeled datasets for diverse downstream tasks has proven to be a successful strategy, for a variety of vision and natural language processing tasks. However, direct fine-tuning of the pre-trained model may be suboptimal if there exist large discrepancies across data domains for pre-training and fine-tuning. To tackle this issue, several previous studies have proposed further pre-training strategies, where we continue to pre-train the model on the target unlabeled dataset before fine-tuning. However, all of them solely focus on language models and we empirically find that a Vision Transformer is vulnerable to overfitting as we continue to pretrain the model on target unlabeled data. In order to tackle this limitation, we propose self-distillation as a regularization for a further pre-training stage. Specifically, we first further pre-train the initial pre-trained model on the target unlabeled data and then consider it as a teacher for self-distillation. Then we take the same initial pre-trained model as a student and enforce its hidden representations to be close to those of the teacher while optimizing the student with a masked auto-encoding objective. We empirically validate the efficacy of self-distillation on a variety of benchmark datasets for image and text classification tasks. Experimentally, we show that our proposed method outperforms all the relevant baselines. Theoretically, we analyze the proposed method with a simplified model to understand how self-distillation for further pre-training can potentially help improve the performance of the downstream tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextual Convolutional Networks",
        "paper_url": "https://openreview.net/pdf?id=PldynS56bN",
        "paper_authors": [
            "Shuxian Liang",
            "Xu Shen",
            "Tongliang Liu",
            "Xian-Sheng Hua"
        ],
        "paper_abstract": "This paper presents a new Convolutional Neural Network, named Contextual Convolutional Network, that capably serves as a general-purpose backbone for visual recognition. Most existing convolutional backbones follow the representation-to-classification paradigm, where representations of the input are firstly generated by category-agnostic convolutional operations, and then fed into classifiers for specific perceptual tasks (e.g., classification and segmentation). In this paper, we deviate from this classic paradigm and propose to augment potential category memberships as contextual priors in the convolution for contextualized representation learning. Specifically, top-k likely classes from the preceding stage are encoded as a contextual prior vector. Based on this vector and the preceding features, offsets for spatial sampling locations and kernel weights are generated to modulate the convolution operations. The new convolutions can readily replace their plain counterparts in existing CNNs and can be easily trained end-to-end by standard back-propagation without additional supervision. The qualities of Contextual Convolutional Networks make it compatible with a broad range of vision tasks and boost the state-of-the-art architecture ConvNeXt-Tiny by 1.8% on top-1 accuracy of ImageNet classification. The superiority of the proposed model reveals the potential of contextualized representation learning for vision tasks. Code is available at: \\url{https://github.com/liang4sx/contextual_cnn}.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Statistical Inference for Fisher Market Equilibrium",
        "paper_url": "https://openreview.net/pdf?id=KemSBwOYJC",
        "paper_authors": [
            "Luofeng Liao",
            "Yuan Gao",
            "Christian Kroer"
        ],
        "paper_abstract": "Statistical inference under market equilibrium effects has attracted increasing attention recently. In this paper we focus on the specific case of linear Fisher markets. They have been widely use in fair resource allocation of food/blood donations and budget management in large-scale Internet ad auctions. In resource allocation, it is crucial to quantify the variability of the resource received by the agents (such as blood banks and food banks) in addition to fairness and efficiency properties of the systems. For ad auction markets, it is important to establish statistical properties of the platform's revenues in addition to their expected values. To this end, we propose a statistical framework based on the concept of infinite-dimensional Fisher markets. In our framework, we observe a market formed by a finite number of items sampled from an underlying distribution (the ``observed market'') and aim to infer several important equilibrium quantities of the underlying long-run market. These equilibrium quantities include individual utilities, social welfare, and pacing multipliers. Through the lens of sample average approximation (SSA), we derive a collection of statistical results and show that the observed market provides useful statistical information of the long-run market. In other words, the equilibrium quantities of the observed market converge to the true ones of the long-run market with strong statistical guarantees. These include consistency, finite sample bounds, asymptotics, and confidence. As an extension, we discuss revenue inference in quasilinear Fisher markets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scenario-based Question Answering with Interacting Contextual Properties",
        "paper_url": "https://openreview.net/pdf?id=tPrRs6YB2P",
        "paper_authors": [
            "Haitian Sun",
            "William W. Cohen",
            "Ruslan Salakhutdinov"
        ],
        "paper_abstract": "In the scenario-based Question Answering (QA) task, models are asked to find answers that are appropriate to the user scenarios associated with the question and identify information that is missing from the scenarios but is necessary for the answers to hold. Scenarios commonly include multiple properties of users, such as age, employment status, and income level for the question \u201cHow much can I claim from this benefit\u201d. The properties relevant to a potential answer are given in a document, which will state conditions necessary for the answer to hold. Documents also may specify how conditions interact with each other, e.g. with text like \u201cone of the conditions below must apply\u201d. Although understanding the relationship between conditions is crucial for solving this challenging QA task, limited work has been done so far in modeling this. In this paper, we propose the T-Reasoner model, which solves this problem with three jointly learned modules: an entailment module which checks whether a condition has been satisfied by the scenario, a decoding module which locates eligible answers from documents, and a reasoning module which infers the relationship between conditions and performs a reasoning step to determine the logically consistent answers and identify missing conditions. T-Reasoner outperforms strong baselines on a synthetic scenario-based QA dataset and achieves a new state-of-the-art on two scenario-based QA benchmarks, outperforming the prior best models by 3-10 points.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Easy Differentially Private Linear Regression",
        "paper_url": "https://openreview.net/pdf?id=rSUCajhLsQ",
        "paper_authors": [
            "Kareem Amin",
            "Matthew Joseph",
            "M\u00f3nica Ribero",
            "Sergei Vassilvitskii"
        ],
        "paper_abstract": "Linear regression is a fundamental tool for statistical analysis. This has motivated the development of linear regression methods that also satisfy differential privacy and thus guarantee that the learned model reveals little about any one data point used to construct it. However, existing differentially private solutions assume that the end user can easily specify good data bounds and hyperparameters. Both present significant practical obstacles. In this paper, we study an algorithm which uses the exponential mechanism to select a model with high Tukey depth from a collection of non-private regression models. Given $n$ samples of $d$-dimensional data used to train $m$ models, we construct an efficient analogue using an approximate Tukey depth that runs in time $O(d^2n + dm\\log(m))$. We find that this algorithm obtains strong empirical performance in the data-rich setting with no data bounds or hyperparameter selection required.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LPT: Long-tailed Prompt Tuning  for Image Classification",
        "paper_url": "https://openreview.net/pdf?id=8pOVAeo8ie",
        "paper_authors": [
            "Bowen Dong",
            "Pan Zhou",
            "Shuicheng Yan",
            "Wangmeng Zuo"
        ],
        "paper_abstract": "For long-tailed classification tasks, most works often pretrain a big model on a large-scale (unlabeled) dataset, and then fine-tune the whole pretrained  model for  adapting to long-tailed data. Though promising, fine-tuning the whole pretrained model tends to suffer from high cost in computation and deployment of different models for different tasks, as well as weakened generalization capability for overfitting to certain features of long-tailed data. To alleviate these issues, we propose an effective Long-tailed Prompt Tuning (LPT) method for long-tailed classification tasks. LPT introduces several trainable prompts into a frozen pretrained model to adapt it to long-tailed data. For better effectiveness, we divide prompts into two groups: 1) a shared prompt for the whole long-tailed dataset to learn general features and to adapt a pretrained model into the target long-tailed domain; and 2) group-specific prompts to gather group-specific features for the samples which have similar features and also to empower the pretrained model with fine-grained discrimination ability. Then we design a two-phase training paradigm to learn these prompts. In the first phase, we train the shared prompt via conventional supervised prompt tuning to adapt a pretrained model to the desired long-tailed domain. In the second phase, we use the learnt shared prompt as query to select a small best matched set for a group of similar samples from the group-specific prompt set to dig the common features of these similar samples, and then optimize these prompts with a dual sampling strategy and the asymmetric Gaussian Clouded Logit loss. By only fine-tuning a few prompts while fixing the pretrained model, LPT can reduce training cost and deployment cost by storing a few prompts, and enjoys a strong generalization ability of the pretrained model. Experiments show that on various long-tailed benchmarks, with only $\\sim$1.1\\% extra trainable parameters, LPT achieves comparable or higher performance than previous whole model fine-tuning methods, and is more robust to domain-shift.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DamoFD: Digging into Backbone Design on Face Detection",
        "paper_url": "https://openreview.net/pdf?id=NkJOhtNKX91",
        "paper_authors": [
            "Yang Liu",
            "Jiankang Deng",
            "Fei Wang",
            "Lei Shang",
            "Xuansong Xie",
            "Baigui Sun"
        ],
        "paper_abstract": "Face detection (FD) has achieved remarkable success over the past few years, yet,\nthese leaps often arrive when consuming enormous computation costs. Moreover,\nwhen considering a realistic situation, i.e., building a lightweight face detector\nunder a computation-scarce scenario, such heavy computation cost limits the application\nof the face detector. To remedy this, several pioneering works design\ntiny face detectors through off-the-shelf neural architecture search (NAS) technologies,\nwhich are usually applied to the classification task. Thus, the searched\narchitectures are sub-optimal for the face detection task since some design criteria\nbetween detection and classification task are different. As a representative, the\nface detection backbone design needs to guarantee the stage-level detection ability\nwhile it is not required for the classification backbone. Furthermore, the detection\nbackbone consumes a vast body of inference budgets in the whole detection framework.\nConsidering the intrinsic design requirement and the virtual importance role\nof the face detection backbone, we thus ask a critical question: How to employ\nNAS to search FD-friendly backbone architecture? To cope with this question,\nwe propose a distribution-dependent stage-aware ranking score (DDSAR-Score)\nto explicitly characterize the stage-level expressivity and identify the individual\nimportance of each stage, thus satisfying the aforementioned design criterion of\nthe FD backbone. Based on our proposed DDSAR-Score, we conduct comprehensive\nexperiments on the challenging Wider Face benchmark dataset and achieve\ndominant performance across a wide range of compute regimes. In particular,\ncompared to the tiniest face detector SCRFD-0.5GF, our method is +2.5 % better\nin Average Precision (AP) score when using the same amount of FLOPs. The\ncode is avaliable at https://github.com/ly19965/FaceMaas/tree/master/face_project/face_detection/DamoFD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Smooth Video Composition",
        "paper_url": "https://openreview.net/pdf?id=W918Ora75q",
        "paper_authors": [
            "Qihang Zhang",
            "Ceyuan Yang",
            "Yujun Shen",
            "Yinghao Xu",
            "Bolei Zhou"
        ],
        "paper_abstract": "Video generation, with the purpose of producing a sequence of frames, requires synthesizing consistent and persistent dynamic contents over time. This work investigates how to model the temporal relations for composing a video with arbitrary number of frames, from a few to even infinite, using generative adversarial networks (GANs). First, towards composing adjacent frames, we show that the alias-free operation for single image generation, together with adequately pre-learned knowledge, bring a smooth frame transition without harming the per-frame quality. Second, through incorporating a temporal shift module (TSM), which is originally designed for video understanding, into the discriminator, we manage to advance the generator in synthesizing more reasonable dynamics. Third, we develop a novel B-Spline based motion representation to ensure the temporal smoothness, and hence achieve infinite-length video generation, going beyond the frame number used in training. We evaluate our approach on a range of datasets and show substantial improvements over baselines on video generation. Code and models are publicly available at \\url{https://genforce.github.io/StyleSV}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DiffMimic: Efficient Motion Mimicking with Differentiable Physics",
        "paper_url": "https://openreview.net/pdf?id=06mk-epSwZ",
        "paper_authors": [
            "Jiawei Ren",
            "Cunjun Yu",
            "Siwei Chen",
            "Xiao Ma",
            "Liang Pan",
            "Ziwei Liu"
        ],
        "paper_abstract": "Motion mimicking is a foundational task in physics-based character animation. However, most existing motion mimicking methods are built upon reinforcement learning (RL) and suffer from heavy reward engineering, high variance, and slow convergence with hard explorations. Specifically, they usually take tens of hours or even days of training to mimic a simple motion sequence, resulting in poor scalability. In this work, we leverage differentiable physics simulators (DPS) and propose an efficient motion mimicking method dubbed $\\textbf{DiffMimic}$. Our key insight is that DPS casts a complex policy learning task to a much simpler state matching problem. In particular, DPS learns a stable policy by analytical gradients with ground-truth physical priors hence leading to significantly faster and stabler convergence than RL-based methods. Moreover, to escape from local optima, we utilize an \\textit{Demonstration Replay} mechanism to enable stable gradient backpropagation in a long horizon. Extensive experiments on standard benchmarks show that DiffMimic has a better sample efficiency and time efficiency than existing methods (e.g., DeepMimic). Notably, DiffMimic allows a physically simulated character to learn back-flip after 10 minutes of training and be able to cycle it after 3 hours of training, while DeepMimic requires about a day of training to cycle back-flip. More importantly, we hope DiffMimic can benefit more differentiable animation systems with techniques like differentiable clothes simulation in future research. Our code is available at https://github.com/diffmimic/diffmimic. Qualitative results can be viewed at https://diffmimic-demo-main-g7h0i8.streamlitapp.com.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Inferential Reproducibility of Machine Learning Research",
        "paper_url": "https://openreview.net/pdf?id=li4GQCQWkv",
        "paper_authors": [
            "Michael Hagmann",
            "Philipp Meier",
            "Stefan Riezler"
        ],
        "paper_abstract": "Reliability of machine learning evaluation --- the consistency of observed evaluation scores across replicated model training runs --- is affected by several sources of nondeterminism which can be regarded as measurement noise. Current tendencies to remove noise in order to enforce reproducibility of research results neglect inherent nondeterminism at the implementation level and disregard crucial interaction effects between algorithmic noise factors and data properties. This limits the scope of conclusions that can be drawn from such experiments. Instead of removing noise, we propose to incorporate several sources of variance, including their interaction with data properties, into an analysis of significance and reliability of machine learning evaluation, with the aim to draw inferences beyond particular instances of trained models. We show how to use linear mixed effects models (LMEMs) to analyze performance evaluation scores, and to conduct statistical inference with a generalized likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources of noise like meta-parameter variations into statistical significance testing, and to assess performance differences conditional on data properties. Furthermore, a variance component analysis (VCA) enables the analysis of the  contribution of noise sources to overall variance and the computation of a reliability coefficient by the ratio of substantial to total variance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation based Degradation Estimation for Blind Super-Resolution",
        "paper_url": "https://openreview.net/pdf?id=Fg3mYW8owg",
        "paper_authors": [
            "Bin Xia",
            "Yulun Zhang",
            "Yitong Wang",
            "Yapeng Tian",
            "Wenming Yang",
            "Radu Timofte",
            "Luc Van Gool"
        ],
        "paper_abstract": "Blind image super-resolution (Blind-SR) aims to recover a high-resolution (HR) image from its corresponding low-resolution (LR) input image with unknown degradations. Most of the existing works design an explicit degradation estimator for each degradation to guide SR. However, it is infeasible to provide concrete labels of multiple degradation combinations (\\eg, blur, noise, jpeg compression) to supervise the degradation estimator training. In addition, these special designs for certain degradation, such as blur, impedes the models from being generalized to handle different degradations. To this end, it is necessary to design an implicit degradation estimator that can extract discriminative degradation representation for all degradations without relying on the supervision of degradation ground-truth. In this paper, we propose a Knowledge Distillation based Blind-SR network (KDSR). It consists of a knowledge distillation based implicit degradation estimator network (KD-IDE) and an efficient SR network. To learn the KDSR model, we first train a teacher network: KD-IDE$_{T}$. It takes paired HR and LR patches as inputs and is optimized with the SR network jointly. Then, we further train a student network KD-IDE$_{S}$, which only takes LR images as input and learns to extract the same implicit degradation representation (IDR) as KD-IDE$_{T}$. In addition, to fully use extracted IDR, we design a simple, strong, and efficient IDR based dynamic convolution residual block (IDR-DCRB) to build an SR network. We conduct extensive experiments under classic and real-world degradation settings. The results show that KDSR achieves SOTA performance and can generalize to various degradation processes. The source codes and pre-trained models will be released.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph Contrastive Learning for Skeleton-based Action Recognition",
        "paper_url": "https://openreview.net/pdf?id=PLUXnnxUdr4",
        "paper_authors": [
            "Xiaohu Huang",
            "Hao Zhou",
            "Jian Wang",
            "Haocheng Feng",
            "Junyu Han",
            "Errui Ding",
            "Jingdong Wang",
            "Xinggang Wang",
            "Wenyu Liu",
            "Bin Feng"
        ],
        "paper_abstract": "In the field of skeleton-based action recognition, current top-performing graph convolutional networks (GCNs) exploit intra-sequence context to construct adaptive graphs for feature aggregation. However, we argue that such context is still $\\textit{local}$ since the rich cross-sequence relations have not been explicitly investigated. In this paper, we propose a graph contrastive learning framework for skeleton-based action recognition ($\\textit{SkeletonGCL}$) to explore the $\\textit{global}$ context across all sequences. In specific, SkeletonGCL associates graph learning across sequences by enforcing graphs to be class-discriminative, i.e., intra-class compact and inter-class dispersed, which improves the GCN capacity to distinguish various action patterns. Besides, two memory banks are designed to enrich cross-sequence context from two complementary levels, i.e., instance and semantic levels, enabling graph contrastive learning in multiple context scales. Consequently, SkeletonGCL establishes a new training paradigm, and it can be seamlessly incorporated into current GCNs. Without loss of generality, we combine SkeletonGCL with three GCNs (2S-ACGN, CTR-GCN, and InfoGCN), and achieve consistent improvements on NTU60, NTU120, and NW-UCLA benchmarks. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation",
        "paper_url": "https://openreview.net/pdf?id=s4WVupnJjmX",
        "paper_authors": [
            "Jie Yang",
            "Ailing Zeng",
            "Shilong Liu",
            "Feng Li",
            "Ruimao Zhang",
            "Lei Zhang"
        ],
        "paper_abstract": "This paper presents a novel end-to-end framework with Explicit box Detection for multi-person Pose estimation, called ED-Pose, where it unifies the contextual learning between human-level (global) and keypoint-level (local) information. Different from previous one-stage methods, ED-Pose re-considers this task as two explicit box detection processes with a unified representation and regression supervision. First, we introduce a human detection decoder from encoded tokens to extract global features. It can provide a good initialization for the latter keypoint detection, making the training process converge fast. Second, to bring in contextual information near keypoints, we regard pose estimation as a keypoint box detection problem to learn both box positions and contents for each keypoint. A human-to-keypoint detection decoder adopts an interactive learning strategy between human and keypoint features to further enhance global and local feature aggregation. In general, ED-Pose is conceptually simple without post-processing and dense heatmap supervision. It demonstrates its effectiveness and efficiency compared with both two-stage and one-stage methods. Notably, explicit box detection boosts the pose estimation performance by 4.5 AP on COCO and 9.9 AP on CrowdPose. For the first time, as a fully end-to-end framework with a L1 regression loss, ED-Pose surpasses heatmap-based Top-down methods under the same backbone by 1.2 AP on COCO and achieves the state-of-the-art with 76.6 AP on CrowdPose without bells and whistles. Code is available at https://github.com/IDEA-Research/ED-Pose.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spikformer: When Spiking Neural Network Meets Transformer ",
        "paper_url": "https://openreview.net/pdf?id=frE4fUwz_h",
        "paper_authors": [
            "Zhaokun Zhou",
            "Yuesheng Zhu",
            "Chao He",
            "Yaowei Wang",
            "Shuicheng YAN",
            "Yonghong Tian",
            "Li Yuan"
        ],
        "paper_abstract": "We consider two biologically plausible structures, the Spiking Neural Network (SNN) and the self-attention mechanism. The former offers an energy-efficient and event-driven paradigm for deep learning, while the latter has the ability to capture feature dependencies, enabling Transformer to achieve good performance. It is intuitively promising to explore the marriage between them. In this paper, we consider leveraging both self-attention capability and biological properties of SNNs, and propose a novel Spiking Self Attention (SSA) as well as a powerful framework, named Spiking Transformer (Spikformer). The SSA mechanism in Spikformer models the sparse visual feature by using spike-form Query, Key, and Value without softmax.  Since its computation is sparse and avoids multiplication, SSA is efficient and has low computational energy consumption. It is shown that Spikformer with SSA can outperform the state-of-the-art SNNs-like frameworks in image classification on both neuromorphic and static datasets. Spikformer (66.3M parameters) with comparable size to SEW-ResNet-152 (60.2M,69.26%) can achieve 74.81% top1 accuracy on ImageNet using 4 time steps, which is the state-of-the-art in directly trained SNNs models. Code is avaiable at https://github.com/ZK-Zhou/spikformer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Analogical Reasoning over Knowledge Graphs",
        "paper_url": "https://openreview.net/pdf?id=NRHajbzg8y0P",
        "paper_authors": [
            "Ningyu Zhang",
            "Lei Li",
            "Xiang Chen",
            "Xiaozhuan Liang",
            "Shumin Deng",
            "Huajun Chen"
        ],
        "paper_abstract": "Analogical reasoning is fundamental to human cognition and holds an important place in various fields. However, previous studies mainly focus on single-modal analogical reasoning and ignore taking advantage of structure knowledge. Notably, the research in cognitive psychology has demonstrated that information from multimodal sources always brings more powerful cognitive transfer than single modality sources. To this end, we introduce the new task of multimodal analogical reasoning over knowledge graphs, which requires multimodal reasoning ability with the help of background knowledge. Specifically, we construct a Multimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph MarKG. We evaluate with multimodal knowledge graph embedding and pre-trained Transformer baselines, illustrating the potential challenges of the proposed task. We further propose a novel model-agnostic Multimodal analogical reasoning framework with Transformer (MarT) motivated by the structure mapping theory, which can obtain better performance. We hope our work can deliver benefits and inspire future research. Code and datasets are available in https://github.com/zjunlp/MKG_Analogy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MECTA: Memory-Economic Continual Test-Time Model Adaptation",
        "paper_url": "https://openreview.net/pdf?id=N92hjSf5NNh",
        "paper_authors": [
            "Junyuan Hong",
            "Lingjuan Lyu",
            "Jiayu Zhou",
            "Michael Spranger"
        ],
        "paper_abstract": "Continual Test-time Adaptation (CTA) is a promising art to secure accuracy gains in continually-changing environments. The state-of-the-art adaptations improve out-of-distribution model accuracy via computation-efficient online test-time gradient descents but meanwhile cost about times of memory versus the inference, even if only a small portion of parameters are updated. Such high memory consumption of CTA substantially impedes wide applications of advanced CTA on memory-constrained devices. In this paper, we provide a novel solution, dubbed MECTA, to drastically improve the memory efficiency of gradient-based CTA. Our profiling shows that the major memory overhead comes from the intermediate cache for back-propagation, which scales by the batch size, channel, and layer number. Therefore, we propose to reduce batch sizes, adopt an adaptive normalization layer to maintain stable and accurate predictions, and stop the back-propagation caching heuristically. On the other hand, we prune the networks to reduce the computation and memory overheads in optimization and recover the parameters afterward to avoid forgetting. The proposed MECTA is efficient and can be seamlessly plugged into state-of-the-art CTA algorithms at negligible overhead on computation and memory. On three datasets, CIFAR10, CIFAR100, and ImageNet, MECTA improves the accuracy by at least 6% with constrained memory and significantly reduces the memory costs of ResNet50 on ImageNet by at least 70% with comparable accuracy. Our codes can be accessed at https://github.com/SonyAI/MECTA.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interpretability with full complexity by constraining feature information",
        "paper_url": "https://openreview.net/pdf?id=R_OL5mLhsv",
        "paper_authors": [
            "Kieran A Murphy",
            "Danielle Bassett"
        ],
        "paper_abstract": "Interpretability is a pressing issue for machine learning. Common approaches to interpretable machine learning constrain interactions between features of the input, sacrificing model complexity in order to render more comprehensible the effects of those features on the model's output. We approach interpretability from a new angle: constrain the information about the features without restricting the complexity of the model. We use the Distributed Information Bottleneck to optimally compress each feature so as to maximally preserve information about the output. The learned information allocation, by feature and by feature value, provides rich opportunities for interpretation, particularly in problems with many features and complex feature interactions. The central object of analysis is not a single trained model, but rather a spectrum of models serving as approximations that leverage variable amounts of information about the inputs. Information is allocated to features by their relevance to the output, thereby solving the problem of feature selection by constructing a learned continuum of feature inclusion-to-exclusion. The optimal compression of each feature---at every stage of approximation---allows fine-grained inspection of the distinctions among feature values that are most impactful for prediction. We develop a framework for extracting insight from the spectrum of approximate models and demonstrate its utility on a range of tabular datasets. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What shapes the loss landscape of self supervised learning?",
        "paper_url": "https://openreview.net/pdf?id=3zSn48RUO8M",
        "paper_authors": [
            "Liu Ziyin",
            "Ekdeep Singh Lubana",
            "Masahito Ueda",
            "Hidenori Tanaka"
        ],
        "paper_abstract": "Prevention of complete and dimensional collapse of representations has recently become a design principle for self-supervised learning (SSL). However, questions remain in our theoretical understanding: When do those collapses occur? What are the mechanisms and causes? We answer these questions by deriving and thoroughly analyzing an analytically tractable theory of SSL loss landscapes. In this theory, we identify the causes of the dimensional collapse and study the effect of normalization and bias. Finally, we leverage the interpretability afforded by the analytical theory to understand how dimensional collapse can be beneficial and what affects the robustness of SSL against data imbalance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies",
        "paper_url": "https://openreview.net/pdf?id=-z9hdsyUwVQ",
        "paper_authors": [
            "Rui Yuan",
            "Simon Shaolei Du",
            "Robert M. Gower",
            "Alessandro Lazaric",
            "Lin Xiao"
        ],
        "paper_abstract": "We consider infinite-horizon discounted Markov decision processes and study the convergence rates of the natural policy gradient (NPG) and the Q-NPG methods with the log-linear policy class. Using the compatible function approximation framework, both methods with log-linear policies can be written as approximate versions of the policy mirror descent (PMD) method. We show that both methods attain linear convergence rates and $\\tilde{\\mathcal{O}}(1/\\epsilon^2)$ sample complexities using a simple, non-adaptive geometrically increasing step size, without resorting to entropy or other strongly convex regularization. Lastly, as a byproduct, we obtain sublinear convergence rates for both methods with arbitrary constant step size.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game",
        "paper_url": "https://openreview.net/pdf?id=UP_GHHPw7rP",
        "paper_authors": [
            "Wei Xiong",
            "Han Zhong",
            "Chengshuai Shi",
            "Cong Shen",
            "Liwei Wang",
            "Tong Zhang"
        ],
        "paper_abstract": "Offline reinforcement learning (RL) aims at learning an optimal strategy using a pre-collected dataset without further interactions with the environment. While various algorithms have been proposed for offline RL in the previous literature, the minimax optimality has only been (nearly) established for tabular Markov decision processes (MDPs). In this paper, we focus on offline RL with linear function approximation and propose a new pessimism-based algorithm for offline linear MDP. At the core of our algorithm is the uncertainty decomposition via a reference function, which is new in the literature of offline RL under linear function approximation. Theoretical analysis demonstrates that our algorithm can match the performance lower bound up to logarithmic factors. We also extend our techniques to the two-player zero-sum Markov games (MGs), and establish a new performance lower bound for MGs, which tightens the existing result, and verifies the nearly minimax optimality of the proposed algorithm. To the best of our knowledge, these are the first computationally efficient and nearly minimax optimal algorithms for offline single-agent MDPs and MGs with linear function approximation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conditional Positional Encodings for Vision Transformers",
        "paper_url": "https://openreview.net/pdf?id=3KWnuT-R1bh",
        "paper_authors": [
            "Xiangxiang Chu",
            "Zhi Tian",
            "Bo Zhang",
            "Xinlong Wang",
            "Chunhua Shen"
        ],
        "paper_abstract": "We propose a conditional positional encoding (CPE) scheme for vision Transformers. Unlike previous fixed or learnable positional encodings that are predefined and independent of input tokens, CPE is dynamically generated and conditioned on the local neighborhood of the input tokens. As a result, CPE can easily generalize to the input sequences that are longer than what the model has ever seen during the training. Besides, CPE can keep the desired translation equivalence in vision tasks, resulting in improved performance. We implement CPE with a simple Position Encoding Generator (PEG) to get seamlessly incorporated into the current Transformer framework. Built on PEG, we present Conditional Position encoding Vision Transformer (CPVT). We demonstrate that CPVT has visually similar attention maps compared to those with learned positional encodings and delivers outperforming results.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills",
        "paper_url": "https://openreview.net/pdf?id=b_CQDy9vrD1",
        "paper_authors": [
            "Jiayuan Gu",
            "Fanbo Xiang",
            "Xuanlin Li",
            "Zhan Ling",
            "Xiqiang Liu",
            "Tongzhou Mu",
            "Yihe Tang",
            "Stone Tao",
            "Xinyue Wei",
            "Yunchao Yao",
            "Xiaodi Yuan",
            "Pengwei Xie",
            "Zhiao Huang",
            "Rui Chen",
            "Hao Su"
        ],
        "paper_abstract": "Generalizable manipulation skills, which can be composed to tackle long-horizon and complex daily chores, are one of the cornerstones of Embodied AI. However, existing benchmarks, mostly composed of a suite of simulatable environments, are insufficient to push cutting-edge research works because they lack object-level topological and geometric variations, are not based on fully dynamic simulation, or are short of native support for multiple types of manipulation tasks. To this end, we present ManiSkill2, the next generation of the SAPIEN ManiSkill benchmark, to address critical pain points often encountered by researchers when using benchmarks for generalizable manipulation skills. ManiSkill2 includes 20 manipulation task families with 2000+ object models and 4M+ demonstration frames, which cover stationary/mobile-base, single/dual-arm, and rigid/soft-body manipulation tasks with 2D/3D-input data simulated by fully dynamic engines. It defines a unified interface and evaluation protocol to support a wide range of algorithms (e.g., classic sense-plan-act, RL, IL), visual observations (point cloud, RGBD), and controllers (e.g., action type and parameterization). Moreover, it empowers fast visual input learning algorithms so that a CNN-based policy can collect samples at about 2000 FPS with 1 GPU and 16 processes on a regular workstation. It implements a render server infrastructure to allow sharing rendering resources across all environments, thereby significantly reducing memory usage. We open-source all codes of our benchmark (simulator, environments, and baselines) and host an online challenge open to interdisciplinary researchers.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deja Vu: Continual Model Generalization for Unseen Domains",
        "paper_url": "https://openreview.net/pdf?id=L8iZdgeKmI6",
        "paper_authors": [
            "Chenxi Liu",
            "Lixu Wang",
            "Lingjuan Lyu",
            "Chen Sun",
            "Xiao Wang",
            "Qi Zhu"
        ],
        "paper_abstract": "In real-world applications, deep learning models often run in non-stationary environments where the target data distribution continually shifts over time. There have been numerous domain adaptation (DA) methods in both online and offline modes to improve cross-domain adaptation ability. However, these DA methods typically only provide good performance after a long period of adaptation, and perform poorly on new domains before and during adaptation \u2013 in what we call the \u201cUnfamiliar Period\u201d, especially when domain shifts happen suddenly and significantly. On the other hand, domain generalization (DG) methods have been proposed to improve the model generalization ability on unadapted domains. However, existing DG works are ineffective for continually changing domains due to severe catastrophic forgetting of learned knowledge. To overcome these limitations of DA and DG in handling the Unfamiliar Period during continual domain shift, we propose RaTP, a framework that focuses on improving models\u2019 target domain generalization (TDG) capability, while also achieving effective target domain adaptation (TDA) capability right after training on certain domains and forgetting alleviation (FA) capability on past domains. RaTP includes a training-free data augmentation module to prepare data for TDG, a novel pseudo-labeling mechanism to provide reliable supervision for TDA, and a prototype contrastive alignment algorithm to align different domains for achieving TDG, TDA and FA. Extensive experiments on Digits, PACS, and DomainNet demonstrate that RaTP significantly outperforms state-of-the-art works from Continual DA, Source-Free DA, Test-Time/Online DA, Single DG, Multiple DG and Unified DA&DG in TDG, and achieves comparable TDA and FA capabilities.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Graph Neural Network Approach to Automated Model Building in Cryo-EM Maps",
        "paper_url": "https://openreview.net/pdf?id=65XDF_nwI61",
        "paper_authors": [
            "Kiarash Jamali",
            "Dari Kimanius",
            "Sjors HW Scheres"
        ],
        "paper_abstract": "Electron cryo-microscopy (cryo-EM) produces three-dimensional (3D) maps of the electrostatic potential of biological macromolecules, including proteins. At sufficient resolution, the cryo-EM maps, along with some knowledge about the imaged molecules, allow de novo atomic modelling. Typically, this is done through a laborious manual process. Recent advances in machine learning applications to protein structure prediction show potential for automating this process. Taking inspiration from these techniques, we have built ModelAngelo for automated model building of proteins in cryo-EM maps. ModelAngelo first uses a residual convolutional neural network (CNN) to initialize a graph representation with nodes assigned to individual amino acids of the proteins in the map and edges representing the protein chain. The graph is then refined with a graph neural network (GNN) that combines the cryo-EM data, the amino acid sequence data and prior knowledge about protein geometries. The GNN refines the geometry of the protein chain and classifies the amino acids for each of its nodes. The final graph is post-processed with a hidden Markov model (HMM) search to map each protein chain to entries in a user provided sequence file. Application to 28 test cases shows that ModelAngelo outperforms state-of-the-art and approximates manual building for cryo-EM maps with resolutions better than 3.5 A.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distilling Cognitive Backdoor Patterns within an Image",
        "paper_url": "https://openreview.net/pdf?id=S3D9NLzjnQ5",
        "paper_authors": [
            "Hanxun Huang",
            "Xingjun Ma",
            "Sarah Monazam Erfani",
            "James Bailey"
        ],
        "paper_abstract": "This paper proposes a simple method to distill and detect backdoor patterns within an image: \\emph{Cognitive Distillation} (CD). The idea is to extract the ``minimal essence\" from an input image responsible for the model's prediction. CD optimizes an input mask to extract a small pattern from the input image that can lead to the same model output (i.e., logits or deep features). The extracted pattern can help understand the cognitive mechanism of a model on clean vs. backdoor images and is thus called a \\emph{Cognitive Pattern} (CP). Using CD and the distilled CPs, we uncover an interesting phenomenon of backdoor attacks: despite the various forms and sizes of trigger patterns used by different attacks, the CPs of backdoor samples are all surprisingly and suspiciously small. \nOne thus can leverage the learned mask to detect and remove backdoor examples from poisoned training datasets. \nWe conduct extensive experiments to show that CD can robustly detect a wide range of advanced backdoor attacks.\nWe also show that CD can potentially be applied to help detect potential biases from face datasets.\nCode is available at https://github.com/HanxunH/CognitiveDistillation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching",
        "paper_url": "https://openreview.net/pdf?id=QjQibO3scV_",
        "paper_authors": [
            "Chang Liu",
            "Zetian Jiang",
            "Runzhong Wang",
            "Lingxiao Huang",
            "Pinyan Lu",
            "Junchi Yan"
        ],
        "paper_abstract": "Graph matching (GM) has been a building block in various areas including computer vision and pattern recognition. Despite recent impressive progress, existing deep GM methods often have obvious difficulty in handling outliers, which are ubiquitous in practice. We propose a deep reinforcement learning based approach RGM, whose sequential node matching scheme naturally fits the strategy for selective inlier matching against outliers. A revocable action framework is devised to improve the agent's flexibility against the complex constrained GM. Moreover, we propose a quadratic approximation technique to regularize the affinity score, in the presence of outliers. As such, the agent can finish inlier matching timely when the affinity score stops growing, for which otherwise an additional parameter i.e. the number of inliers is needed to avoid matching outliers. In this paper, we focus on learning the back-end solver under the most general form of GM: the Lawler's QAP, whose input is the affinity matrix. Especially, our approach can also boost existing GM methods that use such input. Experiments on multiple real-world datasets demonstrate its performance regarding both accuracy and robustness.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One Transformer Can Understand Both 2D & 3D Molecular Data",
        "paper_url": "https://openreview.net/pdf?id=vZTp1oPV3PC",
        "paper_authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Yixian Xu",
            "Shuxin Zheng",
            "Tie-Yan Liu",
            "Liwei Wang",
            "Di He"
        ],
        "paper_abstract": "Unlike vision and language data which usually has a unique format, molecules can naturally be characterized using different chemical formulations. One can view a molecule as a 2D graph or define it as a collection of atoms located in a 3D space. For molecular representation learning, most previous works designed neural networks only for a particular data format, making the learned models likely to fail for other data formats. We believe a general-purpose neural network model for chemistry should be able to handle molecular tasks across data modalities. To achieve this goal, in this work, we develop a novel Transformer-based Molecular model called Transformer-M, which can take molecular data of 2D or 3D formats as input and generate meaningful semantic representations. Using the standard Transformer as the backbone architecture, Transformer-M develops two separated channels to encode 2D and 3D structural information and incorporate them with the atom features in the network modules. When the input data is in a particular format, the corresponding channel will be activated, and the other will be disabled. By training on 2D and 3D molecular data with properly designed supervised signals, Transformer-M automatically learns to leverage knowledge from different data modalities and correctly capture the representations. We conducted extensive experiments for Transformer-M. All empirical results show that Transformer-M can simultaneously achieve strong performance on 2D and 3D tasks, suggesting its broad applicability. The code and models will be made publicly available at https://github.com/lsj2408/Transformer-M.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mind the Gap: Offline Policy Optimization for Imperfect Rewards",
        "paper_url": "https://openreview.net/pdf?id=WumysvcMvV6",
        "paper_authors": [
            "Jianxiong Li",
            "Xiao Hu",
            "Haoran Xu",
            "Jingjing Liu",
            "Xianyuan Zhan",
            "Qing-Shan Jia",
            "Ya-Qin Zhang"
        ],
        "paper_abstract": "Reward function is essential in reinforcement learning (RL), serving as the guiding signal to incentivize agents to solve given tasks, however, is also notoriously difficult to design. In many cases, only imperfect rewards are available, which inflicts substantial performance loss for RL agents. In this study, we propose a unified offline policy optimization approach, \\textit{RGM (Reward Gap Minimization)}, which can smartly handle diverse types of imperfect rewards. RGM is formulated as a bi-level optimization problem: the upper layer optimizes a reward correction term that performs visitation distribution matching w.r.t. some expert data; the lower layer solves a pessimistic RL problem with the corrected rewards. By exploiting the duality of the lower layer, we derive a tractable algorithm that enables sampled-based learning without any online interactions.  Comprehensive experiments demonstrate that RGM achieves superior performance to existing methods under diverse settings of imperfect rewards. Further, RGM can effectively correct wrong or inconsistent rewards against expert preference and retrieve useful information from biased rewards. Code is available at https://github.com/Facebear-ljx/RGM.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to Compose Soft Prompts for Compositional Zero-Shot Learning",
        "paper_url": "https://openreview.net/pdf?id=S8-A2FXnIh",
        "paper_authors": [
            "Nihal V. Nayak",
            "Peilin Yu",
            "Stephen Bach"
        ],
        "paper_abstract": "We introduce compositional soft prompting (CSP), a parameter-efficient learning technique to improve the zero-shot compositionality of large-scale pretrained vision-language models (VLMs) like CLIP. We develop CSP for compositional zero-shot learning, the task of predicting unseen attribute-object compositions (e.g., old cat and young tiger). VLMs have a flexible text encoder that can represent arbitrary classes as natural language prompts but they often underperform task-specific architectures on the compositional zero-shot benchmark datasets. CSP treats the attributes and objects that define classes as learnable tokens of vocabulary. During training, the vocabulary is tuned to recognize classes that compose tokens in multiple ways (e.g., old cat and white cat). At test time, we recompose the learned attribute-object vocabulary in new combinations to recognize novel classes. We show that CSP outperforms the CLIP on benchmark datasets by an average of 10.9 percentage points on AUC. CSP also outperforms CoOp, a soft prompting method that fine-tunes the prefix context tokens, by an average of 5.8 percentage points on AUC. We perform additional experiments to show that CSP improves generalization to higher-order attribute-attribute-object compositions (e.g., old white cat) and combinations of pretrained attributes and fine-tuned objects. The code is available at https://github.com/BatsResearch/csp.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SQA3D: Situated Question Answering in 3D Scenes",
        "paper_url": "https://openreview.net/pdf?id=IDJx97BC38",
        "paper_authors": [
            "Xiaojian Ma",
            "Silong Yong",
            "Zilong Zheng",
            "Qing Li",
            "Yitao Liang",
            "Song-Chun Zhu",
            "Siyuan Huang"
        ],
        "paper_abstract": "We propose a new task to benchmark scene understanding of embodied agents: Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g., 3D scan), SQA3D requires the tested agent to first understand its situation (position, orientation, etc.) in the 3D scene as described by text, then reason about its surrounding environment and answer a question under that situation. Based upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k unique situations, along with 20.4k descriptions and 33.4k diverse reasoning questions for these situations. These questions examine a wide spectrum of reasoning capabilities for an intelligent agent, ranging from spatial relation comprehension to commonsense understanding, navigation, and multi-hop reasoning. SQA3D imposes a significant challenge to current multi-modal especially 3D reasoning models. We evaluate various state-of-the-art approaches and find that the best one only achieves an overall score of 47.20%, while amateur human participants can reach 90.06%. We believe SQA3D could facilitate future embodied AI research with stronger situation understanding and reasoning capability.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Empowering Networks With Scale and Rotation Equivariance Using A Similarity Convolution",
        "paper_url": "https://openreview.net/pdf?id=NJENsJ37sQ",
        "paper_authors": [
            "Zikai Sun",
            "Thierry Blu"
        ],
        "paper_abstract": "The translational equivariant nature of Convolutional Neural Networks (CNNs) is a reason for its great success in computer vision. However, networks do not enjoy more general equivariance properties such as rotation or scaling, ultimately limiting their generalization performance. To address this limitation, we devise a method that endows CNNs with simultaneous equivariance with respect to translation, rotation, and scaling.  Our approach defines a convolution-like operation and ensures equivariance based on our proposed scalable Fourier-Argand representation. The method maintains similar efficiency as a traditional network and hardly introduces any additional learnable parameters, since it does not face the computational issue that often occurs in group-convolution operators. We validate the efficacy of our approach in the image classification task, demonstrating its robustness and the generalization ability to both scaled and rotated inputs.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust and Controllable Object-Centric Learning through Energy-based Models",
        "paper_url": "https://openreview.net/pdf?id=wcNtbEtcGIC",
        "paper_authors": [
            "Ruixiang ZHANG",
            "Tong Che",
            "Boris Ivanovic",
            "Renhao Wang",
            "Marco Pavone",
            "Yoshua Bengio",
            "Liam Paull"
        ],
        "paper_abstract": "Humans are remarkably good at understanding and reasoning about complex visual scenes. The capability of decomposing low-level observations into discrete objects allows us to build a grounded abstract representation and identify the compositional structure of the world. Thus it is a crucial step for machine learning models to be capable of inferring objects and their properties from visual scene without explicit supervision. However, existing works on object-centric representation learning are either relying on tailor-made neural network modules or assuming sophisticated models of underlying generative and inference processes. In this work, we present EGO, a conceptually simple and general approach to learning object-centric representation through energy-based model. By forming a permutation-invariant energy function using vanilla attention blocks that are readily available in Transformers, we can infer object-centric latent variables via gradient-based MCMC methods where permutation equivariance is automatically guaranteed. We show that EGO can be easily integrated into existing architectures, and can effectively extract high-quality object-centric representations, leading to better segmentation accuracy and competitive downstream task performance. We empirically evaluate the robustness of the learned representation from EGO against distribution shift. Finally, we demonstrate the effectiveness of EGO in systematic compositional generalization, by recomposing learned energy functions for novel scene generation and manipulation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Topology-aware Robust Optimization for Out-of-Distribution Generalization",
        "paper_url": "https://openreview.net/pdf?id=ylMq8MBnAp",
        "paper_authors": [
            "Fengchun Qiao",
            "Xi Peng"
        ],
        "paper_abstract": "Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications. \nExisting methods suffer from overly pessimistic modeling with low generalization confidence. As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of distributions is crucial in developing strong OOD resilience. To this end, we propose topology-aware robust optimization (TRO) that seamlessly integrates distributional topology in a principled optimization framework. More specifically, TRO solves two optimization objectives: (1) Topology Learning which explores data manifold to uncover the distributional topology; (2) Learning on Topology which exploits the topology to constrain robust optimization for tightly-bounded generalization risks. We theoretically demonstrate the effectiveness of our approach, and empirically show that it significantly outperforms the state of the arts in a wide range of tasks including classification, regression, and semantic segmentation. Moreover, we empirically find the data-driven distributional topology is consistent with domain knowledge, enhancing the explainability of our approach. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers",
        "paper_url": "https://openreview.net/pdf?id=mfIX4QpsARJ",
        "paper_authors": [
            "Steeven JANNY",
            "Aur\u00e9lien B\u00e9n\u00e9teau",
            "Madiha Nadri",
            "Julie Digne",
            "Nicolas THOME",
            "Christian Wolf"
        ],
        "paper_abstract": "Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural networks (GNN) and variants trained and evaluated on datasets of static objects in static scenes with fixed geometry. We attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE: a large-scale dataset of \u223c1.1 million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving flow source interacting with nonlinear scene structure of varying geometries, with 600 different scenes of three different types in total. To perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh transformer. It leverages node clustering, graph pooling and global attention to learn long-range dependencies between spatially distant data points without needing a large number of iterations, as existing GNN methods do. We show that our transformer outperforms state-of-the-art performance on, both, existing synthetic and real datasets and on EAGLE. Finally, we highlight that our approach learns to attend to airflow, integrating complex information in a single iteration.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Limitless Stability for Graph Convolutional Networks ",
        "paper_url": "https://openreview.net/pdf?id=XqcQhVUr2h0",
        "paper_authors": [
            "Christian Koke"
        ],
        "paper_abstract": "This work establishes rigorous, novel and widely applicable stability guarantees and transferability bounds for general graph convolutional networks  -- without reference to any underlying limit object or statistical distribution. Crucially, utilized graph-shift operators are not necessarily assumed to be normal, allowing for the treatment of networks on both directed- and undirected graphs within the developed framework. In the undirected setting, stability to node-level perturbations is related to an 'adequate spectral covering' property of the filters in each layer. Stability to edge-level perturbations is discussed and related to properties of the utilized filters such as their Lipschitz constants. Results on stability to  vertex-set non-preserving perturbations are obtained by utilizing recently developed mathematical-physics based tools. As an exemplifying application of the developed theory, it is showcased that\ngeneral graph convolutional networks utilizing the un-normalized graph Laplacian as graph-shift-operator  can be rendered stable to collapsing strong edges in the underlying graph if filters are mandated to be constant at infinity. These theoretical results are supported by corresponding numerical investigations showcasing the response of filters and networks to such perturbations. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "De Novo Molecular Generation via Connection-aware Motif Mining",
        "paper_url": "https://openreview.net/pdf?id=Q_Jexl8-qDi",
        "paper_authors": [
            "Zijie Geng",
            "Shufang Xie",
            "Yingce Xia",
            "Lijun Wu",
            "Tao Qin",
            "Jie Wang",
            "Yongdong Zhang",
            "Feng Wu",
            "Tie-Yan Liu"
        ],
        "paper_abstract": "De novo molecular generation is an essential task for science discovery. Recently, fragment-based deep generative models have attracted much research attention due to their flexibility in generating novel molecules based on existing molecule fragments. However, the motif vocabulary, i.e., the collection of frequent fragments, is usually built upon heuristic rules, which brings difficulties to capturing common substructures from large amounts of molecules. In this work, we propose MiCaM to generate molecules based on mined connection-aware motifs. Specifically, it leverages a data-driven algorithm to automatically discover motifs from a molecule library by iteratively merging subgraphs based on their frequency. The obtained motif vocabulary consists of not only molecular motifs (i.e., the frequent fragments), but also their connection information, indicating how the motifs are connected with each other. Based on the mined connection-aware motifs, MiCaM builds a connection-aware generator, which simultaneously picks up motifs and determines how they are connected. We test our method on distribution-learning benchmarks (i.e., generating novel molecules to resemble the distribution of a given training set) and goal-directed benchmarks (i.e., generating molecules with target properties), and achieve significant improvements over previous fragment-based baselines. Furthermore, we demonstrate that our method can effectively mine domain-specific motifs for different tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revisiting the Entropy Semiring for Neural Speech Recognition",
        "paper_url": "https://openreview.net/pdf?id=SNgLnzFQeiD",
        "paper_authors": [
            "Oscar Chang",
            "Dongseong Hwang",
            "Olivier Siohan"
        ],
        "paper_abstract": "In streaming settings, speech recognition models have to map sub-sequences of speech to text before the full audio stream becomes available. However, since alignment information between speech and text is rarely available during training, models need to learn it in a completely self-supervised way. In practice, the exponential number of possible alignments makes this extremely challenging, with models often learning peaky or sub-optimal alignments. Prima facie, the exponential nature of the alignment space makes it difficult to even quantify the uncertainty of a model's alignment distribution. Fortunately, it has been known for decades that the entropy of a probabilistic finite state transducer can be computed in time linear to the size of the transducer via a dynamic programming reduction based on semirings. In this work, we revisit the entropy semiring for neural speech recognition models, and show how alignment entropy can be used to supervise models through regularization or distillation. We also contribute an open-source implementation of CTC and RNN-T in the semiring framework that includes numerically stable and highly parallel variants of the entropy semiring. Empirically, we observe that the addition of alignment distillation improves the accuracy and latency of an already well-optimized teacher-student distillation model, achieving state-of-the-art performance on the Librispeech dataset in the streaming scenario.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking skip connection model as a learnable Markov chain",
        "paper_url": "https://openreview.net/pdf?id=yQdBtFfleh6",
        "paper_authors": [
            "Dengsheng Chen",
            "Jie Hu",
            "Wenwen Qiang",
            "Xiaoming Wei",
            "Enhua Wu"
        ],
        "paper_abstract": "Over the past few years afterward the birth of ResNet, skip connection has become the defacto standard for the design of modern architectures due to its widespread adoption, easy optimization, and proven performance.\nPrior work has explained the effectiveness of the skip connection mechanism from different perspectives.\nIn this work, we deep dive into the model's behaviors with skip connections which can be formulated as a learnable Markov chain.\nAn efficient Markov chain is preferred as it always maps the input data to the target domain in a better way.\nHowever, while a model is explained as a Markov chain, it is not guaranteed to be optimized following an efficient Markov chain by existing SGD-based optimizers prone to getting trapped in local optimal points.\nIn order to move towards a more efficient Markov chain, we propose a simple routine of penal connection to make any residual-like model become a learnable Markov chain.\nAside from that, the penal connection can also be viewed as a particular model regularization and can be easily implemented with one line of code in the most popular deep learning frameworks. \nThe encouraging experimental results in multi-modal translation and image recognition empirically confirm our conjecture of the learnable Markov chain view and demonstrate the superiority of the proposed penal connection.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Measuring axiomatic soundness of counterfactual image models",
        "paper_url": "https://openreview.net/pdf?id=lZOUQQvwI3q",
        "paper_authors": [
            "Miguel Monteiro",
            "Fabio De Sousa Ribeiro",
            "Nick Pawlowski",
            "Daniel C. Castro",
            "Ben Glocker"
        ],
        "paper_abstract": "We present a general framework for evaluating image counterfactuals. The power and flexibility of deep generative models make them valuable tools for learning mechanisms in structural causal models. However, their flexibility makes counterfactual identifiability impossible in the general case.\nMotivated by these issues, we revisit Pearl's axiomatic definition of counterfactuals to determine the necessary constraints of any counterfactual inference model: composition, reversibility, and effectiveness. We frame counterfactuals as functions of an input variable, its parents, and counterfactual parents and use the axiomatic constraints to restrict the set of functions that could represent the counterfactual, thus deriving distance metrics between the approximate and ideal functions. We demonstrate how these metrics can be used to compare and choose between different approximate counterfactual inference models and to provide insight into a model's shortcomings and trade-offs.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alternating Differentiation for Optimization Layers",
        "paper_url": "https://openreview.net/pdf?id=KKBMz-EL4tD",
        "paper_authors": [
            "Haixiang Sun",
            "Ye Shi",
            "Jingya Wang",
            "Hoang Duong Tuan",
            "H. Vincent Poor",
            "Dacheng Tao"
        ],
        "paper_abstract": "The idea of embedding optimization problems into deep neural networks as optimization layers to encode constraints and inductive priors has taken hold in recent years. Most existing methods focus on implicitly differentiating Karush\u2013Kuhn\u2013Tucker (KKT) conditions in a way that requires expensive computations on the Jacobian matrix, which can be slow and memory-intensive. In this paper, we developed a new framework, named Alternating Differentiation (Alt-Diff), that differentiates optimization problems (here, specifically in the form of convex optimization problems with polyhedral constraints) in a fast and recursive way. Alt-Diff decouples the differentiation procedure into a primal update and a dual update in an alternating way. Accordingly, Alt-Diff substantially decreases the dimensions of the Jacobian matrix especially for optimization with large-scale constraints and thus increases the computational speed of implicit differentiation. We show that the gradients obtained by Alt-Diff are consistent with those obtained by differentiating KKT conditions. In addition, we propose to truncate Alt-Diff to further accelerate the computational speed. Under some standard assumptions, we show that the truncation error of gradients is upper bounded by the same order of variables' estimation error. Therefore, Alt-Diff can be truncated to further increase computational speed without sacrificing much accuracy. A series of comprehensive experiments validate the superiority of Alt-Diff. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Out-of-distribution Detection with Implicit Outlier Transformation",
        "paper_url": "https://openreview.net/pdf?id=hdghx6wbGuD",
        "paper_authors": [
            "Qizhou Wang",
            "Junjie Ye",
            "Feng Liu",
            "Quanyu Dai",
            "Marcus Kalander",
            "Tongliang Liu",
            "Jianye HAO",
            "Bo Han"
        ],
        "paper_abstract": "Outlier exposure (OE) is powerful in out-of-distribution (OOD) detection, enhancing detection capability via model fine-tuning with surrogate OOD data. However, surrogate data typically deviate from test OOD data. Thus, the performance of OE when facing unseen OOD data, can be weaken. To address this issue, we propose a novel OE-based approach that makes the model perform well for unseen OOD situations, even for unseen OOD cases. It leads to a min-max learning scheme---searching to synthesize OOD data that leads to worst judgments and learning from such OOD data for the uniform performance in OOD detection. In our realization, these worst OOD data are synthesized by transforming original surrogate ones, where the associated transform functions are learned implicitly based on our novel insight that model perturbation leads to data transformation. Our methodology offers an efficient way of synthesizing OOD data, which can further benefit the detection model, besides the surrogate OOD data. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extracting Robust Models with Uncertain Examples",
        "paper_url": "https://openreview.net/pdf?id=cMAjKYftNwx",
        "paper_authors": [
            "Guanlin Li",
            "Guowen Xu",
            "Shangwei Guo",
            "Han Qiu",
            "Jiwei Li",
            "Tianwei Zhang"
        ],
        "paper_abstract": "Model extraction attacks are proven to be a severe privacy threat to Machine Learning as a Service (MLaaS). A variety of techniques have been designed to steal a remote machine learning model with high accuracy and fidelity. However, how to extract a robust model with similar resilience against adversarial attacks is never investigated. This paper presents the first study toward this goal. We first analyze those existing extraction solutions either fail to maintain the model accuracy or model robustness or lead to the robust overfitting issue. Then we propose Boundary Entropy Searching Thief (BEST), a novel model extraction attack to achieve both accuracy and robustness extraction under restricted attack budgets. BEST generates a new kind of uncertain examples for querying and reconstructing the victim model. These samples have uniform confidence scores across different classes, which can perfectly balance the trade-off between model accuracy and robustness. Extensive experiments demonstrate that BEST outperforms existing attack methods over different datasets and model architectures under limited data. It can also effectively invalidate state-of-the-art extraction defenses.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Groundplans: Persistent Neural Scene Representations from a Single Image",
        "paper_url": "https://openreview.net/pdf?id=Pza24zf9FpS",
        "paper_authors": [
            "Prafull Sharma",
            "Ayush Tewari",
            "Yilun Du",
            "Sergey Zakharov",
            "Rares Andrei Ambrus",
            "Adrien Gaidon",
            "William T. Freeman",
            "Fredo Durand",
            "Joshua B. Tenenbaum",
            "Vincent Sitzmann"
        ],
        "paper_abstract": "We present a method to map 2D image observations of a scene to a persistent 3D scene representation, enabling novel view synthesis and disentangled representation of the movable and immovable components of the scene. Motivated by the bird\u2019s-eye-view (BEV) representation commonly used in vision and robotics, we propose conditional neural groundplans, ground-aligned 2D feature grids, as persistent and memory-efficient scene representations. Our method is trained self-supervised from unlabeled multi-view observations using differentiable rendering, and learns to complete geometry and appearance of occluded regions. In addition, we show that we can leverage multi-view videos at training time to learn to separately reconstruct static and movable components of the scene from a single image at test time. The ability to separately reconstruct movable objects enables a variety of downstream tasks using simple heuristics, such as extraction of object-centric 3D representations, novel view synthesis, instance-level segmentation, 3D bounding box prediction, and scene editing. This highlights the value of neural groundplans as a backbone for efficient 3D scene understanding models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "E-CRF: Embedded Conditional Random Field for Boundary-caused Class Weights Confusion in Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=g1GnnCI1OrC",
        "paper_authors": [
            "Jie Zhu",
            "Huabin Huang",
            "Banghuai Li",
            "Leye Wang"
        ],
        "paper_abstract": "Modern semantic segmentation methods devote much effect to adjusting image feature representations to improve the segmentation performance in various ways, such as architecture design, attention mechnism, etc. However, almost all those methods neglect the particularity of class weights (in the classification layer) in segmentation models. In this paper, we notice that the class weights of categories that tend to share many adjacent boundary pixels lack discrimination, thereby limiting the performance. We call this issue Boundary-caused Class Weights Confusion (BCWC). We try to focus on this problem and propose a novel method named Embedded Conditional Random Field (E-CRF) to alleviate it. E-CRF innovatively fuses the CRF into the CNN network as an organic whole for more effective end-to-end optimization. The reasons are two folds. It utilizes CRF to guide the message passing between pixels in high-level features to purify the feature representation of boundary pixels, with the help of inner pixels belonging to the same object. More importantly, it enables optimizing class weights from both scale and direction during backpropagation. We make detailed theoretical analysis to prove it. Besides, superpixel is integrated into E-CRF and served as an auxiliary to exploit the local object prior for more reliable message passing. Finally, our proposed method yields impressive results on ADE20K, Cityscapes, and Pascal Context datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Networks",
        "paper_url": "https://openreview.net/pdf?id=9x3CO0ZU9LR",
        "paper_authors": [
            "Xiang Ji",
            "Minshuo Chen",
            "Mengdi Wang",
            "Tuo Zhao"
        ],
        "paper_abstract": "We consider the off-policy evaluation problem of reinforcement learning using deep convolutional neural networks. We analyze the deep fitted Q-evaluation method for estimating the expected cumulative reward of a target policy, when the data are generated from an unknown behavior policy. We show that, by choosing network size appropriately, one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality. Specifically, we establish a sharp error bound for fitted Q-evaluation, which depends on the intrinsic dimension of the state-action space, the smoothness of Bellman operator, and a function class-restricted $\\chi^2$-divergence. It is noteworthy that the restricted $\\chi^2$-divergence measures the behavior and target policies' {\\it mismatch in the function space}, which can be small even if the two policies are not close to each other in their tabular forms. We also develop a novel approximation result for convolutional neural networks in Q-function estimation. Numerical experiments are provided to support our theoretical analysis.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Differentially Private and Fair Learning",
        "paper_url": "https://openreview.net/pdf?id=3nM5uhPlfv6",
        "paper_authors": [
            "Andrew Lowy",
            "Devansh Gupta",
            "Meisam Razaviyayn"
        ],
        "paper_abstract": "Machine learning models are increasingly used in high-stakes decision-making systems. In such applications, a major concern is that these models sometimes discriminate against certain demographic groups such as individuals with certain race, gender, or age. Another major concern in these applications is the violation of the privacy of users. While fair learning algorithms have been developed to mitigate discrimination issues, these algorithms can still leak sensitive information, such as individuals\u2019 health or financial records. Utilizing the notion of differential privacy (DP), prior works aimed at developing learning algorithms that are both private and fair. However, existing algorithms for DP fair learning are either not guaranteed to converge or require full batch of data in each iteration of the algorithm to converge. In this paper, we provide the first stochastic differentially private algorithm for fair learning that is guaranteed to converge. Here, the term \u201cstochastic\" refers to the fact that our proposed algorithm converges even when minibatches of data are used at each iteration (i.e. stochastic optimization). Our framework is flexible enough to permit different fairness notions, including demographic parity and equalized odds. In addition, our algorithm can be applied to non-binary classification tasks with multiple (non-binary) sensitive attributes. As a byproduct of our convergence analysis, we provide the first utility guarantee for a DP algorithm for solving nonconvex-strongly concave min-max problems. Our numerical experiments show that the proposed algorithm consistently offers significant performance gains over the state-of-the-art baselines, and can be applied to larger scale problems with non-binary target/sensitive attributes.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On The Inadequacy of Optimizing Alignment and Uniformity in Contrastive Learning of Sentence Representations",
        "paper_url": "https://openreview.net/pdf?id=MxvHVNukama",
        "paper_authors": [
            "Zhijie Nie",
            "Richong Zhang",
            "Yongyi Mao"
        ],
        "paper_abstract": "Contrastive learning is widely used in areas such as visual representation learning (VRL) and sentence representation learning (SRL). Considering the differences between VRL and SRL in terms of negative sample size and evaluation focus, we believe that the solid findings obtained in VRL may not be entirely carried over to SRL. In this work, we consider the suitability of the decoupled form of contrastive loss, i.e., alignment and uniformity, in SRL. We find a performance gap between sentence representations obtained by jointly optimizing alignment and uniformity on the STS task and those obtained using contrastive loss. Further, we find that the joint optimization of alignment and uniformity during training is prone to overfitting, which does not occur on the contrastive loss. Analyzing them based on the variation of the gradient norms, we find that there is a property of ``gradient dissipation'' in contrastive loss and believe that it is the key to preventing overfitting. We simulate similar \"gradient dissipation\" of contrastive loss on four optimization objectives of two forms, and achieve the same or even better performance than contrastive loss on the STS tasks, confirming our hypothesis.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Volumetric Optimal Transportation by Fast Fourier Transform",
        "paper_url": "https://openreview.net/pdf?id=EVrz7UM-ZDm",
        "paper_authors": [
            "Na Lei",
            "DONGSHENG An",
            "Min Zhang",
            "Xiaoyin Xu",
            "David Gu"
        ],
        "paper_abstract": "The optimal transportation map finds the most economical way to transport one probability measure to another, and it has been applied in a broad range of applications in machine learning and computer vision. By the Brenier theory, computing the optimal transport map is equivalent to solving a Monge-Amp\\`ere equation, which is highly non-linear. Therefore, the computation of optimal transportation maps is intrinsically challenging.\n\nIn this work, we propose a novel and powerful method, the FFT-OT (fast Fourier transform-optimal transport), to compute the 3-dimensional OT problems. The method is based on several key ideas: first, the Monge-Amp\\`ere equation is linearized to a sequence of linear elliptic PDEs with spacial and temporal variant coefficients; second, the obliqueness property of optimal transportation maps is reformulated as a Neumann boundary condition; and third, the variant coefficient elliptic PDEs are approximated by constant coefficient elliptic PDEs and solved by FFT on GPUs. We also prove that the algorithm converges linearly, namely the approximation error decreases exponentially fast. Experimental results show that the FFT-OT algorithm is more than a hundred times faster than the conventional methods based on the convex geometry. Furthermore, the method can be directly applied for sampling from complex 3D density functions in machine learning and magnifying the volumetric data in medical imaging. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GFlowNets and variational inference",
        "paper_url": "https://openreview.net/pdf?id=uKiE0VIluA-",
        "paper_authors": [
            "Nikolay Malkin",
            "Salem Lahlou",
            "Tristan Deleu",
            "Xu Ji",
            "Edward J Hu",
            "Katie E Everett",
            "Dinghuai Zhang",
            "Yoshua Bengio"
        ],
        "paper_abstract": "This paper builds bridges between two families of probabilistic algorithms: (hierarchical) variational inference (VI), which is typically used to model distributions over continuous spaces, and generative flow networks (GFlowNets), which have been used for distributions over discrete structures such as graphs. We demonstrate that, in certain cases, VI algorithms are equivalent to special cases of GFlowNets in the sense of equality of expected gradients of their learning objectives. We then point out the differences between the two families and show how these differences emerge experimentally. Notably, GFlowNets, which borrow ideas from reinforcement learning, are more amenable than VI to off-policy training without the cost of high gradient variance induced by importance sampling. We argue that this property of GFlowNets can provide advantages for capturing diversity in multimodal target distributions. Code: https://github.com/GFNOrg/GFN_vs_HVI.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion",
        "paper_url": "https://openreview.net/pdf?id=zlwBI2gQL3K",
        "paper_authors": [
            "Han Wu",
            "Jie Yin",
            "Bala Rajaratnam",
            "Jianyuan Guo"
        ],
        "paper_abstract": "Knowledge graphs (KGs) are powerful in terms of their inference abilities, but are also notorious for their incompleteness and long-tail distribution of relations. To address these challenges and expand the coverage of KGs, few-shot KG completion aims to make predictions for triplets involving novel relations when only a few training triplets are provided as reference. Previous methods have focused on designing local neighbor aggregators to learn entity-level information and/or imposing sequential dependency assumption at the triplet level to learn meta relation information. However, pairwise triplet-level interactions and context-level relational information have been largely overlooked for learning meta representations of few-shot relations. In this paper, we propose a hierarchical relational learning method (HiRe) for few-shot KG completion. By jointly capturing three levels of relational information (entity-level, triplet-level and context-level), HiRe can effectively learn and refine the meta representation of few-shot relations, and consequently generalize well to new unseen relations. Extensive experiments on two benchmark datasets validate the superiority of HiRe over state-of-the-art methods. The code of HiRe can be found in supplementary material and will be released after acceptance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Function-Consistent Feature Distillation",
        "paper_url": "https://openreview.net/pdf?id=pgHNOcxEdRI",
        "paper_authors": [
            "Dongyang Liu",
            "Meina Kan",
            "Shiguang Shan",
            "Xilin CHEN"
        ],
        "paper_abstract": "Feature distillation makes the student mimic the intermediate features of the teacher. Nearly all existing feature-distillation methods use L2 distance or its slight variants as the distance metric between teacher and student features. However, while L2 distance is isotropic w.r.t. all dimensions, the neural network\u2019s operation on different dimensions is usually anisotropic, i.e., perturbations with the same 2-norm but in different dimensions of intermediate features lead to changes in the final output with largely different magnitude. Considering this, we argue that the similarity between teacher and student features should \\textit{not} be measured merely based on their appearance (i.e., L2 distance), but should, more importantly, be measured by their difference in function, namely how later layers of the network will read, decode, and process them. Therefore, we propose Function-Consistent Feature Distillation (FCFD), which explicitly optimizes the functional similarity between teacher and student features. The core idea of FCFD is to make teacher and student features not only numerically similar, but more importantly produce similar outputs when fed to the later part of the same network. With FCFD, the student mimics the teacher more faithfully and learns more from the teacher. Extensive experiments on image classification and object detection demonstrate the superiority of FCFD to existing methods. Furthermore, we can combine FCFD with many existing methods to obtain even higher accuracy. Our codes are available at https://github.com/LiuDongyang6/FCFD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition",
        "paper_url": "https://openreview.net/pdf?id=xLr0I_xYGAs",
        "paper_authors": [
            "Jun CEN",
            "Di Luan",
            "Shiwei Zhang",
            "Yixuan Pei",
            "Yingya Zhang",
            "Deli Zhao",
            "Shaojie Shen",
            "Qifeng Chen"
        ],
        "paper_abstract": "Open-set Recognition (OSR) aims to identify test samples whose classes are not seen during the training process. Recently, Unified Open-set Recognition (UOSR) has been proposed to reject not only unknown samples but also known but wrongly classified samples, which tends to be more practical in real-world applications. In this paper, we deeply analyze the UOSR task under different training and evaluation settings to shed light on this promising research direction. For this purpose, we first evaluate the UOSR performance of several OSR methods and show a significant finding that the uncertainty distribution of almost all these methods is actually closer to the expectation of UOSR than OSR. We show that the reason lies in the known but wrongly classified samples, as their uncertainty distribution is extremely close to unknown samples rather than known and correctly classified samples. Second, we analyze how the two training settings of OSR (i.e., pre-training and outlier exposure) influence the UOSR. We find although they are both beneficial for distinguishing known and correctly classified samples from unknown samples, pre-training is also helpful for identifying known but wrongly classified samples while outlier exposure is not. In addition to different training settings, we also formulate a new evaluation setting for UOSR which is called few-shot UOSR, where only one or five samples per unknown class are available during evaluation to help identify unknown samples. We propose FS-KNNS for the few-shot UOSR to achieve state-of-the-art performance under all settings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MCAL: Minimum Cost Human-Machine Active Labeling",
        "paper_url": "https://openreview.net/pdf?id=1FxRPKrH8bw",
        "paper_authors": [
            "Hang Qiu",
            "Krishna Chintalapudi",
            "Ramesh Govindan"
        ],
        "paper_abstract": "Today, ground-truth generation uses data sets annotated by cloud-based annotation services. These services rely on human annotation, which can be prohibitively expensive. In this paper, we consider the problem of hybrid human-machine labeling, which trains a classifier to accurately auto-label part of the data set. However, training the classifier can be expensive too. We propose an iterative approach that minimizes total overall cost by, at each step, jointly determining which samples to label using humans and which to label using the trained classifier. We validate our approach on well known public data sets such as Fashion-MNIST, CIFAR-10, CIFAR-100, and ImageNet. In some cases, our approach has 6\u00d7 lower overall cost relative to human labeling the entire data set, and is always cheaper than the cheapest competing strategy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learnable Topological Features For Phylogenetic Inference via Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=hVVUY7p64WL",
        "paper_authors": [
            "Cheng Zhang"
        ],
        "paper_abstract": "Structural information of phylogenetic tree topologies plays an important role in phylogenetic inference. However, finding appropriate topological structures for specific phylogenetic inference tasks often requires significant design effort and domain expertise. In this paper, we propose a novel structural representation method for phylogenetic inference based on learnable topological features. By combining the raw node features that minimize the Dirichlet energy with modern graph representation learning techniques, our learnable topological features can provide efficient structural information of phylogenetic trees that automatically adapts to different downstream tasks without requiring domain expertise. We demonstrate the effectiveness and efficiency of our method on a simulated data tree probability estimation task and a benchmark of challenging real data variational Bayesian phylogenetic inference problems.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fairness-aware Contrastive Learning with Partially Annotated Sensitive Attributes",
        "paper_url": "https://openreview.net/pdf?id=woa783QMul",
        "paper_authors": [
            "Fengda Zhang",
            "Kun Kuang",
            "Long Chen",
            "Yuxuan Liu",
            "Chao Wu",
            "Jun Xiao"
        ],
        "paper_abstract": "Learning high-quality representation is important and essential for visual recognition. Unfortunately, traditional representation learning suffers from fairness issues since the model may learn information of sensitive attributes. Recently, a series of studies have been proposed to improve fairness by explicitly decorrelating target labels and sensitive attributes. Most of these methods, however, rely on the assumption that fully annotated labels on target variable and sensitive attributes are available, which is unrealistic due to the expensive annotation cost. In this paper, we investigate a novel and practical problem of Fair Unsupervised Representation Learning with Partially annotated Sensitive labels (FURL-PS). FURL-PS has two key challenges: 1) how to make full use of the samples that are not annotated with sensitive attributes; 2) how to eliminate bias in the dataset without target labels. To address these challenges, we propose a general Fairness-aware Contrastive Learning (FairCL) framework consisting of two stages. Firstly, we generate contrastive sample pairs, which share the same visual information apart from sensitive attributes, for each instance in the original dataset. In this way, we construct a balanced and unbiased dataset. Then, we execute fair contrastive learning by closing the distance between representations of contrastive sample pairs. Besides, we also propose an unsupervised way to balance the utility and fairness of learned representations by feature reweighting. Extensive experimental results illustrate the effectiveness of our method in terms of fairness and utility, even with very limited sensitive attributes and serious data bias.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rotamer Density Estimator is an Unsupervised Learner of the Effect of Mutations on Protein-Protein Interaction",
        "paper_url": "https://openreview.net/pdf?id=_X9Yl1K2mD",
        "paper_authors": [
            "Shitong Luo",
            "Yufeng Su",
            "Zuofan Wu",
            "Chenpeng Su",
            "Jian Peng",
            "Jianzhu Ma"
        ],
        "paper_abstract": "Protein-protein interactions are crucial to many biological processes, and predicting the effect of amino acid mutations on binding is important for protein engineering. While data-driven approaches using deep learning have shown promise, the scarcity of annotated experimental data remains a major challenge. In this work, we propose a new approach that predicts mutational effects on binding using the change in conformational flexibility of the protein-protein interface. Our approach, named Rotamer Density Estimator (RDE), employs a flow-based generative model to estimate the probability distribution of protein side-chain conformations and uses entropy to measure flexibility. RDE is trained solely on protein structures and does not require the supervision of experimental values of changes in binding affinities. Furthermore, the unsupervised representations extracted by RDE can be used for downstream neural network predictions with even greater accuracy. Our method outperforms empirical energy functions and other machine learning-based approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dilated convolution with learnable spacings",
        "paper_url": "https://openreview.net/pdf?id=Q3-1vRh3HOA",
        "paper_authors": [
            "Ismail Khalfaoui Hassani",
            "Thomas Pellegrini",
            "Timoth\u00e9e Masquelier"
        ],
        "paper_abstract": "Recent works indicate that convolutional neural networks (CNN) need large receptive fields (RF) to compete with visual transformers and their attention mechanism. In CNNs, RFs can simply be enlarged by increasing the convolution kernel sizes. Yet the number of trainable parameters, which scales quadratically with the kernel's size in the 2D case, rapidly becomes prohibitive, and the training is notoriously difficult. This paper presents a new method to increase the RF size without increasing the number of parameters. The dilated convolution (DC) has already been proposed for the same purpose. DC can be seen as a convolution with a kernel that contains only a few non-zero elements placed on a regular grid. Here we present a new version of the DC in which the spacings between the non-zero elements, or equivalently their positions, are no longer fixed but learnable via backpropagation thanks to an interpolation technique. We call this method \u201cDilated Convolution with Learnable Spacings\u201d (DCLS) and generalize it to the n-dimensional convolution case. However, our main focus here will be on the 2D case. We first tried our approach on ResNet50: we drop-in replaced the standard convolutions with DCLS ones, which increased the accuracy of ImageNet1k classification at iso-parameters, but at the expense of the throughput. Next, we used the recent ConvNeXt state-of-the-art convolutional architecture and drop-in replaced the depthwise convolutions with DCLS ones. This not only increased the accuracy of ImageNet1k classification but also of typical downstream and robustness tasks, again at iso-parameters but this time with negligible cost on throughput, as ConvNeXt uses separable convolutions. Conversely, classic DC led to poor performance with both ResNet50 and ConvNeXt. The code of the method is based on PyTorch and available at: https://github.com/K-H-Ismail/Dilated-Convolution-with-Learnable-Spacings-PyTorch.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PatchDCT: Patch Refinement for High Quality Instance Segmentation",
        "paper_url": "https://openreview.net/pdf?id=t9Zd7Oi5JPl",
        "paper_authors": [
            "Qinrou Wen",
            "Jirui Yang",
            "Xue Yang",
            "Kewei Liang"
        ],
        "paper_abstract": "High-quality instance segmentation has shown emerging importance in computer vision. Without any refinement, DCT-Mask directly generates high-resolution masks by compressed vectors. To further refine masks obtained by compressed vectors, we propose for the first time a compressed vector based multi-stage refinement framework.  However, the vanilla combination does not bring significant gains, because changes in some elements of the DCT vector will affect the prediction of the entire mask. Thus, we propose a simple and novel method named PatchDCT, which separates the mask decoded from a DCT vector into several patches and refines each patch by the designed classifier and regressor. Specifically, the classifier is used to distinguish mixed patches from all patches, and to correct previously mispredicted foreground and background patches. In contrast, the regressor is used for DCT vector prediction of mixed patches, further refining the segmentation quality at boundary locations. Experiments on COCO show that our method achieves 2.0\\%, 3.2\\%, 4.5\\% AP and 3.4\\%, 5.3\\%, 7.0\\% Boundary AP improvements over Mask-RCNN on COCO, LVIS, and Cityscapes, respectively. It also surpasses DCT-Mask by 0.7\\%, 1.1\\%, 1.3\\% AP and 0.9\\%, 1.7\\%, 4.2\\% Boundary AP on COCO, LVIS and Cityscapes. Besides, the performance of PatchDCT is also competitive with other state-of-the-art methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ChiroDiff: Modelling chirographic data with Diffusion Models",
        "paper_url": "https://openreview.net/pdf?id=1ROAstc9jv",
        "paper_authors": [
            "Ayan Das",
            "Yongxin Yang",
            "Timothy Hospedales",
            "Tao Xiang",
            "Yi-Zhe Song"
        ],
        "paper_abstract": "Generative modelling over continuous-time geometric constructs, a.k.a $chirographic\\ data$ such as handwriting, sketches, drawings etc., have been accomplished through autoregressive distributions. Such strictly-ordered discrete factorization however falls short of capturing key properties of chirographic data -- it fails to build holistic understanding of the temporal concept due to one-way visibility (causality). Consequently, temporal data has been modelled as discrete token sequences of fixed sampling rate instead of capturing the true underlying concept. In this paper, we introduce a powerful model-class namely Denoising\\ Diffusion\\ Probabilistic\\ Models or DDPMs for chirographic data that specifically addresses these flaws. Our model named \"ChiroDiff\", being non-autoregressive, learns to capture holistic concepts and therefore remains resilient to higher temporal sampling rate up to a good extent. Moreover, we show that many important downstream utilities (e.g. conditional sampling, creative mixing) can be flexibly implemented using ChiroDiff. We further show some unique use-cases like stochastic vectorization, de-noising/healing, abstraction are also possible with this model-class. We perform quantitative and qualitative evaluation of our framework on relevant datasets and found it to be better or on par with competing approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time Image Demoir$\\acute{e}$ing on Mobile Devices",
        "paper_url": "https://openreview.net/pdf?id=PmP_sf3JkrH",
        "paper_authors": [
            "Yuxin Zhang",
            "Mingbao Lin",
            "Xunchao Li",
            "Han Liu",
            "Guozhi Wang",
            "Fei Chao",
            "Ren Shuai",
            "Yafei Wen",
            "Xiaoxin Chen",
            "Rongrong Ji"
        ],
        "paper_abstract": "Moir$\\acute{e}$ patterns appear frequently when taking photos of digital screens, drastically degrading the image quality. Despite the advance of CNNs in image demoir$\\acute{e}$ing, existing networks are with heavy design, causing massive computation burden for mobile devices. In this paper, we launch the first study on accelerating demoir$\\acute{e}$ing networks and propose a dynamic demoir$\\acute{e}$ing acceleration method (DDA) towards a real-time deployment on mobile devices. Our stimulus stems from a simple-yet-universal fact that moir${\\'e}$ patterns often unbalancedly distribute across an image. Consequently, excessive computation is wasted upon non-moir$\\acute{e}$ areas. Therefore, we reallocate computation costs in proportion to the complexity of image patches. In order to achieve this aim, we measure the complexity of an image patch by a novel moir$\\acute{e}$ prior that considers both colorfulness and frequency information of moir$\\acute{e}$ patterns. Then, we restore higher-complex image patches using larger networks and the lower-complex ones are assigned with smaller networks to relieve the computation burden. At last, we train all networks in a parameter-shared supernet paradigm to avoid additional parameter burden. Extensive experiments on several benchmarks demonstrate the efficacy of our DDA. In addition, the acceleration evaluated on the VIVO X80 Pro smartphone equipped with the chip of Snapdragon 8 Gen 1 also shows that our method can drastically reduce the inference time, leading to a real-time image demoir$\\acute{e}$ing on mobile devices. Source codes and models are released at https://github.com/zyxxmu/DDA.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot Classification",
        "paper_url": "https://openreview.net/pdf?id=Kn-HA8DFik",
        "paper_authors": [
            "Hao ZHENG",
            "Runqi Wang",
            "Jianzhuang Liu",
            "Asako Kanezaki"
        ],
        "paper_abstract": "The conventional few-shot classification aims at learning a model on a large labeled base dataset and rapidly adapting to a target dataset that is from the same distribution as the base dataset. However, in practice, the base and the target datasets of few-shot classification are usually from different domains, which is the problem of cross-domain few-shot classification. We tackle this problem by making a small proportion of unlabeled images in the target domain accessible in the training stage. In this setup, even though the base data are sufficient and labeled, the large domain shift still makes transferring the knowledge from the base dataset difficult. We meticulously design a cross-level knowledge distillation method, which can strengthen the ability of the model to extract more discriminative features in the target dataset by guiding the network's shallow layers to learn higher-level information. Furthermore, in order to alleviate the overfitting in the evaluation stage, we propose a feature denoising operation which can reduce the feature redundancy and mitigate overfitting. Our approach can surpass the previous state-of-the-art method, Dynamic-Distillation, by 5.44% on 1-shot and 1.37% on 5-shot classification tasks on average in the BSCD-FSL benchmark. The implementation code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/CLDFD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION",
        "paper_url": "https://openreview.net/pdf?id=eGm22rqG93",
        "paper_authors": [
            "Bowen Zhao",
            "Chen Chen",
            "Shu-Tao Xia"
        ],
        "paper_abstract": "Fully test-time adaptation aims at adapting a pre-trained model to the test stream during real-time inference, which is urgently required when the test distribution differs from the training distribution. Several efforts have been devoted to improving adaptation performance. However, we find that two unfavorable defects are concealed in the prevalent adaptation methodologies like test-time batch normalization (BN) and self-learning. First, we reveal that the normalization statistics in test-time BN are completely affected by the currently received test samples, resulting in inaccurate estimates. Second, we show that during test-time adaptation, the parameter update is biased towards some dominant classes. In addition to the extensively studied test stream with independent and class-balanced samples, we further observe that the defects can be exacerbated in more complicated test environments, such as (time) dependent or class-imbalanced data. We observe that previous approaches work well in certain scenarios while show performance degradation in others due to their faults. In this paper, we provide a plug-in solution called DELTA for Degradation-freE fuLly Test-time Adaptation, which consists of two components: (i) Test-time Batch Renormalization (TBR), introduced to improve the estimated normalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to address the class bias within optimization. We investigate various test-time adaptation methods on three commonly used datasets with four scenarios, and a newly introduced real-world dataset. DELTA can help them deal with all scenarios simultaneously, leading to SOTA performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bit-Pruning: A Sparse Multiplication-Less Dot-Product",
        "paper_url": "https://openreview.net/pdf?id=YUDiZcZTI8",
        "paper_authors": [
            "Yusuke Sekikawa",
            "Shingo Yashima"
        ],
        "paper_abstract": "Dot-product is a central building block in neural networks.\nHowever, multiplication ($\\texttt{mult}$) in dot-product consumes intensive energy and space costs that challenge deployment on resource-constrained edge devices.\nIn this study, we realize energy-efficient neural networks by exploiting a $\\texttt{mult}$-less, sparse dot-product. We first reformulate a dot-product between an integer weight and activation into an equivalent operation comprised of additions followed by bit-shifts ($\\texttt{add-shift-add}$).\nIn this formulation, the number of $\\texttt{add}$  operations equals the number of bits of the integer weight in binary format. \nLeveraging this observation, we propose Bit-Pruning, which removes unnecessary bits in each weight value during training to reduce the energy consumption of $\\texttt{add-shift-add}$. Bit-Pruning can be seen as soft Weight-Pruning as it prunes bits, not the whole weight element.\nIn extensive experiments, we demonstrate that sparse $\\texttt{mult}$-less networks trained with Bit-Pruning show a better accuracy-energy trade-off than sparse $\\texttt{mult}$ networks trained with Weight-Pruning. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "kNN-Diffusion: Image Generation via Large-Scale Retrieval",
        "paper_url": "https://openreview.net/pdf?id=x5mtJD2ovc",
        "paper_authors": [
            "Shelly Sheynin",
            "Oron Ashual",
            "Adam Polyak",
            "Uriel Singer",
            "Oran Gafni",
            "Eliya Nachmani",
            "Yaniv Taigman"
        ],
        "paper_abstract": "Recent text-to-image models have achieved impressive results. However, since they require large-scale datasets of text-image pairs, it is impractical to train them on new domains where data is scarce or not labeled.\nIn this work, we propose using large-scale retrieval methods, in particular, efficient k-Nearest-Neighbors (kNN), which offers novel capabilities: (1) training a substantially small and efficient text-to-image diffusion model using only pre-trained multi-modal embeddings, but without an explicit text-image dataset, (2) generating out-of-distribution images by simply swapping the retrieval database at inference time, and (3) performing text-driven local semantic manipulations while preserving object identity. To demonstrate the robustness of our method, we apply our kNN approach on two state-of-the-art diffusion backbones, and show results on several different datasets. As evaluated by human studies and automatic metrics, our method achieves state-of-the-art results compared to existing approaches that train text-to-image generation models using images-only dataset.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": " Decompose to Generalize: Species-Generalized Animal Pose Estimation",
        "paper_url": "https://openreview.net/pdf?id=nQai_B1Zrt",
        "paper_authors": [
            "Guangrui Li",
            "Yifan Sun",
            "Zongxin Yang",
            "Yi Yang"
        ],
        "paper_abstract": "This paper challenges the cross-species generalization problem for animal pose estimation, aiming to learn a pose estimator that can be well generalized to novel species. We find the relation between different joints is important with two-fold impact: 1) on the one hand, some relation is consistent across all the species and may help two joints mutually confirm each other, e.g., the eyes help confirm the nose and vice versa because they are close in all species. 2) on the other hand, some relation is inconsistent for different species due to the species variation and may bring severe distraction rather than benefit. With these two insights, we propose a Decompose-to-Generalize (D-Gen) pose estimation method to break the inconsistent relations while preserving the consistent ones. Specifically, D-Gen first decomposes the body joints into several joint concepts so that each concept contains multiple closely-related joints. Given these joint concepts, D-Gen 1) promotes the interaction between intra-concept joints to enhance their reliable mutual confirmation, and 2) suppresses the interaction between inter-concept joints to prohibit their mutual distraction.  Importantly, we explore various decomposition approaches, i.e., heuristic, geometric and attention-based approaches. Experimental results show that all these decomposition manners yield reasonable joint concepts and substantially improve cross-species generalization (and the attention-based approach is the best). ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "IDEAL: Query-Efficient Data-Free Learning from Black-Box Models",
        "paper_url": "https://openreview.net/pdf?id=ConT6H7MWL",
        "paper_authors": [
            "Jie Zhang",
            "Chen Chen",
            "Lingjuan Lyu"
        ],
        "paper_abstract": "Knowledge Distillation (KD) is a typical method for training a lightweight student model with the help of a well-trained teacher model. \nHowever, most KD methods require access to either the teacher's training data or model parameter, which is unrealistic. To tackle this problem, recent works study KD under data-free and black-box settings. Nevertheless, these works require a large number of queries to the teacher model, which incurs significant monetary and computational costs. To address these problems, we propose a novel method called \\emph{query-effIcient Data-free lEarning from blAck-box modeLs} (IDEAL), which aims to query-efficiently learn from black-box model APIs to train a good student without any real data.   In detail, IDEAL trains the student model in two stages: data generation and model distillation. Note that IDEAL does not require any query in the data generation stage and queries the teacher only once for each sample in the distillation stage. Extensive experiments on various real-world datasets show the effectiveness of the proposed IDEAL. For instance, IDEAL can improve the performance of the best baseline method DFME by 5.83\\% on CIFAR10 dataset with only $0.02\\times$ the query budget of DFME.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trainability Preserving Neural Pruning",
        "paper_url": "https://openreview.net/pdf?id=AZFvpnnewr",
        "paper_authors": [
            "Huan Wang",
            "Yun Fu"
        ],
        "paper_abstract": "Many recent works have shown trainability plays a central role in neural network pruning -- unattended broken trainability can lead to severe under-performance and unintentionally amplify the effect of retraining learning rate, resulting in biased (or even misinterpreted) benchmark results. This paper introduces trainability preserving pruning (TPP), a scalable method to preserve network trainability against pruning, aiming for improved pruning performance and being more robust to retraining hyper-parameters (e.g., learning rate). Specifically, we propose to penalize the gram matrix of convolutional filters to decorrelate the pruned filters from the retained filters. In addition to the convolutional layers, per the spirit of preserving the trainability of the whole network, we also propose to regularize the batch normalization parameters (scale and bias). Empirical studies on linear MLP networks show that TPP can perform on par with the oracle trainability recovery scheme. On nonlinear ConvNets (ResNet56/VGG19) on CIFAR10/100, TPP outperforms the other counterpart approaches by an obvious margin. Moreover, results on ImageNet-1K with ResNets suggest that TPP consistently performs more favorably against other top-performing structured pruning approaches. Code: https://github.com/MingSun-Tse/TPP.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Diagnosing and Rectifying Vision Models using Language",
        "paper_url": "https://openreview.net/pdf?id=D-zfUK7BR6c",
        "paper_authors": [
            "Yuhui Zhang",
            "Jeff Z. HaoChen",
            "Shih-Cheng Huang",
            "Kuan-Chieh Wang",
            "James Zou",
            "Serena Yeung"
        ],
        "paper_abstract": "Recent multi-modal contrastive learning models have demonstrated the ability to learn an embedding space suitable for building strong vision classifiers, by leveraging the rich information in large-scale image-caption datasets. Our work highlights a distinct advantage of this multi-modal embedding space: the ability to diagnose vision classifiers through natural language. The traditional process of diagnosing model behaviors in deployment settings involves labor-intensive data acquisition and annotation. Our proposed method can discover high-error data slices, identify influential attributes and further rectify undesirable model behaviors, without requiring any visual data. Through a combination of theoretical explanation and empirical verification, we present conditions under which classifiers trained on embeddings from one modality can be equivalently applied to embeddings from another modality. On a range of image datasets with known error slices, we demonstrate that our method can effectively identify the error slices and influential attributes, and can further use language to rectify failure modes of the classifier.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Harnessing Out-Of-Distribution Examples via Augmenting Content and Style",
        "paper_url": "https://openreview.net/pdf?id=boNyg20-JDm",
        "paper_authors": [
            "Zhuo Huang",
            "Xiaobo Xia",
            "Li Shen",
            "Bo Han",
            "Mingming Gong",
            "Chen Gong",
            "Tongliang Liu"
        ],
        "paper_abstract": "Machine learning models are vulnerable to Out-Of-Distribution (OOD) examples, such a problem has drawn much attention. However, current methods lack a full understanding of different types of OOD data: there are benign OOD data that can be properly adapted to enhance the learning performance, while other malign OOD data would severely degenerate the classification result. To Harness OOD data, this paper proposes HOOD method that can leverage the content and style from each image instance to identify benign and malign OOD data. Particularly, we design a variational inference framework to causally disentangle content and style features by constructing a structural causal model. Subsequently, we augment the content and style through an intervention process to produce malign and benign OOD data, respectively. The benign OOD data contain novel styles but hold our interested contents, and they can be leveraged to help train a style-invariant model. In contrast, the malign OOD data inherit unknown contents but carry familiar styles, by detecting them can improve model robustness against deceiving anomalies. Thanks to the proposed novel disentanglement and data augmentation techniques, HOOD can effectively deal with OOD examples in unknown and open environments, whose effectiveness is empirically validated in three typical OOD applications including OOD detection, open-set semi-supervised learning, and open-set domain adaptation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training",
        "paper_url": "https://openreview.net/pdf?id=Kn6i2BZW69w",
        "paper_authors": [
            "Joya Chen",
            "Kai Xu",
            "Yuhui Wang",
            "Yifei Cheng",
            "Angela Yao"
        ],
        "paper_abstract": "A standard hardware bottleneck when training deep neural networks is GPU memory. The bulk of memory is occupied by caching intermediate tensors for gradient computation in the backward pass. We propose a novel method to reduce this footprint - Dropping Intermediate Tensors (DropIT).  DropIT drops min-k elements of the intermediate tensors and approximates gradients from the sparsified tensors in the backward pass. Theoretically, DropIT reduces noise on estimated gradients and therefore has a higher rate of convergence than vanilla-SGD. Experiments show that we can drop up to 90\\% of the intermediate tensor elements in fully-connected and convolutional layers while achieving higher testing accuracy for Visual Transformers and Convolutional Neural Networks on various tasks (e.g., classification, object detection, instance segmentation). Our code and models are available at https://github.com/chenjoya/dropit.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified Framework for Soft Threshold Pruning",
        "paper_url": "https://openreview.net/pdf?id=cCFqcrq0d8",
        "paper_authors": [
            "Yanqi Chen",
            "Zhengyu Ma",
            "Wei Fang",
            "Xiawu Zheng",
            "Zhaofei Yu",
            "Yonghong Tian"
        ],
        "paper_abstract": "Soft threshold pruning is among the cutting-edge pruning methods with state-of-the-art performance. However, previous methods either perform aimless searching on the threshold scheduler or simply set the threshold trainable, lacking theoretical explanation from a unified perspective. In this work, we reformulate soft threshold pruning as an implicit optimization problem solved using the Iterative Shrinkage-Thresholding Algorithm (ISTA), a classic method from the fields of sparse recovery and compressed sensing. Under this theoretical framework, all threshold tuning strategies proposed in previous studies of soft threshold pruning are concluded as different styles of tuning $L_1$-regularization term. We further derive an optimal threshold scheduler through an in-depth study of threshold scheduling based on our framework. This scheduler keeps $L_1$-regularization coefficient stable, implying a time-invariant objective function from the perspective of optimization. In principle, the derived pruning algorithm could sparsify any mathematical model trained via SGD. We conduct extensive experiments and verify its state-of-the-art performance on both Artificial Neural Networks (ResNet-50 and MobileNet-V1) and Spiking Neural Networks (SEW ResNet-18) on ImageNet datasets. On the basis of this framework, we derive a family of pruning methods, including sparsify-during-training, early pruning, and pruning at initialization. The code is available at https://github.com/Yanqi-Chen/LATS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding",
        "paper_url": "https://openreview.net/pdf?id=-CwPopPJda",
        "paper_authors": [
            "Hanrong Ye",
            "Dan Xu"
        ],
        "paper_abstract": "Learning effective representations simultaneously from multiple tasks in a unified network framework is a fundamental paradigm for multi-task dense visual scene understanding. This requires joint modeling (i) task-generic and (ii) task-specific representations, and (iii) cross-task representation interactions. Existing works typically model these three perspectives with separately designed structures, using shared network modules for task-generic learning, different modules for task-specific learning, and establishing connections among these components for cross-task interactions. It is barely explored in the literature to model these three perspectives in each network layer in an end-to-end manner, which can not only minimize the effort of carefully designing empirical structures for the three multi-task representation learning objectives, but also greatly improve the representation learning capability of the multi-task network since all the model capacity will be used to optimize the three objectives together. In this paper, we propose TaskPrompter, a novel spatial-channel multi-task prompting transformer framework to achieve this target. Specifically, we design a set of spatial-channel task prompts and learn their spatial- and channel interactions with the shared image tokens in each transformer layer with attention mechanism, as aggregating spatial and channel information is critical for dense prediction tasks. Each task prompt learns task-specific representation for one task, while all the prompts can jointly contribute to the learning of the shared image token representations, and the interactions between different task prompts model the cross-task relationship. To decode dense predictions for multiple tasks with the learned spatial-channel task prompts from transformer, we accordingly design a dense task prompt decoding mechanism, which queries the shared image tokens using task prompts to obtain spatial- and channel-wise task-specific representations. Extensive experiments on two challenging multi-task dense scene understanding benchmarks (i.e. NYUD-V2 and PASCAL-Context) show the superiority of the proposed framework and TaskPrompter establishes significant state-of-the-art performances on multi-task dense predictions. Codes and models are made publicly available at https://github.com/prismformore/Multi-Task-Transformer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Domain-Agnostic Representation for Disease Diagnosis",
        "paper_url": "https://openreview.net/pdf?id=-HHJZlRpGb",
        "paper_authors": [
            "Churan Wang",
            "Jing  Li",
            "Xinwei Sun",
            "Fandong Zhang",
            "Yizhou Yu",
            "Yizhou Wang"
        ],
        "paper_abstract": "In clinical environments, image-based diagnosis is desired to achieve robustness on multi-center samples. Toward this goal, a natural way is to capture only clinically disease-related features. However, such disease-related features are often entangled with center-effect, disabling robust transferring to unseen centers/domains. To disentangle disease-related features, we first leverage structural causal modeling to explicitly model disease-related and center-effects that are provable to be disentangled from each other. Guided by this, we propose a novel Domain Agnostic Representation Model (DarMo) based on variational Auto-Encoder. To facilitate disentanglement, we design domain-agnostic and domain-aware encoders to respectively capture disease-related features and varied center-effects by incorporating a domain-aware batch normalization layer. Besides, we constrain the disease-related features to well predict the disease label as well as clinical attributes, by leveraging Graph Convolutional Network (GCN) into our decoder. The effectiveness and utility of our method are demonstrated by the superior performance over others on both public datasets and inhouse datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning",
        "paper_url": "https://openreview.net/pdf?id=JdgO-ht1uTN",
        "paper_authors": [
            "Chi Han",
            "Qizheng He",
            "Charles Yu",
            "Xinya Du",
            "Hanghang Tong",
            "Heng Ji"
        ],
        "paper_abstract": "Probabilistic logical rule learning has shown great strength in logical rule mining and knowledge graph completion. It learns logical rules to predict missing edges by reasoning on existing edges in the knowledge graph. However, previous efforts have largely been limited to only modeling chain-like Horn clauses such as R1(x; z) ^ R2(z; y) ) H(x; y). This formulation overlooks additional contextual information from neighboring sub-graphs of entity variables x, y and z. Intuitively, there is a large gap here, as local sub-graphs have been found to provide important information for knowledge graph completion. Inspired by these observations, we propose Logical Entity RePresentation (LERP) to encode contextual information of entities in the knowledge graph. A LERP is designed as a vector of probabilistic logical functions on the entity\u2019s neighboring sub-graph. It is an interpretable representation while allowing for differentiable optimization. We can then incorporate LERP into probabilistic logical rule learning to learn more expressive rules. Empirical results demonstrate that with LERP, our model outperforms other rule learning methods in knowledge graph completion and is comparable or even superior to state-of-the-art black-box methods. Moreover, we find that our model can discover a more expressive family of logical rules. LERP can also be further combined with embedding learning methods like TransE to make it more interpretable.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection",
        "paper_url": "https://openreview.net/pdf?id=-2zfgNS917",
        "paper_authors": [
            "Zehui Chen",
            "Zhenyu Li",
            "Shiquan Zhang",
            "Liangji Fang",
            "Qinhong Jiang",
            "Feng Zhao"
        ],
        "paper_abstract": "3D object detection from multiple image views is a fundamental and challenging task for visual scene understanding. Owing to its low cost and high efficiency, multi-view 3D object detection has demonstrated promising application prospects. However, accurately detecting objects through perspective views is extremely difficult due to the lack of depth information. Current approaches tend to adopt heavy backbones for image encoders, making them inapplicable for real-world deployment. Different from the images, LiDAR points are superior in providing spatial cues, resulting in highly precise localization. In this paper, we explore the incorporation of LiDAR-based detectors for multi-view 3D object detection. Instead of directly training a depth prediction network, we unify the image and LiDAR features in the Bird-Eye-View (BEV) space and adaptively transfer knowledge across non-homogenous representations in a teacher-student paradigm. To this end, we propose BEVDistill, a cross-modal BEV knowledge distillation (KD) framework for multi-view 3D object detection. \nExtensive experiments demonstrate that the proposed method outperforms current KD approaches on a highly-competitive baseline, BEVFormer, without introducing any extra cost in the inference phase. Notably, our best model achieves 59.4 NDS on the nuScenes test leaderboard, achieving new state-of-the-arts in comparison with various image-based detectors. Code will be available at https://github.com/zehuichen123/BEVDistill.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-Grained Self-Interpretable Symbolic-Neural Model For Single/Multi-Labeled Text Classification",
        "paper_url": "https://openreview.net/pdf?id=MLJ5TF5FtXH",
        "paper_authors": [
            "Xiang Hu",
            "XinYu KONG",
            "Kewei Tu"
        ],
        "paper_abstract": "Deep neural networks based on layer-stacking architectures have historically suffered from poor inherent interpretability. Meanwhile, symbolic probabilistic models function with clear interpretability, but how to combine them with neural networks to enhance their performance remains to be explored. In this paper, we try to marry these two systems for text classification via a structured language model. We propose a Symbolic-Neural model that can learn to explicitly predict class labels of text spans from a constituency tree without requiring any access to span-level gold labels. As the structured language model learns to predict constituency trees in a self-supervised manner, only raw texts and sentence-level labels are required as training data, which makes it essentially a general constituent-level self-interpretable classification model. Our experiments demonstrate that our approach could achieve good prediction accuracy in downstream tasks. Meanwhile, the predicted span labels are consistent with human rationales to a certain degree.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Suppressing the Heterogeneity: A Strong Feature Extractor for Few-shot Segmentation",
        "paper_url": "https://openreview.net/pdf?id=CGuvK3U09LH",
        "paper_authors": [
            "Zhengdong Hu",
            "Yifan Sun",
            "Yi Yang"
        ],
        "paper_abstract": "This paper tackles the Few-shot Semantic Segmentation (FSS) task with focus on learning the feature extractor. Somehow the feature extractor has been overlooked by recent state-of-the-art methods, which directly use a deep model pretrained on ImageNet for feature extraction (without further fine-tuning). Under this background, we think the FSS feature extractor deserves exploration and observe the heterogeneity (i.e., the intra-class diversity in the raw images) as a critical challenge hindering the intra-class feature compactness. The heterogeneity has three levels from coarse to fine: 1) Sample-level: the inevitable distribution gap between the support and query images makes them heterogeneous from each other. 2) Region-level: the background in FSS actually contains multiple regions with different semantics. 3) Patch-level: some neighboring patches belonging to a same class may appear quite different from each other. Motivated by these observations, we propose a feature extractor with Multi-level Heterogeneity Suppressing (MuHS). MuHS leverages the attention mechanism in transformer backbone to effectively suppress all these three-level heterogeneity. Concretely, MuHS reinforces the attention / interaction between different samples (query and support), different regions and neighboring patches by constructing cross-sample attention, cross-region interaction and a novel masked image segmentation (inspired by the recent masked image modeling), respectively. We empirically show that 1) MuHS brings consistent improvement for various FSS heads and 2) using a simple linear classification head, MuHS sets new states of the art on multiple FSS datasets, validating the importance of FSS feature learning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Achieve the Minimum Width of Neural Networks for Universal Approximation",
        "paper_url": "https://openreview.net/pdf?id=hfUJ4ShyDEU",
        "paper_authors": [
            "Yongqiang Cai"
        ],
        "paper_abstract": "The universal approximation property (UAP) of neural networks is fundamental for deep learning, and it is well known that wide neural networks are universal approximators of continuous functions within both the $L^p$ norm and the continuous/uniform norm. However, the exact minimum width, $w_{\\min}$, for the UAP has not been studied thoroughly. Recently, using a decoder-memorizer-encoder scheme, \\citet{Park2021Minimum} found that $w_{\\min} = \\max(d_x+1,d_y)$ for both the $L^p$-UAP of ReLU networks and the $C$-UAP of ReLU+STEP networks, where $d_x,d_y$ are the input and output dimensions, respectively. In this paper, we consider neural networks with an arbitrary set of activation functions. We prove that both $C$-UAP and $L^p$-UAP for functions on compact domains share a universal lower bound of the minimal width; that is, $w^*_{\\min} = \\max(d_x,d_y)$. In particular, the critical width, $w^*_{\\min}$, for $L^p$-UAP can be achieved by leaky-ReLU networks, provided that the input or output dimension is larger than one. Our construction is based on the approximation power of neural ordinary differential equations and the ability to approximate flow maps by neural networks. The nonmonotone or discontinuous activation functions case and the one-dimensional case are also discussed.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection",
        "paper_url": "https://openreview.net/pdf?id=NPfDKT9OUJ3",
        "paper_authors": [
            "Xue Yang",
            "Gefan Zhang",
            "Wentong Li",
            "Yue Zhou",
            "Xuehui Wang",
            "Junchi Yan"
        ],
        "paper_abstract": "Oriented object detection emerges in many applications from aerial images to autonomous driving, while many existing detection benchmarks are annotated with horizontal bounding box only which is also less costive than fine-grained rotated box, leading to a gap between the readily available training corpus and the rising demand for oriented object detection.  This paper proposes a simple yet effective oriented object detection approach called H2RBox merely using horizontal box annotation for weakly-supervised training, which closes the above gap and shows competitive performance even against those trained with rotated boxes.  The cores of our method are weakly- and self-supervised learning, which predicts the angle of the object by learning the consistency of two different views. To our best knowledge, H2RBox is the first horizontal box annotation-based oriented object detector. Compared to an alternative i.e. horizontal box-supervised instance segmentation with our post adaption to oriented object detection, our approach is not susceptible to the prediction quality of mask and can perform more robustly in complex scenes containing a large number of dense objects and outliers. Experimental results show that H2RBox has significant performance and speed advantages over horizontal box-supervised instance segmentation methods, as well as lower memory requirements. While compared to rotated box-supervised oriented object detectors, our method shows very close performance and speed. The source code is available at PyTorch-based \\href{https://github.com/yangxue0827/h2rbox-mmrotate}{MMRotate} and Jittor-based \\href{https://github.com/yangxue0827/h2rbox-jittor}{JDet}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore",
        "paper_url": "https://openreview.net/pdf?id=xzmqxHdZAwO",
        "paper_authors": [
            "Guoyang Xie",
            "Jinbao Wang",
            "Jiaqi Liu",
            "Yaochu Jin",
            "Feng Zheng"
        ],
        "paper_abstract": "In the area of few-shot anomaly detection (FSAD), efficient visual feature plays an essential role in the memory bank $\\mathcal{M}$-based methods. However, these methods do not account for the relationship between the visual feature and its rotated visual feature, drastically limiting the anomaly detection performance. To push the limits, we reveal that rotation-invariant feature property has a significant impact on industrial-based FSAD. Specifically, we utilize graph representation in FSAD and provide a novel visual isometric invariant feature (VIIF) as an anomaly measurement feature. As a result, VIIF can robustly improve the anomaly discriminating ability and can further reduce the size of redundant features stored in $\\mathcal{M}$ by a large amount. Besides, we provide a novel model GraphCore via VIIFs that can fast implement unsupervised FSAD training and improve the performance of anomaly detection. A comprehensive evaluation is provided for comparing GraphCore and other SOTA anomaly detection models under our proposed few-shot anomaly detection setting, which shows GraphCore can increase average AUC by 5.8%, 4.1%, 3.4%, and 1.6% on MVTec AD and by 25.5%, 22.0%, 16.9%, and 14.1% on MPDD for 1, 2, 4, and 8-shot cases, respectively.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Representation Learning for Low-rank General-sum Markov Games",
        "paper_url": "https://openreview.net/pdf?id=8FroynZv4C",
        "paper_authors": [
            "Chengzhuo Ni",
            "Yuda Song",
            "Xuezhou Zhang",
            "Zihan Ding",
            "Chi Jin",
            "Mengdi Wang"
        ],
        "paper_abstract": "We study multi-agent general-sum Markov games with nonlinear function approximation. We focus on low-rank Markov games whose transition matrix admits a hidden low-rank structure on top of an unknown non-linear representation. The goal is to design an algorithm that (1) finds an $\\varepsilon$-equilibrium policy sample efficiently without prior knowledge of the environment or the representation, and (2) permits a deep-learning friendly implementation. We leverage representation learning and present a model-based and a model-free approach to construct an effective representation from collected data. For both approaches, the algorithm achieves a sample complexity of poly$(H,d,A,1/\\varepsilon)$, where $H$ is the game horizon, $d$ is the dimension of the feature vector, $A$ is the size of the joint action space and $\\varepsilon$ is the optimality gap. When the number of players is large, the above sample complexity can scale exponentially with the number of players in the worst case. To address this challenge, we consider Markov Games with a factorized transition structure and present an algorithm that escapes such exponential scaling. To our best knowledge, this is the first sample-efficient algorithm for multi-agent general-sum Markov games that incorporates (non-linear) function approximation. We accompany our theoretical result with a neural network-based implementation of our algorithm and evaluate it against the widely used deep RL baseline, DQN with fictitious play.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Surgical Fine-Tuning Improves Adaptation to Distribution Shifts",
        "paper_url": "https://openreview.net/pdf?id=APuPRxjHvZ",
        "paper_authors": [
            "Yoonho Lee",
            "Annie S Chen",
            "Fahim Tajwar",
            "Ananya Kumar",
            "Huaxiu Yao",
            "Percy Liang",
            "Chelsea Finn"
        ],
        "paper_abstract": "A common approach to transfer learning under distribution shift is to fine-tune the last few layers of a pre-trained model, preserving learned features while also adapting to the new task. This paper shows that in such settings, selectively fine-tuning a subset of layers (which we term surgical fine-tuning) matches or outperforms commonly used fine-tuning approaches. Moreover, the type of distribution shift influences which subset is more effective to tune: for example, for image corruptions, fine-tuning only the first few layers works best. We validate our findings systematically across seven real-world data tasks spanning three types of distribution shifts. Theoretically, we prove that for two-layer neural networks in an idealized setting, first-layer tuning can outperform fine-tuning all layers. Intuitively, fine-tuning more parameters on a small target dataset can cause information learned during pre-training to be forgotten, and the relevant information depends on the type of shift.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Diversify and Disambiguate: Out-of-Distribution Robustness via Disagreement",
        "paper_url": "https://openreview.net/pdf?id=RVTOp3MwT3n",
        "paper_authors": [
            "Yoonho Lee",
            "Huaxiu Yao",
            "Chelsea Finn"
        ],
        "paper_abstract": "Real-world machine learning problems often exhibit shifts between the source and target distributions, in which source data does not fully convey the desired behavior on target inputs. Different functions that achieve near-perfect source accuracy can make differing predictions on test inputs, and such ambiguity makes robustness to distribution shifts challenging. We propose DivDis, a simple two-stage framework for identifying and resolving ambiguity in data. DivDis first learns a diverse set of hypotheses that achieve low source loss but make differing predictions on target inputs. We then disambiguate by selecting one of the discovered functions using additional information, for example, a small number of target labels. Our experimental evaluation shows improved performance in subpopulation shift and domain generalization settings, demonstrating that DivDis can scalably adapt to distribution shifts in image and text classification benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On amortizing convex conjugates for optimal transport",
        "paper_url": "https://openreview.net/pdf?id=TQ5WUwS_4ai",
        "paper_authors": [
            "Brandon Amos"
        ],
        "paper_abstract": "This paper focuses on computing the convex conjugate operation that arises when solving Euclidean Wasserstein-2 optimal transport problems. This conjugation, which is also referred to as the Legendre-Fenchel conjugate or c-transform,is considered difficult to compute and in practice,Wasserstein-2 methods are limited by not being able to exactly conjugate the dual potentials in continuous space. To overcome this, the computation of the conjugate can be approximated with amortized optimization, which learns a model to predict the conjugate. I show that combining amortized approximations to the conjugate with a solver for fine-tuning significantly improves the quality of transport maps learned for the Wasserstein-2 benchmark by Korotin et al. (2021a) and is able to model many 2-dimensional couplings and flows considered in the literature. All of the baselines, methods, and solvers in this paper are available at http://github.com/facebookresearch/w2ot.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DualAfford: Learning Collaborative Visual Affordance for Dual-gripper Manipulation",
        "paper_url": "https://openreview.net/pdf?id=I_YZANaz5X",
        "paper_authors": [
            "Yan Zhao",
            "Ruihai Wu",
            "Zhehuan Chen",
            "Yourong Zhang",
            "Qingnan Fan",
            "Kaichun Mo",
            "Hao Dong"
        ],
        "paper_abstract": "It is essential yet challenging for future home-assistant robots to understand and manipulate diverse 3D objects in daily human environments. Towards building scalable systems that can perform diverse manipulation tasks over various 3D shapes, recent works have advocated and demonstrated promising results learning visual actionable affordance, which labels every point over the input 3D geometry with an action likelihood of accomplishing the downstream task (e.g., pushing or picking-up). However, these works only studied single-gripper manipulation tasks, yet many real-world tasks require two hands to achieve collaboratively. In this work, we propose a novel learning framework, DualAfford, to learn collaborative affordance for dual-gripper manipulation tasks. The core design of the approach is to reduce the quadratic problem for two grippers into two disentangled yet interconnected subtasks for efficient learning. Using the large-scale PartNet-Mobility and ShapeNet datasets, we set up four benchmark tasks for dual-gripper manipulation. Experiments prove the effectiveness and superiority of our method over three baselines. We will release code and data upon acceptance. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance Matching",
        "paper_url": "https://openreview.net/pdf?id=CjTHVo1dvR",
        "paper_authors": [
            "Shengchao Liu",
            "Hongyu Guo",
            "Jian Tang"
        ],
        "paper_abstract": "Molecular representation pretraining is critical in various applications for drug and material discovery due to the limited number of labeled molecules, and most existing work focuses on pretraining on 2D molecular graphs. However, the power of pretraining on 3D geometric structures has been less explored. This is owing to the difficulty of finding a sufficient proxy task that can empower the pretraining to effectively extract essential features from the geometric structures. Motivated by the dynamic nature of 3D molecules, where the continuous motion of a molecule in the 3D Euclidean space forms a smooth potential energy surface, we propose GeoSSL, a 3D coordinate denoising pretraining framework to model such an energy landscape. Further by leveraging an SE(3)-invariant score matching method, we propose GeoSSL-DDM in which the coordinate denoising proxy task is effectively boiled down to denoising the pairwise atomic distances in a molecule. Our comprehensive experiments confirm the effectiveness and robustness of our proposed method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SIMPLE: Specialized Model-Sample Matching for Domain Generalization",
        "paper_url": "https://openreview.net/pdf?id=BqrPeZ_e5P",
        "paper_authors": [
            "Ziyue Li",
            "Kan Ren",
            "XINYANG JIANG",
            "Yifei Shen",
            "Haipeng Zhang",
            "Dongsheng Li"
        ],
        "paper_abstract": "In domain generalization (DG), most existing methods aspire to fine-tune a specific pretrained model through novel DG algorithms. In this paper, we propose an alternative direction, i.e., to efficiently leverage a pool of pretrained models without fine-tuning. Through extensive empirical and theoretical evidence, we demonstrate that (1) pretrained models have possessed generalization to some extent while there is no single best pretrained model across all distribution shifts, and (2) out-of-distribution (OOD) generalization error depends on the fitness between the pretrained model and unseen test distributions. This analysis motivates us to incorporate diverse pretrained models and to dispatch the best matched models for each OOD sample by means of recommendation techniques. To this end, we propose SIMPLE, a specialized model-sample matching method for domain generalization. First, the predictions of pretrained models are adapted to the target domain by a linear label space transformation. A matching network aware of model specialty is then proposed to dynamically recommend proper pretrained models to predict each test sample. The experiments on DomainBed show that our method achieves significant performance improvements (up to 12.2% for individual dataset and 3.9% on average) compared to state-of-the-art (SOTA) methods and further achieves 6.1% gain via enlarging the pretrained model pool. Moreover, our method is highly efficient and achieves more than 1000 times training speedup compared to the conventional DG methods with fine-tuning a pretrained model. Code and supplemental materials are available at https://seqml.github.io/simple.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from a Single Image",
        "paper_url": "https://openreview.net/pdf?id=6kxApT2r2i",
        "paper_authors": [
            "Yuki M Asano",
            "Aaqib Saeed"
        ],
        "paper_abstract": "What can neural networks learn about the visual world when provided with only a single image as input? While any image obviously cannot contain the multitudes of all existing objects, scenes and lighting conditions -- within the space of all  $256^{3\\cdot224\\cdot224}$ possible $224$-sized square images, it might still provide a strong prior for natural images. To analyze this ``augmented image prior''  hypothesis, we develop a simple framework for training neural networks from scratch using a single image and augmentations using knowledge distillation from a supervised pretrained teacher. With this, we find the answer to the above question to be: `surprisingly, a lot'. In quantitative terms, we find accuracies of $94\\%$/$74\\%$ on CIFAR-10/100, $69$\\% on ImageNet, and by extending this method to video and audio, $51\\%$ on Kinetics-400 and $84$\\% on SpeechCommands. In extensive analyses spanning 13 datasets, we disentangle the effect of augmentations, choice of data and network architectures and also provide qualitative evaluations that include lucid ``panda neurons'' in networks that have never even seen one. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Delving into Semantic Scale Imbalance",
        "paper_url": "https://openreview.net/pdf?id=07tc5kKRIo",
        "paper_authors": [
            "Yanbiao Ma",
            "Licheng Jiao",
            "Fang Liu",
            "Yuxin Li",
            "Shuyuan Yang",
            "Xu Liu"
        ],
        "paper_abstract": "Model bias triggered by long-tailed data has been widely studied. However, measure based on the number of samples cannot explicate three phenomena simultaneously: (1) Given enough data, the classification performance gain is marginal with additional samples. (2) Classification performance decays precipitously as the number of training samples decreases when there is insufficient data. (3) Model trained on sample-balanced datasets still has different biases for different classes. In this work, we define and quantify the semantic scale of classes, which is equivalent to the feature diversity of classes. It is exciting to find experimentally that there is a marginal effect of semantic scale, which perfectly describes the first two phenomena. Further, the quantitative measurement of semantic scale imbalance is proposed, which can accurately reflect model bias on multiple datasets, even on sample-balanced data, revealing a novel perspective for the study of class imbalance. Due to the prevalence of semantic scale imbalance, we propose semantic-scale-balanced learning, including a general loss improvement scheme and a dynamic re-weighting training framework that overcomes the challenge of calculating semantic scales in real-time during iterations. Comprehensive experiments show that dynamic semantic-scale-balanced learning consistently enables the model to perform superiorly on large-scale long-tailed and non-long-tailed datasets, which is a good starting point for mitigating the prevalent but unnoticed model bias. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=jgmuRzM-sb6",
        "paper_authors": [
            "Wenqian Li",
            "Yinchuan Li",
            "Zhigang Li",
            "Jianye HAO",
            "Yan Pang"
        ],
        "paper_abstract": "Uncovering rationales behind predictions of graph neural networks (GNNs) has received increasing attention over the years. Existing literature mainly focus on selecting a subgraph, through combinatorial optimization, to provide faithful explanations. However, the exponential size of candidate subgraphs limits the applicability of state-of-the-art methods to large-scale GNNs. We enhance on this through a different approach: by proposing a generative structure \u2013 GFlowNets-based GNN Explainer (GFlowExplainer), we turn the optimization problem into a step-by-step generative problem. Our GFlowExplainer aims to learn a policy that generates a distribution of subgraphs for which the probability of a subgraph is proportional to its\u2019 reward. The proposed approach eliminates the influence of node sequence and thus does not need any pre-training strategies. We also propose a new cut vertex matrix to efficiently explore parent states for GFlowNets structure, thus making our approach applicable in a large-scale setting. We conduct extensive experiments on both synthetic and real datasets, and both qualitative and quantitative results show the superiority of our GFlowExplainer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextual Image Masking Modeling via Synergized Contrasting without View Augmentation for Faster and Better Visual Pretraining",
        "paper_url": "https://openreview.net/pdf?id=A3sgyt4HWp",
        "paper_authors": [
            "Shaofeng Zhang",
            "Feng Zhu",
            "Rui Zhao",
            "Junchi Yan"
        ],
        "paper_abstract": "We propose a new contextual masking image modeling (MIM) approach called contrasting-aided contextual MIM (ccMIM), under the MIM paradigm for visual pretraining. Specifically, we adopt importance sampling to select the masked patches with richer semantic information for reconstruction, instead of random sampling as done in previous MIM works. As such, the resulting patch reconstruction task from the remaining less semantic patches could be more difficult and helps to learn. To speed up the possibly slowed convergence due to our more difficult reconstruction task, we further propose a new contrastive loss that aligns the tokens of the vision transformer extracted from the selected masked patches and the remaining ones, respectively. The hope is that it serves as a regularizer for patch feature learning such that the image-level global information could be captured in both masked and unmasked patches, and notably such a single-view contrasting avoids the tedious image augmentation step required in recent efforts of introducing contrastive learning to MIM (to speedup convergence and discriminative ability). Meanwhile, the attention score from the contrastive global feature can also carry effective semantic clues to in turn guide our above masking patch selection scheme. In consequence, our contextual MIM and contrastive learning are synergetically performed in a loop (semantic patch selection-token alignment contrasting) to boost the best of the two worlds: fast convergence and strong performance on downstream tasks without ad-hoc augmentations, which are verified by empirical results on ImageNet-1K for both classification and dense vision tasks. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Patch-Level Contrasting without Patch Correspondence for Accurate and Dense Contrastive Representation Learning",
        "paper_url": "https://openreview.net/pdf?id=10R_bcjFwJ",
        "paper_authors": [
            "Shaofeng Zhang",
            "Feng Zhu",
            "Rui Zhao",
            "Junchi Yan"
        ],
        "paper_abstract": "We propose ADCLR: \\underline{A}ccurate and \\underline{D}ense \\underline{C}ontrastive \\underline{R}epresentation \\underline{L}earning, a novel self-supervised learning framework for learning accurate and dense vision representation. To extract spatial-sensitive information, ADCLR introduces query patches for contrasting  in addition with global contrasting. Compared with previous dense contrasting methods, ADCLR mainly enjoys three merits: i) achieving both global-discriminative and spatial-sensitive representation, ii) model-efficient (no extra parameters in addition to the global contrasting baseline), and iii) correspondence-free and thus simpler to implement. Our approach achieves new state-of-the-art performance for contrastive methods. On classification tasks, for ViT-S, ADCLR achieves 78.1\\% top-1 accuracy on ImageNet with linear probing, outperforming our baseline (DINO) without our devised techniques as plug-in, by 1.1\\%. For ViT-B, ADCLR achieves 79.8\\%, 84.0\\% accuracy on ImageNet by linear probing and finetune, outperforming DINO by 0.6\\%, 0.4\\% accuracy. For dense tasks, on MS-COCO, ADCLR achieves significant improvements of 44.3\\% AP on object detection, 39.7\\% AP on instance segmentation, outperforming previous SOTA method SelfPatch by 2.2\\% and 1.2\\%, respectively. On ADE20K, ADCLR outperforms SelfPatch by 1.0\\% mIoU, 1.2\\% mAcc on the segmentation task.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins",
        "paper_url": "https://openreview.net/pdf?id=P5Z-Zl9XJ7",
        "paper_authors": [
            "Hehe Fan",
            "Zhangyang Wang",
            "Yi Yang",
            "Mohan Kankanhalli"
        ],
        "paper_abstract": "The structure of proteins involves 3D geometry of amino acid coordinates and 1D sequence of peptide chains. The 3D structure exhibits irregularity because amino acids are distributed unevenly in Euclidean space and their coordinates are continuous variables. In contrast, the 1D structure is regular because amino acids are arranged uniformly in the chains and their sequential positions (orders) are discrete variables. Moreover, geometric coordinates and sequential orders are in two types of spaces and their units of length are incompatible. These inconsistencies make it challenging to capture the 3D and 1D structures while avoiding the impact of sequence and geometry modeling on each other. This paper proposes a Continuous-Discrete Convolution (CDConv) that uses irregular and regular approaches to model the geometry and sequence structures, respectively. Specifically, CDConv employs independent learnable weights for different regular sequential displacements but directly encodes geometric displacements due to their irregularity. In this way, CDConv significantly improves protein modeling by reducing the impact of geometric irregularity on sequence modeling. Extensive experiments on a range of tasks, including protein fold classification, enzyme reaction classification, gene ontology term prediction and enzyme commission number prediction, demonstrate the effectiveness of the proposed CDConv. ",
        "paper_code": "#",
        "paper_cite": -1
    }
]