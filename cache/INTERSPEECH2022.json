[
    {
        "paper_name": "Interspeech 2022, 23rd Annual Conference of the International Speech Communication Association, Incheon, Korea, 18-22 September 2022",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022",
        "paper_authors": [
            "Hanseok Ko",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-46",
        "paper_authors": [
            "Hyunjae Cho",
            "Wonbin Jung",
            "Junhyeok Lee",
            "Sang Hoon Woo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancement of Pitch Controllability using Timbre-Preserving Pitch Augmentation in FastPitch",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-55",
        "paper_authors": [
            "Hanbin Bae",
            "Young-Sun Joo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaking Rate Control of end-to-end TTS Models by Direct Manipulation of the Encoder's Output Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-759",
        "paper_authors": [
            "Martin Lenglet",
            "Olivier Perrotin",
            "G\u00e9rard Bailly"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TriniTTS: Pitch-controllable End-to-end TTS without External Aligner",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-925",
        "paper_authors": [
            "Yooncheol Ju",
            "Ilhwan Kim",
            "Hongsun Yang",
            "Ji-Hoon Kim",
            "Byeongyeol Kim",
            "Soumi Maiti",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10294",
        "paper_authors": [
            "Dan Lim",
            "Sunghee Jung",
            "Eesung Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interpretable dysarthric speaker adaptation based on optimal-transport",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-36",
        "paper_authors": [
            "Rosanna Turrisi",
            "Leonardo Badino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dysarthric Speech Recognition From Raw Waveform with Parametric CNNs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-163",
        "paper_authors": [
            "Zhengjun Yue",
            "Erfan Loweimi",
            "Heidi Christensen",
            "Jon Barker",
            "Zoran Cvetkovic"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Effectiveness of Time Stretching for Enhancing Dysarthric Speech for Improved Dysarthric Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-190",
        "paper_authors": [
            "Luke Prananta",
            "Bence Mark Halpern",
            "Siyuan Feng",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Self-supervised Pretraining Frameworks for Pathological Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10043",
        "paper_authors": [
            "Lester Phillip Violeta",
            "Wen-Chin Huang",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved ASR Performance for Dysarthric Speech Using Two-stage DataAugmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10335",
        "paper_authors": [
            "Chitralekha Bhat",
            "Ashish Panda",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-lingual Self-Supervised Speech Representations for Improved Dysarthric Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10674",
        "paper_authors": [
            "Abner Hernandez",
            "Paula Andrea P\u00e9rez-Toro",
            "Elmar N\u00f6th",
            "Juan Rafael Orozco-Arroyave",
            "Andreas K. Maier",
            "Seung Hee Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Regularizing Transformer-based Acoustic Models by Penalizing Attention Weights",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-362",
        "paper_authors": [
            "Mun-Hak Lee",
            "Joon-Hyuk Chang",
            "Sang-Eon Lee",
            "Ju-Seok Seong",
            "Chanhee Park",
            "Haeyoung Kwon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Content-Context Factorized Representations for Automated Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-390",
        "paper_authors": [
            "David M. Chan",
            "Shalini Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison and Analysis of New Curriculum Criteria for End-to-End ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10046",
        "paper_authors": [
            "Georgios Karakasidis",
            "Tam\u00e1s Gr\u00f3sz",
            "Mikko Kurimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incremental learning for RNN-Transducer based speech recognition models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10795",
        "paper_authors": [
            "Deepak Baby",
            "Pasquale D'Alterio",
            "Valentin Mendelev"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Production federated keyword spotting via distillation, filtering, and joint federated-centralized training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11050",
        "paper_authors": [
            "Andrew Hard",
            "Kurt Partridge",
            "Neng Chen",
            "Sean Augenstein",
            "Aishanee Shah",
            "Hyun Jin Park",
            "Alex Park",
            "Sara Ng",
            "Jessica Nguyen",
            "Ignacio L\u00f3pez-Moreno",
            "Rajiv Mathews",
            "Fran\u00e7oise Beaufays"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Use of prosodic and lexical cues for disambiguating wh-words in Korean",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-561",
        "paper_authors": [
            "Jieun Song",
            "Hae-Sung Jeon",
            "Jieun Kiaer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Autoencoder-Based Tongue Shape Estimation During Continuous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10272",
        "paper_authors": [
            "Vinicius Ribeiro",
            "Yves Laprie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic erosion and information structure in function words: the case of mia",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10305",
        "paper_authors": [
            "Giuseppe Magistro",
            "Claudia Crocco"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Vertical Larynx Actions Under Prosodic Focus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10661",
        "paper_authors": [
            "Miran Oh",
            "Yoon-Jeong Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fundamental Frequency Variability over Time in Telephone Interactions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10669",
        "paper_authors": [
            "Leah Bradshaw",
            "Eleanor Chodroff",
            "Lena A. J\u00e4ger",
            "Volker Dellwo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SHAS: Approaching optimal Segmentation for End-to-End Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-59",
        "paper_authors": [
            "Ioannis Tsiamas",
            "Gerard I. G\u00e1llego",
            "Jos\u00e9 A. R. Fonollosa",
            "Marta R. Costa-juss\u00e0"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-592",
        "paper_authors": [
            "Jinming Zhao",
            "Hao Yang",
            "Gholamreza Haffari",
            "Ehsan Shareghi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Modal Decision Regularization for Simultaneous Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10617",
        "paper_authors": [
            "Mohd Abbas Zaidi",
            "Beomseok Lee",
            "Sangha Kim",
            "Chanwoo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Segmentation Optimization using Segmented Bilingual Speech Corpus for End-to-end Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11382",
        "paper_authors": [
            "Ryo Fukuda",
            "Katsuhito Sudoh",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Keyword Spotting using ASR embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10450",
        "paper_authors": [
            "Kirandevraj R",
            "Vinod Kumar Kurmi",
            "Vinay P. Namboodiri",
            "C. V. Jawahar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Corpus Speech Emotion Recognition for Unseen Corpus Using Corpus-Wise Weights in Classification Loss",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-111",
        "paper_authors": [
            "Youngdo Ahn",
            "Sung Joo Lee",
            "Jong Won Shin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Speech Emotion Recognition Through Focus and Calibration Attention Mechanisms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-299",
        "paper_authors": [
            "Junghun Kim",
            "Yoojin An",
            "Jihie Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Emotion is Not One-hot Encoding: Learning with Grayscale Label for Emotion Recognition in Conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-551",
        "paper_authors": [
            "Joosung Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Probing speech emotion recognition transformers for linguistic knowledge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10371",
        "paper_authors": [
            "Andreas Triantafyllopoulos",
            "Johannes Wagner",
            "Hagen Wierstorf",
            "Maximilian Schmitt",
            "Uwe Reichel",
            "Florian Eyben",
            "Felix Burkhardt",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-To-End Label Uncertainty Modeling for Speech-based Arousal Recognition Using Bayesian Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10490",
        "paper_authors": [
            "Navin Raj Prabhu",
            "Guillaume Carbajal",
            "Nale Lehmann-Willenbrock",
            "Timo Gerkmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mind the gap: On the value of silence representations to lexical-based speech emotion recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10943",
        "paper_authors": [
            "Matthew Perez",
            "Mimansa Jaiswal",
            "Minxue Niu",
            "Cristina Gorrostieta",
            "Matthew Roddy",
            "Kye Taylor",
            "Reza Lotfian",
            "John Kane",
            "Emily Mower Provost"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploiting Co-occurrence Frequency of Emotions in Perceptual Evaluations To Train A Speech Emotion Classifier",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11041",
        "paper_authors": [
            "Huang-Cheng Chou",
            "Chi-Chun Lee",
            "Carlos Busso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Positional Encoding for Capturing Modality Specific Cadence for Emotion Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11085",
        "paper_authors": [
            "Hira Dhamyal",
            "Bhiksha Raj",
            "Rita Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speak Like a Professional: Increasing Speech Intelligibility by Mimicking Professional Announcer Voice with Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-124",
        "paper_authors": [
            "Tuan Vu Ho",
            "Maori Kobayashi",
            "Masato Akagi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vector-quantized Variational Autoencoder for Phase-aware Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-443",
        "paper_authors": [
            "Tuan Vu Ho",
            "Quoc Huy Nguyen",
            "Masato Akagi",
            "Masashi Unoki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "iDeepMMSE: An improved deep learning approach to MMSE speech and noise power spectrum estimation for speech enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-964",
        "paper_authors": [
            "Minseung Kim",
            "Hyungchan Song",
            "Sein Cheong",
            "Jong Won Shin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Boosting Self-Supervised Embeddings for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10002",
        "paper_authors": [
            "Kuo-Hsuan Hung",
            "Szu-Wei Fu",
            "Huan-Hsin Tseng",
            "Hsin-Tien Chiang",
            "Yu Tsao",
            "Chii-Wann Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Monoaural Speech Enhancement Using a Nested U-Net with Two-Level Skip Connections",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10025",
        "paper_authors": [
            "Seorim Hwang",
            "Youngcheol Park",
            "Sungwook Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CycleGAN-based Unpaired Speech Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10104",
        "paper_authors": [
            "Hannah Muckenhirn",
            "Aleksandr Safin",
            "Hakan Erdogan",
            "Felix de Chaumont Quitry",
            "Marco Tagliasacchi",
            "Scott Wisdom",
            "John R. Hershey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attentive Training: A New Training Framework for Talker-independent Speaker Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10491",
        "paper_authors": [
            "Ashutosh Pandey",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Modulation-Domain Loss for Neural-Network-based Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11082",
        "paper_authors": [
            "Tyler Vuong",
            "Richard M. Stern"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perceptual Characteristics Based Multi-objective Model for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11197",
        "paper_authors": [
            "Chiang-Jen Peng",
            "Yun-Ju Chan",
            "Yih-Liang Shen",
            "Cheng Yu",
            "Yu Tsao",
            "Tai-Shih Chi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Listen only to me! How well can target speech extraction handle false alarms?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11252",
        "paper_authors": [
            "Marc Delcroix",
            "Keisuke Kinoshita",
            "Tsubasa Ochiai",
            "Katerina Zmol\u00edkov\u00e1",
            "Hiroshi Sato",
            "Tomohiro Nakatani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Monaural Speech Enhancement Based on Spectrogram Decomposition for Convolutional Neural Network-sensitive Feature Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11268",
        "paper_authors": [
            "Hao Shi",
            "Longbiao Wang",
            "Sheng Li",
            "Jianwu Dang",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Network-augmented Kalman Filtering for Robust Online Speech Dereverberation in Noisy Reverberant Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11337",
        "paper_authors": [
            "Jean-Marie Lemercier",
            "Joachim Thiemann",
            "Raphael Koning",
            "Timo Gerkmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PodcastMix: A dataset for separating music and speech in podcasts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-41",
        "paper_authors": [
            "Nicol\u00e1s Schmidt",
            "Jordi Pons",
            "Marius Miron"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Independence-based Joint Dereverberation and Separation with Neural Source Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-271",
        "paper_authors": [
            "Kohei Saijo",
            "Robin Scheibler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spatial Loss for Unsupervised Multi-channel Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-274",
        "paper_authors": [
            "Kohei Saijo",
            "Robin Scheibler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effect of Head Orientation on Speech Directivity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-553",
        "paper_authors": [
            "Samuel Bellows",
            "Timothy W. Leishman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Training of Sequential Neural Beamformer Using Coarsely-separated and Non-separated Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-976",
        "paper_authors": [
            "Kohei Saijo",
            "Tetsuji Ogawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Blind Language Separation: Disentangling Multilingual Cocktail Party Voices by Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10187",
        "paper_authors": [
            "Marvin Borsdorf",
            "Kevin Scheck",
            "Haizhou Li",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NTF of Spectral and Spatial Features for Tracking and Separation of Moving Sound Sources in Spherical Harmonic Domain",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10526",
        "paper_authors": [
            "Mateusz Guzik",
            "Konrad Kowalczyk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modelling Turn-taking in Multispeaker Parties for Realistic Data Simulation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10842",
        "paper_authors": [
            "Jack Deadman",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Initialization Scheme for Meeting Separation with Spatial Mixture Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10929",
        "paper_authors": [
            "Christoph B\u00f6ddeker",
            "Tobias Cord-Landwehr",
            "Thilo von Neumann",
            "Reinhold Haeb-Umbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prototypical speaker-interference loss for target voice separation using non-parallel audio samples",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11236",
        "paper_authors": [
            "Seongkyu Mun",
            "Dhananjaya Gowda",
            "Jihwan Lee",
            "Changwoo Han",
            "Dokyun Lee",
            "Chanwoo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reliability criterion based on learning-phase entropy for speaker recognition with neural network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-8",
        "paper_authors": [
            "Pierre-Michel Bousquet",
            "Mickael Rouvier",
            "Jean-Fran\u00e7ois Bonastre"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attentive Feature Fusion for Robust Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-478",
        "paper_authors": [
            "Bei Liu",
            "Zhengyang Chen",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dual Path Embedding Learning for Speaker Verification with Triplet Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-481",
        "paper_authors": [
            "Bei Liu",
            "Zhengyang Chen",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DF-ResNet: Boosting Speaker Verification Performance with Depth-First Design",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-484",
        "paper_authors": [
            "Bei Liu",
            "Zhengyang Chen",
            "Shuai Wang",
            "Haoyu Wang",
            "Bing Han",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Rectangle Loss for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-486",
        "paper_authors": [
            "Ruida Li",
            "Shuo Fang",
            "Chenguang Ma",
            "Liang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MFA-Conformer: Multi-scale Feature Aggregation Conformer for Automatic Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-563",
        "paper_authors": [
            "Yang Zhang",
            "Zhiqiang Lv",
            "Haibin Wu",
            "Shanshan Zhang",
            "Pengfei Hu",
            "Zhiyong Wu",
            "Hung-yi Lee",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enroll-Aware Attentive Statistics Pooling for Target Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-645",
        "paper_authors": [
            "Leying Zhang",
            "Zhengyang Chen",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transport-Oriented Feature Aggregation for Speaker Embedding Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-886",
        "paper_authors": [
            "Yusheng Tian",
            "Jingyu Li",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Frequency Information Enhanced Channel Attention Module for Speaker Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-892",
        "paper_authors": [
            "Mufan Sang",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CS-CTCSCONV1D: Small footprint speaker verification with channel split time-channel-time separable 1-dimensional convolution",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-913",
        "paper_authors": [
            "Linjun Cai",
            "Yuhong Yang",
            "Xufeng Chen",
            "Weiping Tu",
            "Hongyang Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reliable Visualization for Deep Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-926",
        "paper_authors": [
            "Pengqi Li",
            "Lantian Li",
            "Askar Hamdulla",
            "Dong Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unifying Cosine and PLDA Back-ends for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10021",
        "paper_authors": [
            "Zhiyuan Peng",
            "Xuanji He",
            "Ke Ding",
            "Tan Lee",
            "Guanglu Wan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CTFALite: Lightweight Channel-specific Temporal and Frequency Attention Mechanism for Enhancing the Speaker Embedding Extractor",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10288",
        "paper_authors": [
            "Yuheng Wei",
            "Junzhao Du",
            "Hui Liu",
            "Qian Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeechFormer: A Hierarchical Efficient Framework Incorporating the Characteristics of Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-74",
        "paper_authors": [
            "Weidong Chen",
            "Xiaofen Xing",
            "Xiangmin Xu",
            "Jianxin Pang",
            "Lan Du"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VoiceLab: Software for Fully Reproducible Automated Voice Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-113",
        "paper_authors": [
            "David Feinberg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TRILLsson: Distilled Universal Paralinguistic Speech Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-118",
        "paper_authors": [
            "Joel Shor",
            "Subhashini Venugopalan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Global Signal-to-noise Ratio Estimation Based on Multi-subband Processing Using Convolutional Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-154",
        "paper_authors": [
            "Nan Li",
            "Meng Ge",
            "Longbiao Wang",
            "Masashi Unoki",
            "Sheng Li",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Sparsity-promoting Dictionary Model for Variational Autoencoders",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-237",
        "paper_authors": [
            "Mostafa Sadeghi",
            "Paul Magron"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Transductive Transfer Regression Network for Cross-Corpus Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-679",
        "paper_authors": [
            "Yan Zhao",
            "Jincen Wang",
            "Ru Ye",
            "Yuan Zong",
            "Wenming Zheng",
            "Li Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio Anti-spoofing Using Simple Attention Module and Joint Optimization Based on Additive Angular Margin Loss and Meta-learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-904",
        "paper_authors": [
            "John H. L. Hansen",
            "Zhenyu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PEAF: Learnable Power Efficient Analog Acoustic Features for Audio Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10412",
        "paper_authors": [
            "Boris Bergsma",
            "Minhao Yang",
            "Milos Cernak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hybrid Handcrafted and Learnable Audio Representation for Analysis of Speech Under Cognitive and Physical Load",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10498",
        "paper_authors": [
            "Gasser Elbanna",
            "Alice Biryukov",
            "Neil Scheidwasser-Clow",
            "Lara Orlandic",
            "Pablo Mainar",
            "Mikolaj Kegler",
            "Pierre Beckmann",
            "Milos Cernak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generative Data Augmentation Guided by Triplet Loss for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10667",
        "paper_authors": [
            "Shijun Wang",
            "Hamed Hemati",
            "J\u00f3n Gu\u00f0nason",
            "Damian Borth"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning neural audio features without supervision",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10834",
        "paper_authors": [
            "Sarthak Yadav",
            "Neil Zeghidour"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Densely-connected Convolutional Recurrent Network for Fundamental Frequency Estimation in Noisy Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11156",
        "paper_authors": [
            "Yixuan Zhang",
            "Heming Wang",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting label distribution improves non-intrusive speech quality estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11186",
        "paper_authors": [
            "Abu Zaher Md Faridee",
            "Hannes Gamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep versus Wide: An Analysis of Student Architectures for Task-Agnostic Knowledge Distillation of Self-Supervised Speech Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11313",
        "paper_authors": [
            "Takanori Ashihara",
            "Takafumi Moriya",
            "Kohei Matsuura",
            "Tomohiro Tanaka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dataset Pruning for Resource-constrained Spoofed Audio Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-514",
        "paper_authors": [
            "Abdul Hameed Azeemi",
            "Ihsan Ayyub Qazi",
            "Agha Ali Raza"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EdiTTS: Score-based Editing for Controllable Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-6",
        "paper_authors": [
            "Jaesung Tae",
            "Hyeongju Kim",
            "Taesu Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Mandarin Prosodic Structure Prediction with Multi-level Contextual Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-131",
        "paper_authors": [
            "Jie Chen",
            "Changhe Song",
            "Deyi Tuo",
            "Xixin Wu",
            "Shiyin Kang",
            "Zhiyong Wu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeechPainter: Text-conditioned Speech Inpainting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-194",
        "paper_authors": [
            "Zalan Borsos",
            "Matthew Sharifi",
            "Marco Tagliasacchi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A polyphone BERT for Polyphone Disambiguation in Mandarin Chinese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-229",
        "paper_authors": [
            "Song Zhang",
            "Ken Zheng",
            "Xiaoxu Zhu",
            "Baoxiang Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Lexicon Reader: Reduce Pronunciation Errors in End-to-end TTS by Leveraging External Textual Knowledge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-420",
        "paper_authors": [
            "Mutian He",
            "Jingzhou Yang",
            "Lei He",
            "Frank K. Soong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ByT5 model for massively multilingual grapheme-to-phoneme conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-538",
        "paper_authors": [
            "Jian Zhu",
            "Cong Zhang",
            "David Jurgens"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DocLayoutTTS: Dataset and Baselines for Layout-informed Document-level Neural Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-574",
        "paper_authors": [
            "Puneet Mathur",
            "Franck Dernoncourt",
            "Quan Hung Tran",
            "Jiuxiang Gu",
            "Ani Nenkova",
            "Vlad I. Morariu",
            "Rajiv Jain",
            "Dinesh Manocha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme Representations for Text to Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-621",
        "paper_authors": [
            "Guangyan Zhang",
            "Kaitao Song",
            "Xu Tan",
            "Daxin Tan",
            "Yuzi Yan",
            "Yanqing Liu",
            "Gang Wang",
            "Wei Zhou",
            "Tao Qin",
            "Tan Lee",
            "Sheng Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Text-to-Speech Synthesis by Unsupervised Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-816",
        "paper_authors": [
            "Junrui Ni",
            "Liming Wang",
            "Heting Gao",
            "Kaizhi Qian",
            "Yang Zhang",
            "Shiyu Chang",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Efficient and High Fidelity Vietnamese Streaming End-to-End Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-922",
        "paper_authors": [
            "Tho Nguyen Duc Tran",
            "The Chuong Chu",
            "Vu Hoang",
            "Trung Huu Bui",
            "Steven Hung Quoc Truong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting pairwise preferences between TTS audio stimuli using parallel ratings data and anti-symmetric twin neural networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10132",
        "paper_authors": [
            "Cassia Valentini-Botinhao",
            "Manuel Sam Ribeiro",
            "Oliver Watts",
            "Korin Richmond",
            "Gustav Eje Henter"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Automatic Soundtracking System for Text-to-Speech Audiobooks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10236",
        "paper_authors": [
            "Zikai Chen",
            "Lin Wu",
            "Junjie Pan",
            "Xiang Yin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Environment Aware Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10348",
        "paper_authors": [
            "Daxin Tan",
            "Guangyan Zhang",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SoundChoice: Grapheme-to-Phoneme Models with Semantic Disambiguation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11066",
        "paper_authors": [
            "Artem Ploujnikov",
            "Mirco Ravanelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Shallow Fusion of Weighted Finite-State Transducer and Language Model for Text Normalization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11074",
        "paper_authors": [
            "Evelina Bakhturina",
            "Yang Zhang",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosodic alignment for off-screen automatic dubbing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11089",
        "paper_authors": [
            "Yogesh Virkar",
            "Marcello Federico",
            "Robert Enyedi",
            "Roberto Barra-Chicote"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Study of Modeling Rising Intonation in Cantonese Neural Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11173",
        "paper_authors": [
            "Qibing Bai",
            "Tom Ko",
            "Yu Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CAUSE: Crossmodal Action Unit Sequence Estimation from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11232",
        "paper_authors": [
            "Hirokazu Kameoka",
            "Takuhiro Kaneko",
            "Shogo Seki",
            "Kou Tanaka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visualising Model Training via Vowel Space for Text-To-Speech Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-264",
        "paper_authors": [
            "Binu Nisal Abeysinghe",
            "Jesin James",
            "Catherine I. Watson",
            "Felix Marattukalam"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Binary Early-Exit Network for Adaptive Inference on Low-Resource Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-17",
        "paper_authors": [
            "Aaqib Saeed"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Speaker-Attributed ASR with Token-Level Speaker Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-253",
        "paper_authors": [
            "Naoyuki Kanda",
            "Jian Wu",
            "Yu Wu",
            "Xiong Xiao",
            "Zhong Meng",
            "Xiaofei Wang",
            "Yashesh Gaur",
            "Zhuo Chen",
            "Jinyu Li",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker consistency loss and step-wise optimization for semi-supervised joint training of TTS and ASR using unpaired text data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-304",
        "paper_authors": [
            "Naoki Makishima",
            "Satoshi Suzuki",
            "Atsushi Ando",
            "Ryo Masumura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Generalized Few-Shot Learning with Prototype-Based Co-Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-652",
        "paper_authors": [
            "Yi-Kai Zhang",
            "Da-Wei Zhou",
            "Han-Jia Ye",
            "De-Chuan Zhan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Federated Domain Adaptation for ASR with Full Self-Supervision",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-803",
        "paper_authors": [
            "Junteng Jia",
            "Jay Mahadeokar",
            "Weiyi Zheng",
            "Yuan Shangguan",
            "Ozlem Kalinli",
            "Frank Seide"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Augmented Adversarial Self-Supervised Learning for Early-Stage Alzheimer's Speech Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-943",
        "paper_authors": [
            "Longfei Yang",
            "Wenqing Wei",
            "Sheng Li",
            "Jiyi Li",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extending RNN-T-based speech recognition systems with emotion and language classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10480",
        "paper_authors": [
            "Zvi Kons",
            "Hagai Aronowitz",
            "Edmilson da Silva Morais",
            "Matheus Damasceno",
            "Hong-Kwang Kuo",
            "Samuel Thomas",
            "George Saon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Thutmose Tagger: Single-pass neural model for Inverse Text Normalization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10864",
        "paper_authors": [
            "Alexandra Antonova",
            "Evelina Bakhturina",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Prosody for Punctuation Prediction of Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11061",
        "paper_authors": [
            "Yeonjin Cho",
            "Sara Ng",
            "Trang Tran",
            "Mari Ostendorf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Comparative Study on Speaker-attributed Automatic Speech Recognition in Multi-party Meetings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11210",
        "paper_authors": [
            "Fan Yu",
            "Zhihao Du",
            "Shiliang Zhang",
            "Yuxiao Lin",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TMGAN-PLC: Audio Packet Loss Concealment using Temporal Memory Generative Adversarial Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-644",
        "paper_authors": [
            "Yuansheng Guan",
            "Guochen Yu",
            "Andong Li",
            "Chengshi Zheng",
            "Jie Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time Packet Loss Concealment With Mixed Generative and Predictive Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-903",
        "paper_authors": [
            "Jean-Marc Valin",
            "Ahmed Mustafa",
            "Christopher Montgomery",
            "Timothy B. Terriberry",
            "Michael Klingbeil",
            "Paris Smaragdis",
            "Arvindh Krishnaswamy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PLCNet: Real-time Packet Loss Concealment with Semi-supervised Generative Adversarial Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10428",
        "paper_authors": [
            "Baiyun Liu",
            "Qi Song",
            "Mingxue Yang",
            "Wuwen Yuan",
            "Tianbao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "INTERSPEECH 2022 Audio Deep Packet Loss Concealment Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10829",
        "paper_authors": [
            "Lorenz Diener",
            "Sten Sootla",
            "Solomiya Branets",
            "Ando Saabas",
            "Robert Aichner",
            "Ross Cutler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Multi-Loss Training for Low Delay Packet Loss Concealment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11439",
        "paper_authors": [
            "Nan Li",
            "Xiguang Zheng",
            "Chen Zhang",
            "Liang Guo",
            "Bing Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extended U-Net for Speaker Verification in Noisy Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-155",
        "paper_authors": [
            "Ju-ho Kim",
            "Jungwoo Heo",
            "Hye-jin Shim",
            "Ha-Jin Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Agnostic Few-shot Learning for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-940",
        "paper_authors": [
            "Seunghan Yang",
            "Debasmit Das",
            "Janghoon Cho",
            "Hyoungwoo Park",
            "Sungrack Yun"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scoring of Large-Margin Embeddings for Speaker Verification: Cosine or PLDA?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10055",
        "paper_authors": [
            "Qiongqiong Wang",
            "Kong Aik Lee",
            "Tianchi Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training speaker embedding extractors using multi-speaker audio with unknown speaker boundaries",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10165",
        "paper_authors": [
            "Themos Stafylakis",
            "Ladislav Mosner",
            "Oldrich Plchot",
            "Johan Rohdin",
            "Anna Silnova",
            "Luk\u00e1s Burget",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the contribution of speaker attributes to speaker separability using disentangled speaker representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10643",
        "paper_authors": [
            "Chau Luu",
            "Steve Renals",
            "Peter Bell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint domain adaptation and speech bandwidth extension using time-domain GANs for speaker verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10900",
        "paper_authors": [
            "Saurabh Kataria",
            "Jes\u00fas Villalba",
            "Laureano Moro-Vel\u00e1zquez",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variability in Production of Non-Sibilant Fricative [\u00e7] in /hi/",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-303",
        "paper_authors": [
            "Tsukasa Yoshinaga",
            "Kikuo Maekawa",
            "Akiyoshi Iida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming model for Acoustic to Articulatory Inversion with transformer networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10159",
        "paper_authors": [
            "Sathvik Udupa",
            "Aravind Illa",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trajectories predicted by optimal speech motor control using LSTM networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10604",
        "paper_authors": [
            "Tsiky Rakotomalala",
            "Pierre Baraduc",
            "Pascal Perrier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploration strategies for articulatory synthesis of complex syllable onsets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10689",
        "paper_authors": [
            "Daniel R. van Niekerk",
            "Anqi Xu",
            "Branislav Gerazov",
            "Paul Konstantin Krug",
            "Peter Birkholz",
            "Yi Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Linguistic versus biological factors governing acoustic voice variation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10847",
        "paper_authors": [
            "Yoonjeong Lee",
            "Jody Kreiman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acquisition of allophonic variation in second language speech: An acoustic and articulatory study of English laterals by Japanese speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11020",
        "paper_authors": [
            "Takayuki Nagamine"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SAQAM: Spatial Audio Quality Assessment Metric",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-406",
        "paper_authors": [
            "Pranay Manocha",
            "Anurag Kumar",
            "Buye Xu",
            "Anjali Menon",
            "Israel Dejene Gebru",
            "Vamsi Krishna Ithapu",
            "Paul Calamia"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Quality Assessment through MOS using Non-Matching References",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-407",
        "paper_authors": [
            "Pranay Manocha",
            "Anurag Kumar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An objective test tool for pitch extractors' response attributes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-800",
        "paper_authors": [
            "Hideki Kawahara",
            "Kohei Yatabe",
            "Ken-Ichi Sakakibara",
            "Tatsuya Kitamura",
            "Hideki Banno",
            "Masanori Morise"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation Using McAdams-Coefficient-Based Speaker Anonymization for Fake Audio Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10088",
        "paper_authors": [
            "Kai Li",
            "Sheng Li",
            "Xugang Lu",
            "Masato Akagi",
            "Meng Liu",
            "Lin Zhang",
            "Chang Zeng",
            "Longbiao Wang",
            "Jianwu Dang",
            "Masashi Unoki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Data Augmentation Selection and Parametrization in Contrastive Self-Supervised Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10191",
        "paper_authors": [
            "Salah Zaiem",
            "Titouan Parcollet",
            "Slim Essid"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer-based quality assessment model for generalized user-generated multimedia audio content",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10386",
        "paper_authors": [
            "Deebha Mumtaz",
            "Ajit Jena",
            "Vinit Jakhetiya",
            "Karan Nathwani",
            "Sharath Chandra Guntuku"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Space-Efficient Representation of Entity-centric Query Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-193",
        "paper_authors": [
            "Christophe Van Gysel",
            "Mirko Hannemann",
            "Ernest Pusateri",
            "Youssef Oualil",
            "Ilya Oparin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Prompts: Towards memory and compute efficient domain adaptation of ASR systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-824",
        "paper_authors": [
            "Saket Dingliwal",
            "Ashish Shenoy",
            "Sravan Bodapati",
            "Ankur Gandhe",
            "Ravi Teja Gadde",
            "Katrin Kirchhoff"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10820",
        "paper_authors": [
            "W. Ronny Huang",
            "Cal Peyser",
            "Tara N. Sainath",
            "Ruoming Pang",
            "Trevor D. Strohman",
            "Shankar Kumar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UserLibri: A Dataset for ASR Personalization Using Only Text",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10915",
        "paper_authors": [
            "Theresa Breiner",
            "Swaroop Ramaswamy",
            "Ehsan Variani",
            "Shefali Garg",
            "Rajiv Mathews",
            "Khe Chai Sim",
            "Kilol Gupta",
            "Mingqing Chen",
            "Lara McConnaughey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A BERT-based Language Modeling Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11266",
        "paper_authors": [
            "Chin-Yueh Chien",
            "Kuan-Yu Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Optimization of Sampling Rate Offsets Based on Entire Signal Relationship Among Distributed Microphones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-97",
        "paper_authors": [
            "Yoshiki Masuyama",
            "Kouei Yamaoka",
            "Nobutaka Ono"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Challenges and Opportunities in Multi-device Speech Processing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-119",
        "paper_authors": [
            "Gregory Ciccarelli",
            "Jarred Barber",
            "Arun Nair",
            "Israel Cohen",
            "Tao Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Practical Over-the-air Perceptual AcousticWatermarking",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-183",
        "paper_authors": [
            "Ameya Agaskar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Clustering-based Wake Word Detection in Privacy-aware Acoustic Sensor Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-842",
        "paper_authors": [
            "Timm Koppelmann",
            "Luca Becker",
            "Alexandru Nelus",
            "Rene Glitza",
            "Lea Sch\u00f6nherr",
            "Rainer Martin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relative Acoustic Features for Distance Estimation in Smart-Homes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10925",
        "paper_authors": [
            "Francesco Nespoli",
            "Daniel Barreda",
            "Patrick A. Naylor"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Time-domain Ad-hoc Array Speech Enhancement Using a Triple-path Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11215",
        "paper_authors": [
            "Ashutosh Pandey",
            "Buye Xu",
            "Anurag Kumar",
            "Jacob Donley",
            "Paul Calamia",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relationship between the acoustic time intervals and tongue movements of German diphthongs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-73",
        "paper_authors": [
            "Arne-Lukas Fietkau",
            "Simon Stone",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Development of allophonic realization until adolescence: A production study of the affricate-fricative variation of /z/ among Japanese children",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-346",
        "paper_authors": [
            "Sanae Matsui",
            "Kyoji Iwamoto",
            "Reiko Mazuka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recurrent multi-head attention fusion network for combining audio and text for speech emotion recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-888",
        "paper_authors": [
            "Chung Soo Ahn",
            "L. L. Chamara Kasun",
            "Sunil Sivadas",
            "Jagath C. Rajapakse"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-Level Physiological Implications of End-to-End Learning for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10093",
        "paper_authors": [
            "Louise Coppieters de Gibson",
            "Philip N. Garner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Idiosyncratic lingual articulation of American English /\u00e6/ and /\u0251/ using network analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10397",
        "paper_authors": [
            "Carolina Lins Machado",
            "Volker Dellwo",
            "Lei He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Method for improving the word intelligibility of presented speech using bone-conduction headphones",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10463",
        "paper_authors": [
            "Teruki Toya",
            "Wenyu Zhu",
            "Maori Kobayashi",
            "Kenichi Nakamura",
            "Masashi Unoki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Three-dimensional finite-difference time-domain acoustic analysis of simplified vocal tract shapes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10649",
        "paper_authors": [
            "Debasish Ray Mohapatra",
            "Mario Fleischer",
            "Victor Zappi",
            "Peter Birkholz",
            "Sidney S. Fels"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech imitation skills predict automatic phonetic convergence: a GMM-UBM study on L2",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10684",
        "paper_authors": [
            "Dorina De Jong",
            "Aldo Pastore",
            "No\u00ebl Nguyen",
            "Alessandro D'Ausilio"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-supervised speech unit discovery from articulatory and acoustic features using VQ-VAE",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10876",
        "paper_authors": [
            "Marc-Antoine Georges",
            "Jean-Luc Schwartz",
            "Thomas Hueber"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Speech Synthesis from Articulatory Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10892",
        "paper_authors": [
            "Peter Wu",
            "Shinji Watanabe",
            "Louis Goldstein",
            "Alan W. Black",
            "Gopala Krishna Anumanchipalli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Orofacial somatosensory inputs in speech perceptual training modulate speech production",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10993",
        "paper_authors": [
            "Monica Ashokumar",
            "Jean-Luc Schwartz",
            "Takayuki Ito"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-225",
        "paper_authors": [
            "Minchan Kim",
            "Myeonghun Jeong",
            "Byoung Jin Choi",
            "Sunghwan Ahn",
            "Joun Yeop Lee",
            "Nam Soo Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DRSpeech: Degradation-Robust Text-to-Speech Synthesis with Frame-Level and Utterance-Level Acoustic Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-294",
        "paper_authors": [
            "Takaaki Saeki",
            "Kentaro Tachibana",
            "Ryuichi Yamamoto"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MSR-NV: Neural Vocoder Using Multiple Sampling Rates",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-295",
        "paper_authors": [
            "Kentaro Mitsui",
            "Kei Sawada"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-301",
        "paper_authors": [
            "Yuma Koizumi",
            "Heiga Zen",
            "Kohei Yatabe",
            "Nanxin Chen",
            "Michiel Bacchiani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bunched LPCNet2: Efficient Neural Vocoders Covering Devices from Cloud to Edge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-310",
        "paper_authors": [
            "Sangjun Park",
            "Kihyun Choo",
            "Joohyung Lee",
            "Anton V. Porov",
            "Konstantin Osipov",
            "June Sig Sung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical and Multi-Scale Variational Autoencoder for Diverse and Natural Non-Autoregressive Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-737",
        "paper_authors": [
            "Jae-Sung Bae",
            "Jinhyeok Yang",
            "Taejun Bak",
            "Young-Sun Joo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-end LPCNet: A Neural Vocoder With Fully-Differentiable LPC Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-912",
        "paper_authors": [
            "Krishna Subramani",
            "Jean-Marc Valin",
            "Umut Isik",
            "Paris Smaragdis",
            "Arvindh Krishnaswamy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EPIC TTS Models: Empirical Pruning Investigations Characterizing Text-To-Speech Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10626",
        "paper_authors": [
            "Perry Lam",
            "Huayun Zhang",
            "Nancy F. Chen",
            "Berrak Sisman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fine-grained Noise Control for Multispeaker Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10765",
        "paper_authors": [
            "Karolos Nikitaras",
            "Georgios Vamvoukakis",
            "Nikolaos Ellinas",
            "Konstantinos Klapsas",
            "Konstantinos Markopoulos",
            "Spyros Raptis",
            "June Sig Sung",
            "Gunu Jho",
            "Aimilios Chalamandaris",
            "Pirros Tsiakoulis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WavThruVec: Latent speech representation as intermediate features for neural speech synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10797",
        "paper_authors": [
            "Hubert Siuzdak",
            "Piotr Dura",
            "Pol van Rijn",
            "Nori Jacoby"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fast Grad-TTS: Towards Efficient Diffusion-Based Speech Generation on CPU",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10889",
        "paper_authors": [
            "Ivan Vovk",
            "Tasnima Sadekova",
            "Vladimir Gogoryan",
            "Vadim Popov",
            "Mikhail A. Kudinov",
            "Jiansheng Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simple and Effective Unsupervised Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11071",
        "paper_authors": [
            "Alexander H. Liu",
            "Cheng-I Lai",
            "Wei-Ning Hsu",
            "Michael Auli",
            "Alexei Baevski",
            "James R. Glass"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unified Source-Filter GAN with Harmonic-plus-Noise Source Excitation Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11130",
        "paper_authors": [
            "Reo Yoneyama",
            "Yi-Chiao Wu",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NeMo Open Source Speaker Diarization System",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/park22e_interspeech.html",
        "paper_authors": [
            "Taejin Park",
            "Nithin Rao Koluguri",
            "Fei Jia",
            "Jagadeesh Balam",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice2Alliance: Automatic Speaker Diarization and Quality Assurance of Conversational Alignment",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/lin22e_interspeech.html",
        "paper_authors": [
            "Baihan Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VAgyojaka: An Annotating and Post-Editing Tool for Automatic Speech Recognition",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/kumar22d_interspeech.html",
        "paper_authors": [
            "Rishabh Kumar",
            "Devaraja Adiga",
            "Mayank Kothyari",
            "Jatin Dalal",
            "Ganesh Ramakrishnan",
            "Preethi Jyothi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SKYE: More than a conversational AI",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/badi22_interspeech.html",
        "paper_authors": [
            "Alzahra Badi",
            "Chungho Park",
            "Min-Seok Keum",
            "Miguel Alba",
            "Youngsuk Ryu",
            "Jeongmin Bae"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training Data Generation with DOA-based Selecting and Remixing for Unsupervised Training of Deep Separation Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-69",
        "paper_authors": [
            "Hokuto Munakata",
            "Ryu Takeda",
            "Kazunori Komatani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Beam-Guided TasNet: An Iterative Speech Separation Framework with Multi-Channel Output",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-230",
        "paper_authors": [
            "Hangting Chen",
            "Yi Yang",
            "Feng Dang",
            "Pengyuan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Estimation of Direction-of-Arrival and Distance for Arrays with Directional Sensors based on Sparse Bayesian Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-497",
        "paper_authors": [
            "Feifei Xiong",
            "Pengyu Wang",
            "Zhongfu Ye",
            "Jinwei Feng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How to Listen? Rethinking Visual Sound Localization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-520",
        "paper_authors": [
            "Ho-Hsiang Wu",
            "Magdalena Fuentes",
            "Prem Seetharaman",
            "Juan Pablo Bello"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Small Footprint Neural Networks for Acoustic Direction of Arrival Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-979",
        "paper_authors": [
            "Zhiheng Ouyang",
            "Miao Wang",
            "Wei-Ping Zhu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Modal Multi-Correlation Learning for Audio-Visual Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10229",
        "paper_authors": [
            "Xiaoyu Wang",
            "Xiangyu Kong",
            "Xiulian Peng",
            "Yan Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MIMO-DoAnet: Multi-channel Input and Multiple Outputs DoA Network with Unknown Number of Sound Sources",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10493",
        "paper_authors": [
            "Haoran Yin",
            "Meng Ge",
            "Yanjie Fu",
            "Gaoyan Zhang",
            "Longbiao Wang",
            "Lei Zhang",
            "Lin Qiu",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Iterative Sound Source Localization for Unknown Number of Sources",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10525",
        "paper_authors": [
            "Yanjie Fu",
            "Meng Ge",
            "Haoran Yin",
            "Xinyuan Qian",
            "Longbiao Wang",
            "Gaoyan Zhang",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distance-Based Sound Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11100",
        "paper_authors": [
            "Katharine Patterson",
            "Kevin W. Wilson",
            "Scott Wisdom",
            "John R. Hershey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VCSE: Time-Domain Visual-Contextual Speaker Extraction Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11183",
        "paper_authors": [
            "Junjie Li",
            "Meng Ge",
            "Zexu Pan",
            "Longbiao Wang",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TRUNet: Transformer-Recurrent-U Network for Multi-channel Reverberant Sound Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11386",
        "paper_authors": [
            "Ali Aroudi",
            "Stefan Uhlich",
            "Marc Ferras Font"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PercepNet+: A Phase and SNR Aware PercepNet for Real-Time Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-43",
        "paper_authors": [
            "Xiaofeng Ge",
            "Jiangyu Han",
            "Yanhua Long",
            "Haixin Guan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lightweight Full-band and Sub-band Fusion Network for Real Time Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-153",
        "paper_authors": [
            "Zhuangqi Chen",
            "Pingjian Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Layer Similarity Knowledge Distillation for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-429",
        "paper_authors": [
            "Jiaming Cheng",
            "Ruiyu Liang",
            "Yue Xie",
            "Li Zhao",
            "Bj\u00f6rn W. Schuller",
            "Jie Jia",
            "Yiyuan Peng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spectro-Temporal SubNet for Real-Time Monaural Speech Denoising and Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-468",
        "paper_authors": [
            "Feifei Xiong",
            "Weiguang Chen",
            "Pengyu Wang",
            "Xiaofei Li",
            "Jinwei Feng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CMGAN: Conformer-based Metric GAN for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-517",
        "paper_authors": [
            "Ruizhe Cao",
            "Sherif Abdulatif",
            "Bin Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Model Compression by Iterative Pruning with Knowledge Distillation and Its Application to Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-619",
        "paper_authors": [
            "Zeyuan Wei",
            "Li Hao",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Single-channel speech enhancement using Graph Fourier Transform",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-740",
        "paper_authors": [
            "Chenhui Zhang",
            "Xiang Pan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Optimization of the Module and Sign of the Spectral Real Part Based on CRN for Speech Denoising",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-778",
        "paper_authors": [
            "Zilu Guo",
            "Xu Xu",
            "Zhongfu Ye"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attentive Recurrent Network for Low-Latency Active Noise Control",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-811",
        "paper_authors": [
            "Hao Zhang",
            "Ashutosh Pandey",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Memory-Efficient Multi-Step Speech Enhancement with Neural ODE",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-868",
        "paper_authors": [
            "Jen-Hung Huang",
            "Chung-Hsien Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GLD-Net: Improving Monaural Speech Enhancement by Learning Global and Local Dependency Features with GLD Block",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10034",
        "paper_authors": [
            "Xinmeng Xu",
            "Yang Wang",
            "Jie Jia",
            "Binbin Chen",
            "Jianjun Hao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Visual Speech Enhancement Network by Learning Audio-visual Affinity with Multi-head Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10041",
        "paper_authors": [
            "Xinmeng Xu",
            "Yang Wang",
            "Jie Jia",
            "Binbin Chen",
            "Dejun Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Enhancement with Fullband-Subband Cross-Attention Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10257",
        "paper_authors": [
            "Jun Chen",
            "Wei Rao",
            "Zilin Wang",
            "Zhiyong Wu",
            "Yannan Wang",
            "Tao Yu",
            "Shidong Shang",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OSSEM: one-shot speaker adaptive speech enhancement using meta learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10283",
        "paper_authors": [
            "Cheng Yu",
            "Szu-Wei Fu",
            "Tsun-An Hsieh",
            "Yu Tsao",
            "Mirco Ravanelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Speech Enhancement with Neural Homomorphic Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10411",
        "paper_authors": [
            "Wenbin Jiang",
            "Tao Liu",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fast Real-time Personalized Speech Enhancement: End-to-End Enhancement Network (E3Net) and Knowledge Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10962",
        "paper_authors": [
            "Manthan Thakker",
            "Sefik Emre Eskimez",
            "Takuya Yoshioka",
            "Huaming Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Strategies to Improve Robustness of Target Speech Extraction to Enrollment Variations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10767",
        "paper_authors": [
            "Hiroshi Sato",
            "Tsubasa Ochiai",
            "Marc Delcroix",
            "Keisuke Kinoshita",
            "Takafumi Moriya",
            "Naoki Makishima",
            "Mana Ihori",
            "Tomohiro Tanaka",
            "Ryo Masumura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FedNST: Federated Noisy Student Training for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-252",
        "paper_authors": [
            "Haaris Mehmood",
            "Agnieszka Dobrowolska",
            "Karthikeyan Saravanan",
            "Mete Ozay"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SCaLa: Supervised Contrastive Learning for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-412",
        "paper_authors": [
            "Li Fu",
            "Xiaoxiao Li",
            "Runyu Wang",
            "Lu Fan",
            "Zhengchen Zhang",
            "Meng Chen",
            "Youzheng Wu",
            "Xiaodong He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NAS-SCAE: Searching Compact Attention-based Encoders For End-to-end Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-748",
        "paper_authors": [
            "Yukun Liu",
            "Ta Li",
            "Pengyuan Zhang",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Acoustic Contextual Representation by Audio-textual Cross-modal Learning for Conversational ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10326",
        "paper_authors": [
            "Kun Wei",
            "Yike Zhang",
            "Sining Sun",
            "Lei Xie",
            "Long Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PM-MMUT: Boosted Phone-mask Data Augmentation using Multi-Modeling Unit Training for Phonetic-Reduction-Robust E2E Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10422",
        "paper_authors": [
            "Guodong Ma",
            "Pengfei Hu",
            "Nurmemet Yolwas",
            "Shen Huang",
            "Hao Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis of Self-Attention Head Diversity for Conformer-based Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10560",
        "paper_authors": [
            "Kartik Audhkhasi",
            "Yinghui Huang",
            "Bhuvana Ramabhadran",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Rare Word Recognition with LM-aware MWER Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10660",
        "paper_authors": [
            "Weiran Wang",
            "Tongzhou Chen",
            "Tara N. Sainath",
            "Ehsan Variani",
            "Rohit Prabhavalkar",
            "W. Ronny Huang",
            "Bhuvana Ramabhadran",
            "Neeraj Gaur",
            "Sepand Mavandadi",
            "Cal Peyser",
            "Trevor Strohman",
            "Yanzhang He",
            "David Rybach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving the Training Recipe for a Robust Conformer-based Hybrid Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10723",
        "paper_authors": [
            "Mohammad Zeineldeen",
            "Jingjing Xu",
            "Christoph L\u00fcscher",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CTC Variations Through New WFST Topologies",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10854",
        "paper_authors": [
            "Aleksandr Laptev",
            "Somshubra Majumdar",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dealing with Unknowns in Continual Learning for End-to-end Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11139",
        "paper_authors": [
            "Martin Sustek",
            "Samik Sadhu",
            "Hynek Hermansky"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Efficiently Learning Monotonic Alignments for Attention-based End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11259",
        "paper_authors": [
            "Chenfeng Miao",
            "Kun Zou",
            "Ziyang Zhuang",
            "Tao Wei",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On monoaural speech enhancement for automatic recognition of real noisy speech using mixture invariant training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11359",
        "paper_authors": [
            "Jisi Zhang",
            "Catalin Zorila",
            "Rama Doddipatla",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "From Undercomplete to Sparse Overcomplete Autoencoders to Improve LF-MMI based Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11390",
        "paper_authors": [
            "Selen Hande Kabil",
            "Herv\u00e9 Bourlard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Adversarial Self-Supervised Speech Representation Learning for Improving Unknown Domain Downstream Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11414",
        "paper_authors": [
            "Tomohiro Tanaka",
            "Ryo Masumura",
            "Hiroshi Sato",
            "Mana Ihori",
            "Kohei Matsuura",
            "Takanori Ashihara",
            "Takafumi Moriya"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention Weight Smoothing Using Prior Distributions for Transformer-Based End-to-End ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11441",
        "paper_authors": [
            "Takashi Maekaku",
            "Yuya Fujita",
            "Yifan Peng",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reducing Offensive Replies in Open Domain Dialogue Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-200",
        "paper_authors": [
            "Naokazu Uchida",
            "Takeshi Homma",
            "Makoto Iwayama",
            "Yasuhiro Sogawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Induce Spoken Dialog Intents via Deep Unsupervised Context Contrastive Clustering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-240",
        "paper_authors": [
            "Ting-Wei Wu",
            "Biing-Hwang Juang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dialogue Acts Aided Important Utterance Detection Based on Multiparty and Multimodal Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-324",
        "paper_authors": [
            "Fumio Nihei",
            "Ryo Ishii",
            "Yukiko I. Nakano",
            "Kyosuke Nishida",
            "Ryo Masumura",
            "Atsushi Fukayama",
            "Takao Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextual Acoustic Barge-In Classification for Spoken Dialog Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-408",
        "paper_authors": [
            "Dhanush Bekal",
            "Sundararajan Srinivasan",
            "Srikanth Ronanki",
            "Sravan Bodapati",
            "Katrin Kirchhoff"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Calibrate and Refine! A Novel and Agile Framework for ASR Error Robust Intent Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-786",
        "paper_authors": [
            "Peilin Zhou",
            "Dading Chong",
            "Helin Wang",
            "Qingcheng Zeng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR-Robust Natural Language Understanding on ASR-GLUE dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10097",
        "paper_authors": [
            "Lingyun Feng",
            "Jianwei Yu",
            "Yan Wang",
            "Songxiang Liu",
            "Deng Cai",
            "Haitao Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "From Disfluency Detection to Intent Detection and Slot Filling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10161",
        "paper_authors": [
            "Mai Hoang Dao",
            "Thinh Hung Truong",
            "Dat Quoc Nguyen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Wake Word Spotting in MISP2021 Challenge: Dataset Release and Deep Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10650",
        "paper_authors": [
            "Hengshun Zhou",
            "Jun Du",
            "Gongzhen Zou",
            "Zhaoxu Nian",
            "Chin-Hui Lee",
            "Sabato Marco Siniscalchi",
            "Shinji Watanabe",
            "Odette Scharenborg",
            "Jingdong Chen",
            "Shifu Xiong",
            "Jianqing Gao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extending Compositional Attention Networks for Social Reasoning in Videos",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10858",
        "paper_authors": [
            "Christina Sartzetaki",
            "Georgios Paraskevopoulos",
            "Alexandros Potamianos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TopicKS: Topic-driven Knowledge Selection for Knowledge-grounded Dialogue Generation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11188",
        "paper_authors": [
            "Shiquan Wang",
            "Yuke Si",
            "Xiao Wei",
            "Longbiao Wang",
            "Zhiqiang Zhuang",
            "Xiaowang Zhang",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bottom-up discovery of structure and variation in response tokens ('backchannels') across diverse languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11288",
        "paper_authors": [
            "Andreas Liesenfeld",
            "Mark Dingemanse"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-modal Transfer Learning via Multi-grained Alignment for End-to-End Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11378",
        "paper_authors": [
            "Yi Zhu",
            "Zexun Wang",
            "Hang Liu",
            "Peiying Wang",
            "Mingchao Feng",
            "Meng Chen",
            "Xiaodong He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Use of Nods Less Synchronized with Turn-Taking and Prosody During Conversations in Adults with Autism",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11388",
        "paper_authors": [
            "Keiko Ochi",
            "Nobutaka Ono",
            "Keiho Owada",
            "Miho Kuroda",
            "Shigeki Sagayama",
            "Hidenori Yamasue"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DAVIS: Driver's Audio-Visual Speech recognition",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/ivanko22_interspeech.html",
        "paper_authors": [
            "Denis Ivanko",
            "Dmitry Ryumin",
            "Alexey M. Kashevnik",
            "Alexandr Axyonov",
            "Andrey Kitenko",
            "Igor Lashkov",
            "Alexey Karpov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis of Self-Supervised Learning and Dimensionality Reduction Methods in Clustering-Based Active Learning for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-329",
        "paper_authors": [
            "Einari Vaaras",
            "Manu Airaksinen",
            "Okko R\u00e4s\u00e4nen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emotion-Shift Aware CRF for Decoding Emotion Sequence in Conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10438",
        "paper_authors": [
            "Chun-Yu Chen",
            "Yun-Shao Lin",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vaccinating SER to Neutralize Adversarial Attacks with Self-Supervised Augmentation Strategy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10453",
        "paper_authors": [
            "Bo-Hao Su",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion Recognition in the Wild using Multi-task and Adversarial Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10581",
        "paper_authors": [
            "Jack Parry",
            "Eric DeMattos",
            "Anita Klementiev",
            "Axel Ind",
            "Daniela Morse-Kopp",
            "Georgia Clarke",
            "Dimitri Palaz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Magnitude and Phase based Speech Representation Learning using Autoencoder for Classifying Speech Emotions using Deep Canonical Correlation Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10769",
        "paper_authors": [
            "Ashishkumar Prabhakar Gudmalwar",
            "Biplove Basel",
            "Anirban Dutta",
            "Ch V. Rama Rao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Speech Emotion Recognition Using Self-Supervised Learning with Domain-Specific Audiovisual Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11012",
        "paper_authors": [
            "Lucas Goncalves",
            "Carlos Busso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SNRi Target Training for Joint Speech Enhancement and Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-302",
        "paper_authors": [
            "Yuma Koizumi",
            "Shigeki Karita",
            "Arun Narayanan",
            "Sankaran Panchapagesan",
            "Michiel Bacchiani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Self-Supervised Learning of Speech Denoising from Noisy Speeches",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-306",
        "paper_authors": [
            "Yutaro Sanada",
            "Takumi Nakagawa",
            "Yuichiro Wada",
            "Kosaku Takanashi",
            "Yuhui Zhang",
            "Kiichi Tokuyama",
            "Takafumi Kanamori",
            "Tomonori Yamada"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NASTAR: Noise Adaptive Speech Enhancement with Target-Conditional Resampling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-527",
        "paper_authors": [
            "Chi-Chang Lee",
            "Cheng-Hung Hu",
            "Yu-Chen Lin",
            "Chu-Song Chen",
            "Hsin-Min Wang",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FFC-SE: Fast Fourier Convolution for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-603",
        "paper_authors": [
            "Ivan Shchekotov",
            "Pavel K. Andreev",
            "Oleg Ivanov",
            "Aibek Alanov",
            "Dmitry P. Vetrov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Systematic Comparison of Phonetic Aware Techniques for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-695",
        "paper_authors": [
            "Or Tal",
            "Moshe Mandel",
            "Felix Kreuk",
            "Yossi Adi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-View Attention Transfer for Efficient Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10251",
        "paper_authors": [
            "WooSeok Shin",
            "Hyun Joon Park",
            "Jin Sob Kim",
            "Byung Hoon Lee",
            "Sung Won Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SATTS: Speaker Attractor Text to Speech, Learning to Speak by Learning to Separate",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-133",
        "paper_authors": [
            "Nabarun Goswami",
            "Tatsuya Harada"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Correcting Mispronunciations in Speech using Spectrogram Inpainting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-615",
        "paper_authors": [
            "Talia Ben Simon",
            "Felix Kreuk",
            "Faten Awwad",
            "Jacob T. Cohen",
            "Joseph Keshet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Audio Corrector: using speech from non-target speakers for one-off correction of mispronunciations in grapheme-input text-to-speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10138",
        "paper_authors": [
            "Jason Fong",
            "Daniel Lyth",
            "Gustav Eje Henter",
            "Hao Tang",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Binaural Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10603",
        "paper_authors": [
            "Wen-Chin Huang",
            "Dejan Markovic",
            "Alexander Richard",
            "Israel Dejene Gebru",
            "Anjali Menon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PoeticTTS - Controllable Poetry Reading for Literary Studies",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10841",
        "paper_authors": [
            "Julia Koch",
            "Florian Lux",
            "Nadja Schauffler",
            "Toni Bernhart",
            "Felix Dieterle",
            "Jonas Kuhn",
            "Sandra Richter",
            "Gabriel Viehhauser",
            "Ngoc Thang Vu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Articulatory Synthesis for Data Augmentation in Phoneme Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10874",
        "paper_authors": [
            "Paul Konstantin Krug",
            "Peter Birkholz",
            "Branislav Gerazov",
            "Daniel Rudolph van Niekerk",
            "Anqi Xu",
            "Yi Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SF-DST: Few-Shot Self-Feeding Reading Comprehension Dialogue State Tracking with Auxiliary Task",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-380",
        "paper_authors": [
            "Jihyun Lee",
            "Gary Geunbae Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Benchmarking Transformers-based models on French Spoken Language Understanding tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-385",
        "paper_authors": [
            "Oralie Cattan",
            "Sahar Ghannay",
            "Christophe Servan",
            "Sophie Rosset"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot Filling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-839",
        "paper_authors": [
            "Seong-Hwan Heo",
            "WonKee Lee",
            "Jong-Hyeok Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bottleneck Low-rank Transformers for Low-resource Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10801",
        "paper_authors": [
            "Pu Wang",
            "Hugo Van hamme"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On joint training with interfaces for spoken language understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11067",
        "paper_authors": [
            "Anirudh Raju",
            "Milind Rao",
            "Gautam Tiwari",
            "Pranav Dheram",
            "Bryan Anderson",
            "Zhe Zhang",
            "Chul Lee",
            "Bach Bui",
            "Ariya Rastrow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Device-Directed Speech Detection: Regularization via Distillation for Weakly-Supervised Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11228",
        "paper_authors": [
            "Vineet Garg",
            "Ognjen Rudovic",
            "Pranay Dighe",
            "Ahmed Hussen Abdelaziz",
            "Erik Marchi",
            "Saurabh Adya",
            "Chandra Dhir",
            "Ahmed H. Tewfik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Building African Voices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-152",
        "paper_authors": [
            "Perez Ogayo",
            "Graham Neubig",
            "Alan W. Black"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Fairness in Speech Recognition: Discovery and mitigation of performance disparities",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10816",
        "paper_authors": [
            "Pranav Dheram",
            "Murugesan Ramakrishnan",
            "Anirudh Raju",
            "I-Fan Chen",
            "Brian King",
            "Katherine Powell",
            "Melissa Saboowala",
            "Karan Shetty",
            "Andreas Stolcke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training and typological bias in ASR performance for world Englishes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10869",
        "paper_authors": [
            "May Pik Yu Chan",
            "June Choe",
            "Aini Li",
            "Yiran Chen",
            "Xin Gao",
            "Nicole R. Holliday"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Study of Gender Impact in Self-supervised Models for Speech-to-Text Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-353",
        "paper_authors": [
            "Marcely Zanon Boito",
            "Laurent Besacier",
            "Natalia A. Tomashenko",
            "Yannick Est\u00e8ve"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Dialect Density Estimation for African American English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-796",
        "paper_authors": [
            "Alexander Johnson",
            "Kevin Everson",
            "Vijay Ravi",
            "Anissa Gladney",
            "Mari Ostendorf",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Language Identification of Accented Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10455",
        "paper_authors": [
            "Kunnar Kukk",
            "Tanel Alum\u00e4e"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Design Guidelines for Inclusive Speaker Verification Evaluation Datasets",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10799",
        "paper_authors": [
            "Wiebke Toussaint",
            "Lauriane Gorce",
            "Aaron Yi Ding"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reducing Geographic Disparities in Automatic Speech Recognition via Elastic Weight Consolidation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11063",
        "paper_authors": [
            "Viet Anh Trinh",
            "Pegah Ghahremani",
            "Brian John King",
            "Jasha Droppo",
            "Andreas Stolcke",
            "Roland Maas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gradual Improvements Observed in Learners' Perception and Production of L2 Sounds Through Continuing Shadowing Practices on a Daily Basis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-101",
        "paper_authors": [
            "Takuya Kunihara",
            "Chuanbo Zhu",
            "Nobuaki Minematsu",
            "Noriko Nakanishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoofed speech from the perspective of a forensic phonetician",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-661",
        "paper_authors": [
            "Christin Kirchh\u00fcbel",
            "Georgina Brown"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Prosodic Variation in British English Varieties using ProPer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-792",
        "paper_authors": [
            "Hae-Sung Jeon",
            "Stephen Nichols"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perceived prominence and downstep in Japanese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-908",
        "paper_authors": [
            "Hyun Kyung Hwang",
            "Manami Hirayama",
            "Takaomi Kato"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The discrimination of [zi]-[d\u0291i] by Japanese listeners and the prospective phonologization of /zi/",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-973",
        "paper_authors": [
            "Andrea Alicehajic",
            "Silke Hamann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Glottal inverse filtering based on articulatory synthesis and deep learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10119",
        "paper_authors": [
            "Ingo Langheinrich",
            "Simon Stone",
            "Xinyu Zhang",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating phonetic convergence of laughter in conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10332",
        "paper_authors": [
            "Bogdan Ludusan",
            "Marin Schr\u00f6er",
            "Petra Wagner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Telling self-defining memories: An acoustic study of natural emotional speech productions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10554",
        "paper_authors": [
            "V\u00e9ronique Delvaux",
            "Audrey Lavall\u00e9e",
            "Fanny Degouis",
            "Xavier Saloppe",
            "Jean-Louis Nandrino",
            "Thierry Pham"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voicing neutralization in Romanian fricatives across different speech styles",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10716",
        "paper_authors": [
            "Laura Spinu",
            "Ioana Vasilescu",
            "Lori Lamel",
            "Jason Lilley"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nasal Coda Loss in the Chengdu Dialect of Mandarin: Evidence from RT-MRI",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10775",
        "paper_authors": [
            "Sishi Liao",
            "Phil Hoole",
            "Concei\u00e7\u00e3o Cunha",
            "Esther Kunay",
            "Aletheia Cui",
            "Lia Saki Bucar Shigemori",
            "Felicitas Kleber",
            "Dirk Voit",
            "Jens Frahm",
            "Jonathan Harrington"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ema2wav: doing articulation by Praat",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10813",
        "paper_authors": [
            "Philipp Buech",
            "Simon Roessig",
            "Lena Pagel",
            "Doris M\u00fccke",
            "Anne Hermes"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Phonetic Transcriptions of Children's Speech by Pronunciation Modelling with Constrained CTC-Decoding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-332",
        "paper_authors": [
            "Lars Rumberg",
            "Christopher Gebauer",
            "Hanna Ehlert",
            "Ulrike L\u00fcdtke",
            "J\u00f6rn Ostermann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Simultaneous Translation for Enhancing Transcription of Low-resource Language via Cross Attention Mechanism",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-343",
        "paper_authors": [
            "Soky Kak",
            "Sheng Li",
            "Masato Mimura",
            "Chenhui Chu",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-421",
        "paper_authors": [
            "Saida Mussakhojayeva",
            "Yerbolat Khassanov",
            "Huseyin Atakan Varol"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge of accent differences can be used to predict speech recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10162",
        "paper_authors": [
            "T\u00fcnde Szalay",
            "Mostafa Ali Shahin",
            "Beena Ahmed",
            "Kirrie J. Ballard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lombard Effect for Bilingual Speakers in Cantonese and English: importance of spectro-temporal features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10235",
        "paper_authors": [
            "Maximilian Karl Scharf",
            "Sabine Hochmuth",
            "Lena L. N. Wong",
            "Birger Kollmeier",
            "Anna Warzybok"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-end speech recognition modeling from de-identified data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10484",
        "paper_authors": [
            "Martin Flechl",
            "Shou-Chun Yin",
            "Junho Park",
            "Peter Skala"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Task End-to-End Model for Telugu Dialect and Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10739",
        "paper_authors": [
            "Aditya Yadavalli",
            "Mirishkar Sai Ganesh",
            "Anil Kumar Vuppala"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11172",
        "paper_authors": [
            "Jiamin Xie",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Keyword Spotting with Synthetic Data using Heterogeneous Knowledge Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-47",
        "paper_authors": [
            "Yuna Lee",
            "Seung Jun Baek"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Probing phoneme, language and speaker information in unsupervised speech representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-373",
        "paper_authors": [
            "Maureen de Seyssel",
            "Marvin Lavechin",
            "Yossi Adi",
            "Emmanuel Dupoux",
            "Guillaume Wisniewski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection of Reactive Attachment Disorder Through Turn-Taking Analysis in Clinical Child-Caregiver Sessions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-387",
        "paper_authors": [
            "Andrei B\u00eerladeanu",
            "Helen Minnis",
            "Alessandro Vinciarelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10245",
        "paper_authors": [
            "Eesung Kim",
            "Jae-Jin Jeon",
            "Hyeji Seo",
            "Hoon Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Few-Shot Fine-Tuning Strategies for Models of Visually Grounded Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10966",
        "paper_authors": [
            "Tyler Miller",
            "David Harwath"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pseudo Label Is Better Than Human Label",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11034",
        "paper_authors": [
            "Dongseong Hwang",
            "Khe Chai Sim",
            "Zhouyuan Huo",
            "Trevor Strohman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11369",
        "paper_authors": [
            "Werner van der Merwe",
            "Herman Kamper",
            "Johan Adam du Preez"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PRISM: Pre-trained Indeterminate Speaker Representation Model for Speaker Diarization and Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-289",
        "paper_authors": [
            "Siqi Zheng",
            "Hongbin Suo",
            "Qian Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Age Speaker Verification: Learning Age-Invariant Speaker Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-648",
        "paper_authors": [
            "Xiaoyi Qin",
            "Na Li",
            "Chao Weng",
            "Dan Su",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Target Speaker Voice Activity Detection for Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-677",
        "paper_authors": [
            "Weiqing Wang",
            "Ming Li",
            "Qingjian Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Probabilistic Spherical Discriminant Analysis: An Alternative to PLDA for length-normalized embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-731",
        "paper_authors": [
            "Niko Brummer",
            "Albert Swart",
            "Ladislav Mosner",
            "Anna Silnova",
            "Oldrich Plchot",
            "Themos Stafylakis",
            "Luk\u00e1s Burget"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep speaker embedding with frame-constrained training strategy for speaker verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-867",
        "paper_authors": [
            "Bin Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interrelate Training and Searching: A Unified Online Clustering Framework for Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-944",
        "paper_authors": [
            "Yifan Chen",
            "Yifan Guo",
            "Qingxuan Li",
            "Gaofeng Cheng",
            "Pengyuan Zhang",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Audio-Visual Neural Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10106",
        "paper_authors": [
            "Mao-Kui He",
            "Jun Du",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Speaker Diarization with Core Samples Selection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10363",
        "paper_authors": [
            "Yanyan Yue",
            "Jun Du",
            "Mao-Kui He",
            "Yu Ting Yeung",
            "Renyu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust End-to-end Speaker Diarization with Generic Neural Clustering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10404",
        "paper_authors": [
            "Chenyu Yang",
            "Yu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MSDWild: Multi-modal Speaker Diarization Dataset in the Wild",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10466",
        "paper_authors": [
            "Tao Liu",
            "Shuai Fan",
            "Xu Xiang",
            "Hongbo Song",
            "Shaoxiong Lin",
            "Jiaqi Sun",
            "Tianyuan Han",
            "Siyuan Chen",
            "Binwei Yao",
            "Sen Liu",
            "Yifei Wu",
            "Yanmin Qian",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Speaker Diarization that is Agnostic to Language, Overlap-Aware, and Tuning Free",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10605",
        "paper_authors": [
            "Md. Iftekhar Tanveer",
            "Diego Casabuena",
            "Jussi Karlgren",
            "Rosie Jones"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Utterance-by-utterance overlap-aware neural diarization with Graph-PIT",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11408",
        "paper_authors": [
            "Keisuke Kinoshita",
            "Thilo von Neumann",
            "Marc Delcroix",
            "Christoph B\u00f6ddeker",
            "Reinhold Haeb-Umbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spatial-aware Speaker Diarizaiton for Multi-channel Multi-party Meeting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11412",
        "paper_authors": [
            "Jie Wang",
            "Yuji Liu",
            "Binling Wang",
            "Yiming Zhi",
            "Song Li",
            "Shipeng Xia",
            "Jiayang Zhang",
            "Feng Tong",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Selective Pseudo-labeling and Class-wise Discriminative Fusion for Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-42",
        "paper_authors": [
            "Yunhao Liang",
            "Yanhua Long",
            "Yijie Li",
            "Jiaen Liang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An End-to-End Macaque Voiceprint Verification Method Based on Channel Fusion Mechanism",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-307",
        "paper_authors": [
            "Peng Liu",
            "Songbin Li",
            "Jigang Tang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Human Sound Classification based on Feature Fusion Method with Air and Bone Conducted Signal",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-348",
        "paper_authors": [
            "Liang Xu",
            "Jing Wang",
            "Lizhong Wang",
            "Sijun Bi",
            "Jianqian Zhang",
            "Qiuyue Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RaDur: A Reference-aware and Duration-robust Network for Target Sound Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-433",
        "paper_authors": [
            "Dongchao Yang",
            "Helin Wang",
            "Zhongjie Ye",
            "Yuexian Zou",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Temporal Self Attention-Based Residual Network for Environmental Sound Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-488",
        "paper_authors": [
            "Achyut Mani Tripathi",
            "Konark Paul"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AudioTagging Done Right: 2nd comparison of deep learning methods for environmental sound classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-515",
        "paper_authors": [
            "Juncheng Li",
            "Shuhui Qu",
            "Po-Yao Huang",
            "Florian Metze"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Target Sound Extraction with Timestamp Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-676",
        "paper_authors": [
            "Helin Wang",
            "Dongchao Yang",
            "Chao Weng",
            "Jianwei Yu",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-grained based Attention Network for Semi-supervised Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-767",
        "paper_authors": [
            "Ying Hu",
            "Xiujuan Zhu",
            "Yunlong Li",
            "Hao Huang",
            "Liang He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Temporal coding with magnitude-phase regularization for sound event detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-950",
        "paper_authors": [
            "Sangwook Park",
            "Sandeep Reddy Kothinti",
            "Mounya Elhilali"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RCT: Random consistency training for semi-supervised sound event detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10037",
        "paper_authors": [
            "Nian Shao",
            "Erfan Loweimi",
            "Xiaofei Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio Pyramid Transformer with Domain Adaption for Weakly Supervised Sound Event Detection and Audio Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10057",
        "paper_authors": [
            "Yifei Xin",
            "Dongchao Yang",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Active Few-Shot Learning for Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10907",
        "paper_authors": [
            "Yu Wang",
            "Mark Cartwright",
            "Juan Pablo Bello"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Uncertainty Calibration for Deep Audio Classifiers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11384",
        "paper_authors": [
            "Tong Ye",
            "Shijing Si",
            "Jianzong Wang",
            "Ning Cheng",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Event-related data conditioning for acoustic event classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11481",
        "paper_authors": [
            "Yuanbo Hou",
            "Dick Botteldooren"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-Scale Time-Frequency Spectrogram Discriminator for GAN-based Non-Autoregressive TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-52",
        "paper_authors": [
            "Haohan Guo",
            "Hui Lu",
            "Xixin Wu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RetrieverTTS: Modeling Decomposed Factors for Text-Based Speech Insertion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-245",
        "paper_authors": [
            "Dacheng Yin",
            "Chuanxin Tang",
            "Yanqing Liu",
            "Xiaoqiang Wang",
            "Zhiyuan Zhao",
            "Yucheng Zhao",
            "Zhiwei Xiong",
            "Sheng Zhao",
            "Chong Luo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FlowVocoder: A small Footprint Neural Vocoder based Normalizing Flow for Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-272",
        "paper_authors": [
            "Manh Luong",
            "Viet-Anh Tran"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial Vector-Quantized Auto-Encoders",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-277",
        "paper_authors": [
            "Yanqing Liu",
            "Ruiqing Xue",
            "Lei He",
            "Xu Tan",
            "Sheng Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AdaVocoder: Adaptive Vocoder for Custom Voice",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-288",
        "paper_authors": [
            "Xin Yuan",
            "Robin Feng",
            "Mingming Ye",
            "Cheng Tuo",
            "Minghang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RefineGAN: Universally Generating Waveform Better than Ground Truth with Highly Accurate Pitch and Intensity Responses",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-349",
        "paper_authors": [
            "Shengyuan Xu",
            "Wenxiao Zhao",
            "Jing Guo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VQTTS: High-Fidelity Text-to-Speech Synthesis with Self-Supervised VQ Acoustic Feature",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-489",
        "paper_authors": [
            "Chenpeng Du",
            "Yiwei Guo",
            "Xie Chen",
            "Kai Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving GAN-based vocoder for fast and high-quality speech synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-730",
        "paper_authors": [
            "Mengnan He",
            "Tingwei Guo",
            "Zhenxing Lu",
            "Ruixiong Zhang",
            "Caixia Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SoftSpeech: Unsupervised Duration Model in FastSpeech 2",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-887",
        "paper_authors": [
            "Yuanhao Yi",
            "Lei He",
            "Shifeng Pan",
            "Xi Wang",
            "Yuchao Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-Stage Multi-Codebook VQ-VAE Approach to High-Performance Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-952",
        "paper_authors": [
            "Haohan Guo",
            "Feng-Long Xie",
            "Frank K. Soong",
            "Xixin Wu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SiD-WaveFlow: A Low-Resource Vocoder Independent of Prior Knowledge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10222",
        "paper_authors": [
            "Yuhan Li",
            "Ying Shen",
            "Dongqing Wang",
            "Lin Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text-to-speech synthesis using spectral modeling based on non-negative autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10290",
        "paper_authors": [
            "Takeru Gorai",
            "Daisuke Saito",
            "Nobuaki Minematsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Modeling of Multi-Sample and Subband Signals for Fast Neural Vocoding on CPU",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10556",
        "paper_authors": [
            "Hiroki Kanagawa",
            "Yusuke Ijima",
            "Hiroyuki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MISRNet: Lightweight Neural Vocoder Using Multi-Input Single Shared Residual Blocks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11152",
        "paper_authors": [
            "Takuhiro Kaneko",
            "Hirokazu Kameoka",
            "Kou Tanaka",
            "Shogo Seki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A compact transformer-based GAN vocoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11254",
        "paper_authors": [
            "Chenfeng Miao",
            "Ting Chen",
            "Minchuan Chen",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Diffusion Generative Vocoder for Fullband Speech Synthesis Based on Weak Third-order SDE Solver",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11366",
        "paper_authors": [
            "Hideyuki Tachibana",
            "Muneyoshi Inahara",
            "Mocho Go",
            "Yotaro Katayama",
            "Yotaro Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Adaptive Weight Interpolation of the Hybrid Autoregressive Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-4",
        "paper_authors": [
            "Ehsan Variani",
            "Michael Riley",
            "David Rybach",
            "Cyril Allauzen",
            "Tongzhou Chen",
            "Bhuvana Ramabhadran"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to rank with BERT-based confidence models in ASR rescoring",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-145",
        "paper_authors": [
            "Ting-Wei Wu",
            "I-Fan Chen",
            "Ankur Gandhe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VQ-T: RNN Transducers using Vector-Quantized Prediction Network States",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-414",
        "paper_authors": [
            "Jiatong Shi",
            "George Saon",
            "David Haws",
            "Shinji Watanabe",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WeNet 2.0: More Productive End-to-End Speech Recognition Toolkit",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-483",
        "paper_authors": [
            "Binbin Zhang",
            "Di Wu",
            "Zhendong Peng",
            "Xingchen Song",
            "Zhuoyuan Yao",
            "Hang Lv",
            "Lei Xie",
            "Chao Yang",
            "Fuping Pan",
            "Jianwei Niu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Internal Language Model Estimation Through Explicit Context Vector Learning for Attention-based Encoder-decoder ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-606",
        "paper_authors": [
            "Yufei Liu",
            "Rao Ma",
            "Haihua Xu",
            "Yi He",
            "Zejun Ma",
            "Weibin Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Streaming End-to-End ASR on Transformer-based Causal Models with Encoder States Revision Strategies",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-707",
        "paper_authors": [
            "Zehan Li",
            "Haoran Miao",
            "Keqi Deng",
            "Gaofeng Cheng",
            "Sanli Tian",
            "Ta Li",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parameter-Efficient Conformers via Sharing Sparsely-Gated Experts for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-709",
        "paper_authors": [
            "Ye Bai",
            "Jie Li",
            "Wenjing Han",
            "Hao Ni",
            "Kaituo Xu",
            "Zhuo Zhang",
            "Cheng Yi",
            "Xiaorui Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CaTT-KWS: A Multi-stage Customized Keyword Spotting Framework based on Cascaded Transducer-Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10258",
        "paper_authors": [
            "Zhanheng Yang",
            "Sining Sun",
            "Jin Li",
            "Xiaoming Zhang",
            "Xiong Wang",
            "Long Ma",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LightHuBERT: Lightweight and Configurable Speech Representation Learning with Once-for-All Hidden-Unit BERT",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10269",
        "paper_authors": [
            "Rui Wang",
            "Qibing Bai",
            "Junyi Ao",
            "Long Zhou",
            "Zhixiang Xiong",
            "Zhihua Wei",
            "Yu Zhang",
            "Tom Ko",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-stage Progressive Compression of Conformer Transducer for On-device Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10582",
        "paper_authors": [
            "Jash Rathod",
            "Nauman Dawalatabad",
            "Shatrughan Singh",
            "Dhananjaya Gowda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Align-Refine for Non-autoregressive Deliberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10715",
        "paper_authors": [
            "Weiran Wang",
            "Ke Hu",
            "Tara N. Sainath"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Federated Pruning: Improving Neural Network Efficiency with Federated Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10787",
        "paper_authors": [
            "Rongmei Lin",
            "Yonghui Xiao",
            "Tien-Ju Yang",
            "Ding Zhao",
            "Li Xiong",
            "Giovanni Motta",
            "Fran\u00e7oise Beaufays"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10791",
        "paper_authors": [
            "Shaojin Ding",
            "Weiran Wang",
            "Ding Zhao",
            "Tara N. Sainath",
            "Yanzhang He",
            "Robert David",
            "Rami Botros",
            "Xin Wang",
            "Rina Panigrahy",
            "Qiao Liang",
            "Dongseong Hwang",
            "Ian McGraw",
            "Rohit Prabhavalkar",
            "Trevor Strohman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "4-bit Conformer with Native Quantization Aware Training for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10809",
        "paper_authors": [
            "Shaojin Ding",
            "Phoenix Meadowlark",
            "Yanzhang He",
            "Lukasz Lew",
            "Shivani Agrawal",
            "Oleg Rybakov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Distillation Based on High-level Information Supervision for Compressing End-to-End ASR Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11423",
        "paper_authors": [
            "Qiang Xu",
            "Tongtong Song",
            "Longbiao Wang",
            "Hao Shi",
            "Yuqin Lin",
            "Yongjie Lv",
            "Meng Ge",
            "Qiang Yu",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging unsupervised and weakly-supervised data to improve direct speech-to-speech translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10938",
        "paper_authors": [
            "Ye Jia",
            "Yifan Ding",
            "Ankur Bapna",
            "Colin Cherry",
            "Yu Zhang",
            "Alexis Conneau",
            "Nobu Morioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A High-Quality and Large-Scale Dataset for English-Vietnamese Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-218",
        "paper_authors": [
            "Linh The Nguyen",
            "Nguyen Luong Tran",
            "Long Doan",
            "Manh Luong",
            "Dat Quoc Nguyen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating Parameter Sharing in Multilingual Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-552",
        "paper_authors": [
            "Qian Wang",
            "Chen Wang",
            "Jiajun Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Open Source MagicData-RAMC: A Rich Annotated Mandarin Conversational(RAMC) Speech Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-729",
        "paper_authors": [
            "Zehui Yang",
            "Yifan Chen",
            "Lei Luo",
            "Runyan Yang",
            "Lingxuan Ye",
            "Gaofeng Cheng",
            "Ji Xu",
            "Yaohui Jin",
            "Qingqing Zhang",
            "Pengyuan Zhang",
            "Lei Xie",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TALCS: An open-source Mandarin-English code-switching corpus and a speech recognition baseline",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-877",
        "paper_authors": [
            "Chengfei Li",
            "Shuhao Deng",
            "Yaoping Wang",
            "Guangjing Wang",
            "Yaguang Gong",
            "Changbin Chen",
            "Jinfeng Bai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Blockwise Streaming Transformer for Spoken Language Understanding and Simultaneous Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-933",
        "paper_authors": [
            "Keqi Deng",
            "Shinji Watanabe",
            "Jiatong Shi",
            "Siddhant Arora"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10177",
        "paper_authors": [
            "Nguyen Luong Tran",
            "Duong Minh Le",
            "Dat Quoc Nguyen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Biometric Russian Audio-Visual Extended MASKS (BRAVE-MASKS) Corpus: Multimodal Mask Type Recognition Task",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10240",
        "paper_authors": [
            "Maxim Markitantov",
            "Elena Ryumina",
            "Dmitry Ryumin",
            "Alexey Karpov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bayesian Transformer Using Disentangled Mask Attention",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10457",
        "paper_authors": [
            "Jen-Tzung Chien",
            "Yu-Han Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Speech Recognition in MISP2021 Challenge: Dataset Release and Deep Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10483",
        "paper_authors": [
            "Hang Chen",
            "Jun Du",
            "Yusheng Dai",
            "Chin-Hui Lee",
            "Sabato Marco Siniscalchi",
            "Shinji Watanabe",
            "Odette Scharenborg",
            "Jingdong Chen",
            "Baocai Yin",
            "Jia Pan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "From Start to Finish: Latency Reduction Strategies for Incremental Speech Synthesis in Simultaneous Speech-to-Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10568",
        "paper_authors": [
            "Danni Liu",
            "Changhan Wang",
            "Hongyu Gong",
            "Xutai Ma",
            "Yun Tang",
            "Juan Miguel Pino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Isochrony-Aware Neural Machine Translation for Automatic Dubbing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11136",
        "paper_authors": [
            "Derek Tam",
            "Surafel Melaku Lakew",
            "Yogesh Virkar",
            "Prashant Mathur",
            "Marcello Federico"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Pseudo-labeled Data to Improve Direct Speech-to-Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10011",
        "paper_authors": [
            "Qianqian Dong",
            "Fengpeng Yue",
            "Tom Ko",
            "Mingxuan Wang",
            "Qibing Bai",
            "Yu Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Hybrid Continuity Loss to Reduce Over-Suppression for Time-domain Target Speaker Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-157",
        "paper_authors": [
            "Zexu Pan",
            "Meng Ge",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extending GCC-PHAT using Shift Equivariant Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-524",
        "paper_authors": [
            "Axel Berg",
            "Mark O'Connor",
            "Kalle \u00c5str\u00f6m",
            "Magnus Oskarsson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Heterogeneous Target Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10717",
        "paper_authors": [
            "Efthymios Tzinis",
            "Gordon Wichern",
            "Aswin Shanmugam Subramanian",
            "Paris Smaragdis",
            "Jonathan Le Roux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Separate What You Describe: Language-Queried Audio Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10894",
        "paper_authors": [
            "Xubo Liu",
            "Haohe Liu",
            "Qiuqiang Kong",
            "Xinhao Mei",
            "Jinzheng Zhao",
            "Qiushi Huang",
            "Mark D. Plumbley",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Implicit Neural Spatial Filtering for Multichannel Source Separation in the Waveform Domain",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11153",
        "paper_authors": [
            "Dejan Markovic",
            "Alexandre D\u00e9fossez",
            "Alexander Richard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-end Speech-to-Punctuated-Text Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-5",
        "paper_authors": [
            "Jumon Nozaki",
            "Tatsuya Kawahara",
            "Kenkichi Ishizuka",
            "Taiichi Hashimoto"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Dependency Parsing of Spoken French",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-381",
        "paper_authors": [
            "Adrien Pupier",
            "Maximin Coavoux",
            "Benjamin Lecouteux",
            "J\u00e9r\u00f4me Goulian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Turn-Taking Prediction for Natural Conversational Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-566",
        "paper_authors": [
            "Shuo-Yiin Chang",
            "Bo Li",
            "Tara N. Sainath",
            "Chao Zhang",
            "Trevor Strohman",
            "Qiao Liang",
            "Yanzhang He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Intended Query Detection using E2E Modeling for Continued Conversation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-569",
        "paper_authors": [
            "Shuo-Yiin Chang",
            "Guru Prakash",
            "Zelin Wu",
            "Tara N. Sainath",
            "Bo Li",
            "Qiao Liang",
            "Adam Stambler",
            "Shyam Upadhyay",
            "Manaal Faruqui",
            "Trevor Strohman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Capabilities of Monolingual Audio Transformers using Large Datasets in Automatic Speech Recognition of Czech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10439",
        "paper_authors": [
            "Jan Lehecka",
            "Jan Svec",
            "Ales Praz\u00e1k",
            "Josef Psutka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SVTS: Scalable Video-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10770",
        "paper_authors": [
            "Rodrigo Schoburg Carrillo de Mira",
            "Alexandros Haliassos",
            "Stavros Petridis",
            "Bj\u00f6rn W. Schuller",
            "Maja Pantic"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One-step models in pitch perception: Experimental evidence from Japanese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-265",
        "paper_authors": [
            "Takeshi Kishiyama",
            "Chuyu Huang",
            "Yuki Hirose"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generating iso-accented stimuli for second language research: methodology and a dataset for Spanish-accented English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-850",
        "paper_authors": [
            "Rub\u00e9n P\u00e9rez Ram\u00f3n",
            "Martin Cooke",
            "Mar\u00eda Luisa Garc\u00eda Lecumberri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Factors affecting the percept of Yanny v. Laurel (or mixed): Insights from a large-scale study on Swiss German listeners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10048",
        "paper_authors": [
            "Adrian Leemann",
            "P\u00e9ter Jeszenszky",
            "Carina Steiner",
            "Corinne Lanthemann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of laryngeal manipulations on voice gender perception",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10815",
        "paper_authors": [
            "Zhaoyan Zhang",
            "Jason Zhang",
            "Jody Kreiman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Why is Korean lenis stop difficult to perceive for L2 Korean learners?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10912",
        "paper_authors": [
            "Boram Lee",
            "Naomi Yamaguchi",
            "C\u00e9cile Fougeron"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lexical stress in Spanish word segmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11185",
        "paper_authors": [
            "Alvaro Martin Iturralde Zurita",
            "Meghan Clayards"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Audio-Text Agreement for Open-vocabulary Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-580",
        "paper_authors": [
            "Hyeon-Kyeong Shin",
            "Hyewon Han",
            "Doyeon Kim",
            "Soo-Whan Chung",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Integrating Form and Meaning: A Multi-Task Learning Model for Acoustic Word Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-626",
        "paper_authors": [
            "Badr M. Abdullah",
            "Bernd M\u00f6bius",
            "Dietrich Klakow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Personalized Keyword Spotting through Multi-task Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-947",
        "paper_authors": [
            "Seunghan Yang",
            "Byeonggeun Kim",
            "Inseop Chung",
            "Simyung Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep LSTM Spoken Term Detection using Wav2Vec 2.0 Recognizer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10409",
        "paper_authors": [
            "Jan Svec",
            "Jan Lehecka",
            "Lubos Sm\u00eddl"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Latency Control for Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10608",
        "paper_authors": [
            "Christin Jose",
            "Joe Wang",
            "Grant P. Strimel",
            "Mohammad Omar Khursheed",
            "Yuriy Mishchenko",
            "Brian Kulis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Voice Trigger Detection with Metric Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11160",
        "paper_authors": [
            "Prateeth Nayak",
            "Takuya Higuchi",
            "Anmol Gupta",
            "Shivesh Ranjan",
            "Stephen Shum",
            "Siddharth Sigtia",
            "Erik Marchi",
            "Varun Lakshminarasimhan",
            "Minsik Cho",
            "Saurabh Adya",
            "Chandra Dhir",
            "Ahmed H. Tewfik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RNN Transducers for Named Entity Recognition with constraints on alignment for understanding medical conversations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-391",
        "paper_authors": [
            "Hagen Soltau",
            "Izhak Shafran",
            "Mingqiu Wang",
            "Laurent El Shafey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Automated Counselling Decision-Making: Remarks on Therapist Action Forecasting on the AnnoMI Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-506",
        "paper_authors": [
            "Zixiu Wu",
            "Rim Helaoui",
            "Diego Reforgiato Recupero",
            "Daniele Riboni"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech and the n-Back task as a lens into depression. How combining both may allow us to isolate different core symptoms of depression",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10393",
        "paper_authors": [
            "Salvatore Fara",
            "Stefano Goria",
            "Emilia Molimpakis",
            "Nicholas Cummins"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enabling Off-the-Shelf Disfluency Detection and Categorization for Pathological Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10971",
        "paper_authors": [
            "Amrit Romana",
            "Minxue Niu",
            "Matthew Perez",
            "Angela Roberts",
            "Emily Mower Provost"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Challenges of using longitudinal and cross-domain corpora on studies of pathological speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10995",
        "paper_authors": [
            "Catarina Botelho",
            "Tanja Schultz",
            "Alberto Abad",
            "Isabel Trancoso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "g2pW: A Conditional Weighted Softmax BERT for Polyphone Disambiguation in Mandarin",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-216",
        "paper_authors": [
            "Yi-Chang Chen",
            "Yu-Chuan Steven",
            "Yen-Cheng Chang",
            "Yi-Ren Yeh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified Accent Estimation Method Based on Multi-Task Learning for Japanese Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-334",
        "paper_authors": [
            "Byeongseon Park",
            "Ryuichi Yamamoto",
            "Kentaro Tachibana"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vocal effort modeling in neural TTS for improving the intelligibility of synthetic speech in noise",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-825",
        "paper_authors": [
            "Tuomo Raitio",
            "Petko Petkov",
            "Jiangchuan Li",
            "P. V. Muhammed Shifas",
            "Andrea Davis",
            "Yannis Stylianou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TTS-by-TTS 2: Data-Selective Augmentation for Neural Speech Synthesis Using Ranking Support Vector Machine with Variational Autoencoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10134",
        "paper_authors": [
            "Eunwoo Song",
            "Ryuichi Yamamoto",
            "Ohsung Kwon",
            "Chan-Ho Song",
            "Min-Jae Hwang",
            "Suhyeon Oh",
            "Hyun-Wook Yoon",
            "Jin-Seob Kim",
            "Jae-Min Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-data? No problem: low-resource, language-agnostic conversational text-to-speech via F0-conditioned data augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10338",
        "paper_authors": [
            "Giulia Comini",
            "Goeric Huybrechts",
            "Manuel Sam Ribeiro",
            "Adam Gabrys",
            "Jaime Lorenzo-Trueba"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Real-Time Monitoring of Silences in Contact Center Conversations",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/ingle22_interspeech.html",
        "paper_authors": [
            "Digvijay Ingle",
            "Ayush Kumar",
            "Krishnachaitanya Gogineni",
            "Jithendra Vepa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Humanizing bionic voice: interactive demonstration of aesthetic design and control factors influencing the devices assembly and waveshape engineering",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/zielinski22_interspeech.html",
        "paper_authors": [
            "Konrad Zielinski",
            "Marek Grzelec",
            "Martin Hagm\u00fcller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Application for Real-time Personalized Speaker Extraction",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/ronssin22_interspeech.html",
        "paper_authors": [
            "Damien Ronssin",
            "Milos Cernak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coswara: A website application enabling COVID-19 screening by analysing respiratory sound samples and health symptoms",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/bhattacharya22b_interspeech.html",
        "paper_authors": [
            "Debarpan Bhattacharya",
            "Debottam Dutta",
            "Neeraj Kumar Sharma",
            "Srikanth Raj Chetupalli",
            "Pravin Mote",
            "Sriram Ganapathy",
            "Chandrakiran C",
            "Sahiti Nori",
            "Suhail K. K",
            "Sadhana Gonuguntla",
            "Murali Alagesan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CoachLea: an Android Application to Evaluate the Speech Production and Perception of Children with Hearing Loss",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/schafer22_interspeech.html",
        "paper_authors": [
            "P. Sch\u00e4fer",
            "Paula Andrea P\u00e9rez-Toro",
            "Philipp Klumpp",
            "Juan Rafael Orozco-Arroyave",
            "Elmar N\u00f6th",
            "Andreas K. Maier",
            "A. Abad",
            "Maria Schuster",
            "Tom\u00e1s Arias-Vergara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Automated Mood Diary for Older User's using Ambient Assisted Living Recorded Speech",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/haider22_interspeech.html",
        "paper_authors": [
            "Fasih Haider",
            "Saturnino Luz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Differential Time-frequency Log-mel Spectrogram Features for Vision Transformer Based Infant Cry Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-18",
        "paper_authors": [
            "Hai-tao Xu",
            "Jie Zhang",
            "Li-Rong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Automated Dialog Personalization using MBTI Personality Indicators",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-376",
        "paper_authors": [
            "Daniel Fernau",
            "Stefan Hillmann",
            "Nils Feldhus",
            "Tim Polzehl"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Word-wise Sparse Attention for Multimodal Sentiment Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-532",
        "paper_authors": [
            "Fan Qian",
            "Hongwei Song",
            "Jiqing Han"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Estimation of speaker age and height from speech signal using bi-encoder transformer mixture model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-567",
        "paper_authors": [
            "Tarun Gupta",
            "Duc-Tuan Truong",
            "Tran The Anh",
            "Eng Siong Chng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Multi-task Learning Based Gender Recognition and Age Estimation for Class-imbalanced Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-682",
        "paper_authors": [
            "Weiqiao Zheng",
            "Ping Yang",
            "Rongfeng Lai",
            "Kongyang Zhu",
            "Tao Zhang",
            "Junpeng Zhang",
            "Hongcheng Fu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Domain Adaptation Feature Fusion for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-703",
        "paper_authors": [
            "Jie Wei",
            "Guanyu Hu",
            "Xinyu Yang",
            "Anh Tuan Luu",
            "Yizhuo Dong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Impact of Background Noise and Contribution of Visual Information in Emotion Identification by Native Mandarin Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10142",
        "paper_authors": [
            "Minyue Zhang",
            "Hongwei Ding"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploiting Fine-tuning of Self-supervised Learning Models for Improving Bi-modal Sentiment Analysis and Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10354",
        "paper_authors": [
            "Wei Yang",
            "Satoru Fukayama",
            "Panikos Heracleous",
            "Jun Ogata"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Characterizing Therapist's Speaking Style in Relation to Empathy in Psychotherapy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10416",
        "paper_authors": [
            "Dehua Tao",
            "Tan Lee",
            "Harold Chui",
            "Sarah Luk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical Attention Network for Evaluating Therapist Empathy in Counseling Session",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10550",
        "paper_authors": [
            "Dehua Tao",
            "Tan Lee",
            "Harold Chui",
            "Sarah Luk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Context-aware Multimodal Fusion for Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10592",
        "paper_authors": [
            "Jinchao Li",
            "Shuai Wang",
            "Yang Chao",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Instance Discriminative Learning for Depression Detection from Speech Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10814",
        "paper_authors": [
            "Jinhan Wang",
            "Vijay Ravi",
            "Jonathan Flint",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How do our eyebrows respond to masks and whispering? The case of Persians",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10867",
        "paper_authors": [
            "Nasim Mahdinazhad Sardhaei",
            "Marzena Zygis",
            "Hamid Sharifzadeh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "State & Trait Measurement from Nonverbal Vocalizations: A Multi-Task Joint Learning Approach",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10927",
        "paper_authors": [
            "Alice Baird",
            "Panagiotis Tzirakis",
            "Jeffrey A. Brooks",
            "Lauren Kim",
            "Michael Opara",
            "Christopher B. Gregory",
            "Jacob Metrick",
            "Garrett Boseck",
            "Dacher Keltner",
            "Alan Cowen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Confidence Measure for Automatic Age Estimation From Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11135",
        "paper_authors": [
            "Amruta Saraf",
            "Ganesh Sivaraman",
            "Elie Khoury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Accelerating Inference and Language Model Fusion of Recurrent Neural Network Transducers via End-to-End 4-bit Quantization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-413",
        "paper_authors": [
            "Andrea Fasoli",
            "Chia-Yu Chen",
            "Mauricio J. Serrano",
            "Swagath Venkataramani",
            "George Saon",
            "Xiaodong Cui",
            "Brian Kingsbury",
            "Kailash Gopalakrishnan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tree-constrained Pointer Generator with Graph Neural Network Encodings for Contextual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-461",
        "paper_authors": [
            "Guangzhi Sun",
            "Chao Zhang",
            "Philip C. Woodland"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bring dialogue-context into RNN-T for streaming ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-697",
        "paper_authors": [
            "Junfeng Hou",
            "Jinkun Chen",
            "Wanyu Li",
            "Yufeng Tang",
            "Jun Zhang",
            "Zejun Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conformer with dual-mode chunked attention for joint online and offline ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-733",
        "paper_authors": [
            "Felix Weninger",
            "Marco Gaudesi",
            "Md. Akmal Haidar",
            "Nicola Ferri",
            "Jes\u00fas Andr\u00e9s-Ferrer",
            "Puming Zhan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Training of Neural Transducer for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-829",
        "paper_authors": [
            "Wei Zhou",
            "Wilfried Michel",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-9996",
        "paper_authors": [
            "Zhifu Gao",
            "Shiliang Zhang",
            "Ian McLoughlin",
            "Zhijie Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pruned RNN-T for fast, memory-efficient ASR training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10340",
        "paper_authors": [
            "Fangjun Kuang",
            "Liyong Guo",
            "Wei Kang",
            "Long Lin",
            "Mingshuang Luo",
            "Zengwei Yao",
            "Daniel Povey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Sparse Conformer for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10384",
        "paper_authors": [
            "Xianchao Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Chain-based Discriminative Autoencoders for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10474",
        "paper_authors": [
            "Hung-Shin Lee",
            "Pin-Tuan Huang",
            "Yao-Fei Cheng",
            "Hsin-Min Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming parallel transducer beam search with fast slow cascaded encoders",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10551",
        "paper_authors": [
            "Jay Mahadeokar",
            "Yangyang Shi",
            "Ke Li",
            "Duc Le",
            "Jiedan Zhu",
            "Vikas Chandra",
            "Ozlem Kalinli",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-regularised Minimum Latency Training for Streaming Transformer-based Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10682",
        "paper_authors": [
            "Mohan Li",
            "Rama Sanand Doddipatla",
            "Catalin Zorila"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Prediction Network Architecture in RNN-T for ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10954",
        "paper_authors": [
            "Dario Albesano",
            "Jes\u00fas Andr\u00e9s-Ferrer",
            "Nicola Ferri",
            "Puming Zhan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Minimum latency training of sequence transducers for streaming end-to-end speech recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10989",
        "paper_authors": [
            "Yusuke Shinohara",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CUSIDE: Chunking, Simulating Future Context and Decoding for Streaming ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11214",
        "paper_authors": [
            "Keyu An",
            "Huahuan Zheng",
            "Zhijian Ou",
            "Hongyu Xiang",
            "Ke Ding",
            "Guanglu Wan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention Enhanced Citrinet for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11394",
        "paper_authors": [
            "Xianchao Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simple and Effective Zero-shot Cross-lingual Phoneme Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-60",
        "paper_authors": [
            "Qiantong Xu",
            "Alexei Baevski",
            "Michael Auli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Self-Supervised Audio-Visual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-99",
        "paper_authors": [
            "Bowen Shi",
            "Wei-Ning Hsu",
            "Abdelrahman Mohamed"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Sequence Embeddings using Nearest Neighbors Contrastive Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-226",
        "paper_authors": [
            "Robin Algayres",
            "Adel Nabli",
            "Beno\u00eet Sagot",
            "Emmanuel Dupoux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Green ASR: Lossless 4-bit Quantization of a Hybrid TDNN System on the 300-hr Swithboard Corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-678",
        "paper_authors": [
            "Junhao Xu",
            "Shoukang Hu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Finer-grained Modeling units-based Meta-Learning for Low-resource Tibetan Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10015",
        "paper_authors": [
            "Siqing Qin",
            "Longbiao Wang",
            "Sheng Li",
            "Yuqin Lin",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial-Free Speaker Identity-Invariant Representation Learning for Automatic Dysarthric Speech Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-402",
        "paper_authors": [
            "Parvaneh Janbakhshi",
            "Ina Kodrasi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automated Detection of Wilson's Disease Based on Improved Mel-frequency Cepstral Coefficients with Signal Decomposition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-859",
        "paper_authors": [
            "Zhenglin Zhang",
            "Lizhuang Yang",
            "Xun Wang",
            "Hai Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The effect of backward noise on lexical tone discrimination in Mandarin-speaking amusics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10004",
        "paper_authors": [
            "Zixia Fan",
            "Jing Shao",
            "Weigong Pan",
            "Min Xu",
            "Lan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Selection of Discriminative Features for Dementia Detection in Cantonese-Speaking People",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10122",
        "paper_authors": [
            "Xiaoquan Ke",
            "Man-Wai Mak",
            "Helen M. Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automated Voice Pathology Discrimination from Continuous Speech Benefits from Analysis by Phonetic Context",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10154",
        "paper_authors": [
            "Zhuoya Liu",
            "Mark A. Huckvale",
            "Julian McGlashan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Type Outer Product-Based Fusion of Respiratory Sounds for Detecting COVID-19",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10291",
        "paper_authors": [
            "Adria Mallol-Ragolta",
            "Helena Cuesta",
            "Emilia G\u00f3mez",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Cough Feature Extraction and Classification Method for COVID-19 Cough Detection Based on Vocalization Characteristics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10401",
        "paper_authors": [
            "Xueshuai Zhang",
            "Jiakun Shen",
            "Jun Zhou",
            "Pengyuan Zhang",
            "Yonghong Yan",
            "Zhihua Huang",
            "Yanfen Tang",
            "Yu Wang",
            "Fujie Zhang",
            "Shaoxing Zhang",
            "Aijun Sun"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparing 1-dimensional and 2-dimensional spectral feature representations in voice pathology detection using machine learning and deep learning classifiers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10420",
        "paper_authors": [
            "Farhad Javanmardi",
            "Sudarsana Reddy Kadiri",
            "Manila Kodali",
            "Paavo Alku"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Cross-lingual Aphasia Detection using Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10681",
        "paper_authors": [
            "Gerasimos Chatzoudis",
            "Manos Plitsis",
            "Spyridoula Stamouli",
            "Athanasia-Lida Dimou",
            "Nassos Katsamanis",
            "Vassilis Katsouros"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain-aware Intermediate Pretraining for Dementia Detection with Limited Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10862",
        "paper_authors": [
            "Youxiang Zhu",
            "Xiaohui Liang",
            "John A. Batsis",
            "Robert M. Roth"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison of 5 methods for the evaluation of intelligibility in mild to moderate French dysarthric speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10590",
        "paper_authors": [
            "C\u00e9cile Fougeron",
            "Nicolas Audibert",
            "Ina Kodrasi",
            "Parvaneh Janbakhshi",
            "Michaela Pernon",
            "Nathalie L\u00e9v\u00eaque",
            "Stephanie Borel",
            "Marina Laganaro",
            "Herv\u00e9 Bourlard",
            "Fr\u00e9d\u00e9ric Assal"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Distortion Robustness of Self-supervised Speech Processing Tasks with Domain Adaptation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-519",
        "paper_authors": [
            "Kuan-Po Huang",
            "Yu-Kuan Fu",
            "Yu Zhang",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Listen, Adapt, Better WER: Source-free Single-utterance Test-time Adaptation for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-600",
        "paper_authors": [
            "Guan-Ting Lin",
            "Shang-Wen Li",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distilling a Pretrained Language Model to a Multilingual ASR Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-716",
        "paper_authors": [
            "Kwanghee Choi",
            "Hyung-Min Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text-Only Domain Adaptation Based on Intermediate CTC",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10114",
        "paper_authors": [
            "Hiroaki Sato",
            "Tomoyasu Komori",
            "Takeshi Mishima",
            "Yoshihiko Kawai",
            "Takahiro Mochizuki",
            "Shoei Sato",
            "Tetsuji Ogawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning for Robust Low-Resource Children's Speech ASR with Transformers and Source-Filter Warping",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10964",
        "paper_authors": [
            "Jenthe Thienpondt",
            "Kris Demuynck"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Updating Only Encoders Prevents Catastrophic Forgetting of End-to-End ASR Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11282",
        "paper_authors": [
            "Yuki Takashima",
            "Shota Horiguchi",
            "Shinji Watanabe",
            "Leibny Paola Garc\u00eda-Perera",
            "Yohei Kawaguchi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved CNN-Transformer using Broadcasted Residual Learning for Text-Independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-88",
        "paper_authors": [
            "Jeong-Hwan Choi",
            "Joon-Young Yang",
            "Ye-Rin Jeoung",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pushing the limits of raw waveform speaker recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-126",
        "paper_authors": [
            "Jee-weon Jung",
            "You Jin Kim",
            "Hee-Soo Heo",
            "Bong-Jin Lee",
            "Youngki Kwon",
            "Joon Son Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PHO-LID: A Unified Model Incorporating Acoustic-Phonetic and Phonotactic Information for Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-354",
        "paper_authors": [
            "Hexin Liu",
            "Leibny Paola Garc\u00eda-Perera",
            "Andy W. H. Khong",
            "Suzy J. Styles",
            "Sanjeev Khudanpur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prosodic Information in Dialect Identification of a Tonal Language: The case of Ao",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10779",
        "paper_authors": [
            "Moakala Tzudir",
            "Priyankoo Sarmah",
            "S. R. Mahadeva Prasanna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multimodal Strategy for Singing Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11007",
        "paper_authors": [
            "Wo Jae Lee",
            "Emanuele Coviello"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A comparative study on vowel articulation in Parkinson's disease and multiple system atrophy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-845",
        "paper_authors": [
            "Khalid Daoudi",
            "Biswajit Das",
            "Solange Milh\u00e9 de Saint Victor",
            "Alexandra Foubert-Samier",
            "Margherita Fabbri",
            "Anne Pavy-Le Traon",
            "Olivier Rascol",
            "Virginie Woisard",
            "Wassilios G. Meissner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voicing decision based on phonemes classification and spectral moments for whisper-to-speech conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10675",
        "paper_authors": [
            "Luc Ardaillon",
            "Nathalie Henrich Bernardoni",
            "Olivier Perrotin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Acoustics in Mild Cognitive Impairment and Parkinson's Disease With and Without Concurrent Drawing Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10772",
        "paper_authors": [
            "Tanya Talkar",
            "Christina Manxhari",
            "James J. Williamson",
            "Kara M. Smith",
            "Thomas F. Quatieri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the Impact of Speech Compression on the Acoustics of Dysarthric Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10817",
        "paper_authors": [
            "Kelvin Tran",
            "Lingfeng Xu",
            "Gabriela Stegmann",
            "Julie Liss",
            "Visar Berisha",
            "Rene Utianski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Trait Enhancement for Cochlear Implant Users: A Case Study for Speaker Emotion Perception",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10951",
        "paper_authors": [
            "Avamarie Brueggeman",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimal thyroplasty implant shape and stiffness for treatment of acute unilateral vocal fold paralysis: Evidence from a canine in vivo phonation model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11158",
        "paper_authors": [
            "Neha Reddy",
            "Yoonjeong Lee",
            "Zhaoyan Zhang",
            "Dinesh K. Chhetri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-143",
        "paper_authors": [
            "Arun Babu",
            "Changhan Wang",
            "Andros Tjandra",
            "Kushal Lakhotia",
            "Qiantong Xu",
            "Naman Goyal",
            "Kritika Singh",
            "Patrick von Platen",
            "Yatharth Saraf",
            "Juan Pino",
            "Alexei Baevski",
            "Alexis Conneau",
            "Michael Auli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantically Meaningful Metrics for Norwegian ASR Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-817",
        "paper_authors": [
            "Janine Rugayan",
            "Torbj\u00f8rn Svendsen",
            "Giampiero Salvi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deciphering Speech: a Zero-Resource Approach to Cross-Lingual Transfer in ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10170",
        "paper_authors": [
            "Ondrej Klejch",
            "Electra Wallington",
            "Peter Bell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Linguistically Informed Post-processing for ASR Error correction in Sanskrit",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11189",
        "paper_authors": [
            "Rishabh Kumar",
            "Devaraja Adiga",
            "Rishav Ranjan",
            "Amrith Krishna",
            "Ganesh Ramakrishnan",
            "Pawan Goyal",
            "Preethi Jyothi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-lingual articulatory feature information transfer for speech recognition using recurrent progressive neural networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11202",
        "paper_authors": [
            "Mahir Morshed",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison of Models for Detecting Off-Putting Speaking Styles",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-232",
        "paper_authors": [
            "Diego Aguirre",
            "Nigel G. Ward",
            "Jonathan E. Avila",
            "Heike Lehnert-LeHouillier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Persuasive Dialogue Corpus using Teleoperated Android",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-565",
        "paper_authors": [
            "Seiya Kawano",
            "Muteki Arioka",
            "Akishige Yuguchi",
            "Kenta Yamamoto",
            "Koji Inoue",
            "Tatsuya Kawahara",
            "Satoshi Nakamura",
            "Koichiro Yoshino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text-driven Emotional Style Control and Cross-speaker Style Transfer in Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10131",
        "paper_authors": [
            "Yookyung Shin",
            "Younggun Lee",
            "Suhee Jo",
            "Yeongtae Hwang",
            "Taesu Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Strategies for developing a Conversational Speech Dataset for Text-To-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10802",
        "paper_authors": [
            "Adaeze O. Adigwe",
            "Esther Klabbers"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep CNN-based Inductive Transfer Learning for Sarcasm Detection in Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11323",
        "paper_authors": [
            "Xiyuan Gao",
            "Shekhar Nayak",
            "Matt Coler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Text-to-Speech Based on Latent Representation of Speaking Styles Using Spontaneous Dialogue",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-259",
        "paper_authors": [
            "Kentaro Mitsui",
            "Tianyu Zhao",
            "Kei Sawada",
            "Yukiya Hono",
            "Yoshihiko Nankaku",
            "Keiichi Tokuda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attention-based conditioning methods using variable frame rate for style-robust speaker verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-882",
        "paper_authors": [
            "Amber Afshan",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning from human perception to improve automatic speaker verification in style-mismatched conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-883",
        "paper_authors": [
            "Amber Afshan",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring audio-based stylistic variation in podcasts",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10871",
        "paper_authors": [
            "Katariina Martikainen",
            "Jussi Karlgren",
            "Khiet Truong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Evaluation of Speaker Similarity",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-75",
        "paper_authors": [
            "Kamil Deja",
            "Ariadna S\u00e1nchez",
            "Julian Roth",
            "Marius Cotescu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mix and Match: An Empirical Study on Training Corpus Composition for Polyglot Text-To-Speech (TTS)",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-242",
        "paper_authors": [
            "Ziyao Zhang",
            "Alessio Falai",
            "Ariadna S\u00e1nchez",
            "Orazio Angelini",
            "Kayoko Yanagisawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "J-MAC: Japanese multi-speaker audiobook corpus for speech synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-444",
        "paper_authors": [
            "Shinnosuke Takamichi",
            "Wataru Nakata",
            "Naoko Tanji",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "REYD - The First Yiddish Text-to-Speech Dataset and System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-789",
        "paper_authors": [
            "Jacob Webber",
            "Samuel K. Lo",
            "Isaac L. Bleaman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data-augmented cross-lingual synthesis in a teacher-student framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-9995",
        "paper_authors": [
            "Marcel de Korte",
            "Jaebok Kim",
            "Aki Kunikoshi",
            "Adaeze Adigwe",
            "Esther Klabbers"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Production characteristics of obstruents in WaveNet and older TTS systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10606",
        "paper_authors": [
            "Ayushi Pandey",
            "S\u00e9bastien Le Maguer",
            "Julie Carson-Berndsen",
            "Naomi Harte"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Back to the Future: Extending the Blizzard Challenge 2013",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10633",
        "paper_authors": [
            "S\u00e9bastien Le Maguer",
            "Simon King",
            "Naomi Harte"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BibleTTS: a large, high-fidelity, multilingual, and uniquely African speech corpus",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10850",
        "paper_authors": [
            "Josh Meyer",
            "David Ifeoluwa Adelani",
            "Edresson Casanova",
            "Alp \u00d6ktem",
            "Daniel Whitenack",
            "Julian Weber",
            "Salomon Kabongo",
            "Elizabeth Salesky",
            "Iroro Orife",
            "Colin Leong",
            "Perez Ogayo",
            "Chris Chinenye Emezue",
            "Jonathan Mukiibi",
            "Salomey Osei",
            "Apelete Agbolo",
            "Victor Akinode",
            "Bernard Opoku",
            "Samuel Olanrewaju",
            "Jesujoba O. Alabi",
            "Shamsuddeen Hassan Muhammad"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10922",
        "paper_authors": [
            "Georgia Maniati",
            "Alexandra Vioni",
            "Nikolaos Ellinas",
            "Karolos Nikitaras",
            "Konstantinos Klapsas",
            "June Sig Sung",
            "Gunu Jho",
            "Aimilios Chalamandaris",
            "Pirros Tsiakoulis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Domain Generalization with Relaxed Instance Frequency-wise Normalization for Multi-device Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-61",
        "paper_authors": [
            "Byeonggeun Kim",
            "Seunghan Yang",
            "Jangho Kim",
            "Hyunsin Park",
            "Juntae Lee",
            "Simyung Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Couple learning for semi-supervised sound event detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-103",
        "paper_authors": [
            "Rui Tao",
            "Long Yan",
            "Kazushige Ouchi",
            "Xiangdong Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Oktoechos Classification in Liturgical Music Using SBU-LSTM/GRU",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-136",
        "paper_authors": [
            "Rajeev Rajan",
            "Ananya Ayasi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SoundDoA: Learn Sound Source Direction of Arrival and Semantics from Sound Raw Waveforms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-378",
        "paper_authors": [
            "Yuhang He",
            "Andrew Markham"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ORCA-WHISPER: An Automatic Killer Whale Sound Type Generation Toolkit Using Deep Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-846",
        "paper_authors": [
            "Christian Bergler",
            "Alexander Barnhill",
            "Dominik Perrin",
            "Manuel Schmitt",
            "Andreas K. Maier",
            "Elmar N\u00f6th"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Convolutional Recurrent Neural Network with Auxiliary Stream for Robust Variable-Length Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-959",
        "paper_authors": [
            "Joon-Hyuk Chang",
            "Won-Gook Choi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Symbolic Music Segmentation using Ensemble Temporal Prediction Errors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10379",
        "paper_authors": [
            "Shahaf Bassan",
            "Yossi Adi",
            "Jeffrey S. Rosenschein"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visually-aware Acoustic Event Detection using Heterogeneous Graphs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10670",
        "paper_authors": [
            "Amir Shirian",
            "Krishna Somandepalli",
            "Victor Sanchez",
            "Tanaya Guha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Passive Similarity based CNN Filter Pruning for Efficient Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10714",
        "paper_authors": [
            "Arshdeep Singh",
            "Mark D. Plumbley"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MAE-AST: Masked Autoencoding Audio Spectrogram Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10961",
        "paper_authors": [
            "Alan Baade",
            "Puyuan Peng",
            "David Harwath"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What can Speech and Language Tell us About the Working Alliance in Psychotherapy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-347",
        "paper_authors": [
            "Sebastian Peter Bayerl",
            "Gabriel Roccabruna",
            "Shammur Absar Chowdhury",
            "Tommaso Ciulli",
            "Morena Danieli",
            "Korbinian Riedhammer",
            "Giuseppe Riccardi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TB or not TB? Acoustic cough analysis for tuberculosis classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-383",
        "paper_authors": [
            "Geoffrey T. Frost",
            "Grant Theron",
            "Thomas Niesler"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Are reported accuracies in the clinical speech machine learning literature overoptimistic?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-691",
        "paper_authors": [
            "Visar Berisha",
            "Chelsea Krantsevich",
            "Gabriela Stegmann",
            "Shira Hahn",
            "Julie Liss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection of Expressed Emotion from Five-Minute Speech Samples: Challenges and Opportunities",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10188",
        "paper_authors": [
            "Bahman Mirheidari",
            "Andr\u00e9 Bittar",
            "Nicholas Cummins",
            "Johnny Downs",
            "Helen L. Fisher",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic cognitive assessment: Combining sparse datasets with disparate cognitive scores",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10205",
        "paper_authors": [
            "Bahman Mirheidari",
            "Daniel Blackburn",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Semi-supervised Learning for Audio-based COVID-19 Detection using FixMatch",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10274",
        "paper_authors": [
            "Ting Dang",
            "Thomas Quinnell",
            "Cecilia Mascolo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analyzing the impact of SARS-CoV-2 variants on respiratory sound signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10389",
        "paper_authors": [
            "Debarpan Bhattacharya",
            "Debottam Dutta",
            "Neeraj Kumar Sharma",
            "Srikanth Raj Chetupalli",
            "Pravin Mote",
            "Sriram Ganapathy",
            "Chandrakiran C",
            "Sahiti Nori",
            "Suhail K. K",
            "Sadhana Gonuguntla",
            "Murali Alagesan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automated Evaluation of Standardized Dementia Screening Tests",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10436",
        "paper_authors": [
            "Franziska Braun",
            "Markus F\u00f6rstel",
            "Bastian Oppermann",
            "Andreas Erzigkeit",
            "Hartmut Lehfeld",
            "Thomas Hillemacher",
            "Korbinian Riedhammer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alzheimer's Detection from English to Spanish Using Acoustic and Linguistic Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10883",
        "paper_authors": [
            "Paula Andrea P\u00e9rez-Toro",
            "Philipp Klumpp",
            "Abner Hernandez",
            "Tomas Arias",
            "Patricia Lillo",
            "Andrea Slachevsky",
            "Adolfo Mart\u00edn Garc\u00eda",
            "Maria Schuster",
            "Andreas K. Maier",
            "Elmar N\u00f6th",
            "Juan Rafael Orozco-Arroyave"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extract and Abstract with BART for Clinical Notes from Doctor-Patient Conversations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10935",
        "paper_authors": [
            "Jing Su",
            "Longxiang Zhang",
            "Hamid Reza Hassanzadeh",
            "Thomas Schaaf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dyadic Interaction Assessment from Free-living Audio for Depression Severity Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11129",
        "paper_authors": [
            "Bishal Lamichhane",
            "Nidal Moukaddam",
            "Ankit B. Patel",
            "Ashutosh Sabharwal"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "COVID-19 detection based on respiratory sensing from speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11209",
        "paper_authors": [
            "Venkata Srikanth Nallanthighal",
            "Aki H\u00e4rm\u00e4",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bifurcation and Reunion: A Loss-Guided Two-Stage Approach for Monaural Speech Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-668",
        "paper_authors": [
            "Xiaoxue Luo",
            "Chengshi Zheng",
            "Andong Li",
            "Yuxuan Ke",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A deep complex multi-frame filtering network for stereophonic acoustic echo cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-669",
        "paper_authors": [
            "Linjuan Cheng",
            "Chengshi Zheng",
            "Andong Li",
            "Yuquan Wu",
            "Renhua Peng",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker- and Phone-aware Convolutional Transformer Network for Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10077",
        "paper_authors": [
            "Chang Han",
            "Weiping Tu",
            "Yuhong Yang",
            "Jingyi Li",
            "Xinhong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Personalized Acoustic Echo Cancellation for Full-duplex Communications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10225",
        "paper_authors": [
            "Shimin Zhang",
            "Ziteng Wang",
            "Yukai Ju",
            "Yihui Fu",
            "Yueyue Na",
            "Qiang Fu",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LCSM: A Lightweight Complex Spectral Mapping Framework for Stereophonic Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10252",
        "paper_authors": [
            "Chenggang Zhang",
            "Jinjiang Liu",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Neural AEC and Beamforming with Double-Talk Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10358",
        "paper_authors": [
            "Vinay Kothapally",
            "Yong Xu",
            "Meng Yu",
            "Shi-Xiong Zhang",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Clock Skew Robust Acoustic Echo Cancellation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10833",
        "paper_authors": [
            "Karim Helwani",
            "Erfan Soltanmohammadi",
            "Michael Mark Goodwin",
            "Arvindh Krishnaswamy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Conformer-based Waveform-domain Neural Acoustic Echo Canceller Optimized for ASR Accuracy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10974",
        "paper_authors": [
            "Sankaran Panchapagesan",
            "Arun Narayanan",
            "Turaj Zakizadeh Shabestary",
            "Shuai Shao",
            "Nathan Howard",
            "Alex Park",
            "James Walker",
            "Alexander Gruenstein"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Complex-Valued Time-Frequency Self-Attention for Speech Dereverberation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11277",
        "paper_authors": [
            "Vinay Kothapally",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Noise-independent Speech Representation for High-quality Voice Conversion for Noisy Target Speakers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-570",
        "paper_authors": [
            "Liumeng Xue",
            "Shan Yang",
            "Na Hu",
            "Dan Su",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Representation Disentanglement with Adversarial Mutual Information Learning for One-shot Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-571",
        "paper_authors": [
            "Sicheng Yang",
            "Methawee Tantrawenith",
            "Haolin Zhuang",
            "Zhiyong Wu",
            "Aolan Sun",
            "Jianzong Wang",
            "Ning Cheng",
            "Huaizhen Tang",
            "Xintao Zhao",
            "Jie Wang",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FlowCPCVC: A Contrastive Predictive Coding Supervised Flow Framework for Any-to-Any Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-577",
        "paper_authors": [
            "Jiahong Huang",
            "Wen Xu",
            "Yule Li",
            "Junshi Liu",
            "Dongpeng Ma",
            "Wei Xiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Glow-WaveGAN 2: High-quality Zero-shot Text-to-speech Synthesis and Any-to-any Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-684",
        "paper_authors": [
            "Yi Lei",
            "Shan Yang",
            "Jian Cong",
            "Lei Xie",
            "Dan Su"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AdaSpeech 4: Adaptive Text to Speech in Zero-Shot Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-901",
        "paper_authors": [
            "Yihan Wu",
            "Xu Tan",
            "Bohan Li",
            "Lei He",
            "Sheng Zhao",
            "Ruihua Song",
            "Tao Qin",
            "Tie-Yan Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Content-Dependent Fine-Grained Speaker Embedding for Zero-Shot Speaker Adaptation in Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10054",
        "paper_authors": [
            "Yixuan Zhou",
            "Changhe Song",
            "Xiang Li",
            "Luwen Zhang",
            "Zhiyong Wu",
            "Yanyao Bian",
            "Dan Su",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streamable Speech Representation Disentanglement and Multi-Level Prosody Modeling for Live One-Shot Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10277",
        "paper_authors": [
            "Haoquan Yang",
            "Liqun Deng",
            "Yu Ting Yeung",
            "Nianzu Zheng",
            "Yong Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Accent Conversion using Pre-trained Model and Synthesized Data from Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10729",
        "paper_authors": [
            "Tuan-Nam Nguyen",
            "Ngoc-Quan Pham",
            "Alexander Waibel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VoiceMe: Personalized voice generation in TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10855",
        "paper_authors": [
            "Pol van Rijn",
            "Silvan Mertes",
            "Dominik Schiller",
            "Piotr Dura",
            "Hubert Siuzdak",
            "Peter M. C. Harrison",
            "Elisabeth Andr\u00e9",
            "Nori Jacoby"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DeID-VC: Speaker De-identification via Zero-shot Pseudo Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11036",
        "paper_authors": [
            "Ruibin Yuan",
            "Yuxuan Wu",
            "Jacob Li",
            "Jaxter Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Improved Zero-shot Voice Conversion with Conditional DSVAE",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11225",
        "paper_authors": [
            "Jiachen Lian",
            "Chunlei Zhang",
            "Gopala Krishna Anumanchipalli",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Disentanglement of Emotional Style and Speaker Identity for Expressive Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10249",
        "paper_authors": [
            "Zongyang Du",
            "Berrak Sisman",
            "Kun Zhou",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-13",
        "paper_authors": [
            "Zhong Meng",
            "Yashesh Gaur",
            "Naoyuki Kanda",
            "Jinyu Li",
            "Xie Chen",
            "Yu Wu",
            "Yifan Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Complementary Joint Training Approach Using Unpaired Speech and Text A Complementary Joint Training Approach Using Unpaired Speech and Text",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-291",
        "paper_authors": [
            "Ye-Qian Du",
            "Jie Zhang",
            "Qiu-Shi Zhu",
            "Lirong Dai",
            "Ming-Hui Wu",
            "Xin Fang",
            "Zhou-Wang Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Transfer and Distillation from Autoregressive to Non-Autoregessive Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-632",
        "paper_authors": [
            "Xun Gong",
            "Zhikai Zhou",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Confidence Score Based Conformer Speaker Adaptation for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-680",
        "paper_authors": [
            "Jiajun Deng",
            "Xurong Xie",
            "Tianzi Wang",
            "Mingyu Cui",
            "Boyang Xue",
            "Zengrui Jin",
            "Mengzhe Geng",
            "Guinan Li",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decoupled Federated Learning for ASR with Non-IID Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-720",
        "paper_authors": [
            "Han Zhu",
            "Jindong Wang",
            "Gaofeng Cheng",
            "Pengyuan Zhang",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation For CTC-based Speech Recognition Via Consistent Acoustic Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-775",
        "paper_authors": [
            "Sanli Tian",
            "Keqi Deng",
            "Zehan Li",
            "Lingxuan Ye",
            "Gaofeng Cheng",
            "Ta Li",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Generalization of Deep Neural Network Acoustic Models with Length Perturbation and N-best Based Label Smoothing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-821",
        "paper_authors": [
            "Xiaodong Cui",
            "George Saon",
            "Tohru Nagano",
            "Masayuki Suzuki",
            "Takashi Fukuda",
            "Brian Kingsbury",
            "Gakuto Kurata"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Supervision-Guided Codebooks for Masked Prediction in Speech Pre-training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-936",
        "paper_authors": [
            "Chengyi Wang",
            "Yiming Wang",
            "Yu Wu",
            "Sanyuan Chen",
            "Jinyu Li",
            "Shujie Liu",
            "Furu Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Pre-training with Acoustic Piece",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-981",
        "paper_authors": [
            "Shuo Ren",
            "Shujie Liu",
            "Yu Wu",
            "Long Zhou",
            "Furu Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Censer: Curriculum Semi-supervised Learning for Speech Recognition Based on Self-supervised Pre-training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10226",
        "paper_authors": [
            "Bowen Zhang",
            "Songjun Cao",
            "Xiaoming Zhang",
            "Yike Zhang",
            "Long Ma",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10368",
        "paper_authors": [
            "Junyi Ao",
            "Ziqiang Zhang",
            "Long Zhou",
            "Shujie Liu",
            "Haizhou Li",
            "Tom Ko",
            "Lirong Dai",
            "Jinyu Li",
            "Yao Qian",
            "Furu Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PISA: PoIncar\u00e9 Saliency-Aware Interpolative Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11001",
        "paper_authors": [
            "Ramit Sawhney",
            "Megh Thakkar",
            "Vishwa Shah",
            "Puneet Mathur",
            "Vasu Sharma",
            "Dinesh Manocha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Continual Learning of End-to-End Speech Recognition Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11093",
        "paper_authors": [
            "Muqiao Yang",
            "Ian R. Lane",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Target-Speaker ASR with Neural Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11425",
        "paper_authors": [
            "Takafumi Moriya",
            "Hiroshi Sato",
            "Tsubasa Ochiai",
            "Marc Delcroix",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SPLICEOUT: A Simple and Efficient Audio Augmentation Method",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-572",
        "paper_authors": [
            "Arjit Jain",
            "Pranay Reddy Samala",
            "Deepak Mittal",
            "Preethi Jyothi",
            "Maneesh Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tokenwise Contrastive Pretraining for Finer Speech-to-BERT Alignment in End-to-End Speech-to-Intent Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-239",
        "paper_authors": [
            "Vishal Sunder",
            "Eric Fosler-Lussier",
            "Samuel Thomas",
            "Hong-Kwang Kuo",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Japanese ASR-Robust Pre-trained Language Model with Pseudo-Error Sentences Generated by Grapheme-Phoneme Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-327",
        "paper_authors": [
            "Yasuhito Ohsugi",
            "Itsumi Saito",
            "Kyosuke Nishida",
            "Sen Yoshida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Spoken Language Understanding with Cross-Modal Contrastive Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-658",
        "paper_authors": [
            "Jingjing Dong",
            "Jiayi Fu",
            "Peng Zhou",
            "Hao Li",
            "Xiaorui Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-bit Shift Network for End-to-End Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-760",
        "paper_authors": [
            "Anderson R. Avila",
            "Khalil Bibi",
            "Rui Heng Yang",
            "Xinlin Li",
            "Chao Xing",
            "Xiao Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Meta Auxiliary Learning for Low-resource Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-916",
        "paper_authors": [
            "Yingying Gao",
            "Junlan Feng",
            "Chao Deng",
            "Shilei Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Knowledge Distillation For Robust Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-958",
        "paper_authors": [
            "Ye Wang",
            "Baishun Ling",
            "Yanmeng Wang",
            "Junhao Xue",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incorporating Dual-Aware with Hierarchical Interactive Memory Networks for Task-Oriented Dialogue",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10501",
        "paper_authors": [
            "Yangyang Ou",
            "Peng Zhang",
            "Jing Zhang",
            "Hui Gao",
            "Xing Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pay More Attention to History: A Context Modeling Strategy for Conversational Text-to-SQL",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10596",
        "paper_authors": [
            "Yuntao Li",
            "Hanchu Zhang",
            "Yutian Li",
            "Sirui Wang",
            "Wei Wu",
            "Yan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Small Changes Make Big Differences: Improving Multi-turn Response Selection in Dialogue Systems via Fine-Grained Contrastive Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10656",
        "paper_authors": [
            "Yuntao Li",
            "Can Xu",
            "Huang Hu",
            "Lei Sha",
            "Yan Zhang",
            "Daxin Jiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Low-Cost End-to-End Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10702",
        "paper_authors": [
            "Marco Dinarelli",
            "Marco Naguib",
            "Fran\u00e7ois Portet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-Task BERT Model for Schema-Guided Dialogue State Tracking",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10852",
        "paper_authors": [
            "Eleftherios Kapelonis",
            "Efthymios Georgiou",
            "Alexandros Potamianos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WavPrompt: Towards Few-Shot Spoken Language Understanding with Frozen Language Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11031",
        "paper_authors": [
            "Heting Gao",
            "Junrui Ni",
            "Kaizhi Qian",
            "Yang Zhang",
            "Shiyu Chang",
            "Mark Hasegawa-Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis of praising skills focusing on utterance contents",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11200",
        "paper_authors": [
            "Asahi Ogushi",
            "Toshiki Onishi",
            "Yohei Tahara",
            "Ryo Ishii",
            "Atsushi Fukayama",
            "Takao Nakamura",
            "Akihiro Miyata"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech2Slot: A Limited Generation Framework with Boundary Detection for Slot Filling from Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11347",
        "paper_authors": [
            "Pengwei Wang",
            "Yinpei Su",
            "Xiaohuan Zhou",
            "Xin Ye",
            "Liangchen Wei",
            "Ming Liu",
            "Yuan You",
            "Feijun Jiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Training of Audio Transformers with Patchout",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-227",
        "paper_authors": [
            "Khaled Koutini",
            "Jan Schl\u00fcter",
            "Hamid Eghbal-zadeh",
            "Gerhard Widmer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CNN-based Audio Event Recognition for Automated Violence Classification and Rating for Prime Video Content",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10053",
        "paper_authors": [
            "Mayank Sharma",
            "Tarun Gupta",
            "Kenny Qiu",
            "Xiang Hao",
            "Raffay Hamid"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Frequency Dynamic Convolution: Frequency-Adaptive Pattern Recognition for Sound Event Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10127",
        "paper_authors": [
            "Hyeonuk Nam",
            "Seong-Hu Kim",
            "Byeong-Yun Ko",
            "Yong-Hwa Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Breathing Pattern Information in Synthetic Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10271",
        "paper_authors": [
            "Zohreh Mostaani",
            "Mathew Magimai-Doss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interactive Auido-text Representation for Automated Audio Captioning with Contrastive Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10510",
        "paper_authors": [
            "Chen Chen",
            "Nana Hou",
            "Yuchen Hu",
            "Heqing Zou",
            "Xiaofeng Qi",
            "Eng Siong Chng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deformable CNN and Imbalance-Aware Feature Learning for Singing Technique Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11137",
        "paper_authors": [
            "Yuya Yamamoto",
            "Juhan Nam",
            "Hiroko Terasawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Does Audio Deepfake Detection Generalize?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-108",
        "paper_authors": [
            "Nicolas M. M\u00fcller",
            "Pavel Czempin",
            "Franziska Dieckmann",
            "Adam Froghyar",
            "Konstantin B\u00f6ttinger"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attacker Attribution of Audio Deepfakes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-129",
        "paper_authors": [
            "Nicolas M. M\u00fcller",
            "Franziska Dieckmann",
            "Jennifer Williams"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Are disentangled representations all you need to build speaker anonymization systems?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10586",
        "paper_authors": [
            "Pierre Champion",
            "Anthony Larcher",
            "Denis Jouvet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards End-to-End Private Automatic Speaker Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10672",
        "paper_authors": [
            "Francisco Teixeira",
            "Alberto Abad",
            "Bhiksha Raj",
            "Isabel Trancoso"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Extracting Targeted Training Data from ASR Models, and How to Mitigate It",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10895",
        "paper_authors": [
            "Ehsan Amid",
            "Om Dipakbhai Thakkar",
            "Arun Narayanan",
            "Rajiv Mathews",
            "Fran\u00e7oise Beaufays"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Unintended Memorization in Language-Model-Fused ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10909",
        "paper_authors": [
            "W. Ronny Huang",
            "Steve Chien",
            "Om Dipakbhai Thakkar",
            "Rajiv Mathews"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer-Based Automatic Speech Recognition with Auxiliary Input of Source Language Text Toward Transcribing Simultaneous Interpretation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-448",
        "paper_authors": [
            "Shuta Taniguchi",
            "Tsuneo Kato",
            "Akihiro Tamura",
            "Keiji Yasuda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AVATAR: Unconstrained Audiovisual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-776",
        "paper_authors": [
            "Valentin Gabeur",
            "Paul Hongsuck Seo",
            "Arsha Nagrani",
            "Chen Sun",
            "Karteek Alahari",
            "Cordelia Schmid"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Word Discovery in Visually Grounded, Self-Supervised Speech Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10652",
        "paper_authors": [
            "Puyuan Peng",
            "David Harwath"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End multi-talker audio-visual ASR using an active speaker attention module",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10866",
        "paper_authors": [
            "Richard Rose",
            "Olivier Siohan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer-Based Video Front-Ends for Audio-Visual Speech Recognition for Single and Muti-Person Video",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10920",
        "paper_authors": [
            "Dmitriy Serdyuk",
            "Otavio Braga",
            "Olivier Siohan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11311",
        "paper_authors": [
            "Joanna Hong",
            "Minsu Kim",
            "Daehun Yoo",
            "Yong Man Ro"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Frame-Level Stutter Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-204",
        "paper_authors": [
            "John B. Harvill",
            "Mark Hasegawa-Johnson",
            "Chang D. Yoo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Heart Failure Through Voice Analysis using Self-Supervised Mode-Based Memory Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-643",
        "paper_authors": [
            "Darshana Priyasad",
            "Andi Partovi",
            "Sridha Sridharan",
            "Maryam Kashefpoor",
            "Tharindu Fernando",
            "Simon Denman",
            "Clinton Fookes",
            "Jia Tang",
            "David Kaye"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Detection of Speech Sound Disorder in Child Speech Using Posterior-based Speaker Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-935",
        "paper_authors": [
            "Si Ioi Ng",
            "Cymie Wing-Yee Ng",
            "Jiarui Wang",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation for Dementia Detection in Spoken Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10210",
        "paper_authors": [
            "Dominika Woszczyk",
            "Anna Hl\u00e9dikov\u00e1",
            "Alican Akman",
            "Soteris Demetriou",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Representation Learning on Breathing and Speech Signals for COVID-19 Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10376",
        "paper_authors": [
            "Debottam Dutta",
            "Debarpan Bhattacharya",
            "Sriram Ganapathy",
            "Amir Hossein Poorjam",
            "Deepak Mittal",
            "Maneesh Singh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detecting Dysfluencies in Stuttering Therapy Using wav2vec 2.0",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10908",
        "paper_authors": [
            "Sebastian Peter Bayerl",
            "Dominik Wagner",
            "Elmar N\u00f6th",
            "Korbinian Riedhammer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HYU Submission for the SASV Challenge 2022: Reforming Speaker Embeddings with Spoofing-Aware Conditioning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-210",
        "paper_authors": [
            "Jeong-Hwan Choi",
            "Joon-Young Yang",
            "Ye-Rin Jeoung",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Two Methods for Spoofing-Aware Speaker Verification: Multi-Layer Perceptron Score Fusion Model and Integrated Embedding Projector",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-602",
        "paper_authors": [
            "Jungwoo Heo",
            "Ju-Ho Kim",
            "Hyun-seo Shin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoofing-Aware Attention based ASV Back-end with Multiple Enrollment Utterances and a Sampling Strategy for the SASV Challenge 2022",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10495",
        "paper_authors": [
            "Chang Zeng",
            "Lin Zhang",
            "Meng Liu",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Subnetwork Approach for Spoofing Aware Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10921",
        "paper_authors": [
            "Alexander Alenin",
            "Nikita Torgashov",
            "Anton Okhotnikov",
            "Rostislav Makarov",
            "Ivan Yakovlev"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SASV 2022: The First Spoofing-Aware Speaker Verification Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11270",
        "paper_authors": [
            "Jee-weon Jung",
            "Hemlata Tak",
            "Hye-jin Shim",
            "Hee-Soo Heo",
            "Bong-Jin Lee",
            "Soo-Whan Chung",
            "Ha-Jin Yu",
            "Nicholas W. D. Evans",
            "Tomi Kinnunen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Representation Selective Self-distillation and wav2vec 2.0 Feature Exploration for Spoof-aware Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11460",
        "paper_authors": [
            "Jin Woo Lee",
            "Eungbeom Kim",
            "Junghyun Koo",
            "Kyogu Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "tPLCnet: Real-time Deep Packet Loss Concealment in the Time Domain Using a Short Temporal Context",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10157",
        "paper_authors": [
            "Nils L. Westhausen",
            "Bernd T. Meyer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Role of Spatial, Spectral, and Temporal Processing for DNN-based Non-linear Multi-channel Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-162",
        "paper_authors": [
            "Kristina Tesch",
            "Nils-Hendrik Mohrmann",
            "Timo Gerkmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DDS: A new device-degraded speech dataset for speech enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-441",
        "paper_authors": [
            "Haoyu Li",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Direction-Aware Joint Adaptation of Neural Speech Enhancement and Recognition in Real Multiparty Conversational Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10508",
        "paper_authors": [
            "Yicheng Du",
            "Aditya Arie Nugraha",
            "Kouhei Sekiguchi",
            "Yoshiaki Bando",
            "Mathieu Fontaine",
            "Kazuyoshi Yoshii"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Refining DNN-based Mask Estimation using CGMM-based EM Algorithm for Multi-channel Noise Reduction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10632",
        "paper_authors": [
            "Julitta Bartolewska",
            "Stanislaw Kacprzak",
            "Konrad Kowalczyk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10653",
        "paper_authors": [
            "Simon Welker",
            "Julius Richter",
            "Timo Gerkmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Embeddings for Speech Classification in Noisy Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10707",
        "paper_authors": [
            "Mohamed Nabih Ali",
            "Alessio Brutti",
            "Daniele Falavigna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Audio Waveform Prior",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10735",
        "paper_authors": [
            "Arnon Turetzky",
            "Tzvi Michelson",
            "Yossi Adi",
            "Shmuel Peleg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Convolutive Weighted Multichannel Wiener Filter Front-end for Distant Automatic Speech Recognition in Reverberant Multispeaker Scenarios",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10780",
        "paper_authors": [
            "Mieszko Fras",
            "Marcin Witkowski",
            "Konrad Kowalczyk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Transformer-based Speech Enhancement Using Long Frames and STFT Magnitudes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10781",
        "paper_authors": [
            "Danilo de Oliveira",
            "Tal Peer",
            "Timo Gerkmann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Speech Enhancement through Fine-Grained Speech Characteristics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11161",
        "paper_authors": [
            "Muqiao Yang",
            "Joseph Konan",
            "David Bick",
            "Anurag Kumar",
            "Shinji Watanabe",
            "Bhiksha Raj"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Creating New Voices using Normalizing Flows",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10195",
        "paper_authors": [
            "Piotr Bilinski",
            "Thomas Merritt",
            "Abdelhamid Ezzerg",
            "Kamil Pokora",
            "Sebastian Cygert",
            "Kayoko Yanagisawa",
            "Roberto Barra-Chicote",
            "Daniel Korzekwa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unify and Conquer: How Phonetic Feature Representation Affects Polyglot Text-To-Speech (TTS)",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-233",
        "paper_authors": [
            "Ariadna S\u00e1nchez",
            "Alessio Falai",
            "Ziyao Zhang",
            "Orazio Angelini",
            "Kayoko Yanagisawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Human-in-the-loop Speaker Adaptation for DNN-based Multi-speaker TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-257",
        "paper_authors": [
            "Kenta Udagawa",
            "Yuki Saito",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GlowVC: Mel-spectrogram space disentangling model for language-independent text-free voice conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-322",
        "paper_authors": [
            "Magdalena Proszewska",
            "Grzegorz Beringer",
            "Daniel S\u00e1ez-Trigueros",
            "Thomas Merritt",
            "Abdelhamid Ezzerg",
            "Roberto Barra-Chicote"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One-Shot Speaker Adaptation Based on Initialization by Generative Adversarial Networks for TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-934",
        "paper_authors": [
            "Jaeuk Lee",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10045",
        "paper_authors": [
            "Alon Levkovitch",
            "Eliya Nachmani",
            "Lior Wolf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Advanced Speaker Embedding with Predictive Variance of Gaussian Distribution for Speaker Adaptation in TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10193",
        "paper_authors": [
            "Jaeuk Lee",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Karaoker: Alignment-free singing voice synthesis with speech training data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10446",
        "paper_authors": [
            "Panagiotis Kakoulidis",
            "Nikolaos Ellinas",
            "Georgios Vamvoukakis",
            "Konstantinos Markopoulos",
            "June Sig Sung",
            "Gunu Jho",
            "Pirros Tsiakoulis",
            "Aimilios Chalamandaris"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ACNN-VC: Utilizing Adaptive Convolution Neural Network for One-Shot Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10473",
        "paper_authors": [
            "Ji Sub Um",
            "Yeunju Choi",
            "Hoi Rin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified System for Voice Cloning and Voice Conversion through Diffusion Probabilistic Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10879",
        "paper_authors": [
            "Tasnima Sadekova",
            "Vladimir Gogoryan",
            "Ivan Vovk",
            "Vadim Popov",
            "Mikhail A. Kudinov",
            "Jiansheng Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Multi-Task Learning for Disentangling Timbre and Pitch in Singing Voice Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10994",
        "paper_authors": [
            "Tae-Woo Kim",
            "Min-Su Kang",
            "Gyeong-Hoon Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Symmetrical Convolutional Transformer Networks for Speech to Singing Voice Style Transfer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11256",
        "paper_authors": [
            "Shrutina Agarwal",
            "Naoya Takahashi",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Speaker Emotion Transfer for Low-Resource Text-to-Speech Using Non-Parallel Voice Conversion with Pitch-Shift Data Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11278",
        "paper_authors": [
            "Ryo Terashima",
            "Ryuichi Yamamoto",
            "Eunwoo Song",
            "Yuma Shirahata",
            "Hyun-Wook Yoon",
            "Jae-Min Kim",
            "Kentaro Tachibana"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep residual spiking neural network for keyword spotting in low-resource settings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-107",
        "paper_authors": [
            "Qu Yang",
            "Qi Liu",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reducing Domain mismatch in Self-supervised speech pre-training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-736",
        "paper_authors": [
            "Murali Karthick Baskar",
            "Andrew Rosenberg",
            "Bhuvana Ramabhadran",
            "Yu Zhang",
            "Nicol\u00e1s Serrano"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sub-8-Bit Quantization Aware Training for 8-Bit Neural Network Accelerator with On-Device Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-874",
        "paper_authors": [
            "Kai Zhen",
            "Hieu Duy Nguyen",
            "Raviteja Chinta",
            "Nathan Susanj",
            "Athanasios Mouchtaris",
            "Tariq Afzal",
            "Ariya Rastrow"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "W2V2-Light: A Lightweight Version of Wav2vec 2.0 for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10339",
        "paper_authors": [
            "Dong-Hyun Kim",
            "Jae-Hong Lee",
            "Ji-Hwan Mo",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Compute Cost Amortized Transformer for Streaming ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10465",
        "paper_authors": [
            "Yi Xie",
            "Jonathan Macoskey",
            "Martin Radfar",
            "Feng-Ju Chang",
            "Brian John King",
            "Ariya Rastrow",
            "Athanasios Mouchtaris",
            "Grant P. Strimel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On-demand compute reduction with stochastic wav2vec 2.0",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10584",
        "paper_authors": [
            "Apoorv Vyas",
            "Wei-Ning Hsu",
            "Michael Auli",
            "Alexei Baevski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transfer Learning from Multi-Lingual Speech Translation Benefits Low-Resource Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10744",
        "paper_authors": [
            "Geoffroy Vanderreydt",
            "Fran\u00e7ois Remy",
            "Kris Demuynck"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FeaRLESS: Feature Refinement Loss for Ensembling Self-Supervised Learning Features in Robust End-to-end Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10917",
        "paper_authors": [
            "Szu-Jui Chen",
            "Jiamin Xie",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perceptual Evaluation of Penetrating Voices through a Semantic Differential Method",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-100",
        "paper_authors": [
            "Tatsuya Kitamura",
            "Naoki Kunimoto",
            "Hideki Kawahara",
            "Shigeaki Amano"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-native Perception of Japanese Singleton/Geminate Contrasts: Comparison of Mandarin and Mongolian Speakers Differing in Japanese Experience",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-397",
        "paper_authors": [
            "Kimiko Tsukada",
            "Yurong Yurong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating the effects of modified speech on perceptual speaker identification performance",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-463",
        "paper_authors": [
            "Benjamin O'Brien",
            "Christine Meunier",
            "Alain Ghio"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mandarin Lombard Grid: a Lombard-grid-like corpus of Standard Chinese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-854",
        "paper_authors": [
            "Yuhong Yang",
            "Xufeng Chen",
            "Qingmu Liu",
            "Weiping Tu",
            "Hongyang Chen",
            "Linjun Cai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Syllable sequence of /a/+/ta/ can be heard as /atta/ in Japanese with visual or tactile cues",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10099",
        "paper_authors": [
            "Takayuki Arai",
            "Miho Yamada",
            "Megumi Okusawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "InQSS: a speech intelligibility and quality assessment model using a multi-task learning network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10153",
        "paper_authors": [
            "Yu-Wen Chen",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the influence of personality on acoustic-prosodic entrainment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10470",
        "paper_authors": [
            "Andreas Weise",
            "Rivka Levitan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Common and differential acoustic representation of interpersonal and tactile iconic perception of Mandarin vowels",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10531",
        "paper_authors": [
            "Yi Li",
            "Xiaoming Jiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Noise on Speech Perception and Spoken Word Comprehension",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10543",
        "paper_authors": [
            "Jovan Eranovic",
            "Daniel Pape",
            "Magda Stroinska",
            "Elisabet Service",
            "Marijana Matkovski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acquisition of Two Consecutive Neutral Tones in Mandarin-Speaking Preschoolers: Phonological Representation and Phonetic Realization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10561",
        "paper_authors": [
            "Sichen Zhang",
            "Aijun Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Air tissue boundary segmentation using regional loss in real-time Magnetic Resonance Imaging video for speech production",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10579",
        "paper_authors": [
            "Anwesha Roy",
            "Varun Belagali",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language-specific interactions of vowel discrimination in noise",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10673",
        "paper_authors": [
            "Mark Gibson",
            "Marcel Schlechtweg",
            "Beatriz Blecua Falgueras",
            "Judit Ayala Alcalde"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Improved Transformer Transducer Architecture for Hindi-English Code Switched Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10763",
        "paper_authors": [
            "Ansen Antony",
            "Sumanth Reddy Kota",
            "Akhilesh Lade",
            "Spoorthy V",
            "Shashidhar G. Koolagudi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VocaLiST: An Audio-Visual Synchronisation Model for Lips and Voices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10861",
        "paper_authors": [
            "Venkatesh Shenoy Kadandale",
            "Juan F. Montesinos",
            "Gloria Haro"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Lingual Transfer Learning Approach to Phoneme Error Detection via Latent Phonetic Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10228",
        "paper_authors": [
            "Jovan M. Dalhouse",
            "Katunobu Itou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Global RNN Transducer Models For Multi-dialect Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-165",
        "paper_authors": [
            "Takashi Fukuda",
            "Samuel Thomas",
            "Masayuki Suzuki",
            "Gakuto Kurata",
            "George Saon",
            "Brian Kingsbury"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Stress Detection in Isolated English Words for Computer-Assisted Pronunciation Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-197",
        "paper_authors": [
            "Vera Bernhard",
            "Sandra Schwab",
            "Jean-Philippe Goldman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On-the-fly ASR Corrections with Audio Exemplars",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-389",
        "paper_authors": [
            "Golan Pundak",
            "Tsendsuren Munkhdalai",
            "Khe Chai Sim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FFM: A Frame Filtering Mechanism To Accelerate Inference Speed For Conformer In Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-656",
        "paper_authors": [
            "Zongfeng Quan",
            "Nick J. C. Wang",
            "Wei Chu",
            "Tao Wei",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Two-pass Decoding and Cross-adaptation Based System Combination of End-to-end Conformer and Hybrid TDNN ASR Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-696",
        "paper_authors": [
            "Mingyu Cui",
            "Jiajun Deng",
            "Shoukang Hu",
            "Xurong Xie",
            "Tianzi Wang",
            "Shujie Hu",
            "Mengzhe Geng",
            "Boyang Xue",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Recognition of Out-of-vocabulary Words in E2E Code-switching ASR by Fusing Speech Generation Methods",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-719",
        "paper_authors": [
            "Lingxuan Ye",
            "Gaofeng Cheng",
            "Runyan Yang",
            "Zehui Yang",
            "Sanli Tian",
            "Pengyuan Zhang",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mitigating bias against non-native accents",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-836",
        "paper_authors": [
            "Yuanyuan Zhang",
            "Yixuan Zhang",
            "Bence Mark Halpern",
            "Tanvina Patel",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Multi-level Acoustic Feature Extraction Framework for Transformer Based End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-915",
        "paper_authors": [
            "Jin Li",
            "Rongfeng Su",
            "Xurong Xie",
            "Lan Wang",
            "Nan Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LAE: Language-Aware Encoder for Monolingual and Multilingual ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-923",
        "paper_authors": [
            "Jinchuan Tian",
            "Jianwei Yu",
            "Chunlei Zhang",
            "Yuexian Zou",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Significance of single frequency filter for the development of children's KWS system",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-980",
        "paper_authors": [
            "Biswaranjan Pattanayak",
            "Gayadhar Pradhan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Language Agnostic Multilingual Streaming On-Device ASR System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10006",
        "paper_authors": [
            "Bo Li",
            "Tara N. Sainath",
            "Ruoming Pang",
            "Shuo-Yiin Chang",
            "Qiumin Xu",
            "Trevor Strohman",
            "Vince Chen",
            "Qiao Liang",
            "Heguang Liu",
            "Yanzhang He",
            "Parisa Haghani",
            "Sameer Bidichandani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Minimizing Sequential Confusion Error in Speech Command Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10067",
        "paper_authors": [
            "Zhanheng Yang",
            "Hang Lv",
            "Xiong Wang",
            "Ao Zhang",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Homophone Disambiguation Profits from Durational Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10109",
        "paper_authors": [
            "Barbara Schuppler",
            "Emil Berger",
            "Xenia Kogler",
            "Franz Pernkopf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Specific Utterance Ensemble based Transfer Attack on Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10139",
        "paper_authors": [
            "Chu-Xiao Zuo",
            "Jia-Yi Leng",
            "Wu-Jun Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Complex Frequency Domain Linear Prediction: A Tool to Compute Modulation Spectrum of Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11095",
        "paper_authors": [
            "Samik Sadhu",
            "Hynek Hermansky"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spectral Modification Based Data Augmentation For Improving End-to-End ASR For Children's Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11343",
        "paper_authors": [
            "Vishwanath Pratap Singh",
            "Hardik B. Sailor",
            "Supratik Bhattacharya",
            "Abhishek Pandey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Joint Modeling of Conversation History-Dependent and Independent ASR Systems with Multi-History Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11357",
        "paper_authors": [
            "Ryo Masumura",
            "Yoshihiro Yamazaki",
            "Saki Mizuno",
            "Naoki Makishima",
            "Mana Ihori",
            "Mihiro Uchida",
            "Hiroshi Sato",
            "Tomohiro Tanaka",
            "Akihiko Takashima",
            "Satoshi Suzuki",
            "Shota Orihashi",
            "Takafumi Moriya",
            "Nobukatsu Hojo",
            "Atsushi Ando"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming End-to-End Multilingual Speech Recognition with Joint Language Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11249",
        "paper_authors": [
            "Chao Zhang",
            "Bo Li",
            "Tara N. Sainath",
            "Trevor Strohman",
            "Sepand Mavandadi",
            "Shuo-Yiin Chang",
            "Parisa Haghani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Anchor-Free Detector for Continuous Speech Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-296",
        "paper_authors": [
            "Zhiyuan Zhao",
            "Chuanxin Tang",
            "Chengdong Yao",
            "Chong Luo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-complex and Highly-performed Binary Residual Neural Network for Small-footprint Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-573",
        "paper_authors": [
            "Xiao Wang",
            "Song Cheng",
            "Jun Li",
            "Shushan Qiao",
            "Yumei Zhou",
            "Yi Zhan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UniKW-AT: Unified Keyword Spotting and Audio Tagging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-607",
        "paper_authors": [
            "Heinrich Dinkel",
            "Yongqing Wang",
            "Zhiyong Yan",
            "Junbo Zhang",
            "Yujun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ESSumm: Extractive Speech Summarization from Untranscribed Meeting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-945",
        "paper_authors": [
            "Jun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "XTREME-S: Evaluating Cross-lingual Speech Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10007",
        "paper_authors": [
            "Alexis Conneau",
            "Ankur Bapna",
            "Yu Zhang",
            "Min Ma",
            "Patrick von Platen",
            "Anton Lozhkov",
            "Colin Cherry",
            "Ye Jia",
            "Clara Rivera",
            "Mihir Kale",
            "Daan van Esch",
            "Vera Axelrod",
            "Simran Khanuja",
            "Jonathan H. Clark",
            "Orhan Firat",
            "Michael Auli",
            "Sebastian Ruder",
            "Jason Riesa",
            "Melvin Johnson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Negative Guided Abstractive Dialogue Summarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10395",
        "paper_authors": [
            "Junpeng Liu",
            "Yanyan Zou",
            "Yuxuan Xi",
            "Shengjie Li",
            "Mian Ma",
            "Zhuoye Ding",
            "Bo Long"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring representation learning for small-footprint keyword spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10558",
        "paper_authors": [
            "Fan Cui",
            "Liyong Guo",
            "Quandong Wang",
            "Peng Gao",
            "Yujun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large-Scale Streaming End-to-End Speech Translation with Neural Transducers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10953",
        "paper_authors": [
            "Jian Xue",
            "Peidong Wang",
            "Jinyu Li",
            "Matt Post",
            "Yashesh Gaur"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic Embedding for ASR Robustness in Entity Resolution",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10956",
        "paper_authors": [
            "Xiaozhou Zhou",
            "Ruying Bao",
            "William M. Campbell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical Tagger with Multi-task Learning for Cross-domain Slot Filling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11187",
        "paper_authors": [
            "Xiao Wei",
            "Yuke Si",
            "Shiquan Wang",
            "Longbiao Wang",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-class AUC Optimization for Robust Small-footprint Keyword Spotting with Limited Training Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11356",
        "paper_authors": [
            "Menglong Xu",
            "Shengqiang Li",
            "Chengdong Liang",
            "Xiao-Lei Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weak supervision for Question Type Detection with large language models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-345",
        "paper_authors": [
            "Jir\u00ed Mart\u00ednek",
            "Christophe Cerisara",
            "Pavel Kr\u00e1l",
            "Ladislav Lenc",
            "Josef Baloun"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BIT-MI Deep Learning-based Model to Non-intrusive Speech Quality Assessment Challenge in Online Conferencing Applications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10010",
        "paper_authors": [
            "Miao Liu",
            "Jing Wang",
            "Liang Xu",
            "Jianqian Zhang",
            "Shicong Li",
            "Fei Xiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MOS Prediction Network for Non-intrusive Speech Quality Assessment in Online Conferencing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10081",
        "paper_authors": [
            "Wenjing Liu",
            "Chuan Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-intrusive Speech Quality Assessment with a Multi-Task Learning based Subband Adaptive Attention Temporal Convolutional Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10315",
        "paper_authors": [
            "Xiaofeng Shu",
            "Yanjie Chen",
            "Chuxiang Shang",
            "Yan Zhao",
            "Chengshuai Zhao",
            "Yehang Zhu",
            "Chuanzeng Huang",
            "Yuxuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Soft-label Learn for No-Intrusive Speech Quality Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10400",
        "paper_authors": [
            "Junyong Hao",
            "Shunzhou Ye",
            "Cheng Lu",
            "Fei Dong",
            "Jingang Liu",
            "Dong Pi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ConferencingSpeech 2022 Challenge: Non-intrusive Objective Speech Quality Assessment (NISQA) Challenge for Online Conferencing Applications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10597",
        "paper_authors": [
            "Gaoxiong Yi",
            "Wei Xiao",
            "Yiming Xiao",
            "Babak Naderi",
            "Sebastian M\u00f6ller",
            "Wafaa Wardah",
            "Gabriel Mittag",
            "Ross Cutler",
            "Zhuohuang Zhang",
            "Donald S. Williamson",
            "Fei Chen",
            "Fuzheng Yang",
            "Shidong Shang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MOSRA: Joint Mean Opinion Score and Room Acoustics Speech Quality Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10698",
        "paper_authors": [
            "Karl El Hajal",
            "Milos Cernak",
            "Pablo Mainar"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CCATMos: Convolutional Context-aware Transformer Network for Non-intrusive Speech Quality Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10857",
        "paper_authors": [
            "Yuchen Liu",
            "Li-Chia Yang",
            "Alexander Pawlicki",
            "Marko Stamenovic"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Impairment Representation Learning for Speech Quality Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11295",
        "paper_authors": [
            "Lianwu Chen",
            "Xinlei Ren",
            "Xu Zhang",
            "Xiguang Zheng",
            "Chen Zhang",
            "Liang Guo",
            "Bing Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring linguistic feature and model combination for speech recognition based automatic AD detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-723",
        "paper_authors": [
            "Yi Wang",
            "Tianzi Wang",
            "Zi Ye",
            "Lingwei Meng",
            "Shoukang Hu",
            "Xixin Wu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ECAPA-TDNN Based Depression Detection from Clinical Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10051",
        "paper_authors": [
            "Dong Wang",
            "Yanhui Ding",
            "Qing Zhao",
            "Peilin Yang",
            "Shuping Tan",
            "Ya Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Step Towards Preserving Speakers' Identity While Detecting Depression Via Speaker Disentanglement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10798",
        "paper_authors": [
            "Vijay Ravi",
            "Jinhan Wang",
            "Jonathan Flint",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Corpus Size Requirements for Training and Evaluating Depression Risk Models Using Spoken Language",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10888",
        "paper_authors": [
            "Tomasz Rutowski",
            "Amir Harati",
            "Elizabeth Shriberg",
            "Yang Lu",
            "Piotr Chlebek",
            "Ricardo Oliveira"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Learning Approaches for Detecting Alzheimer's Dementia from Conversational Speech of ILSE Study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10942",
        "paper_authors": [
            "Ayimnisagul Ablimit",
            "Karen Scholz",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Depression Severity Score Prediction Using Articulatory Coordination Features and Hierarchical Attention Based Text Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11099",
        "paper_authors": [
            "Nadee Seneviratne",
            "Carol Y. Espy-Wilson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR Error Detection via Audio-Transcript entailment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11177",
        "paper_authors": [
            "Nimshi Venkat Meripo",
            "Sandeep Konam"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CopyCat2: A Single Model for Multi-Speaker TTS and Many-to-Many Fine-Grained Prosody Transfer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-367",
        "paper_authors": [
            "Sri Karlapati",
            "Penny Karanasou",
            "Mateusz Lajszczak",
            "Syed Ammar Abbas",
            "Alexis Moinet",
            "Peter Makarov",
            "Ray Li",
            "Arent van Korlaar",
            "Simon Slangen",
            "Thomas Drugman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simple and Effective Multi-sentence TTS with Expressive and Coherent Prosody",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-379",
        "paper_authors": [
            "Peter Makarov",
            "Syed Ammar Abbas",
            "Mateusz Lajszczak",
            "Arnaud Joly",
            "Sri Karlapati",
            "Alexis Moinet",
            "Thomas Drugman",
            "Penny Karanasou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Modeling for End-to-End Empathetic Dialogue Speech Synthesis Using Linguistic and Prosodic Contexts of Dialogue History",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-403",
        "paper_authors": [
            "Yuto Nishimura",
            "Yuki Saito",
            "Shinnosuke Takamichi",
            "Kentaro Tachibana",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Emphasis Control for Parallel Neural TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-411",
        "paper_authors": [
            "Shreyas Seshadri",
            "Tuomo Raitio",
            "Dan Castellani",
            "Jiangchuan Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BERT, can HE predict contrastive focus? Predicting and controlling prominence in neural TTS using a language model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10116",
        "paper_authors": [
            "Brooke Stephenson",
            "Laurent Besacier",
            "Laurent Girin",
            "Thomas Hueber"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Combining conversational speech with read speech to improve prosody in Text-to-Speech synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10167",
        "paper_authors": [
            "Johannah O'Mahony",
            "Catherine Lai",
            "Simon King"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Data Selection via Discrete Speech Representation for ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-399",
        "paper_authors": [
            "Zhiyun Lu",
            "Yongqiang Wang",
            "Yu Zhang",
            "Wei Han",
            "Zhehuai Chen",
            "Parisa Haghani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CTRL: Continual Representation Learning to Transfer Information of Pre-trained for WAV2VEC 2.0",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10063",
        "paper_authors": [
            "Jae-Hong Lee",
            "Chae Won Lee",
            "Jin-Seong Choi",
            "Joon-Hyuk Chang",
            "Woo Kyeong Seong",
            "Jeonghan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker adaptation for Wav2vec2 based dysarthric ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10896",
        "paper_authors": [
            "Murali Karthick Baskar",
            "Tim Herzig",
            "Diana Nguyen",
            "Mireia D\u00edez",
            "Tim Polzehl",
            "Luk\u00e1s Burget",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Parallel Voice Conversion for ASR Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10990",
        "paper_authors": [
            "Gary Wang",
            "Andrew Rosenberg",
            "Bhuvana Ramabhadran",
            "Fadi Biadsy",
            "Jesse Emond",
            "Yinghui Huang",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Consistency Training for Semi-Supervised Sequence-to-Sequence ASR via Speech Chain Reconstruction and Self-Transcribing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11169",
        "paper_authors": [
            "Heli Qi",
            "Sashi Novitasari",
            "Sakriani Sakti",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Encoder-Decoder Self-Supervised Pre-training for ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11338",
        "paper_authors": [
            "A. Arunkumar",
            "Srinivasan Umesh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An overview of discourse clicks in Central Swedish",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-583",
        "paper_authors": [
            "Margaret Zellers"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VOT and F0 perturbations for the realization of voicing contrast in Tohoku Japanese",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-587",
        "paper_authors": [
            "Hiroto Noguchi",
            "Sanae Matsui",
            "Naoya Watabe",
            "Chuyu Huang",
            "Ayako Hashimoto",
            "Ai Mizoguchi",
            "Mafuyu Kitahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Complex sounds and cross-language influence: The case of ejectives in Omani Mehri",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10199",
        "paper_authors": [
            "Rachid Ridouane",
            "Philipp Buech"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "When Phonetics Meets Morphology: Intervocalic Voicing Within and Across Words in Romance Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10725",
        "paper_authors": [
            "Mathilde Hutin",
            "Martine Adda-Decker",
            "Lori Lamel",
            "Ioana Vasilescu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The mapping between syntactic and prosodic phrasing in English and Mandarin",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10726",
        "paper_authors": [
            "Jianjing Kuang",
            "May Pik Yu Chan",
            "Nari Rhee",
            "Mark Liberman",
            "Hongwei Ding"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pharyngealization in Amazigh: Acoustic and articulatory marking over time",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10831",
        "paper_authors": [
            "Philipp Buech",
            "Rachid Ridouane",
            "Anne Hermes"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR-Generated Text for Language Model Pre-training Applied to Speech Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-352",
        "paper_authors": [
            "Valentin Pelloin",
            "Franck Dary",
            "Nicolas Herv\u00e9",
            "Beno\u00eet Favre",
            "Nathalie Camelin",
            "Antoine Laurent",
            "Laurent Besacier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contrastive Learning for Improving ASR Robustness in Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-781",
        "paper_authors": [
            "Ya-Hsin Chang",
            "Yun-Nung Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Under Label Noise for Robust Spoken Language Understanding systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-880",
        "paper_authors": [
            "Anoop Kumar",
            "Pankaj Kumar Sharma",
            "Aravind Illa",
            "Sriram Venkatapathy",
            "Subhrangshu Nandi",
            "Pritam Varma",
            "Anurag Dwarakanath",
            "Aram Galstyan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deliberation Model for On-Device Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10800",
        "paper_authors": [
            "Duc Le",
            "Akshat Shrivastava",
            "Paden D. Tomasello",
            "Suyoun Kim",
            "Aleksandr Livshits",
            "Ozlem Kalinli",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intent classification using pre-trained language agnostic embeddings for low resource languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10873",
        "paper_authors": [
            "Hemant Yadav",
            "Akshat Gupta",
            "Sai Krishna Rallabandi",
            "Alan W. Black",
            "Rajiv Ratn Shah"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Two-Pass Low Latency End-to-End Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10890",
        "paper_authors": [
            "Siddhant Arora",
            "Siddharth Dalmia",
            "Xuankai Chang",
            "Brian Yan",
            "Alan W. Black",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-intrusive Speech Intelligibility Metric Prediction for Hearing Impaired Individuals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10182",
        "paper_authors": [
            "George Close",
            "Samuel Hollands",
            "Stefan Goetze",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploiting Hidden Representations from a DNN-based Speech Recogniser for Speech Intelligibility Prediction in Hearing-impaired Listeners",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10399",
        "paper_authors": [
            "Zehai Tu",
            "Ning Ma",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Uncertainty Measures of Automatic Speech Recognition for Non-intrusive Speech Intelligibility Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10408",
        "paper_authors": [
            "Zehai Tu",
            "Ning Ma",
            "Jon Barker"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Intelligibility Prediction for Hearing-Impaired Listeners with the LEAP Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10460",
        "paper_authors": [
            "Jana Ro\u00dfbach",
            "Rainer Huber",
            "Saskia R\u00f6ttges",
            "Christopher F. Hauth",
            "Thomas Biberger",
            "Thomas Brand",
            "Bernd T. Meyer",
            "Jan Rennies"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Speech Intelligibility using the Spike Acativity Mutual Information Index",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10488",
        "paper_authors": [
            "Franklin Alvarez Cardinale",
            "Waldo Nogueira"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The 1st Clarity Prediction Challenge: A machine learning challenge for hearing aid intelligibility prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10821",
        "paper_authors": [
            "Jon Barker",
            "Michael Akeroyd",
            "Trevor J. Cox",
            "John F. Culling",
            "Jennifer Firth",
            "Simone Graetzer",
            "Holly Griffiths",
            "Lara Harris",
            "Graham Naylor",
            "Zuzanna Podwinska",
            "Eszter Porter",
            "Rhoddy Viveros Mu\u00f1oz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Conversion Can Improve ASR in Very Low-Resource Settings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-112",
        "paper_authors": [
            "Matthew Baas",
            "Herman Kamper"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation for Low-Resource Quechua ASR Improvement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-770",
        "paper_authors": [
            "Rodolfo Zevallos",
            "N\u00faria Bel",
            "Guillermo C\u00e1mbara",
            "Mireia Farr\u00fas",
            "Jordi Luque"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ScoutWav: Two-Step Fine-Tuning on Self-Supervised Automatic Speech Recognition for Low-Resource Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10270",
        "paper_authors": [
            "Kavan Fatehi",
            "Mercedes Torres Torres",
            "Ayse K\u00fc\u00e7\u00fckyilmaz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-supervised Acoustic and Language Modeling for Hindi ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10336",
        "paper_authors": [
            "Tarun Sai Bandarupalli",
            "Shakti Rath",
            "Nirmesh Shah",
            "Naoyuki Onoe",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Combining Spectral and Self-Supervised Features for Low Resource Speech Recognition and Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10796",
        "paper_authors": [
            "Dan Berrebbi",
            "Jiatong Shi",
            "Brian Yan",
            "Osbel L\u00f3pez-Francisco",
            "Jonathan D. Amith",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "When Is TTS Augmentation Through a Pivot Language Useful?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11203",
        "paper_authors": [
            "Nathaniel Romney Robinson",
            "Perez Ogayo",
            "Swetha R. Gangu",
            "David R. Mortensen",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low Resource Comparison of Attention-based and Hybrid ASR Exploiting wav2vec 2.0",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11318",
        "paper_authors": [
            "Aku Rouhe",
            "Anja Virkkunen",
            "Juho Leinonen",
            "Mikko Kurimo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gram Vaani ASR Challenge on spontaneous telephone speech recordings in regional variations of Hindi",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11371",
        "paper_authors": [
            "Anish Bhanushali",
            "Grant Bridgman",
            "Deekshitha G",
            "Prasanta Kumar Ghosh",
            "Pratik Kumar",
            "Saurabh Kumar",
            "Adithya Raj Kolladath",
            "Nithya Ravi",
            "Aaditeshwar Seth",
            "Ashish Seth",
            "Abhayjeet Singh",
            "Vrunda N. Sukhadia",
            "Srinivasan Umesh",
            "Sathvik Udupa",
            "Lodagala V. S. V. Durga Prasad"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio Similarity is Unreliable as a Proxy for Audio Quality",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-405",
        "paper_authors": [
            "Pranay Manocha",
            "Zeyu Jin",
            "Adam Finkelstein"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Overlapped Frequency-Distributed Network: Frequency-Aware Voice Spoofing Countermeasure",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-657",
        "paper_authors": [
            "Sunmook Choi",
            "Il-Youp Kwak",
            "Seungsang Oh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Formant Estimation and Tracking using Probabilistic Heat-Maps",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-749",
        "paper_authors": [
            "Yosi Shrem",
            "Felix Kreuk",
            "Joseph Keshet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Anti-Spoofing Using Transfer Learning with Variational Information Bottleneck",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10200",
        "paper_authors": [
            "Youngsik Eom",
            "Yeonghyeon Lee",
            "Ji Sub Um",
            "Hoi Rin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Pitch Estimation Using Multi-Branch CNN-LSTM and 1-Norm LP Residual",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10704",
        "paper_authors": [
            "Mudit D. Batra",
            "M. K. Jayesh",
            "C. S. Ramalingam"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DeepFry: Identifying Vocal Fry Using Deep Neural Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10756",
        "paper_authors": [
            "Bronya Roni Chernyak",
            "Talia Ben Simon",
            "Yael Segal",
            "Jeremy Steffman",
            "Eleanor Chodroff",
            "Jennifer Cole",
            "Joseph Keshet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phonetic Analysis of Self-supervised Representations of English Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10884",
        "paper_authors": [
            "Dan Wells",
            "Hao Tang",
            "Korin Richmond"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FitHuBERT: Going Thinner and Deeper for Knowledge Distillation of Speech Self-Supervised Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11112",
        "paper_authors": [
            "Yeonghyeon Lee",
            "Kangwook Jang",
            "Jahyun Goo",
            "Youngmoon Jung",
            "Hoi Rin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Combining Global and Localized Self-Supervised Models of Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11174",
        "paper_authors": [
            "Sri Harsha Dumpala",
            "Chandramouli Shama Sastry",
            "Rudolf Uher",
            "Sageev Oore"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-supervised Representation Fusion for Speech and Wearable Based Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11258",
        "paper_authors": [
            "Vipula Dissanayake",
            "Sachith Seneviratne",
            "Hussel Suriyaarachchi",
            "Elliott Wen",
            "Suranga Nanayakkara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Disentangled Speech Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-30",
        "paper_authors": [
            "Cal Peyser",
            "W. Ronny Huang",
            "Andrew Rosenberg",
            "Tara N. Sainath",
            "Michael Picheny",
            "Kyunghyun Cho"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Assessment of Speech Intelligibility using Consonant Similarity for Head and Neck Cancer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-182",
        "paper_authors": [
            "Sebasti\u00e3o Quintas",
            "Julie Mauclair",
            "Virginie Woisard",
            "Julien Pinquier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Compensation in Verbal and Nonverbal Communication after Total Laryngectomy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-369",
        "paper_authors": [
            "Marise Neijman",
            "Femke Hof",
            "Noelle Oosterom",
            "Roland Pfau",
            "Bertus van Rooy",
            "Rob J. J. H. van Son",
            "Michiel W. M. van den Brekel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "wav2vec2-based Speech Rating System for Children with Speech Sound Disorder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10103",
        "paper_authors": [
            "Yaroslav Getman",
            "Ragheb Al-Ghezi",
            "Katja Voskoboinik",
            "Tam\u00e1s Gr\u00f3sz",
            "Mikko Kurimo",
            "Giampiero Salvi",
            "Torbj\u00f8rn Svendsen",
            "Sofia Str\u00f6mbergsson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distinguishing between pre- and post-treatment in the speech of patients with chronic obstructive pulmonary disease",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10333",
        "paper_authors": [
            "Andreas Triantafyllopoulos",
            "Markus Fendler",
            "Anton Batliner",
            "Maurice Gerczuk",
            "Shahin Amiriparian",
            "Thomas M. Berghaus",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Study on the Phonetic Inventory Development of Children with Cochlear Implants for 5 Years after Implantation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10387",
        "paper_authors": [
            "Seonwoo Lee",
            "Sunhee Kim",
            "Minhwa Chung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluation of different antenna types and positions in a stepped frequency continuous-wave radar-based silent speech interface",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10431",
        "paper_authors": [
            "Jo\u00e3o V\u00edtor Menezes",
            "Pouriya Amini Digehsara",
            "Christoph Wagner",
            "Marco M\u00fctze",
            "Michael B\u00e4rhold",
            "Petr Schaffer",
            "Dirk Plettemeier",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Validation of the Neuro-Concept Detector framework for the characterization of speech disorders: A comparative study including Dysarthria and Dysphonia",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10631",
        "paper_authors": [
            "Sondes Abderrazek",
            "Corinne Fredouille",
            "Alain Ghio",
            "Muriel Lalain",
            "Christine Meunier",
            "Virginie Woisard"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Nonwords Pronunciation Classification in Language Development Tests for Preschool Children",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10777",
        "paper_authors": [
            "Ilja Baumann",
            "Dominik Wagner",
            "Sebastian P. Bayerl",
            "Tobias Bocklet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PERCEPT-R: An Open-Access American English Child/Clinical Speech Corpus Specialized for the Audio Classification of /\u0279/",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10785",
        "paper_authors": [
            "Nina Benway",
            "Jonathan L. Preston",
            "Elaine Hitchcock",
            "Asif Salekin",
            "Harshit Sharma",
            "Tara McAllister Byun"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Data Augmentation for End-to-end Silent Speech Recognition for Laryngectomees",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10868",
        "paper_authors": [
            "Beiming Cao",
            "Kristin Teplansky",
            "Nordine Sebkhi",
            "Arpan Bhavsar",
            "Omer T. Inan",
            "Robin Samlan",
            "Ted Mau",
            "Jun Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Statistical and clinical utility of multimodal dialogue-based speech and facial metrics for Parkinson's disease assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11048",
        "paper_authors": [
            "Hardik Kothare",
            "Michael Neumann",
            "Jackson Liscombe",
            "Oliver Roesler",
            "William Burke",
            "Andrew Exner",
            "Sandy Snyder",
            "Andrew Cornish",
            "Doug Habberstad",
            "David Pautler",
            "David Suendermann-Oeft",
            "Jessica Huber",
            "Vikram Ramanarayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluation of call centre conversations based on a high-level symbolic representation",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/arco22_interspeech.html",
        "paper_authors": [
            "Leticia Arco",
            "Carlos Mosquera",
            "Fabjola Braho",
            "Yisel Clavel Quintero",
            "Johan Loeckx"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evoc-Learn - High quality simulation of early vocal learning",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/xu22j_interspeech.html",
        "paper_authors": [
            "Yi Xu",
            "Anqi Xu",
            "Daniel R. van Niekerk",
            "Branislav Gerazov",
            "Peter Birkholz",
            "Paul Konstantin Krug",
            "Santitham Prom-on",
            "Lorna F. Halliday"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Watch Me Speak: 2D Visualization of Human Mouth during Speech",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/siddarth22_interspeech.html",
        "paper_authors": [
            "C. Siddarth",
            "Sathvik Udupa",
            "Prasanta Kumar Ghosh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Classification of Accented English Using CNN Model Trained on Amplitude Mel-Spectrograms",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-462",
        "paper_authors": [
            "Mariia Lesnichaia",
            "Veranika Mikhailava",
            "Natalia Bogach",
            "Yurii Lezhenin",
            "John Blake",
            "Evgeny Pyshkin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MIM-DG: Mutual information minimization-based domain generalization for speaker verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-142",
        "paper_authors": [
            "Woo Hyun Kang",
            "Jahangir Alam",
            "Abderrahim Fathan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Channel Far-Field Speaker Verification with Large-Scale Ad-hoc Microphone Arrays",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-219",
        "paper_authors": [
            "Chengdong Liang",
            "Yijiang Chen",
            "Jiadi Yao",
            "Xiao-Lei Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ant Multilingual Recognition System for OLR 2021 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-355",
        "paper_authors": [
            "Anqi Lyu",
            "Zhiming Wang",
            "Huijia Zhu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Class-Aware Distribution Alignment based Unsupervised Domain Adaptation for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-591",
        "paper_authors": [
            "Hang-Rui Hu",
            "Yan Song",
            "Li-Rong Dai",
            "Ian McLoughlin",
            "Lin Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EDITnet: A Lightweight Network for Unsupervised Domain Adaptation in Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-967",
        "paper_authors": [
            "Jingyu Li",
            "Wei Liu",
            "Tan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Why does Self-Supervised Learning for Speech Recognition Benefit Speaker Recognition?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10019",
        "paper_authors": [
            "Sanyuan Chen",
            "Yu Wu",
            "Chengyi Wang",
            "Shujie Liu",
            "Zhuo Chen",
            "Peidong Wang",
            "Gang Liu",
            "Jinyu Li",
            "Jian Wu",
            "Xiangzhan Yu",
            "Furu Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio Visual Multi-Speaker Tracking with Improved GCF and PMBM Filter",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10190",
        "paper_authors": [
            "Jinzheng Zhao",
            "Peipei Wu",
            "Xubo Liu",
            "Shidrokh Goudarzi",
            "Haohe Liu",
            "Yong Xu",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The HCCL System for the NIST SRE21",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10342",
        "paper_authors": [
            "Zhuo Li",
            "Runqiu Xiao",
            "Hangting Chen",
            "Zhenduo Zhao",
            "Zihan Zhang",
            "Wenchao Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UNet-DenseNet for Robust Far-Field Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10350",
        "paper_authors": [
            "Zhenke Gao",
            "Man-Wai Mak",
            "Weiwei Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Linguistic-Acoustic Similarity Based Accent Shift for Accent Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10444",
        "paper_authors": [
            "Qijie Shao",
            "Jinghao Yan",
            "Jian Kang",
            "Pengcheng Guo",
            "Xian Shi",
            "Pengfei Hu",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transducer-based language embedding for spoken language identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11281",
        "paper_authors": [
            "Peng Shen",
            "Xugang Lu",
            "Hisashi Kawai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Oriental Language Recognition (OLR) 2021: Summary and Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11348",
        "paper_authors": [
            "Binling Wang",
            "Feng Wang",
            "Wenxuan Hu",
            "Qiulin Wang",
            "Jing Li",
            "Dong Wang",
            "Lin Li",
            "Qingyang Hong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mixup regularization strategies for spoofing countermeasure system",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-140",
        "paper_authors": [
            "Woo Hyun Kang",
            "Jahangir Alam",
            "Abderrahim Fathan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-resource Low-footprint Wake-word Detection using Knowledge Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-529",
        "paper_authors": [
            "Arindam Ghosh",
            "Mark C. Fuhs",
            "Deblin Bagchi",
            "Bahman Farahani",
            "Monika Woszczyna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-856",
        "paper_authors": [
            "Shaojin Ding",
            "Rajeev Rikhye",
            "Qiao Liang",
            "Yanzhang He",
            "Quan Wang",
            "Arun Narayanan",
            "Tom O'Malley",
            "Ian McGraw"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Token-level Speaker Change Detection Using Speaker Difference and Speech Content via Continuous Integrate-and-fire",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-914",
        "paper_authors": [
            "Zhiyun Fan",
            "Zhenlin Liang",
            "Linhao Dong",
            "Yi Liu",
            "Shiyu Zhou",
            "Meng Cai",
            "Jun Zhang",
            "Zejun Ma",
            "Bo Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NAS-VAD: Neural Architecture Search for Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-975",
        "paper_authors": [
            "Daniel Rho",
            "Jinhyeok Park",
            "Jong Hwan Ko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Multi-Task Deep Learning for Noise-Robust Voice Activity Detection with Low Algorithmic Delay",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10033",
        "paper_authors": [
            "Claus M. Larsen",
            "Peter Koch",
            "Zheng-Hua Tan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rainbow Keywords: Efficient Incremental Learning for Online Spoken Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10500",
        "paper_authors": [
            "Yang Xiao",
            "Nana Hou",
            "Eng Siong Chng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Filler Word Detection and Classification: A Dataset and Benchmark",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10992",
        "paper_authors": [
            "Ge Zhu",
            "Juan Pablo C\u00e1ceres",
            "Justin Salamon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Multi-Talker ASR with Token-Level Serialized Output Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-7",
        "paper_authors": [
            "Naoyuki Kanda",
            "Jian Wu",
            "Yu Wu",
            "Xiong Xiao",
            "Zhong Meng",
            "Xiaofei Wang",
            "Yashesh Gaur",
            "Zhuo Chen",
            "Jinyu Li",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "pMCT: Patched Multi-Condition Training for Robust Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-117",
        "paper_authors": [
            "Pablo Peso Parada",
            "Agnieszka Dobrowolska",
            "Karthikeyan Saravanan",
            "Mete Ozay"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving ASR Robustness in Noisy Condition Through VAD Integration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-260",
        "paper_authors": [
            "Sashi Novitasari",
            "Takashi Fukuda",
            "Gakuto Kurata"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Empirical Sampling from Latent Utterance-wise Evidence Model for Missing Data ASR based on Neural Encoder-Decoder Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-576",
        "paper_authors": [
            "Ryu Takeda",
            "Yui Sudo",
            "Kazuhiro Nakadai",
            "Kazunori Komatani"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coarse-Grained Attention Fusion With Joint Training Framework for Complex Speech Enhancement and End-to-End Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-698",
        "paper_authors": [
            "Xuyi Zhuang",
            "Lu Zhang",
            "Zehua Zhang",
            "Yukun Qian",
            "Mingjiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DENT-DDSP: Data-efficient noisy speech generator using differentiable digital signal processors for explicit distortion modelling and noise-robust speech recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-763",
        "paper_authors": [
            "Zixun Guo",
            "Chen Chen",
            "Eng Siong Chng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Transformer-based Conversational ASR by Inter-Sentential Attention Mechanism",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10066",
        "paper_authors": [
            "Kun Wei",
            "Pengcheng Guo",
            "Ning Jiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Federated Self-supervised Speech Representations: Are We There Yet?",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10644",
        "paper_authors": [
            "Yan Gao",
            "Javier Fern\u00e1ndez-Marqu\u00e9s",
            "Titouan Parcollet",
            "Abhinav Mehrotra",
            "Nicholas D. Lane"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Leveraging Real Conversational Data for Multi-Channel Continuous Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10706",
        "paper_authors": [
            "Xiaofei Wang",
            "Dongmei Wang",
            "Naoyuki Kanda",
            "Sefik Emre Eskimez",
            "Takuya Yoshioka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Integration of Speech Recognition, Speech Enhancement, and Self-Supervised Learning Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10839",
        "paper_authors": [
            "Xuankai Chang",
            "Takashi Maekaku",
            "Yuya Fujita",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly-Supervised Neural Full-Rank Spatial Covariance Analysis for a Front-End System of Distant Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11077",
        "paper_authors": [
            "Yoshiaki Bando",
            "Takahiro Aizawa",
            "Katsutoshi Itoyama",
            "Kazuhiro Nakadai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A universally-deployable ASR frontend for joint acoustic echo cancellation, speech enhancement, and voice separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11140",
        "paper_authors": [
            "Thomas R. O'Malley",
            "Arun Narayanan",
            "Quan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker conditioned acoustic modeling for multi-speaker conversational ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11267",
        "paper_authors": [
            "Srikanth Raj Chetupalli",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hear No Evil: Towards Adversarial Robustness of Automatic Speech Recognition via Multi-Task Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11361",
        "paper_authors": [
            "Nilaksh Das",
            "Polo Chau"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tandem Multitask Training of Speaker Diarisation and Speech Recognition for Meeting Transcription",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11368",
        "paper_authors": [
            "Xianrui Zheng",
            "Chao Zhang",
            "Philip C. Woodland"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating the Impact of Crosslingual Acoustic-Phonetic Similarities on Multilingual Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10916",
        "paper_authors": [
            "Muhammad Umar Farooq",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Improved Deliberation Network with Text Pre-training for Code-Switching Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-221",
        "paper_authors": [
            "Zhijie Shen",
            "Wu Guo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CyclicAugment: Speech Data Random Augmentation with Cosine Annealing Scheduler for Auotmatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-526",
        "paper_authors": [
            "Zhihan Wang",
            "Feng Hou",
            "Yuanhang Qiu",
            "Zhizhong Ma",
            "Satwinder Singh",
            "Ruili Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prompt-based Re-ranking Language Model for ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-536",
        "paper_authors": [
            "Mengxi Nie",
            "Ming Yan",
            "Caixia Gong"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Avoid Overfitting User Specific Information in Federated Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-558",
        "paper_authors": [
            "Xin-Chun Li",
            "Jin-Lin Tang",
            "Shaoming Song",
            "Bingshuai Li",
            "Yinchuan Li",
            "Yunfeng Shao",
            "Le Gan",
            "De-Chuan Zhan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR Error Correction with Constrained Decoding on Operation Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-660",
        "paper_authors": [
            "Jingyuan Yang",
            "Rongjun Li",
            "Wei Peng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive multilingual speech recognition with pretrained models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-872",
        "paper_authors": [
            "Ngoc-Quan Pham",
            "Alexander Waibel",
            "Jan Niehues"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vietnamese Capitalization and Punctuation Recovery Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-931",
        "paper_authors": [
            "Hoang Thi Thu Uyen",
            "Nguyen Anh Tu",
            "Ta Duc Huy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-autoregressive Error Correction for CTC-based ASR with Phone-conditioned Masked LM",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10062",
        "paper_authors": [
            "Hayato Futami",
            "Hirofumi Inaguma",
            "Sei Ueno",
            "Masato Mimura",
            "Shinsuke Sakai",
            "Tatsuya Kawahara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "reducing multilingual context confusion for end-to-end code-switching automatic speech recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10286",
        "paper_authors": [
            "Shuai Zhang",
            "Jiangyan Yi",
            "Zhengkun Tian",
            "Jianhua Tao",
            "Yu Ting Yeung",
            "Liqun Deng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Residual Language Model for End-to-end Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10557",
        "paper_authors": [
            "Emiru Tsunoo",
            "Yosuke Kashiwagi",
            "Chaitanya Prasad Narisetty",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Empirical Study of Language Model Integration for Transducer based Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10576",
        "paper_authors": [
            "Huahuan Zheng",
            "Keyu An",
            "Zhijian Ou",
            "Chen Huang",
            "Ke Ding",
            "Guanglu Wan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Normalized Importance Sampling for Neural Language Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10588",
        "paper_authors": [
            "Zijian Yang",
            "Yingbo Gao",
            "Alexander Gerstenberger",
            "Jintao Jiang",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Contextual Recognition of Rare Words with an Alternate Spelling Prediction Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10991",
        "paper_authors": [
            "Jennifer Drexler Fox",
            "Natalie Delworth"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effect and Analysis of Large-scale Language Model Rescoring on Competitive ASR Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11123",
        "paper_authors": [
            "Takuma Udagawa",
            "Masayuki Suzuki",
            "Gakuto Kurata",
            "Nobuyasu Itoh",
            "George Saon"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language-specific Characteristic Assistance for Code-switching Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11426",
        "paper_authors": [
            "Tongtong Song",
            "Qiang Xu",
            "Meng Ge",
            "Longbiao Wang",
            "Hao Shi",
            "Yongjie Lv",
            "Yuqin Lin",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech intelligibility of simulated hearing loss sounds and its prediction using the Gammachirp Envelope Similarity Index (GESI)",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-211",
        "paper_authors": [
            "Toshio Irino",
            "Honoka Tamaru",
            "Ayako Yamamoto"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ELO-SPHERES intelligibility prediction model for the Clarity Prediction Challenge 2022",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10521",
        "paper_authors": [
            "Mark A. Huckvale",
            "Gaston Hilkhuysen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Listening with Googlears: Low-Latency Neural Multiframe Beamforming and Equalization for Hearing Aids",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10783",
        "paper_authors": [
            "Samuel J. Yang",
            "Scott Wisdom",
            "Chet Gnegy",
            "Richard F. Lyon",
            "Sagar Savla"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10838",
        "paper_authors": [
            "Ryandhimas Edo Zezario",
            "Fei Chen",
            "Chiou-Shann Fuh",
            "Hsin-Min Wang",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep Learning Platform for Language Education Research and Development",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/tan22c_interspeech.html",
        "paper_authors": [
            "Kye Min Tan",
            "Richeng Duan",
            "Xin Huang",
            "Bowei Zou",
            "Xuan Long Do"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A VR Interactive 3D Mandarin Pronunciation Teaching Model",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/jin22b_interspeech.html",
        "paper_authors": [
            "Yujia Jin",
            "Yanlu Xie",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Squashed Weight Distribution for Low Bit Quantization of Deep Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-50",
        "paper_authors": [
            "Nikko Strom",
            "Haidar Khan",
            "Wael Hamza"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating the Performance of State-of-the-Art ASR Systems on Non-Native English using Corpora with Extensive Language Background Variation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10433",
        "paper_authors": [
            "Samuel Hollands",
            "Daniel Blackburn",
            "Heidi Christensen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Seq-2-Seq based Refinement of ASR Output for Spoken Name Capture",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10885",
        "paper_authors": [
            "Karan Singla",
            "Shahab Jalalvand",
            "Yeon-Jun Kim",
            "Ryan Price",
            "Daniel Pressel",
            "Srinivas Bangalore"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Qualitative Evaluation of Language Model Rescoring in Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10931",
        "paper_authors": [
            "Thibault Ba\u00f1eras Roux",
            "Mickael Rouvier",
            "Jane Wottawa",
            "Richard Dufour"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Zero Oracle Word Error Rate on the Switchboard Benchmark",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10959",
        "paper_authors": [
            "Arlo Faria",
            "Adam Janin",
            "Sidhi Adkoli",
            "Korbinian Riedhammer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evaluating User Perception of Speech Recognition System Quality with Semantic Distance Metric",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11144",
        "paper_authors": [
            "Suyoun Kim",
            "Duc Le",
            "Weiyi Zheng",
            "Tarun Singh",
            "Abhinav Arora",
            "Xiaoyu Zhai",
            "Christian Fuegen",
            "Ozlem Kalinli",
            "Michael L. Seltzer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Emotional Intensity in Political Debates via Non-verbal Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-938",
        "paper_authors": [
            "Jeewoo Yoon",
            "Jinyoung Han",
            "Erik P. Bucy",
            "Jungseock Joo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Confusion Detection for Adaptive Conversational Strategies of An Oral Proficiency Assessment Interview Agent",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10075",
        "paper_authors": [
            "Mao Saeki",
            "Kotoka Miyagi",
            "Shinya Fujie",
            "Shungo Suzuki",
            "Tetsuji Ogawa",
            "Tetsunori Kobayashi",
            "Yoichi Matsuyama"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Learning for Prosody-Based Irony Classification in Spontaneous Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10978",
        "paper_authors": [
            "Helen Gent",
            "Chase Adams",
            "Yan Tang",
            "Chilin Shih"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Span Classification with Structured Information for Disfluency Detection in Spoken Utterances",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11242",
        "paper_authors": [
            "Sreyan Ghosh",
            "Sonal Kumar",
            "Yaman Kumar",
            "Rajiv Ratn Shah",
            "Srinivasan Umesh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Example-based Explanations with Adversarial Attacks for Respiratory Sound Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11355",
        "paper_authors": [
            "Yi Chang",
            "Zhao Ren",
            "Thanh Tam Nguyen",
            "Wolfgang Nejdl",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Which Model is Best: Comparing Methods and Metrics for Automatic Laughter Detection in a Naturalistic Conversational Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11379",
        "paper_authors": [
            "Gordon Rennie",
            "Olga Perepelkina",
            "Alessandro Vinciarelli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-supervised Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-777",
        "paper_authors": [
            "Yehoshua Dissen",
            "Felix Kreuk",
            "Joseph Keshet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Label-Efficient Self-Supervised Speaker Verification With Information Maximization and Contrastive Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-802",
        "paper_authors": [
            "Th\u00e9o Lepage",
            "R\u00e9da Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Attack Agnostic Dataset: Towards Generalization and Stabilization of Audio DeepFake Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10078",
        "paper_authors": [
            "Piotr Kawa",
            "Marcin Plata",
            "Piotr Syga"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-contrastive self-supervised learning of utterance-level speech representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11141",
        "paper_authors": [
            "Jaejin Cho",
            "Raghavendra Pappagari",
            "Piotr Zelasko",
            "Laureano Moro-Vel\u00e1zquez",
            "Jes\u00fas Villalba",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Barlow Twins self-supervised learning for robust speaker recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11301",
        "paper_authors": [
            "Mohammad MohammadAmini",
            "Driss Matrouf",
            "Jean-Fran\u00e7ois Bonastre",
            "Sandipana Dowerah",
            "Romain Serizel",
            "Denis Jouvet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relating the fundamental frequency of speech with EEG using a dilated convolutional network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-315",
        "paper_authors": [
            "Corentin Puffay",
            "Jana Van Canneyt",
            "Jonas Vanthornhout",
            "Hugo Van hamme",
            "Tom Francart"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prediction of L2 speech proficiency based on multi-level linguistic features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10369",
        "paper_authors": [
            "Verdiana De Fino",
            "Lionel Fontan",
            "Julien Pinquier",
            "Isabelle Ferran\u00e9",
            "Sylvain Detey"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The effect of increasing acoustic and linguistic complexity on auditory processing: an EEG study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10607",
        "paper_authors": [
            "Fareeha S. Rana",
            "Daniel Pape",
            "Elisabet Service"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recording and timing vocal responses in online experimentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10697",
        "paper_authors": [
            "Katrina Kechun Li",
            "Julia Schwarz",
            "Jasper Hong Sim",
            "Yixin Zhang",
            "Elizabeth Buchanan-Worster",
            "Brechtje Post",
            "Kirsty McDougall"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural correlates of acoustic and semantic cues during speech segmentation in French",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10986",
        "paper_authors": [
            "Maria del Mar Cordero",
            "Ambre Denis-No\u00ebl",
            "Elsa Spinelli",
            "Fanny Meunier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Evidence of Onset and Sustained Neural Responses to Isolated Phonemes from Intracranial Recordings in a Voice-based Cursor Control Task",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11344",
        "paper_authors": [
            "Kevin Meng",
            "Seo-Hyun Lee",
            "Farhad Goodarzy",
            "Simon J. Vogrin",
            "Mark J. Cook",
            "Seong-Whan Lee",
            "David B. Grayden"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-end model for named entity recognition from speech without paired training data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10231",
        "paper_authors": [
            "Salima Mdhaffar",
            "Jarod Duret",
            "Titouan Parcollet",
            "Yannick Est\u00e8ve"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multitask Learning for Low Resource Spoken Language Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11401",
        "paper_authors": [
            "Quentin Meeus",
            "Marie-Francine Moens",
            "Hugo Van hamme"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer Networks for Non-Intrusive Speech Quality Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10020",
        "paper_authors": [
            "M. K. Jayesh",
            "Mukesh Sharma",
            "Praneeth Vonteddu",
            "Mahaboob Ali Basha Shaik",
            "Sriram Ganapathy"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pre-trained Speech Representations as Feature Extractors for Speech Quality Assessment in Online Conferencing Applications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10147",
        "paper_authors": [
            "Bastiaan Tamm",
            "Helena Balabin",
            "Rik Vandenberghe",
            "Hugo Van hamme"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring the influence of fine-tuning data on wav2vec 2.0 model for blind speech quality prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10766",
        "paper_authors": [
            "Helard Becerra Martinez",
            "Alessandro Ragano",
            "Andrew Hines"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MAESTRO: Matched Speech Text Representations through Modality Matching",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10937",
        "paper_authors": [
            "Zhehuai Chen",
            "Yu Zhang",
            "Andrew Rosenberg",
            "Bhuvana Ramabhadran",
            "Pedro J. Moreno",
            "Ankur Bapna",
            "Heiga Zen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FiLM Conditioning with Enhanced Feature to the Transformer-based End-to-End Noisy Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-161",
        "paper_authors": [
            "Da-Hee Yang",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SepTr: Separable Transformer for Audio Spectrogram Processing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-249",
        "paper_authors": [
            "Nicolae-Catalin Ristea",
            "Radu Tudor Ionescu",
            "Fahad Shahbaz Khan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Spontaneous Speech Recognition Using Disfluency Labeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-281",
        "paper_authors": [
            "Koharu Horii",
            "Meiko Fukuda",
            "Kengo Ohta",
            "Ryota Nishimura",
            "Atsunori Ogawa",
            "Norihide Kitaoka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recent improvements of ASR models in the face of adversarial attacks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-400",
        "paper_authors": [
            "Rapha\u00ebl Olivier",
            "Bhiksha Raj"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Similarity and Content-based Phonetic Self Attention for Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-422",
        "paper_authors": [
            "Kyuhong Shim",
            "Wonyong Sung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalizing RNN-Transducer to Out-Domain Audio via Sparse Self-Attention Layers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-581",
        "paper_authors": [
            "Juntae Kim",
            "Jeehye Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge distillation for In-memory keyword spotting model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-633",
        "paper_authors": [
            "Zeyang Song",
            "Qi Liu",
            "Qu Yang",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Learning of Subword Dependent Model Scales",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10136",
        "paper_authors": [
            "Felix Meyer",
            "Wilfried Michel",
            "Mohammad Zeineldeen",
            "Ralf Schl\u00fcter",
            "Hermann Ney"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bayesian Recurrent Units and the Forward-Backward Algorithm",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11035",
        "paper_authors": [
            "Alexandre Bittar",
            "Philip N. Garner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Metric Learning for Audio-Text Cross-Modal Retrieval",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11115",
        "paper_authors": [
            "Xinhao Mei",
            "Xubo Liu",
            "Jianyuan Sun",
            "Mark D. Plumbley",
            "Wenwu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CT-SAT: Contextual Transformer for Sequential Audio Tagging",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-196",
        "paper_authors": [
            "Yuanbo Hou",
            "Zhaoyi Liu",
            "Bo Kang",
            "Yun Wang",
            "Dick Botteldooren"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ADFF: Attention Based Deep Feature Fusion Approach for Music Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-726",
        "paper_authors": [
            "Zi Huang",
            "Shulei Ji",
            "Zhilan Hu",
            "Chuangjian Cai",
            "Jing Luo",
            "Xinyu Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Visual Scene Classification Based on Multi-modal Graph Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-741",
        "paper_authors": [
            "Han Lei",
            "Ning Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MusicNet: Compact Convolutional Neural Network for Real-time Background Music Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-864",
        "paper_authors": [
            "Chandan K. A. Reddy",
            "Vishak Gopal",
            "Harishchandra Dubey",
            "Ross Cutler",
            "Sergiy Matusevych",
            "Robert Aichner"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "iCNN-Transformer: An improved CNN-Transformer with Channel-spatial Attention and Keyword Prediction for Automated Audio Captioning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10073",
        "paper_authors": [
            "Kun Chen",
            "Jun Wang",
            "Feng Deng",
            "Xiaorui Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ATST: Audio Representation Learning with Teacher-Student Transformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10126",
        "paper_authors": [
            "Xian Li",
            "Xiaofei Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Segment Model for Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10418",
        "paper_authors": [
            "Yajian Wang",
            "Jun Du",
            "Hang Chen",
            "Qing Wang",
            "Chin-Hui Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Novel Augmentation Schemes for Device Robust Acoustic Scene Classification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10468",
        "paper_authors": [
            "Sukanya Sonowal",
            "Anish Tamse"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WideResNet with Joint Representation Learning and Data Augmentation for Cover Song Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10600",
        "paper_authors": [
            "Shichao Hu",
            "Bin Zhang",
            "Jinhong Lu",
            "Yiliang Jiang",
            "Wucheng Wang",
            "Lingcheng Kong",
            "Weifeng Zhao",
            "Tao Jiang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Impact of Acoustic Event Tagging on Scene Classification in a Multi-Task Learning Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10905",
        "paper_authors": [
            "Rahil Parikh",
            "Harshavardhan Sundar",
            "Ming Sun",
            "Chao Wang",
            "Spyros Matsoukas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Introducing Auxiliary Text Query-modifier to Content-based Audio Retrieval",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11428",
        "paper_authors": [
            "Daiki Takeuchi",
            "Yasunori Ohishi",
            "Daisuke Niizumi",
            "Noboru Harada",
            "Kunio Kashino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker recognition-assisted robust audio deepfake detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-72",
        "paper_authors": [
            "Jiahui Pan",
            "Shuai Nie",
            "Hui Zhang",
            "Shulin He",
            "Kanghao Zhang",
            "Shan Liang",
            "Xueliang Zhang",
            "Jianhua Tao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Preventing sensitive-word recognition using self-supervised learning to preserve user-privacy for automatic speech recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-85",
        "paper_authors": [
            "Yuchen Liu",
            "Apu Kapadia",
            "Donald S. Williamson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NESC: Robust Neural End-2-End Speech Coding with GANs",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-430",
        "paper_authors": [
            "Nicola Pia",
            "Kishan Gupta",
            "Srikanth Korse",
            "Markus Multrus",
            "Guillaume Fuchs"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Error-Resilient Neural Speech Coding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-779",
        "paper_authors": [
            "Huaying Xue",
            "Xiulian Peng",
            "Xue Jiang",
            "Yan Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Scale Vector Quantization for Scalable Neural Speech Coding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10084",
        "paper_authors": [
            "Xue Jiang",
            "Xiulian Peng",
            "Huaying Xue",
            "Yuan Zhang",
            "Yan Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Vocoder is All You Need for Speech Super-resolution",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11017",
        "paper_authors": [
            "Haohe Liu",
            "Woosung Choi",
            "Xubo Liu",
            "Qiuqiang Kong",
            "Qiao Tian",
            "DeLiang Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11026",
        "paper_authors": [
            "Haohe Liu",
            "Xubo Liu",
            "Qiuqiang Kong",
            "Qiao Tian",
            "Yan Zhao",
            "DeLiang Wang",
            "Chuanzeng Huang",
            "Yuxuan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generating gender-ambiguous voices for privacy-preserving speech recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11322",
        "paper_authors": [
            "Dimitrios Stoidis",
            "Andrea Cavallaro"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for Singing Voice Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-48",
        "paper_authors": [
            "Yu Wang",
            "Xinsheng Wang",
            "Pengcheng Zhu",
            "Jie Wu",
            "Hanzhao Li",
            "Heyang Xue",
            "Yongmao Zhang",
            "Lei Xie",
            "Mengxiao Bi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Timbre Disentanglement in Non-Autoregressive Cross-Lingual Text-to-Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-205",
        "paper_authors": [
            "Haoyue Zhan",
            "Xinyuan Yu",
            "Haitong Zhang",
            "Yang Zhang",
            "Yue Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WeSinger: Data-augmented Singing Voice Synthesis with Auxiliary Losses",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-454",
        "paper_authors": [
            "Zewang Zhang",
            "Yibin Zheng",
            "Xinhui Li",
            "Li Lu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decoupled Pronunciation and Prosody Modeling in Meta-Learning-based Multilingual Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-831",
        "paper_authors": [
            "Yukun Peng",
            "Zhenhua Ling"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "KaraTuner: Towards End-to-End Natural Pitch Correction for Singing Voice in Karaoke",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-939",
        "paper_authors": [
            "Xiaobin Zhuang",
            "Huiran Yu",
            "Weifeng Zhao",
            "Tao Jiang",
            "Peng Hu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learn2Sing 2.0: Diffusion and Mutual Information-Based Target Speaker SVS by Learning from Singing Teacher",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-960",
        "paper_authors": [
            "Heyang Xue",
            "Xinsheng Wang",
            "Yongmao Zhang",
            "Lei Xie",
            "Pengcheng Zhu",
            "Mengxiao Bi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SingAug: Data Augmentation for Singing Voice Synthesis with Cycle-consistent Training Strategy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-978",
        "paper_authors": [
            "Shuai Guo",
            "Jiatong Shi",
            "Tao Qian",
            "Shinji Watanabe",
            "Qin Jin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Muskits: an End-to-end Music Processing Toolkit for Singing Voice Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10039",
        "paper_authors": [
            "Jiatong Shi",
            "Shuai Guo",
            "Tao Qian",
            "Tomoki Hayashi",
            "Yuning Wu",
            "Fangzheng Xu",
            "Xuankai Chang",
            "Huazhe Li",
            "Peter Wu",
            "Shinji Watanabe",
            "Qin Jin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pronunciation Dictionary-Free Multilingual Speech Synthesis by Combining Unsupervised and Supervised Phonetic Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10140",
        "paper_authors": [
            "Chang Liu",
            "Zhen-Hua Ling",
            "Ling-Hui Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards high-fidelity singing voice conversion with acoustic reference and contrastive predictive coding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10316",
        "paper_authors": [
            "Chao Wang",
            "Zhonghao Li",
            "Benlai Tang",
            "Xiang Yin",
            "Yuan Wan",
            "Yibiao Yu",
            "Zejun Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Improving the Expressiveness of Singing Voice Synthesis with BERT Derived Semantic Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10585",
        "paper_authors": [
            "Shaohuan Zhou",
            "Shun Lei",
            "Weiya You",
            "Deyi Tuo",
            "Yuren You",
            "Zhiyong Wu",
            "Shiyin Kang",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Normalization of code-switched text for speech synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10719",
        "paper_authors": [
            "Sreeram Manghat",
            "Sreeja Manghat",
            "Tanja Schultz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Synthesizing Near Native-accented Speech for a Non-native Speaker by Imitating the Pronunciation and Prosody of a Native Speaker",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11124",
        "paper_authors": [
            "Raymond Chung",
            "Brian Mak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Hierarchical Speaker Representation Framework for One-shot Singing Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11305",
        "paper_authors": [
            "Xu Li",
            "Shansong Liu",
            "Ying Shan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Learning with Multi-Target Contrastive Coding for Non-Native Acoustic Modeling of Mispronunciation Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-207",
        "paper_authors": [
            "Longfei Yang",
            "Jinsong Zhang",
            "Takahiro Shinozaki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "L2-GEN: A Neural Phoneme Paraphrasing Approach to L2 Speech Synthesis for Mispronunciation Diagnosis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-209",
        "paper_authors": [
            "Daniel Zhang",
            "Ashwinkumar Ganesan",
            "Sarah Campbell",
            "Daniel Korzekwa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Challenges remain in Building ASR for Spontaneous Preschool Children Speech in Naturalistic Educational Environments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-555",
        "paper_authors": [
            "Satwik Dutta",
            "Sarah Anne Tao",
            "Jacob C. Reyna",
            "Rebecca Elizabeth Hacker",
            "Dwight W. Irvin",
            "Jay F. Buzhardt",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-end Mispronunciation Detection with Simulated Error Distance",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-870",
        "paper_authors": [
            "Zhan Zhang",
            "Yuehai Wang",
            "Jianyi Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BiCAPT: Bidirectional Computer-Assisted Pronunciation Training with Normalizing Flows",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-878",
        "paper_authors": [
            "Zhan Zhang",
            "Yuehai Wang",
            "Jianyi Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Fluency Representation Learned from Sequential Raw Features for Improving Non-native Fluency Scoring",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-896",
        "paper_authors": [
            "Kaiqi Fu",
            "Shaojun Gao",
            "Xiaohai Tian",
            "Wei Li",
            "Zejun Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Alignment Method Leveraging Articulatory Features for Mispronunciation Detection and Diagnosis in L2 English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10309",
        "paper_authors": [
            "Qi Chen",
            "BingHuai Lin",
            "YanLu Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RefTextLAS: Reference Text Biased Listen, Attend, and Spell Model For Accurate Reading Evaluation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11078",
        "paper_authors": [
            "Phani Sankar Nidadavolu",
            "Na Xu",
            "Nick Jutila",
            "Ravi Teja Gadde",
            "Aswarth Abhilash Dara",
            "Joseph Savold",
            "Sapan Patel",
            "Aaron Hoff",
            "Veerdhawal Pande",
            "Kevin Crews",
            "Ankur Gandhe",
            "Ariya Rastrow",
            "Roland Maas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CoCA-MDD: A Coupled Cross-Attention based Framework for Streaming Mispronunciation Detection and Diagnosis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11155",
        "paper_authors": [
            "Nianzu Zheng",
            "Liqun Deng",
            "Wenyong Huang",
            "Yu Ting Yeung",
            "Baohua Xu",
            "Yuanyuan Guo",
            "Yasheng Wang",
            "Xiao Chen",
            "Xin Jiang",
            "Qun Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoofing-Aware Speaker Verification by Multi-Level Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-920",
        "paper_authors": [
            "Haibin Wu",
            "Lingwei Meng",
            "Jiawen Kang",
            "Jinchao Li",
            "Xu Li",
            "Xixin Wu",
            "Hung-yi Lee",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-end framework for spoof-aware speaker verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-139",
        "paper_authors": [
            "Woo Hyun Kang",
            "Jahangir Alam",
            "Abderrahim Fathan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The CLIPS System for 2022 Spoofing-Aware Speaker Verification Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-320",
        "paper_authors": [
            "Jucai Lin",
            "Tingwei Chen",
            "Jingbiao Huang",
            "Ruidong Fang",
            "Jun Yin",
            "Yuanping Yin",
            "Wei Shi",
            "Weizhen Huang",
            "Yapeng Mao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Norm-constrained Score-level Ensemble for Spoofing Aware Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-470",
        "paper_authors": [
            "Peng Zhang",
            "Peng Hu",
            "Xueliang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SASV Based on Pre-trained ASV System and Integrated Scoring Module",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10149",
        "paper_authors": [
            "Yuxiang Zhang",
            "Zhuo Li",
            "Wenchao Wang",
            "Pengyuan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Backend Ensemble for Speaker Verification and Spoofing Countermeasure",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10259",
        "paper_authors": [
            "Li Zhang",
            "Yue Li",
            "Huan Zhao",
            "Qing Wang",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NRI-FGSM: An Efficient Transferable Adversarial Attack for Speaker Recognition Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10499",
        "paper_authors": [
            "Hao Tan",
            "Junjian Zhang",
            "Huan Zhang",
            "Le Wang",
            "Yaguan Qian",
            "Zhaoquan Gu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SA-SASV: An End-to-End Spoof-Aggregated Spoofing-Aware Speaker Verification System",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11029",
        "paper_authors": [
            "Zhongwei Teng",
            "Quchen Fu",
            "Jules White",
            "Maria E. Powell",
            "Douglas C. Schmidt"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The DKU-OPPO System for the 2022 Spoofing-Aware Speaker Verification Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11190",
        "paper_authors": [
            "Xingming Wang",
            "Xiaoyi Qin",
            "Yikang Wang",
            "Yunfei Xu",
            "Ming Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-45",
        "paper_authors": [
            "Seungu Han",
            "Junhyeok Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SelfRemaster: Self-Supervised Speech Restoration with Analysis-by-Synthesis Approach Using Channel Modeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-298",
        "paper_authors": [
            "Takaaki Saeki",
            "Shinnosuke Takamichi",
            "Tomohiko Nakamura",
            "Naoko Tanji",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimization of Deep Neural Network (DNN) Speech Coder Using a Multi Time Scale Perceptual Loss Function",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-955",
        "paper_authors": [
            "Joon Byun",
            "Seungmin Shin",
            "Jongmo Sung",
            "Seungkwon Beack",
            "Youngcheol Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phase Vocoder For Time Stretch Based On Center Frequency Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10593",
        "paper_authors": [
            "Donghyeon Kim",
            "Bowon Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ultra-Low-Bitrate Speech Coding with Pretrained Transformers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10988",
        "paper_authors": [
            "Ali Siahkoohi",
            "Michael Chinen",
            "Tom Denton",
            "W. Bastiaan Kleijn",
            "Jan Skoglund"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analyzing Language-Independent Speaker Anonymization Framework under Unseen Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11065",
        "paper_authors": [
            "Xiaoxiao Miao",
            "Xin Wang",
            "Erica Cooper",
            "Junichi Yamagishi",
            "Natalia A. Tomashenko"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ConvRNN-T: Convolutional Augmented Recurrent Neural Network Transducers for Streaming Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10844",
        "paper_authors": [
            "Martin Radfar",
            "Rohit Barnwal",
            "Rupak Vignesh Swaminathan",
            "Feng-Ju Chang",
            "Grant P. Strimel",
            "Nathan Susanj",
            "Athanasios Mouchtaris"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Knowledge Distillation via Module Replacing for Automatic Speech Recognition with Recurrent Neural Network Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-500",
        "paper_authors": [
            "Kaiqi Zhao",
            "Hieu Nguyen",
            "Animesh Jain",
            "Nathan Susanj",
            "Athanasios Mouchtaris",
            "Lokesh Gupta",
            "Ming Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Memory-Efficient Training of RNN-Transducer with Sampled Softmax",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-787",
        "paper_authors": [
            "Jaesong Lee",
            "Lukas Lee",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multiple-hypothesis RNN-T Loss for Unsupervised Fine-tuning and Self-training of Neural Transducer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10330",
        "paper_authors": [
            "Cong-Thanh Do",
            "Mohan Li",
            "Rama Doddipatla"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Separator-Transducer-Segmenter: Streaming Recognition and Segmentation of Multi-party Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10738",
        "paper_authors": [
            "Ilya Sklyar",
            "Anna Piunova",
            "Christian Osendorfer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variations of multi-task learning for spoken language assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-28",
        "paper_authors": [
            "Jeremy Heng Meng Wong",
            "Huayun Zhang",
            "Nancy F. Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Detection of Learners' Listening Breakdown with Oral Dictation and Its Use to Model Listening Skill Improvement Exclusively Through Shadowing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-440",
        "paper_authors": [
            "Takuya Kunihara",
            "Chuanbo Zhu",
            "Daisuke Saito",
            "Nobuaki Minematsu",
            "Noriko Nakanishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Prosody Evaluation of L2 English Read Speech in Reference to Accent Dictionary with Transformer Encoder",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10344",
        "paper_authors": [
            "Yu Suzuki",
            "Tsuneo Kato",
            "Akihiro Tamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "View-Specific Assessment of L2 Spoken English",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10691",
        "paper_authors": [
            "Stefano Bann\u00f2",
            "Bhanu Balusu",
            "Mark J. F. Gales",
            "Kate Knill",
            "Konstantinos Kyriakopoulos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Effects of Implicit and Explicit Feedback in an ASR-based Reading Tutor for Dutch First-graders",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10810",
        "paper_authors": [
            "Yu Bai",
            "Ferdy Hubers",
            "Catia Cucchiarini",
            "Roeland van Hout",
            "Helmer Strik"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11039",
        "paper_authors": [
            "Mu Yang",
            "Kevin Hirschi",
            "Stephen Daniel Looney",
            "Okim Kang",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Response Timing Estimation for Spoken Dialog System using Dialog Act Estimation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-746",
        "paper_authors": [
            "Jin Sakuma",
            "Shinya Fujie",
            "Tetsunori Kobayashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hesitations in Urdu/Hindi: Distribution and Properties of Fillers & Silences",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-805",
        "paper_authors": [
            "Farhat Jabeen",
            "Simon Betz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interpretabilty of Speech Emotion Recognition modelled using Self-Supervised Speech and Text Pre-Trained Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10685",
        "paper_authors": [
            "K. V. Vijay Girish",
            "Srikanth Konjeti",
            "Jithendra Vepa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Does Utterance entails Intent?: Evaluating Natural Language Inference Based Setup for Few-Shot Intent Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10794",
        "paper_authors": [
            "Ayush Kumar",
            "Vijit Malik",
            "Jithendra Vepa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigating perception of spoken dialogue acceptability through surprisal",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10808",
        "paper_authors": [
            "Sarenne Carrol Wallbridge",
            "Catherine Lai",
            "Peter Bell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-Latency Online Streaming VideoQA Using Audio-Visual Transformers",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10891",
        "paper_authors": [
            "Chiori Hori",
            "Takaaki Hori",
            "Jonathan Le Roux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The ZevoMOS entry to VoiceMOS Challenge 2022",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-105",
        "paper_authors": [
            "Adriana Stan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-439",
        "paper_authors": [
            "Takaaki Saeki",
            "Detai Xin",
            "Wataru Nakata",
            "Tomoki Koriyama",
            "Shinnosuke Takamichi",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Mean Opinion Score Estimation with Temporal Modulation Features on Gammatone Filterbank for Speech Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-528",
        "paper_authors": [
            "Huy Nguyen",
            "Kai Li",
            "Masashi Unoki"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Rater and System Metadata to Explain Variance in the VoiceMOS Challenge 2022 Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-799",
        "paper_authors": [
            "Michael Chinen",
            "Jan Skoglund",
            "Chandan K. A. Reddy",
            "Alessandro Ragano",
            "Andrew Hines"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The VoiceMOS Challenge 2022",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-970",
        "paper_authors": [
            "Wen-Chin Huang",
            "Erica Cooper",
            "Yu Tsao",
            "Hsin-Min Wang",
            "Tomoki Toda",
            "Junichi Yamagishi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11247",
        "paper_authors": [
            "Wei-Cheng Tseng",
            "Wei-Tsung Kao",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Expressive, Variable, and Controllable Duration Modelling in TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-384",
        "paper_authors": [
            "Syed Ammar Abbas",
            "Thomas Merritt",
            "Alexis Moinet",
            "Sri Karlapati",
            "Ewa Muszynska",
            "Simon Slangen",
            "Elia Gatti",
            "Thomas Drugman"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting VQVAE-based Character Acting Style from Quotation-Annotated Text for Audiobook Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-638",
        "paper_authors": [
            "Wataru Nakata",
            "Tomoki Koriyama",
            "Shinnosuke Takamichi",
            "Yuki Saito",
            "Yusuke Ijima",
            "Ryo Masumura",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial and Sequential Training for Cross-lingual Prosody Transfer TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-865",
        "paper_authors": [
            "Min-Kyung Kim",
            "Joon-Hyuk Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FluentTTS: Text-dependent Fine-grained Style Control for Multi-style TTS",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-988",
        "paper_authors": [
            "Changhwan Kim",
            "Se-Yun Um",
            "Hyungchan Yoon",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Few Shot Cross-Lingual TTS Using Transferable Phoneme Embedding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-994",
        "paper_authors": [
            "Wei-Ping Huang",
            "Po-Chun Chen",
            "Sung-Feng Huang",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training Text-To-Speech Systems From Synthetic Data: A Practical Approach For Accent Transfer Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10115",
        "paper_authors": [
            "Lev Finkelstein",
            "Heiga Zen",
            "Norman Casagrande",
            "Chun-an Chan",
            "Ye Jia",
            "Tom Kenter",
            "Alexey Petelin",
            "Jonathan Shen",
            "Vincent Wan",
            "Yu Zhang",
            "Yonghui Wu",
            "Rob Clark"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoken-Text-Style Transfer with Conditional Variational Autoencoder and Content Word Storage",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10118",
        "paper_authors": [
            "Daiki Yoshioka",
            "Yusuke Yasuda",
            "Noriyuki Matsunaga",
            "Yamato Ohtani",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Analysis of expressivity transfer in non-autoregressive end-to-end multispeaker TTS systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10388",
        "paper_authors": [
            "Ajinkya Kulkarni",
            "Vincent Colotte",
            "Denis Jouvet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-lingual Style Transfer with Conditional Prior VAE and Style Loss",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10572",
        "paper_authors": [
            "Dino Rattcliffe",
            "You Wang",
            "Alex Mansbridge",
            "Penny Karanasou",
            "Alexis Moinet",
            "Marius Cotescu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Daft-Exprt: Cross-Speaker Prosody Transfer on Any Text for Expressive Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10761",
        "paper_authors": [
            "Julian Za\u00efdi",
            "Hugo Seut\u00e9",
            "Benjamin van Niekerk",
            "Marc-Andr\u00e9 Carbonneau"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language Model-Based Emotion Prediction Methods for Emotional Speech Synthesis Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11133",
        "paper_authors": [
            "Hyun-Wook Yoon",
            "Ohsung Kwon",
            "Hoyeon Lee",
            "Ryuichi Yamamoto",
            "Eunwoo Song",
            "Jae-Min Kim",
            "Min-Jae Hwang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text aware Emotional Text-to-speech with BERT",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11293",
        "paper_authors": [
            "Arijit Mukherjee",
            "Shubham Bansal",
            "Sandeepkumar Satpal",
            "Rupesh K. Mehta"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Overlapped Speech Detection in Broadcast Streams Using X-vectors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-81",
        "paper_authors": [
            "Luk\u00e1s Mateju",
            "Frantisek Kynych",
            "Petr Cerva",
            "Jir\u00ed M\u00e1lek",
            "Jindrich Zd\u00e1nsk\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DDKtor: Automatic Diadochokinetic Speech Analysis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-311",
        "paper_authors": [
            "Yael Segal",
            "Kasia Hitczenko",
            "Matthew Goldrick",
            "Adam Buchwald",
            "Angela Roberts",
            "Joseph Keshet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SiDi KWS: A Large-Scale Multilingual Dataset for Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-394",
        "paper_authors": [
            "Michel Cardoso Meneses",
            "Rafael B\u00e9rgamo Holanda",
            "Luis Vasconcelos Peres",
            "Gabriela Dantas Rocha"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dummy Prototypical Networks for Few-Shot Open-Set Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-921",
        "paper_authors": [
            "Byeonggeun Kim",
            "Seunghan Yang",
            "Inseop Chung",
            "Simyung Chang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Voice Activity Detection by Modeling Source and System Information using Zero Frequency Filtering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10535",
        "paper_authors": [
            "Eklavya Sarkar",
            "RaviShankar Prasad",
            "Mathew Magimai-Doss"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multilingual and Multimodal Abuse Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10629",
        "paper_authors": [
            "Rini A. Sharon",
            "Heet Shah",
            "Debdoot Mukherjee",
            "Vikram Gupta"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Microphone Array Channel Combination Algorithms for Overlapped Speech Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10758",
        "paper_authors": [
            "Th\u00e9o Mariotte",
            "Anthony Larcher",
            "Silvio Montr\u00e9sor",
            "Jean-Hugh Thomas"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Streaming Automatic Speech Recognition with Re-blocking Processing Based on Integrated Voice Activity Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11216",
        "paper_authors": [
            "Yui Sudo",
            "Muhammad Shakeel",
            "Kazuhiro Nakadai",
            "Jiatong Shi",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Word Segmentation using K Nearest Neighbors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11474",
        "paper_authors": [
            "Tzeviya Fuchs",
            "Yedid Hoshen",
            "Yossi Keshet"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation on the Band Importance of Phase-aware Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-284",
        "paper_authors": [
            "Zhuohuang Zhang",
            "Donald S. Williamson",
            "Yi Shen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Acoustic-to-Articulatory Inversion with Variable Vocal Tract Anatomy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-477",
        "paper_authors": [
            "Yifan Sun",
            "Qinlong Huang",
            "Xihong Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Inference of Physiologically Meaningful Articulatory Trajectories with VocalTractLab",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-659",
        "paper_authors": [
            "Yifan Sun",
            "Qinlong Huang",
            "Xihong Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Radio2Speech: High Quality Speech Recovery from Radio Frequency Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-738",
        "paper_authors": [
            "Running Zhao",
            "Jiangtao Yu",
            "Tingle Li",
            "Hang Zhao",
            "Edith C. H. Ngai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Isochronous is beautiful? Syllabic event detection in a neuro-inspired oscillatory model is facilitated by isochrony in speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10426",
        "paper_authors": [
            "Mamady Nab\u00e9",
            "Julien Diard",
            "Jean-Luc Schwartz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An investigation of regression-based prediction of the femininity or masculinity in speech of transgender people",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10759",
        "paper_authors": [
            "Leon Liebig",
            "Christoph Wagner",
            "Alexander Mainka",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic To Articulatory Speech Inversion Using Multi-Resolution Spectro-Temporal Representations Of Speech Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10926",
        "paper_authors": [
            "Rahil Parikh",
            "Nadee Seneviratne",
            "Ganesh Sivaraman",
            "Shihab A. Shamma",
            "Carol Y. Espy-Wilson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Neural Convolutive Matrix Factorization for Articulatory Representation Decomposition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11233",
        "paper_authors": [
            "Jiachen Lian",
            "Alan W. Black",
            "Louis Goldstein",
            "Gopala Krishna Anumanchipalli"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vocal-Tract Area Functions with Articulatory Reality for Tract Opening",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11320",
        "paper_authors": [
            "Zhao Zhang",
            "Ju Zhang",
            "Jianguo Wei",
            "Kiyoshi Honda",
            "Tatsuya Kitamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coupled Discriminant Subspace Alignment for Cross-database Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-40",
        "paper_authors": [
            "Shaokai Li",
            "Peng Song",
            "Keke Zhao",
            "Wenjing Zhang",
            "Wenming Zheng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Performance Improvement of Speech Emotion Recognition by Neutral Speech Detection Using Autoencoder and Intermediate Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-584",
        "paper_authors": [
            "Jennifer Santoso",
            "Takeshi Yamada",
            "Kenkichi Ishizuka",
            "Taiichi Hashimoto",
            "Shoji Makino"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Graph Isomorphism Network with Weighted Multiple Aggregators for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-637",
        "paper_authors": [
            "Ying Hu",
            "Yuwu Tang",
            "Hao Huang",
            "Liang He"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion Recognition via Generation using an Attention-based Variational Recurrent Neural Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-753",
        "paper_authors": [
            "Murchana Baruah",
            "Bonny Banerjee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Emotion: Investigating Model Representations, Multi-Task Learning and Knowledge Distillation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-957",
        "paper_authors": [
            "Vikramjit Mitra",
            "Hsiang-Yun Sherry Chien",
            "Vasudha Kowtha",
            "Joseph Yitan Cheng",
            "Erdrin Azemi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multiple Enhancements to LSTM for Learning Emotion-Salient Features in Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-985",
        "paper_authors": [
            "Desheng Hu",
            "Xinhui Hu",
            "Xinkang Xu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-level Fusion of Wav2vec 2.0 and BERT for Multimodal Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10230",
        "paper_authors": [
            "Zihan Zhao",
            "Yanfeng Wang",
            "Yu Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CTA-RNN: Channel and Temporal-wise Attention RNN leveraging Pre-trained ASR Embeddings for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10403",
        "paper_authors": [
            "Chengxin Chen",
            "Pengyuan Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Complex Paralinguistic Analysis of Speech: Predicting Gender, Emotions and Deception in a Hierarchical Framework",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11294",
        "paper_authors": [
            "Alena Velichko",
            "Maxim Markitantov",
            "Heysem Kaya",
            "Alexey Karpov"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interactive Co-Learning with Cross-Modal Transformer for Audio-Visual Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11307",
        "paper_authors": [
            "Akihiko Takashima",
            "Ryo Masumura",
            "Atsushi Ando",
            "Yoshihiro Yamazaki",
            "Mihiro Uchida",
            "Shota Orihashi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SpeechEQ: Speech Emotion Recognition based on Multi-scale Unified Datasets and Multitask Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11456",
        "paper_authors": [
            "Zuheng Kang",
            "Junqing Peng",
            "Jianzong Wang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discriminative Feature Representation Based on Cascaded Attention Network with Adversarial Joint Loss for Speech Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11480",
        "paper_authors": [
            "Yang Liu",
            "Haoqin Sun",
            "Wenbo Guan",
            "Yuqi Xia",
            "Zhen Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intra-speaker phonetic variation in read speech: comparison with inter-speaker variability in a controlled population",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10965",
        "paper_authors": [
            "Nicolas Audibert",
            "C\u00e9cile Fougeron"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training speaker recognition systems with limited data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-135",
        "paper_authors": [
            "Nik Vaessen",
            "David A. van Leeuwen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep One-Class Learning Method for Replay Attack Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-427",
        "paper_authors": [
            "Yijie Lou",
            "Shiliang Pu",
            "Jianfeng Zhou",
            "Xin Qi",
            "Qinbo Dong",
            "Hongwei Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Universal Identity Backdoor Attack against Speaker Verification based on Siamese Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-446",
        "paper_authors": [
            "Haodong Zhao",
            "Wei Du",
            "Junjie Guo",
            "Gongshen Liu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Novel Phoneme-based Modeling for Text-independent Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-617",
        "paper_authors": [
            "Xin Wang",
            "Chuan Xie",
            "Qiang Wu",
            "Huayi Zhan",
            "Ying Wu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Speaker Verification Using Dynamic Loss-Gate and Label Correction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-742",
        "paper_authors": [
            "Bing Han",
            "Zhengyang Chen",
            "Yanmin Qian"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Lip-Based Audio-Visual Speaker Embeddings with AV-HuBERT",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-885",
        "paper_authors": [
            "Bowen Shi",
            "Abdelrahman Mohamed",
            "Wei-Ning Hsu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic Feature Shuffling Network for Text-independent Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10278",
        "paper_authors": [
            "Jin Li",
            "Xin Fang",
            "Fan Chu",
            "Tian Gao",
            "Yan Song",
            "Rong Li Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Path GMM-MobileNet Based on Attack Algorithms and Codecs for Synthetic Speech and Deepfake Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10312",
        "paper_authors": [
            "Yan Wen",
            "Zhenchun Lei",
            "Yingen Yang",
            "Changhong Liu",
            "Minglei Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Reweighting for Speaker Verification Fairness",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10948",
        "paper_authors": [
            "Minho Jin",
            "Chelsea Ju",
            "Zeya Chen",
            "Yi-Chieh Liu",
            "Jasha Droppo",
            "Andreas Stolcke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph-based Multi-View Fusion and Local Adaptation: Mitigating Within-Household Confusability for Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11053",
        "paper_authors": [
            "Long Chen",
            "Yixiong Meng",
            "Venkatesh Ravichandran",
            "Andreas Stolcke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Local Context-aware Self-attention for Continuous Sign Language Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-164",
        "paper_authors": [
            "Ronglai Zuo",
            "Brian Mak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Disentangled Latent Speech Representation for Automatic Pathological Intelligibility Assessment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-356",
        "paper_authors": [
            "Tobias Weise",
            "Philipp Klumpp",
            "Andreas K. Maier",
            "Elmar N\u00f6th",
            "Bj\u00f6rn Heismann",
            "Maria Schuster",
            "Seung Hee Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Hypernasality Estimation with Automatic Speech Recognition in Cleft Palate Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-438",
        "paper_authors": [
            "Kaitao Song",
            "Teng Wan",
            "Bixia Wang",
            "Huiqiang Jiang",
            "Luna Qiu",
            "Jiahang Xu",
            "Liping Jiang",
            "Qun Lou",
            "Yuqing Yang",
            "Dongsheng Li",
            "Xudong Wang",
            "Lili Qiu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conformer Based Elderly Speech Recognition System for Alzheimer's Disease Detection",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-712",
        "paper_authors": [
            "Tianzi Wang",
            "Jiajun Deng",
            "Mengzhe Geng",
            "Zi Ye",
            "Shoukang Hu",
            "Yi Wang",
            "Mingyu Cui",
            "Zengrui Jin",
            "Xunying Liu",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revisiting visuo-spatial processing in individuals with congenital amusia",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10014",
        "paper_authors": [
            "Zixia Fan",
            "Jing Shao",
            "Weigong Pan",
            "Lan Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A user-friendly headset for radar-based silent speech recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10090",
        "paper_authors": [
            "Pouriya Amini Digehsara",
            "Jo\u00e3o V\u00edtor Possamai de Menezes",
            "Christoph Wagner",
            "Michael B\u00e4rhold",
            "Petr Schaffer",
            "Dirk Plettemeier",
            "Peter Birkholz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A study of production error analysis for Mandarin-speaking Children with Hearing Impairment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10477",
        "paper_authors": [
            "Jingwen Cheng",
            "Yuchen Yan",
            "Yingming Gao",
            "Xiaoli Feng",
            "Yannan Wang",
            "Jinsong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Incremental Layer-Wise Self-Supervised Learning for Efficient Unsupervised Speech Domain Adaptation On Device",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10904",
        "paper_authors": [
            "Zhouyuan Huo",
            "Dongseong Hwang",
            "Khe Chai Sim",
            "Shefali Garg",
            "Ananya Misra",
            "Nikhil Siddhartha",
            "Trevor Strohman",
            "Fran\u00e7oise Beaufays"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Linear Pairwise Language Mappings for Low-Resource Multilingual Acoustic Model Fusion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11449",
        "paper_authors": [
            "Muhammad Umar Farooq",
            "Darshan Adiga Haniya Narayana",
            "Thomas Hain"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The THUEE System Description for the IARPA OpenASR21 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-269",
        "paper_authors": [
            "Jing Zhao",
            "Haoyu Wang",
            "Jinpeng Li",
            "Shuzhou Chai",
            "Guanbo Wang",
            "Guoguo Chen",
            "Wei-Qiang Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "External Text Based Data Augmentation for Low-Resource Speech Recognition in the Constrained Condition of OpenASR21 Challenge",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-649",
        "paper_authors": [
            "Guolong Zhong",
            "Hongyu Song",
            "Ruoyu Wang",
            "Lei Sun",
            "Diyuan Liu",
            "Jia Pan",
            "Xin Fang",
            "Jun Du",
            "Jie Zhang",
            "Lirong Dai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-dialect lexicon optimisation for an endangered language ASR system: the case of Irish",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-838",
        "paper_authors": [
            "Liam Lonergan",
            "Mengjie Qian",
            "Neasa N\u00ed Chiar\u00e1in",
            "Christer Gobl",
            "Ailbhe N\u00ed Chasaide"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Wav2vec-S: Semi-Supervised Pre-Training for Low-Resource ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-909",
        "paper_authors": [
            "Han Zhu",
            "Li Wang",
            "Gaofeng Cheng",
            "Jindong Wang",
            "Pengyuan Zhang",
            "Yonghong Yan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Comparison of Unsupervised Learning and Supervised Learning with Noisy Labels for Low-Resource Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10620",
        "paper_authors": [
            "Yanick Schraner",
            "Christian Scheller",
            "Michel Pl\u00fcss",
            "Lukas Neukom",
            "Manfred Vogel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using cross-model learnings for the Gram Vaani ASR Challenge 2022",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10639",
        "paper_authors": [
            "Tanvina Patel",
            "Odette Scharenborg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASR2K: Speech Recognition for Around 2000 Languages without Audio",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10712",
        "paper_authors": [
            "Xinjian Li",
            "Florian Metze",
            "David R. Mortensen",
            "Alan W. Black",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Combining Simple but Novel Data Augmentation Methods for Improving Conformer ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10835",
        "paper_authors": [
            "Ronit Damania",
            "Christopher Homan",
            "Emily Prud'hommeaux"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OpenASR21: The Second Open Challenge for Automatic Speech Recognition of Low-Resource Languages",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10972",
        "paper_authors": [
            "Kay Peterson",
            "Audrey Tong",
            "Yan Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DRAFT: A Novel Framework to Reduce Domain Shifting in Self-supervised Learning and Its Application to Children's ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11128",
        "paper_authors": [
            "Ruchao Fan",
            "Abeer Alwan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Plugging a neural phoneme recognizer into a simple language model: a workflow for low-resource setting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11314",
        "paper_authors": [
            "S\u00e9verine Guillaume",
            "Guillaume Wisniewski",
            "Benjamin Galliot",
            "Minh Chau Nguyen",
            "Maxime Fily",
            "Guillaume Jacques",
            "Alexis Michaud"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Evaluation of Three-Stage Voice Conversion Framework for Noisy and Reverberant Conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10158",
        "paper_authors": [
            "Yeonjong Choi",
            "Chao Xie",
            "Tomoki Toda"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Overview & Analysis of Sequence-to-Sequence Emotional Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10636",
        "paper_authors": [
            "Zijiang Yang",
            "Xin Jing",
            "Andreas Triantafyllopoulos",
            "Meishu Song",
            "Ilhan Aslan",
            "Bj\u00f6rn W. Schuller"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Foreign Accent Conversion without a Native Reference",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10664",
        "paper_authors": [
            "Waris Quamer",
            "Anurag Das",
            "John Levis",
            "Evgeny Chukharev-Hudilainen",
            "Ricardo Gutierrez-Osuna"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker Anonymization with Phonetic Intermediate Representations",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10703",
        "paper_authors": [
            "Sarina Meyer",
            "Florian Lux",
            "Pavel Denisov",
            "Julia Koch",
            "Pascal Tilli",
            "Ngoc Thang Vu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation into Target Speaking Rate Adaptation for Voice Conversion",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10740",
        "paper_authors": [
            "Michael Kuhlmann",
            "Fritz Seebauer",
            "Janek Ebbers",
            "Petra Wagner",
            "Reinhold Haeb-Umbach"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self supervised learning for robust voice cloning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10856",
        "paper_authors": [
            "Konstantinos Klapsas",
            "Nikolaos Ellinas",
            "Karolos Nikitaras",
            "Georgios Vamvoukakis",
            "Panagiotis Kakoulidis",
            "Konstantinos Markopoulos",
            "Spyros Raptis",
            "June Sig Sung",
            "Gunu Jho",
            "Aimilios Chalamandaris",
            "Pirros Tsiakoulis"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Deliberation by Text-Only and Semi-Supervised Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-243",
        "paper_authors": [
            "Ke Hu",
            "Tara N. Sainath",
            "Yanzhang He",
            "Rohit Prabhavalkar",
            "Trevor Strohman",
            "Sepand Mavandadi",
            "Weiran Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "K-Wav2vec 2.0: Automatic Speech Recognition based on Joint Decoding of Graphemes and Syllables",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-547",
        "paper_authors": [
            "Jounghee Kim",
            "Pilsung Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Wav2Vec-Aug: Improved self-supervised training with limited data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-667",
        "paper_authors": [
            "Anuroop Sriram",
            "Michael Auli",
            "Alexei Baevski"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revisiting joint decoding based multi-talker speech recognition with DNN acoustic model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10406",
        "paper_authors": [
            "Martin Kocour",
            "Katerina Zmol\u00edkov\u00e1",
            "Lucas Ondel",
            "Jan Svec",
            "Marc Delcroix",
            "Tsubasa Ochiai",
            "Luk\u00e1s Burget",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RNN-T lattice enhancement by grafting of pruned paths",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10945",
        "paper_authors": [
            "Mirek Novak",
            "Pavlos Papadopoulos"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Better Intermediates Improve CTC Inference",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11276",
        "paper_authors": [
            "Tatsuya Komatsu",
            "Yusuke Fujita",
            "Jaesong Lee",
            "Lukas Lee",
            "Shinji Watanabe",
            "Yusuke Kida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Cultural Comparison of Gradient Emotion Perception: Human vs. Alexa TTS Voices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-146",
        "paper_authors": [
            "Iona Gessinger",
            "Michelle Cohn",
            "Georgia Zellou",
            "Bernd M\u00f6bius"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discriminative Adversarial Learning for Speaker Independent Emotion Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-285",
        "paper_authors": [
            "L. L. Chamara Kasun",
            "Chung Soo Ahn",
            "Jagath C. Rajapakse",
            "Zhiping Lin",
            "Guang-Bin Huang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Representing 'how you say' with 'what you say': English corpus of focused speech and text reflecting corresponding implications",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10284",
        "paper_authors": [
            "Naoaki Suzuki",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Production Strategies of Vocal Attitudes",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10947",
        "paper_authors": [
            "L\u00e9ane Salais",
            "Pablo Arias",
            "Cl\u00e9ment Le Moine",
            "Victor Rosi",
            "Yann Teytaut",
            "Nicolas Obin",
            "Axel Roebel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Where's the uh, hesitation? The interplay between filled pause location, speech rate and fundamental frequency in perception of confidence",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10973",
        "paper_authors": [
            "Ambika Kirkland",
            "Harm Lameris",
            "\u00c9va Sz\u00e9kely",
            "Joakim Gustafson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "E2E Segmenter: Joint Segmenting and Decoding for Long-Form ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-38",
        "paper_authors": [
            "W. Ronny Huang",
            "Shuo-Yiin Chang",
            "David Rybach",
            "Tara N. Sainath",
            "Rohit Prabhavalkar",
            "Cal Peyser",
            "Zhiyun Lu",
            "Cyril Allauzen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Autoregressive Co-Training for Learning Discrete Speech Representation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-530",
        "paper_authors": [
            "Sung-Lin Yeh",
            "Hao Tang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10610",
        "paper_authors": [
            "Kai-Wei Chang",
            "Wei-Cheng Tseng",
            "Shang-Wen Li",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Overlapped speech and gender detection with WavLM pre-trained features",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10825",
        "paper_authors": [
            "Martin Lebourdais",
            "Marie Tahon",
            "Antoine Laurent",
            "Sylvain Meignier"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A study on constraining Connectionist Temporal Classification for temporal audio alignment",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10940",
        "paper_authors": [
            "Yann Teytaut",
            "Baptiste Bouvier",
            "Axel Roebel"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Acoustic-to-articulatory Speech Inversion with Multi-task Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11164",
        "paper_authors": [
            "Yashish M. Siriwardena",
            "Ganesh Sivaraman",
            "Carol Y. Espy-Wilson"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Speech Privacy with Slicing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-752",
        "paper_authors": [
            "Mohamed Maouche",
            "Brij Mohan Lal Srivastava",
            "Nathalie Vauquier",
            "Aur\u00e9lien Bellet",
            "Marc Tommasi",
            "Emmanuel Vincent"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Attention-Based Method for Guiding Attribute-Aligned Speech Representation Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10419",
        "paper_authors": [
            "Yu-Lin Huang",
            "Bo-Hao Su",
            "Y.-W. Peter Hong",
            "Chi-Chun Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Defense against Adversarial Attacks on Hybrid Speech Recognition System using Adversarial Fine-tuning with Denoiser",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10977",
        "paper_authors": [
            "Sonal Joshi",
            "Saurabh Kataria",
            "Yiwen Shao",
            "Piotr Zelasko",
            "Jes\u00fas Villalba",
            "Sanjeev Khudanpur",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Membership Inference Attacks Against Self-supervised Speech Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11245",
        "paper_authors": [
            "Wei-Cheng Tseng",
            "Wei-Tsung Kao",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Chunking Defense for Adversarial Attacks on ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11096",
        "paper_authors": [
            "Yiwen Shao",
            "Jes\u00fas Villalba",
            "Sonal Joshi",
            "Saurabh Kataria",
            "Sanjeev Khudanpur",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-FedSER: Semi-supervised Learning for Speech Emotion Recognition On Federated Learning using Multiview Pseudo-Labeling",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-141",
        "paper_authors": [
            "Tiantian Feng",
            "Shrikanth Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "User-Level Differential Privacy against Attribute Inference Attack of Speech Emotion Recognition on Federated Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10060",
        "paper_authors": [
            "Tiantian Feng",
            "Raghuveer Peri",
            "Shrikanth Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AdvEst: Adversarial Perturbation Estimation to Classify and Detect Adversarial Attacks against Speaker Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10985",
        "paper_authors": [
            "Sonal Joshi",
            "Saurabh Kataria",
            "Jes\u00fas Villalba",
            "Najim Dehak"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Learning of Open-set Speaker Identification by Active User-registration",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-25",
        "paper_authors": [
            "Eunkyung Yoo",
            "Hyeonseop Song",
            "Taehyeong Kim",
            "Chul Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Speaker Verification System for Dysarthria Patients",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-375",
        "paper_authors": [
            "Shinimol Salim",
            "Syed Shahnawazuddin",
            "Waquar Ahmad"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multimodal Clustering with Role Induced Constraints for Speaker Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-814",
        "paper_authors": [
            "Nikolaos Flemotomos",
            "Shrikanth Narayanan"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-scale Speaker Diarization with Dynamic Scale Weighting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-991",
        "paper_authors": [
            "Taejin Park",
            "Nithin Rao Koluguri",
            "Jagadeesh Balam",
            "Boris Ginsburg"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Relation Networks for End-to-End Speaker Verification and Identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10064",
        "paper_authors": [
            "Ashutosh Chaubey",
            "Sparsh Sinha",
            "Susmita Ghose"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-End Neural Speaker Diarization with an Iterative Refinement of Non-Autoregressive Attention-based Attractors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10169",
        "paper_authors": [
            "Magdalena Rybicka",
            "Jes\u00fas Villalba",
            "Najim Dehak",
            "Konrad Kowalczyk"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "From Simulated Mixtures to Simulated Conversations as Training Data for End-to-End Neural Diarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10451",
        "paper_authors": [
            "Federico Landini",
            "Alicia Lozano-Diez",
            "Mireia D\u00edez",
            "Luk\u00e1s Burget"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Can Humans Correct Errors From System? Investigating Error Tendencies in Speaker Identification Using Crowdsourcing",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10580",
        "paper_authors": [
            "Yuta Ide",
            "Susumu Saito",
            "Teppei Nakano",
            "Tetsuji Ogawa"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Light-Weight Speaker Verification with Global Context Information",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10932",
        "paper_authors": [
            "Miseul Kim",
            "Zhenyu Piao",
            "Se-Yun Um",
            "Ran Lee",
            "Jaemin Joh",
            "Seungshin Lee",
            "Hong-Goo Kang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learnable Sparse Filterbank for Speaker Verification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11309",
        "paper_authors": [
            "Junyi Peng",
            "Rongzhi Gu",
            "Ladislav Mosner",
            "Oldrich Plchot",
            "Luk\u00e1s Burget",
            "Jan Cernock\u00fd"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using Data Augmentation and Consistency Regularization to Improve Semi-supervised Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10462",
        "paper_authors": [
            "Ashtosh Sapru"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised domain adaptation for speech recognition with unsupervised error correction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10565",
        "paper_authors": [
            "Long Mai",
            "Julie Carson-Berndsen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Scalable Model Specialization Framework for Training and Inference using Submodels and its Application to Speech Model Personalization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10613",
        "paper_authors": [
            "Fadi Biadsy",
            "Youzheng Chen",
            "Xia Zhang",
            "Oleg Rybakov",
            "Andrew Rosenberg",
            "Pedro J. Moreno"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Wav2vec behind the Scenes: How end2end Models learn Phonetics",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10865",
        "paper_authors": [
            "Teena tom Dieck",
            "Paula Andrea P\u00e9rez-Toro",
            "Tomas Arias",
            "Elmar N\u00f6th",
            "Philipp Klumpp"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scaling ASR Improves Zero and Few Shot Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11023",
        "paper_authors": [
            "Weiyi Zheng",
            "Alex Xiao",
            "Gil Keren",
            "Duc Le",
            "Frank Zhang",
            "Christian Fuegen",
            "Ozlem Kalinli",
            "Yatharth Saraf",
            "Abdelrahman Mohamed"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "InterAug: Augmenting Noisy Intermediate Predictions for CTC-based ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11284",
        "paper_authors": [
            "Yu Nakagome",
            "Tatsuya Komatsu",
            "Yusuke Fujita",
            "Shuta Ichimura",
            "Yusuke Kida"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Investigation of Ensemble features of Self-Supervised Pretrained Models for Automatic Speech Recognition",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11376",
        "paper_authors": [
            "A. Arunkumar",
            "Vrunda Nileshkumar Sukhadia",
            "Srinivasan Umesh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Sliding Window Modeling for Abstractive Meeting Summarization",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-121",
        "paper_authors": [
            "Zhengyuan Liu",
            "Nancy F. Chen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "STUDIES: Corpus of Japanese Empathetic Dialogue Speech Towards Friendly Voice Agent",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-300",
        "paper_authors": [
            "Yuki Saito",
            "Yuto Nishimura",
            "Shinnosuke Takamichi",
            "Kentaro Tachibana",
            "Hiroshi Saruwatari"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "kidsTALC: A Corpus of 3- to 11-year-old German Children's Connected Natural Speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-330",
        "paper_authors": [
            "Lars Rumberg",
            "Christopher Gebauer",
            "Hanna Ehlert",
            "Maren Wallbaum",
            "Lena Bornholt",
            "J\u00f6rn Ostermann",
            "Ulrike L\u00fcdtke"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken Question Answering",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-612",
        "paper_authors": [
            "Guan-Ting Lin",
            "Yung-Sung Chuang",
            "Ho-Lam Chung",
            "Shu-Wen Yang",
            "Hsuan-Jui Chen",
            "Shuyan Annie Dong",
            "Shang-Wen Li",
            "Abdelrahman Mohamed",
            "Hung-yi Lee",
            "Lin-Shan Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Asymmetric Proxy Loss for Multi-View Acoustic Word Embeddings",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10013",
        "paper_authors": [
            "Myunghun Jung",
            "Hoi Rin Kim"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Continuous Integrate-and-Fire for Adaptive Simultaneous Speech Translation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10627",
        "paper_authors": [
            "Chih-Chiang Chang",
            "Hung-yi Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Building Vietnamese Conversational Smart Home Dataset and Natural Language Understanding Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10645",
        "paper_authors": [
            "Thi Thu Trang Nguyen",
            "Trung Duc Anh Dang",
            "Quoc Viet Vu",
            "Woomyoung Park"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10752",
        "paper_authors": [
            "Sreyan Ghosh",
            "Samden Lepcha",
            "S. Sakshi",
            "Rajiv Ratn Shah",
            "Srinivasan Umesh"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Activity Projection: Self-supervised Learning of Turn-taking Events",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10955",
        "paper_authors": [
            "Erik Ekstedt",
            "Gabriel Skantze"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11032",
        "paper_authors": [
            "Sravya Popuri",
            "Peng-Jen Chen",
            "Changhan Wang",
            "Juan Pino",
            "Yossi Adi",
            "Jiatao Gu",
            "Wei-Ning Hsu",
            "Ann Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "QbyE-MLPMixer: Query-by-Example Open-Vocabulary Keyword Spotting using MLPMixer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11080",
        "paper_authors": [
            "Jinmiao Huang",
            "Waseem Gharbieh",
            "Qianhui Wan",
            "Han Suk Shim",
            "Hyun Chul Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DyConvMixer: Dynamic Convolution Mixer Architecture for Open-Vocabulary Keyword Spotting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11090",
        "paper_authors": [
            "Waseem Gharbieh",
            "Jinmiao Huang",
            "Qianhui Wan",
            "Han Suk Shim",
            "Hyun Chul Lee"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Challenges in Metadata Creation for Massive Naturalistic Team-Based Audio Data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11243",
        "paper_authors": [
            "Chelzy Belitz",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spoken Dialogue System for Call Centers with Expressive Speech Synthesis",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/nicmanis22_interspeech.html",
        "paper_authors": [
            "Davis Nicmanis",
            "Askars Salimbajevs"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OCTRA - An Innovative Approach to Orthographic Transcription",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/draxler22_interspeech.html",
        "paper_authors": [
            "Christoph Draxler",
            "Julian Pomp"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Voice Puppetry with FastPitch",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/vandevreken22_interspeech.html",
        "paper_authors": [
            "Emelie Van De Vreken",
            "Korin Richmond",
            "Catherine Lai"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Data Driven Inverse Text Normalization using Data Augmentation and Machine Translation",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/paul22_interspeech.html",
        "paper_authors": [
            "Debjyoti Paul",
            "Yutong Pang",
            "Szu-Jui Chen",
            "Xuedong Zhang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Native phonotactic interference in L2 vowel processing: Mouse-tracking reveals cognitive conflicts during identification",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-12",
        "paper_authors": [
            "Yizhou Wang",
            "Rikke L. Bundgaard-Nielsen",
            "Brett Baker",
            "Olga Maxwell"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mandarin nasal place assimilation revisited: an acoustic study",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-89",
        "paper_authors": [
            "Mingqiong Luo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bending the string: intonation contour length as a correlate of macro-rhythm",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-185",
        "paper_authors": [
            "Constantijn Kaland"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Eliciting and evaluating likelihood ratios for speaker recognition by human listeners under forensically realistic channel-mismatched conditions",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-490",
        "paper_authors": [
            "Vincent Hughes",
            "Carmen Llamas",
            "Thomas Kettig"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reducing uncertainty at the score-to-LR stage in likelihood ratio-based forensic voice comparison using automatic speaker recognition systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-518",
        "paper_authors": [
            "Bruce Xiao Wang",
            "Vincent Hughes"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Durational Patterning at Discourse Boundaries in Relation to Therapist Empathy in Psychotherapy",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-722",
        "paper_authors": [
            "Jonathan Him Nok Lee",
            "Dehua Tao",
            "Harold Chui",
            "Tan Lee",
            "Sarah Luk",
            "Nicolette Wing Tung Lee",
            "Koonkan Fung"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Convolutional Neural Networks for Classification of Voice Qualities from Speech and Neck Surface Accelerometer Signals",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10513",
        "paper_authors": [
            "Sudarsana Reddy Kadiri",
            "Farhad Javanmardi",
            "Paavo Alku"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Applying Syntax-Prosody Mapping Hypothesis and Prosodic Well-Formedness Constraints to Neural Sequence-to-Sequence Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10541",
        "paper_authors": [
            "Kei Furukawa",
            "Takeshi Kishiyama",
            "Satoshi Nakamura"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effects of Language Contact on Vowel Nasalization in Wenzhou and Rugao Dialects",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10591",
        "paper_authors": [
            "Yan Li",
            "Ying Chen",
            "Xinya Zhang",
            "Yanyang Chen",
            "Jiazheng Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A blueprint for using deepfakes in sociolinguistic matched-guise experiments",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10782",
        "paper_authors": [
            "Nathan Joel Young",
            "David Britain",
            "Adrian Leemann"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mandarin Tone Sandhi Realization: Evidence from Large Speech Corpora",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10897",
        "paper_authors": [
            "Zuoyu Tian",
            "Xiao Dong",
            "Feier Gao",
            "Haining Wang",
            "Chien-Jer Charles Lin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Laryngographic Study on the Voice Quality of Northern Vietnamese Tones under the Lombard Effect",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10970",
        "paper_authors": [
            "Giang Le",
            "Chilin Shih",
            "Yan Tang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Prosody of Cheering in Sport Events",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10982",
        "paper_authors": [
            "Marzena Zygis",
            "Sarah Wesolek",
            "Nina Hosseini-Kivanani",
            "Manfred Krifka"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contribution of the glottal flow residual in affect-related voice transformation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11038",
        "paper_authors": [
            "Zihan Wang",
            "Christer Gobl"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "High level feature fusion in forensic voice comparison",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11127",
        "paper_authors": [
            "Michael Carne",
            "Yuko Kinoshita",
            "Shunichi Ishihara"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Modeling speech recognition and synthesis simultaneously: Encoding and decoding lexical and sublexical semantic information into speech with no direct access to speech data",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11219",
        "paper_authors": [
            "Gasper Begus",
            "Alan Zhou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Paraguayan Guarani: Tritonal pitch accent and Accentual Phrase",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11257",
        "paper_authors": [
            "Sun-Ah Jun",
            "Maria Luisa Zubizarreta"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Low-resource Accent Classification in Geographically-proximate Settings: A Forensic and Sociophonetics Perspective",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11372",
        "paper_authors": [
            "Qingcheng Zeng",
            "Dading Chong",
            "Peilin Zhou",
            "Jie Yang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tiny-Sepformer: A Tiny Time-Domain Transformer Network For Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-66",
        "paper_authors": [
            "Jian Luo",
            "Jianzong Wang",
            "Ning Cheng",
            "Edward Xiao",
            "Xulong Zhang",
            "Jing Xiao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speaker-Aware Mixture of Mixtures Training for Weakly Supervised Speaker Extraction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-96",
        "paper_authors": [
            "Zifeng Zhao",
            "Rongzhi Gu",
            "Dongchao Yang",
            "Jinchuan Tian",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SepIt: Approaching a Single Channel Speech Separation Bound",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-149",
        "paper_authors": [
            "Shahar Lutati",
            "Eliya Nachmani",
            "Lior Wolf"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Use of Deep Mask Estimation Module for Neural Source Separation Systems",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-174",
        "paper_authors": [
            "Kai Li",
            "Xiaolin Hu",
            "Yi Luo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Target Confusion in End-to-end Speaker Extraction: Analysis and Approaches",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-176",
        "paper_authors": [
            "Zifeng Zhao",
            "Dongchao Yang",
            "Rongzhi Gu",
            "Haoran Zhang",
            "Yuexian Zou"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Embedding Recurrent Layers with Dual-Path Strategy in a Variant of Convolutional Network for Speaker-Independent Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-220",
        "paper_authors": [
            "Xue Yang",
            "Changchun Bao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Disentangling the Impacts of Language and Channel Variability on Speech Separation Networks",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-509",
        "paper_authors": [
            "Fan-Lin Wang",
            "Hung-Shin Lee",
            "Yu Tsao",
            "Hsin-Min Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Objective Metrics to Evaluate Residual-Echo Suppression During Double-Talk in the Stereophonic Case",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-673",
        "paper_authors": [
            "Amir Ivry",
            "Israel Cohen",
            "Baruch Berdugo"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "QDPN - Quasi-dual-path Network for single-channel Speech Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-700",
        "paper_authors": [
            "Joel Rixen",
            "Matthias Renz"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Conformer Space Neural Architecture Search for Multi-Task Audio Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-755",
        "paper_authors": [
            "Shun Lu",
            "Yang Wang",
            "Peng Yao",
            "Chenxing Li",
            "Jianchao Tan",
            "Feng Deng",
            "Xiaorui Wang",
            "Chengru Song"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ResectNet: An Efficient Architecture for Voice Activity Detection on Mobile Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-820",
        "paper_authors": [
            "Okan K\u00f6p\u00fckl\u00fc",
            "Maja Taseska"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gated Convolutional Fusion for Time-Domain Target Speaker Extraction Network",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-961",
        "paper_authors": [
            "Wenjing Liu",
            "Chuan Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "WA-Transformer: Window Attention-based Transformer with Two-stage Strategy for Multi-task Audio Source Separation",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-995",
        "paper_authors": [
            "Yang Wang",
            "Chenxing Li",
            "Feng Deng",
            "Shun Lu",
            "Peng Yao",
            "Jianchao Tan",
            "Chengru Song",
            "Xiaorui Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multichannel Speech Separation with Narrow-band Conformer",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10018",
        "paper_authors": [
            "Changsheng Quan",
            "Xiaofei Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Separating Long-Form Speech with Group-wise Permutation Invariant Training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10362",
        "paper_authors": [
            "Wangyou Zhang",
            "Zhuo Chen",
            "Naoyuki Kanda",
            "Shujie Liu",
            "Jinyu Li",
            "Sefik Emre Eskimez",
            "Takuya Yoshioka",
            "Xiong Xiao",
            "Zhong Meng",
            "Yanmin Qian",
            "Furu Wei"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Directed speech separation for automatic speech recognition of long form conversational speech",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10843",
        "paper_authors": [
            "Rohit Paturi",
            "Sundararajan Srinivasan",
            "Katrin Kirchhoff",
            "Daniel Garcia-Romero"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Separation for an Unknown Number of Speakers Using Transformers With Encoder-Decoder Attractors",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10849",
        "paper_authors": [
            "Srikanth Raj Chetupalli",
            "Emanu\u00ebl A. P. Habets"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cooperative Speech Separation With a Microphone Array and Asynchronous Wearable Devices",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11025",
        "paper_authors": [
            "Ryan M. Corey",
            "Manan Mittal",
            "Kanad Sarkar",
            "Andrew C. Singer"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Text-Driven Separation of Arbitrary Sounds",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11052",
        "paper_authors": [
            "Kevin Kilgour",
            "Beat Gfeller",
            "Qingqing Huang",
            "Aren Jansen",
            "Scott Wisdom",
            "Marco Tagliasacchi"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Empirical Analysis on the Vulnerabilities of End-to-End Speech Segregation Models",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11222",
        "paper_authors": [
            "Rahil Parikh",
            "Gaspar Rochette",
            "Carol Y. Espy-Wilson",
            "Shihab A. Shamma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TaylorBeamformer: Learning All-Neural Beamformer for Multi-Channel Speech Enhancement from Taylor's Approximation Theory",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-159",
        "paper_authors": [
            "Andong Li",
            "Guochen Yu",
            "Chengshi Zheng",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "How bad are artifacts?: Analyzing the impact of speech enhancement errors on ASR",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-318",
        "paper_authors": [
            "Kazuma Iwamoto",
            "Tsubasa Ochiai",
            "Marc Delcroix",
            "Rintaro Ikeshita",
            "Hiroshi Sato",
            "Shoko Araki",
            "Shigeru Katagiri"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-source wideband DOA estimation method by frequency focusing and error weighting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-445",
        "paper_authors": [
            "Jing Zhou",
            "Changchun Bao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Convolutional Recurrent Smart Speech Enhancement Architecture for Hearing Aids",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-522",
        "paper_authors": [
            "Soha A. Nossier",
            "Julie A. Wall",
            "Mansour Moniri",
            "Cornelius Glackin",
            "Nigel Cannings"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fully Automatic Balance between Directivity Factor and White Noise Gain for Large-scale Microphone Arrays in Diffuse Noise Fields",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-625",
        "paper_authors": [
            "Weixin Meng",
            "Chengshi Zheng",
            "Xiaodong Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Transfer and Multi-Task Learning based Approach for MOS Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10022",
        "paper_authors": [
            "Xiaohai Tian",
            "Kaiqi Fu",
            "Shaojun Gao",
            "Yiwei Gu",
            "Kai Wang",
            "Wei Li",
            "Zejun Ma"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fusion of Self-supervised Learned Models for MOS Prediction",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10262",
        "paper_authors": [
            "Zhengdong Yang",
            "Wangjin Zhou",
            "Chenhui Chu",
            "Sheng Li",
            "Raj Dabre",
            "Raphael Rubino",
            "Yi Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Perceptual Contrast Stretching on Target Feature for Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10478",
        "paper_authors": [
            "Rong Chao",
            "Cheng Yu",
            "Szu-Wei Fu",
            "Xugang Lu",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A speech enhancement method for long-range speech acquisition task",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10523",
        "paper_authors": [
            "Yanzhang Geng",
            "Heng Wang",
            "Tao Zhang",
            "Xin Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ESPnet-SE++: Speech Enhancement for Robust Speech Recognition, Translation, and Understanding",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10727",
        "paper_authors": [
            "Yen-Ju Lu",
            "Xuankai Chang",
            "Chenda Li",
            "Wangyou Zhang",
            "Samuele Cornell",
            "Zhaoheng Ni",
            "Yoshiki Masuyama",
            "Brian Yan",
            "Robin Scheibler",
            "Zhong-Qiu Wang",
            "Yu Tsao",
            "Yanmin Qian",
            "Shinji Watanabe"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MTI-Net: A Multi-Target Speech Intelligibility Prediction Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10828",
        "paper_authors": [
            "Ryandhimas Edo Zezario",
            "Szu-Wei Fu",
            "Fei Chen",
            "Chiou-Shann Fuh",
            "Hsin-Min Wang",
            "Yu Tsao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Steering vector correction in MVDR beamformer for speech enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11084",
        "paper_authors": [
            "Suliang Bu",
            "Yunxin Zhao",
            "Tuo Zhao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Speech Modification for Intelligibility in Cochlear Implant Listeners: Individual Effects of Vowel- and Consonant-Boosting",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11131",
        "paper_authors": [
            "Juliana N. Saba",
            "John H. L. Hansen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DCTCN: Deep Complex Temporal Convolutional Network for Long Time Speech Enhancement",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11269",
        "paper_authors": [
            "Jigang Ren",
            "Qirong Mao"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improve Speech Enhancement using Perception-High-Related Time-Frequency Loss",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11471",
        "paper_authors": [
            "Ding Zhao",
            "Zhan Zhang",
            "Bin Yu",
            "Yuehai Wang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transplantation of Conversational Speaking Style with Interjections in Sequence-to-Sequence Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-388",
        "paper_authors": [
            "Raul Fernandez",
            "David Haws",
            "Guy Lorberbom",
            "Slava Shechtman",
            "Alexander Sorin"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Accurate Emotion Strength Assessment for Seen and Unseen Speech Based on Data-Driven Deep Learning",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-534",
        "paper_authors": [
            "Rui Liu",
            "Berrak Sisman",
            "Bj\u00f6rn W. Schuller",
            "Guanglai Gao",
            "Haizhou Li"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-speaker Emotion Transfer Based On Prosody Compensation for End-to-End Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-610",
        "paper_authors": [
            "Tao Li",
            "Xinsheng Wang",
            "Qicong Xie",
            "Zhichao Wang",
            "Mingqi Jiang",
            "Lei Xie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-supervised Context-aware Style Representation for Expressive Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-686",
        "paper_authors": [
            "Yihan Wu",
            "Xi Wang",
            "Shaofei Zhang",
            "Lei He",
            "Ruihua Song",
            "Jian-Yun Nie"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Integrating Discrete Word-Level Style Variations into Non-Autoregressive Acoustic Models for Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-984",
        "paper_authors": [
            "Zhaoci Liu",
            "Ning-Qian Wu",
            "Yajie Zhang",
            "Zhenhua Ling"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Automatic Prosody Annotation with Pre-Trained Text-Speech Model",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10005",
        "paper_authors": [
            "Ziqian Dai",
            "Jianwei Yu",
            "Yan Wang",
            "Nuo Chen",
            "Yanyao Bian",
            "Guangzhi Li",
            "Deng Cai",
            "Dong Yu"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhancing Word-Level Semantic Representation via Dependency Structure for Expressive Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-10061",
        "paper_authors": [
            "Yixuan Zhou",
            "Changhe Song",
            "Jingbei Li",
            "Zhiyong Wu",
            "Yanyao Bian",
            "Dan Su",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Multi-Scale Speaking Style Modelling with Hierarchical Context Information for Mandarin Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11171",
        "paper_authors": [
            "Shun Lei",
            "Yixuan Zhou",
            "Liyang Chen",
            "Jiankun Hu",
            "Zhiyong Wu",
            "Shiyin Kang",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Cross-speaker Reading Style Transfer on Audiobook Dataset",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11223",
        "paper_authors": [
            "Xiang Li",
            "Changhe Song",
            "Xianhao Wei",
            "Zhiyong Wu",
            "Jia Jia",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CALM: Constrastive Cross-modal Speaking Style Modeling for Expressive Text-to-Speech Synthesis",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11275",
        "paper_authors": [
            "Yi Meng",
            "Xiang Li",
            "Zhiyong Wu",
            "Tingtian Li",
            "Zixun Sun",
            "Xinyu Xiao",
            "Chi Sun",
            "Hui Zhan",
            "Helen Meng"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improve emotional speech synthesis quality by learning explicit and implicit representations with semi-supervised training",
        "paper_url": "https://doi.org/10.21437/Interspeech.2022-11336",
        "paper_authors": [
            "Jiaxu He",
            "Cheng Gong",
            "Longbiao Wang",
            "Di Jin",
            "Xiaobao Wang",
            "Junhai Xu",
            "Jianwu Dang"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Vietnamese-English Neural Machine Translation System",
        "paper_url": "https://www.isca-speech.org/archive/interspeech_2022/nguyen22e_interspeech.html",
        "paper_authors": [
            "Tuan-Duy H. Nguyen",
            "Duy Phung",
            "Duy Tran-Cong Nguyen",
            "Hieu Minh Tran",
            "Manh Luong",
            "Tin Duy Vo",
            "Hung Hai Bui",
            "Dinh Q. Phung",
            "Dat Quoc Nguyen"
        ],
        "paper_abstract": "",
        "paper_code": "#",
        "paper_cite": -1
    }
]