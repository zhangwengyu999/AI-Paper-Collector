[
    {
        "paper_name": "Randomized Message-Interception Smoothing: Gray-box Certificates for Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=t0VbBTw-o8",
        "paper_authors": [
            "Yan Scholten",
            "Jan Schuchardt",
            "Simon Geisler",
            "Aleksandar Bojchevski",
            "Stephan G\u00fcnnemann"
        ],
        "paper_abstract": "Randomized smoothing is one of the most promising frameworks for certifying the adversarial robustness of machine learning models, including Graph Neural Networks (GNNs). Yet, existing randomized smoothing certificates for GNNs are overly pessimistic since they treat the model as a black box, ignoring the underlying architecture. To remedy this, we propose novel gray-box certificates that exploit the message-passing principle of GNNs: We randomly intercept messages and carefully analyze the probability that messages from adversarially controlled nodes reach their target nodes. Compared to existing certificates, we certify robustness to much stronger adversaries that control entire nodes in the graph and can arbitrarily manipulate node features. Our certificates provide stronger guarantees for attacks at larger distances, as messages from farther-away nodes are more likely to get intercepted. We demonstrate the effectiveness of our method on various models and datasets. Since our gray-box certificates consider the underlying graph structure, we can significantly improve certifiable robustness by applying graph sparsification.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UQGAN: A Unified Model for Uncertainty Quantification of Deep Classifiers trained via Conditional GANs",
        "paper_url": "https://openreview.net/pdf?id=djOANbV2zSu",
        "paper_authors": [
            "Philipp Oberdiek",
            "Gernot A. Fink",
            "Matthias Rottmann"
        ],
        "paper_abstract": "We present an approach to quantifying both aleatoric and epistemic uncertainty for deep neural networks in image classification, based on generative adversarial networks (GANs). While most works in the literature that use GANs to generate out-of-distribution (OoD) examples only focus on the evaluation of OoD detection, we present a GAN based approach to learn a classifier that produces proper uncertainties for OoD examples as well as for false positives (FPs). Instead of shielding the entire in-distribution data with GAN generated OoD examples which is state-of-the-art, we shield each class separately with out-of-class examples generated by a conditional GAN and complement this with a one-vs-all image classifier. In our experiments, in particular on CIFAR10, CIFAR100 and Tiny ImageNet, we improve over the OoD detection and FP detection performance of state-of-the-art GAN-training based classifiers. Furthermore, we also find that the generated GAN examples do not significantly affect the calibration error of our classifier and result in a significant gain in model accuracy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Oscillatory Tracking of Continuous Attractor Neural Networks Account for Phase Precession and Procession of Hippocampal Place Cells",
        "paper_url": "https://openreview.net/pdf?id=WOuGTb9QswS",
        "paper_authors": [
            "Tianhao Chu",
            "Zilong Ji",
            "Junfeng Zuo",
            "Wenhao Zhang",
            "Tiejun Huang",
            "Yuanyuan Mi",
            "Si Wu"
        ],
        "paper_abstract": "Hippocampal place cells of freely moving rodents display an intriguing temporal organization in their responses known as `theta phase precession', in which individual neurons fire at progressively earlier phases in successive theta cycles as the animal traverses the place fields. Recent experimental studies found that in addition to phase precession, many place cells also exhibit accompanied phase procession, but the underlying neural mechanism remains unclear. Here, we propose a neural circuit model to elucidate the generation of both kinds of phase shift in place cells' firing. Specifically, we consider a continuous attractor neural network (CANN) with feedback inhibition, which is inspired by the reciprocal interaction between the hippocampus and the medial septum. The feedback inhibition induces intrinsic mobility of the CANN which competes with the extrinsic mobility arising from the external drive. Their interplay generates an oscillatory tracking state, that is, the network bump state (resembling the decoded virtual position of the animal) sweeps back and forth around the external moving input (resembling the physical position of the animal). We show that this oscillatory tracking naturally explains the forward and backward sweeps of the decoded position during the animal's locomotion.  At the single neuron level, the forward and backward sweeps account for, respectively, theta phase precession and procession. Furthermore, by tuning the feedback inhibition strength, we also explain the emergence of bimodal cells and unimodal cells, with the former having co-existed phase precession and procession, and the latter having only significant phase precession. We hope that this study facilitates our understanding of hippocampal temporal coding and lays foundation for unveiling their computational functions.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ELASTIC: Numerical Reasoning with Adaptive Symbolic Compiler",
        "paper_url": "https://openreview.net/pdf?id=gd7ZI0X7Q-h",
        "paper_authors": [
            "Jiaxin Zhang",
            "Yashar Moshfeghi"
        ],
        "paper_abstract": "Numerical reasoning over text is a challenging task of Artificial Intelligence (AI), requiring reading comprehension and numerical reasoning abilities. Previous approaches use numerical reasoning programs to represent the reasoning process. However, most works do not separate the generation of operators and operands, which are key components of a numerical reasoning program, thus limiting their ability to generate such programs for complicated tasks. In this paper, we introduce the numEricaL reASoning with adapTive symbolIc Compiler (ELASTIC) model, which is constituted of the RoBERTa as the Encoder and a Compiler with four modules: Reasoning Manager, Operator Generator, Operands Generator, and Memory Register. ELASTIC is robust when conducting complicated reasoning. Also, it is domain agnostic by supporting the expansion of diverse operators without caring about the number of operands it contains. Experiments show that ELASTIC achieves 68.96 and 65.21 of execution accuracy and program accuracy on the FinQA dataset and 83.00 program accuracy on the MathQA dataset, outperforming previous state-of-the-art models significantly.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptation Accelerating Sampling-based Bayesian Inference in Attractor Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=Y0Bm5tL92lg",
        "paper_authors": [
            "Xingsi Dong",
            "Zilong Ji",
            "Tianhao Chu",
            "Tiejun Huang",
            "Wenhao Zhang",
            "Si Wu"
        ],
        "paper_abstract": "The brain performs probabilistic Bayesian inference to interpret the external world. The sampling-based view assumes that the brain represents the stimulus posterior distribution via samples of stochastic neuronal responses. Although the idea of sampling-based inference is appealing, it faces a critical challenge of whether stochastic sampling is fast enough to match the rapid computation of the brain. In this study, we explore how latent stimulus sampling can be accelerated in neural circuits. Specifically, we consider a canonical neural circuit model called continuous attractor neural networks (CANNs) and investigate how sampling-based inference of latent continuous variables is accelerated in CANNs. Intriguingly, we find that by including noisy adaptation in the neuronal dynamics, the CANN is able to speed up the sampling process significantly. We theoretically derive that the CANN with noisy adaptation implements the efficient sampling method called Hamiltonian dynamics with friction, where noisy adaption effectively plays the role of momentum. We theoretically analyze the sampling performances of the network and derive the condition when the acceleration has the maximum effect. Simulation results confirm our theoretical analyses. We further extend the model to coupled CANNs and demonstrate that noisy adaptation accelerates the sampling of the posterior distribution of multivariate stimuli. We hope that this study enhances our understanding of how Bayesian inference is realized in the brain.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Subspace clustering in high-dimensions: Phase transitions & Statistical-to-Computational gap",
        "paper_url": "https://openreview.net/pdf?id=hYx-xr1wdo",
        "paper_authors": [
            "Luca Pesce",
            "Bruno Loureiro",
            "Florent Krzakala",
            "Lenka Zdeborova"
        ],
        "paper_abstract": "A simple model to study subspace clustering is the high-dimensional $k$-Gaussian mixture model where the cluster means are sparse vectors. Here we provide an exact asymptotic characterization of the statistically optimal reconstruction error in this model in the high-dimensional regime with extensive sparsity, i.e. when the fraction of non-zero components of the cluster means $\\rho$, as well as the ratio $\\alpha$ between the number of samples and the dimension are fixed, while the dimension diverges. We identify the information-theoretic threshold below which obtaining a positive correlation with the true cluster means is statistically impossible. Additionally, we investigate the performance of the approximate message passing (AMP) algorithm analyzed via its state evolution, which is conjectured to be optimal among polynomial algorithm for this task. We identify in particular the existence of a statistical-to-computational gap between the algorithm that requires a signal-to-noise ratio $\\lambda_{\\text{alg}} \\ge k  / \\sqrt{\\alpha}$ to perform better than random, and the information theoretic threshold at $\\lambda_{\\text{it}} \\approx \\sqrt{-k \\rho \\log{\\rho}}  / \\sqrt{\\alpha}$. Finally, we discuss the case of sub-extensive sparsity $\\rho$ by comparing the performance of the AMP with other sparsity-enhancing algorithms, such as sparse-PCA and diagonal thresholding.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Diagnosing failures of fairness transfer across distribution shift in real-world medical settings",
        "paper_url": "https://openreview.net/pdf?id=K-A4tDJ6HHf",
        "paper_authors": [
            "Jessica Schrouff",
            "Natalie Harris",
            "Oluwasanmi O Koyejo",
            "Ibrahim Alabdulmohsin",
            "Eva Schnider",
            "Krista Opsahl-Ong",
            "Alexander Brown",
            "Subhrajit Roy",
            "Diana Mincu",
            "Chrsitina Chen",
            "Awa Dieng",
            "Yuan Liu",
            "Vivek Natarajan",
            "Alan Karthikesalingam",
            "Katherine A Heller",
            "Silvia Chiappa",
            "Alexander D'Amour"
        ],
        "paper_abstract": "Diagnosing and mitigating changes in model fairness under distribution shift is an important component of the safe deployment of machine learning in healthcare settings. Importantly, the success of any mitigation strategy strongly depends on the \\textit{structure} of the shift. Despite this, there has been little discussion of how to empirically assess the structure of a distribution shift that one is encountering in practice. In this work, we adopt a causal framing to motivate conditional independence tests as a key tool for characterizing distribution shifts. Using our approach in two medical applications, we show that this knowledge can help diagnose failures of fairness transfer, including cases where real-world shifts are more complex than is often assumed in the literature. Based on these results, we discuss potential remedies at each step of the machine learning pipeline.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient identification of informative features in simulation-based inference",
        "paper_url": "https://openreview.net/pdf?id=AYQI3rlp9tW",
        "paper_authors": [
            "Jonas Beck",
            "Michael Deistler",
            "Yves Bernaerts",
            "Jakob H. Macke",
            "Philipp Berens"
        ],
        "paper_abstract": "Simulation-based Bayesian inference (SBI) can be used to estimate the parameters of complex mechanistic models given observed model outputs without requiring access to explicit likelihood evaluations. A prime example for the application of SBI in neuroscience involves estimating the parameters governing the response dynamics of Hodgkin-Huxley (HH) models from electrophysiological measurements, by inferring a posterior over the parameters that is consistent with a set of observations. To this end, many SBI methods employ a set of summary statistics or scientifically interpretable features to estimate a surrogate likelihood or posterior. However, currently, there is no way to identify how much each summary statistic or feature contributes to reducing posterior uncertainty. To address this challenge, one could simply compare the posteriors with and without a given feature included in the inference process. However, for large or nested feature sets, this would necessitate repeatedly estimating the posterior, which is computationally expensive or even prohibitive. Here, we provide a more efficient approach based on the SBI method neural likelihood estimation (NLE): We show that one can marginalize the trained surrogate likelihood post-hoc before inferring the posterior to assess the contribution of a feature. We demonstrate the usefulness of our method by identifying the most important features for inferring parameters of an example HH neuron model. Beyond neuroscience, our method is generally applicable to SBI workflows that rely on data features for inference used in other scientific fields.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sound and Complete Causal Identification with Latent Variables Given Local Background Knowledge",
        "paper_url": "https://openreview.net/pdf?id=S8-duMv77W3",
        "paper_authors": [
            "Tian-Zuo Wang",
            "Tian Qin",
            "Zhi-Hua Zhou"
        ],
        "paper_abstract": "Great efforts have been devoted to causal discovery from observational data, and it is well known that introducing some background knowledge attained from experiments or human expertise can be very helpful. However, it remains unknown that \\emph{what causal relations are identifiable given background knowledge in the presence of latent confounders}. In this paper, we solve the problem with sound and complete orientation rules when the background knowledge is given in a \\emph{local} form. Furthermore, based on the solution to the problem, this paper proposes a general active learning framework for causal discovery in the presence of latent confounders, with its effectiveness and efficiency validated by experiments.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Active Learning by Leveraging Training Dynamics",
        "paper_url": "https://openreview.net/pdf?id=aJ5xc1QB7EX",
        "paper_authors": [
            "Haonan Wang",
            "Wei Huang",
            "Ziwei Wu",
            "Hanghang Tong",
            "Andrew J Margenot",
            "Jingrui He"
        ],
        "paper_abstract": "Active learning theories and methods have been extensively studied in classical statistical learning settings. However, deep active learning, i.e., active learning with deep learning models, is usually based on empirical criteria without solid theoretical justification, thus suffering from heavy doubts when some of those fail to provide benefits in applications. In this paper, by exploring the connection between the generalization performance and the training dynamics, we propose a theory-driven deep active learning method (dynamicAL) which selects samples to maximize training dynamics. In particular, we prove that the convergence speed of training and the generalization performance is positively correlated under the ultra-wide condition and show that maximizing the training dynamics leads to a better generalization performance. Furthermore, to scale up to large deep neural networks and data sets, we introduce two relaxations for the subset selection problem and reduce the time complexity from polynomial to constant. Empirical results show that dynamicAL not only outperforms the other baselines consistently but also scales well on large deep learning models. We hope our work inspires more attempts in bridging the theoretical findings of deep networks and practical impacts in deep active learning applications.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CageNeRF: Cage-based Neural Radiance Field for Generalized 3D Deformation and Animation",
        "paper_url": "https://openreview.net/pdf?id=kUnHCGiILeU",
        "paper_authors": [
            "Yicong Peng",
            "Yichao Yan",
            "Shengqi Liu",
            "Yuhao Cheng",
            "Shanyan Guan",
            "Bowen Pan",
            "Guangtao Zhai",
            "Xiaokang Yang"
        ],
        "paper_abstract": "While implicit representations have achieved high-fidelity results in 3D rendering, it remains challenging to deforming and animating the implicit field. Existing works typically leverage data-dependent models as deformation priors, such as SMPL for human body animation. However, this dependency on category-specific priors limits them to generalize to other objects. To solve this problem, we propose a novel framework for deforming and animating the neural radiance field learned on \\textit{arbitrary} objects. The key insight is that we introduce a cage-based representation as deformation prior, which is category-agnostic. Specifically, the deformation is performed based on an enclosing polygon mesh with sparsely defined vertices called \\textit{cage} inside the rendering space, where each point is projected into a novel position based on the barycentric interpolation of the deformed cage vertices. In this way, we transform the cage into a generalized constraint, which is able to deform and animate arbitrary target objects while preserving geometry details. Based on extensive experiments, we demonstrate the effectiveness of our framework in the task of geometry editing, object animation and deformation transfer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Boosting the Transferability of Adversarial Attacks with Reverse Adversarial Perturbation",
        "paper_url": "https://openreview.net/pdf?id=k5uFiFLWv3X",
        "paper_authors": [
            "Zeyu Qin",
            "Yanbo Fan",
            "Yi Liu",
            "Li Shen",
            "Yong Zhang",
            "Jue Wang",
            "Baoyuan Wu"
        ],
        "paper_abstract": "Deep neural networks (DNNs) have been shown to be vulnerable to adversarial examples, which can produce erroneous predictions by injecting imperceptible perturbations. In this work, we study the transferability of adversarial examples, which is significant due to its threat to real-world applications where model architecture or parameters are usually unknown. Many existing works reveal that the adversarial examples are likely to overfit the surrogate model that they are generated from, limiting its transfer attack performance against different target models. To mitigate the overfitting of the surrogate model, we propose a novel attack method, dubbed reverse adversarial perturbation (RAP). Specifically, instead of minimizing the loss of a single adversarial point, we advocate seeking adversarial example located at a region with unified low loss value, by injecting the worst-case perturbation (the reverse adversarial perturbation) for each step of the optimization procedure. The adversarial attack with RAP is formulated as a min-max bi-level optimization problem.  By integrating RAP into the iterative process for attacks, our method can find more stable adversarial examples which are less sensitive to the changes of decision boundary, mitigating the overfitting of the surrogate model.  Comprehensive experimental comparisons demonstrate that RAP can significantly boost adversarial transferability. Furthermore, RAP can be naturally combined with many existing black-box attack techniques, to further boost the transferability. When attacking a real-world image recognition system, Google Cloud Vision API, we obtain 22% performance improvement of targeted attacks over the compared method. Our codes are available at https://github.com/SCLBD/Transfer_attack_RAP.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contextual Bandits with Knapsacks for a Conversion Model",
        "paper_url": "https://openreview.net/pdf?id=OoN6TVb4Vkq",
        "paper_authors": [
            "Zhen LI",
            "Gilles Stoltz"
        ],
        "paper_abstract": "We consider contextual bandits with knapsacks, with an underlying structure between rewards generated and cost vectors suffered. We do so motivated by sales with commercial discounts. At each round, given the stochastic i.i.d.\\ context $\\mathbf{x}_t$ and the arm picked $a_t$ (corresponding, e.g., to a discount level), a customer conversion may be obtained, in which case a reward $r(a,\\mathbf{x}_t)$ is gained and vector costs $\\mathbf{c}(a_t,\\mathbf{x}_t)$ are suffered (corresponding, e.g., to losses of earnings). Otherwise, in the absence of a conversion, the reward and costs are null. The reward and costs achieved are thus coupled through the binary variable measuring conversion or the absence thereof. This underlying structure between rewards and costs is different from the linear structures considered by Agrawal and Devanur [2016] (but we show that the techniques introduced in the present article may also be applied to the case of these linear structures). The adaptive policies exhibited in this article solve at each round a linear program based on upper-confidence estimates of the probabilities of conversion given $a$ and $\\mathbf{x}$. This kind of policy is most natural and achieves a regret bound of the typical order $(\\mathrm{OPT}/B) \\smash{\\sqrt{T}}$, where $B$ is the total budget allowed, $\\mathrm{OPT}$ is the optimal expected reward achievable by a static policy, and $T$ is the number of rounds. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Using natural language and program abstractions to instill human inductive biases in machines",
        "paper_url": "https://openreview.net/pdf?id=buXZ7nIqiwE",
        "paper_authors": [
            "Sreejan Kumar",
            "Carlos G Correa",
            "Ishita Dasgupta",
            "Raja Marjieh",
            "Michael Hu",
            "Robert D. Hawkins",
            "Jonathan Cohen",
            "Nathaniel Daw",
            "Karthik R Narasimhan",
            "Thomas L. Griffiths"
        ],
        "paper_abstract": "Strong inductive biases give humans the ability to quickly learn to perform a variety of tasks. Although meta-learning is a method to endow neural networks with useful inductive biases, agents trained by meta-learning may sometimes acquire very different strategies from humans. We show that co-training these agents on predicting representations from natural language task descriptions and programs induced to generate such tasks guides them toward more human-like inductive biases. Human-generated language descriptions and program induction models that add new learned primitives both contain abstract concepts that can compress description length. Co-training on these representations result in more human-like behavior in downstream meta-reinforcement learning agents than less abstract controls (synthetic language descriptions, program induction without learned primitives), suggesting that the abstraction supported by these representations is key. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FairVFL: A Fair Vertical Federated Learning Framework with Contrastive Adversarial Learning",
        "paper_url": "https://openreview.net/pdf?id=5vVSA_cdRqe",
        "paper_authors": [
            "Tao Qi",
            "Fangzhao Wu",
            "Chuhan Wu",
            "Lingjuan Lyu",
            "Tong Xu",
            "Hao Liao",
            "Zhongliang Yang",
            "Yongfeng Huang",
            "Xing Xie"
        ],
        "paper_abstract": "Vertical federated learning (VFL) is a privacy-preserving machine learning paradigm that can learn models from features distributed on different platforms in a privacy-preserving way. Since in real-world applications the data may contain bias on fairness-sensitive features (e.g., gender), VFL models may inherit bias from training data and become unfair for some user groups. However, existing fair machine learning methods usually rely on the centralized storage of fairness-sensitive features to achieve model fairness, which are usually inapplicable in federated scenarios. In this paper, we propose a fair vertical federated learning framework (FairVFL), which can improve the fairness of VFL models. The core idea of FairVFL is to learn unified and fair representations of samples based on the decentralized feature fields in a privacy-preserving way. Specifically, each platform with fairness-insensitive features first learns local data representations from local features. Then, these local representations are uploaded to a server and aggregated into a unified representation for the target task. In order to learn a fair unified representation, we send it to each platform storing fairness-sensitive features and apply adversarial learning to remove bias from the unified representation inherited from the biased data. Moreover, for protecting user privacy, we further propose a contrastive adversarial learning method to remove private information from the unified representation in server before sending it to the platforms keeping fairness-sensitive features. Experiments on three real-world datasets validate that our method can effectively improve model fairness with user privacy well-protected.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Wasserstein Logistic Regression with Mixed Features",
        "paper_url": "https://openreview.net/pdf?id=U-RsnLYHcKa",
        "paper_authors": [
            "Aras Selvi",
            "Mohammad Reza Belbasi",
            "Martin B Haugh",
            "Wolfram Wiesemann"
        ],
        "paper_abstract": "Recent work has leveraged the popular distributionally robust optimization paradigm to combat overfitting in classical logistic regression. While the resulting classification scheme displays a promising performance in numerical experiments, it is inherently limited to numerical features. In this paper, we show that distributionally robust logistic regression with mixed (\\emph{i.e.}, numerical and categorical) features, despite amounting to an optimization problem of exponential size, admits a polynomial-time solution scheme. We subsequently develop a practically efficient cutting plane approach that solves the problem as a sequence of polynomial-time solvable exponential conic programs. Our method retains many of the desirable theoretical features of previous works, but---in contrast to the literature---it does not admit an equivalent representation as a regularized logistic regression, that is, it represents a genuinely novel variant of the logistic regression problem. We show that our method outperforms both the unregularized and the regularized logistic regression on categorical as well as mixed-feature benchmark instances.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Forecasting Human Trajectory from Scene History",
        "paper_url": "https://openreview.net/pdf?id=RW-OOBU11xl",
        "paper_authors": [
            "Mancheng Meng",
            "Ziyan Wu",
            "Terrence Chen",
            "Xiran Cai",
            "Xiang Sean Zhou",
            "Fan Yang",
            "Dinggang Shen"
        ],
        "paper_abstract": "Predicting the future trajectory of a person remains a challenging problem, due to randomness and subjectivity. However, the moving patterns of human in constrained scenario typically conform to a limited number of regularities to a certain extent, because of the scenario restrictions (\\eg, floor plan, roads and obstacles) and person-person or person-object interactivity. Thus, an individual person in this scenario should follow one of the regularities as well. In other words, a person's subsequent trajectory has likely been traveled by others. Based on this hypothesis, we propose to forecast a person's future trajectory by learning from the implicit scene regularities. We call the regularities, inherently derived from the past dynamics of the people and the environment in the scene,  \\emph{scene history}. We categorize scene history information into two types: historical group trajectories and individual-surroundings interaction. To exploit these information for trajectory prediction, we propose a novel framework Scene History Excavating Network (SHENet), where the scene history is leveraged in a simple yet effective approach. In particular, we design two components, the group trajectory bank module to extract representative group trajectories as the candidate for future path, and the cross-modal interaction module to model the interaction between individual past trajectory and its surroundings for trajectory refinement, respectively.  In addition, to mitigate the uncertainty in the evaluation, caused by the aforementioned randomness and subjectivity, we propose to include smoothness into evaluation metrics. We conduct extensive evaluations to validate the efficacy of proposed framework on ETH, UCY, as well as a new, challenging benchmark dataset PAV, demonstrating superior performance compared to state-of-the-art methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Nature of Temporal Difference Errors in Multi-step Distributional Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=Mn4IkuWamy",
        "paper_authors": [
            "Yunhao Tang",
            "Remi Munos",
            "Mark Rowland",
            "Bernardo Avila Pires",
            "Will Dabney",
            "Marc G Bellemare"
        ],
        "paper_abstract": "We study the multi-step off-policy learning approach to distributional RL. Despite the apparent similarity between value-based RL and distributional RL, our study reveals intriguing and fundamental differences between the two cases in the multi-step setting. We identify a novel notion of path-dependent distributional TD error, which is indispensable for principled multi-step distributional RL. The distinction from the value-based case bears important implications on concepts such as backward-view algorithms. Our work provides the first theoretical guarantees on multi-step off-policy distributional RL algorithms, including results that apply to the small number of existing approaches to multi-step distributional RL. In addition, we derive a novel algorithm, Quantile Regression-Retrace, which leads to a deep RL agent QR-DQN-Retrace that shows empirical improvements over QR-DQN on the Atari-57 benchmark. Collectively, we shed light on how unique challenges in multi-step distributional RL can be addressed both in theory and practice.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DivBO: Diversity-aware CASH for Ensemble Learning",
        "paper_url": "https://openreview.net/pdf?id=sFQJ0IOkHF",
        "paper_authors": [
            "Yu Shen",
            "Yupeng Lu",
            "Yang Li",
            "Yaofeng Tu",
            "Wentao Zhang",
            "Bin CUI"
        ],
        "paper_abstract": "The Combined Algorithm Selection and Hyperparameters optimization (CASH) problem is one of the fundamental problems in Automated Machine Learning (AutoML). Motivated by the success of ensemble learning, recent AutoML systems build post-hoc ensembles to output the final predictions instead of using the best single learner. However, while most CASH methods focus on searching for a single learner with the best performance, they neglect the diversity among base learners (i.e., they may suggest similar configurations to previously evaluated ones), which is also a crucial consideration when building an ensemble. To tackle this issue and further enhance the ensemble performance, we propose DivBO, a diversity-aware framework to inject explicit search of diversity into the CASH problems. In the framework, we propose to use a diversity surrogate to predict the pair-wise diversity of two unseen configurations. Furthermore, we introduce a temporary pool and a weighted acquisition function to guide the search of both performance and diversity based on Bayesian optimization. Empirical results on 15 public datasets show that DivBO achieves the best average ranks (1.82 and 1.73) on both validation and test errors among 10 compared methods, including post-hoc designs in recent AutoML systems and state-of-the-art baselines for ensemble learning on CASH problems.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TREC: Transient Redundancy Elimination-based Convolution",
        "paper_url": "https://openreview.net/pdf?id=FNzLe2-ppRO",
        "paper_authors": [
            "Jiawei Guan",
            "Feng Zhang",
            "Jiesong Liu",
            "Hsin-Hsuan Sung",
            "Ruofan Wu",
            "Xiaoyong Du",
            "Xipeng Shen"
        ],
        "paper_abstract": "The intensive computations in convolutional neural networks (CNNs) pose challenges for resource-constrained devices; eliminating redundant computations from convolution is essential. This paper gives a principled method to detect and avoid transient redundancy, a type of redundancy existing in input data or activation maps and hence changing across inferences. By introducing a new form of convolution (TREC), this new method makes transient redundancy detection and avoidance an inherent part of the CNN architecture, and the determination of the best configurations for redundancy elimination part of CNN backward propagation. We provide a rigorous proof of the robustness and convergence of TREC-equipped CNNs. TREC removes over 96% computations and achieves 3.51x average speedups on microcontrollers with minimal (about 0.7%) accuracy loss.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bidirectional Learning for Offline Infinite-width Model-based Optimization",
        "paper_url": "https://openreview.net/pdf?id=_j8yVIyp27Q",
        "paper_authors": [
            "Can Chen",
            "Yingxue Zhang",
            "Jie Fu",
            "Xue Liu",
            "Mark Coates"
        ],
        "paper_abstract": "In offline model-based optimization, we strive to maximize a black-box objective function by only leveraging a static dataset of designs and their scores. This problem setting arises in numerous fields including the design of materials, robots, DNAs, proteins, etc. Recent approaches train a deep neural network (DNN) model on the static dataset to act as a proxy function, and then perform gradient ascent on the existing designs to obtain potentially high-scoring designs. This methodology frequently suffers from the out-of-distribution problem where the proxy function often returns adversarial designs. To mitigate this problem, we propose $\\textit{\\textbf{B}i\\textbf{D}irectional learning for offline \\textbf{I}nfinite-width model-based optimization}~(\\textbf{BDI})$. BDI consists of two mappings: the forward mapping leverages the static dataset to predict the scores of the high-scoring designs, and the backward mapping leverages the high-scoring designs to predict the scores of the static dataset. The backward mapping, neglected in previous work, can distill more information of the static dataset into the high-scoring designs, which effectively mitigates the out-of-distribution problem. Yet, for a finite-width DNN model, the loss function of the backward mapping is intractable and only has an approximate form, which leads to a significant deterioration of the design quality. We thus adopt an infinite-width DNN model and propose to employ the corresponding neural tangent kernel to yield a closed-form loss for more accurate design updates. Experiments on various tasks verify the effectiveness of BDI. The code is available [here](https://github.com/GGchen1997/BDI).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Transformer-Based Object Detector with Coarse-Fine Crossing Representations",
        "paper_url": "https://openreview.net/pdf?id=iuW96ssPQX",
        "paper_authors": [
            "Zhishan Li",
            "Ying Nie",
            "Kai Han",
            "Jianyuan Guo",
            "Lei Xie",
            "Yunhe Wang"
        ],
        "paper_abstract": "Transformer-based object detectors have shown competitive performance recently.  Compared with convolutional neural networks limited by the relatively small receptive fields, the advantage of transformer for visual tasks is the capacity to perceive long-range dependencies among all image patches, while the deficiency is that the local fine-grained information is not fully excavated. In this paper, we introduce the Coarse-grained and Fine-grained crossing representations to build an efficient Detection Transformer (CFDT). Specifically, we propose a local-global cross fusion module to establish the connection between local fine-grained features and global coarse-grained features. Besides, we propose a coarse-fine aware neck which enables detection tokens to interact with both coarse-grained and fine-grained features. Furthermore, an efficient feature integration module is presented for fusing multi-scale representations from different stages. Experimental results on the COCO dataset demonstrate the effectiveness of the proposed method. For instance, our CFDT achieves 48.1 AP with 173G FLOPs, which possesses higher accuracy and less computation compared with the state-of-the-art transformer-based detector ViDT. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/CFDT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bessel Equivariant Networks for Inversion of Transmission Effects in Multi-Mode Optical Fibres",
        "paper_url": "https://openreview.net/pdf?id=0zlLhfG6rxI",
        "paper_authors": [
            "Joshua Mitton",
            "Simon Peter Mekhail",
            "Miles Padgett",
            "Daniele Faccio",
            "Marco Aversa",
            "Roderick Murray-Smith"
        ],
        "paper_abstract": "We develop a new type of model for solving the task of inverting the transmission effects of multi-mode optical fibres through the construction of an $\\mathrm{SO}^{+}(2,1)$-equivariant neural network. This model takes advantage of the of the azimuthal correlations known to exist in fibre speckle patterns and naturally accounts for the difference in spatial arrangement between input and speckle patterns. In addition, we use a second post-processing network to remove circular artifacts, fill gaps, and sharpen the images, which is required due to the nature of optical fibre transmission. This two stage approach allows for the inspection of the predicted images produced by the more robust physically motivated equivariant model, which could be useful in a safety-critical application, or by the output of both models, which produces high quality images. Further, this model can scale to previously unachievable resolutions of imaging with multi-mode optical fibres and is demonstrated on $256 \\times 256$ pixel images. This is a result of improving the trainable parameter requirement from $\\mathcal{O}(N^4)$ to $\\mathcal{O}(m)$, where $N$ is pixel size and $m$ is number of fibre modes. Finally, this model generalises to new images, outside of the set of training data classes, better than previous models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VICE: Variational Interpretable Concept Embeddings",
        "paper_url": "https://openreview.net/pdf?id=WE92fqi-N_g",
        "paper_authors": [
            "Lukas Muttenthaler",
            "Charles Yang Zheng",
            "Patrick McClure",
            "Robert A. Vandermeulen",
            "Martin N Hebart",
            "Francisco Pereira"
        ],
        "paper_abstract": "A central goal in the cognitive sciences is the development of numerical models for mental representations of object concepts. This paper introduces Variational Interpretable Concept Embeddings (VICE), an approximate Bayesian method for embedding object concepts in a vector space using data collected from humans in a triplet odd-one-out task. VICE uses variational inference to obtain sparse, non-negative representations of object concepts with uncertainty estimates for the embedding values. These estimates are used to automatically select the dimensions that best explain the data. We derive a PAC learning bound for VICE that can be used to estimate generalization performance or determine a sufficient sample size for experimental design. VICE rivals or outperforms its predecessor, SPoSE, at predicting human behavior in the triplet odd-one-out task. Furthermore, VICE's object representations are more reproducible and consistent across random initializations, highlighting the unique advantage of using VICE for deriving interpretable embeddings from human behavior.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Chefs' Random Tables: Non-Trigonometric Random Features",
        "paper_url": "https://openreview.net/pdf?id=vRwCvlvd8eA",
        "paper_authors": [
            "Valerii Likhosherstov",
            "Krzysztof Marcin Choromanski",
            "Kumar Avinava Dubey",
            "Frederick Liu",
            "Tamas Sarlos",
            "Adrian Weller"
        ],
        "paper_abstract": "We introduce chefs' random tables (CRTs), a new class of non-trigonometric random features (RFs) to approximate Gaussian and softmax kernels. CRTs are an alternative to standard random kitchen sink (RKS) methods, which inherently rely on the trigonometric maps. We present variants of CRTs where RFs are positive, a key requirement for applications in recent low-rank Transformers. Further variance reduction is possible by leveraging statistics which are simple to compute. One instantiation of CRTs, the optimal positive random features (OPRFs), is to our knowledge the first RF method for unbiased softmax kernel estimation with positive and bounded RFs, resulting in exponentially small tails and much lower variance than its counterparts. As we show, orthogonal random features applied in OPRFs provide additional variance reduction for any dimensionality $d$ (not only asymptotically for sufficiently large $d$, as for RKS). We test CRTs on many tasks ranging from non-parametric classification to training Transformers for text, speech and image data, obtaining new state-of-the-art results for low-rank text Transformers, while providing linear space and time complexity.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SketchBoost: Fast Gradient Boosted Decision Tree for Multioutput Problems",
        "paper_url": "https://openreview.net/pdf?id=WSxarC8t-T",
        "paper_authors": [
            "Leonid Iosipoi",
            "Anton Vakhrushev"
        ],
        "paper_abstract": "Gradient Boosted Decision Tree (GBDT) is a widely-used machine learning algorithm that has been shown to achieve state-of-the-art results on many standard data science problems. We are interested in its application to multioutput problems when the output is highly multidimensional. Although there are highly effective GBDT implementations, their scalability to such problems is still unsatisfactory. In this paper, we propose novel methods aiming to accelerate the training process of GBDT in the multioutput scenario. The idea behind these methods lies in the approximate computation of a scoring function used to find the best split of decision trees. These methods are implemented in SketchBoost, which itself is integrated into our easily customizable Python-based GPU implementation of GBDT called Py-Boost. Our numerical study demonstrates that SketchBoost speeds up the training process of GBDT by up to over 40 times while achieving comparable or even better performance.\n\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SizeShiftReg: a Regularization Method for Improving Size-Generalization in Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=wOI0AUAq9BR",
        "paper_authors": [
            "Davide Buffelli",
            "Pietro Lio",
            "Fabio Vandin"
        ],
        "paper_abstract": "In the past few years, graph neural networks (GNNs) have become the de facto model of choice for graph classification. While, from the theoretical viewpoint, most GNNs can operate on graphs of any size, it is empirically observed that their classification performance degrades when they are applied on graphs with sizes that differ from those in the training data. Previous works have tried to tackle this issue in graph classification by providing the model with inductive biases derived from assumptions on the generative process of the graphs, or by requiring access to graphs from the test domain. The first strategy is tied to the quality of the assumptions made for the generative process, and requires the use of specific models designed after the explicit definition of the generative process of the data, leaving open the question of how to improve the performance of generic GNN models in general settings. On the other hand, the second strategy can be applied to any GNN, but requires access to information that is not always easy to obtain. In this work we consider the scenario in which we only have access to the training data, and we propose a regularization strategy that can be applied to any GNN to improve its generalization capabilities from smaller to larger graphs without requiring access to the test data. Our regularization is based on the idea of simulating a shift in the size of the training graphs using coarsening techniques, and enforcing the model to be robust to such a shift. Experimental results on standard datasets show that popular GNN models, trained on the 50% smallest graphs in the dataset and tested on the 10% largest graphs, obtain performance improvements of up to 30% when trained with our regularization strategy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers",
        "paper_url": "https://openreview.net/pdf?id=GkDbQb6qu_r",
        "paper_authors": [
            "Ming Ding",
            "Wendi Zheng",
            "Wenyi Hong",
            "Jie Tang"
        ],
        "paper_abstract": "Development of transformer-based text-to-image models is impeded by its slow generation and complexity, for high-resolution images. In this work, we put forward a solution based on hierarchical transformers and local parallel autoregressive generation.  \nWe pretrain a 6B-parameter transformer with a simple and flexible self-supervised task, a cross-modal general language model (CogLM), and fine-tune it for fast super-resolution. \nThe new text-to-image system, CogView2, shows very competitive generation compared to concurrent state-of-the-art DALL-E-2, and naturally supports interactive text-guided editing on images.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep invariant networks with differentiable augmentation layers",
        "paper_url": "https://openreview.net/pdf?id=nxw9_ny7_H",
        "paper_authors": [
            "C\u00e9dric Rommel",
            "Thomas Moreau",
            "Alexandre Gramfort"
        ],
        "paper_abstract": "Designing learning systems which are invariant to certain data transformations is critical in machine learning. Practitioners can typically enforce a desired invariance on the trained model through the choice of a network architecture, e.g. using convolutions for translations, or using data augmentation. Yet, enforcing true invariance in the network can be difficult, and data invariances are not always known a piori. State-of-the-art methods for learning data augmentation policies require held-out data and are based on bilevel optimization problems, which are complex to solve and often computationally demanding. In this work we investigate new ways of learning invariances only from the training data. Using learnable augmentation layers built directly in the network, we demonstrate that our method is very versatile. It can incorporate any type of differentiable augmentation and be applied to a broad class of learning problems beyond computer vision. We provide empirical evidence showing that our approach is easier and faster to train than modern automatic data augmentation techniques based on bilevel optimization, while achieving comparable results. Experiments show that while the invariances transferred to a model through automatic data augmentation are limited by the model expressivity, the invariance yielded by our approach is insensitive to it by design.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FNeVR: Neural Volume Rendering for Face Animation",
        "paper_url": "https://openreview.net/pdf?id=7HTEHRMlxYH",
        "paper_authors": [
            "Bohan Zeng",
            "Boyu Liu",
            "Hong Li",
            "Xuhui Liu",
            "Jianzhuang Liu",
            "Dapeng Chen",
            "Wei Peng",
            "Baochang Zhang"
        ],
        "paper_abstract": "Face animation, one of the hottest topics in computer vision, has achieved a promising performance with the help of generative models. However, it remains a critical challenge to generate identity preserving and photo-realistic images due to the sophisticated motion deformation and complex facial detail modeling. To address these problems, we propose a Face Neural Volume Rendering (FNeVR) network to fully explore the potential of 2D motion warping and 3D volume rendering in a unified framework. In FNeVR, we design a 3D Face Volume Rendering (FVR) module to enhance the facial details for image rendering. Specifically, we first extract 3D information with a well designed architecture, and then introduce an orthogonal adaptive ray-sampling module for efficient rendering. We also design a lightweight pose editor, enabling FNeVR to edit the facial pose in a simple yet effective way. Extensive experiments show that our FNeVR obtains the best overall quality and performance on widely used talking-head benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HF-NeuS: Improved Surface Reconstruction Using High-Frequency Details",
        "paper_url": "https://openreview.net/pdf?id=UPnJuDKqOfX",
        "paper_authors": [
            "Yiqun Wang",
            "Ivan Skorokhodov",
            "Peter Wonka"
        ],
        "paper_abstract": "Neural rendering can be used to reconstruct implicit representations of shapes without 3D supervision. However, current neural surface reconstruction methods have difficulty learning high-frequency geometry details, so the reconstructed shapes are often over-smoothed. We develop HF-NeuS, a novel method to improve the quality of surface reconstruction in neural rendering. We follow recent work to model surfaces as signed distance functions (SDFs). First, we offer a derivation to analyze the relationship between the SDF, the volume density, the transparency function, and the weighting function used in the volume rendering equation and propose to model transparency as a transformed SDF. Second, we observe that attempting to jointly encode high-frequency and low-frequency components in a single SDF leads to unstable optimization. We propose to decompose the SDF into base and displacement functions with a coarse-to-fine strategy to increase the high-frequency details gradually. Finally, we design an adaptive optimization strategy that makes the training process focus on improving those regions near the surface where the SDFs have artifacts. Our qualitative and quantitative results show that our method can reconstruct fine-grained surface details and obtain better surface reconstruction quality than the current state of the art. Code available at https://github.com/yiqun-wang/HFS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TCT: Convexifying Federated Learning using Bootstrapped Neural Tangent Kernels",
        "paper_url": "https://openreview.net/pdf?id=jzd2bE5MxW",
        "paper_authors": [
            "Yaodong Yu",
            "Alexander Wei",
            "Sai Praneeth Karimireddy",
            "Yi Ma",
            "Michael Jordan"
        ],
        "paper_abstract": "State-of-the-art federated learning methods can perform far worse than their centralized counterparts when clients have dissimilar data distributions. For neural networks, even when centralized SGD easily finds a solution that is simultaneously performant for all clients, current federated optimization methods fail to converge to a comparable solution. We show that this performance disparity can largely be attributed to optimization challenges presented by nonconvexity. Specifically, we find that the early layers of the network do learn useful features, but the final layers fail to make use of them. That is, federated optimization applied to this non-convex problem distorts the learning of the final layers. Leveraging this observation, we propose a Train-Convexify-Train (TCT) procedure to sidestep this issue: first, learn features using off-the-shelf methods (e.g., FedAvg); then, optimize a convexified problem obtained from the network's empirical neural tangent kernel approximation. Our technique yields accuracy improvements of up to $+36\\%$ on FMNIST and $+37\\%$ on CIFAR10 when clients have dissimilar data. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scalable Neural Video Representations with Learnable Positional Features",
        "paper_url": "https://openreview.net/pdf?id=OxfI-3i5M8g",
        "paper_authors": [
            "Subin Kim",
            "Sihyun Yu",
            "Jaeho Lee",
            "Jinwoo Shin"
        ],
        "paper_abstract": "Succinct representation of complex signals using coordinate-based neural representations (CNRs) has seen great progress, and several recent efforts focus on extending them for handling videos. Here, the main challenge is how to (a) alleviate a compute-inefficiency in training CNRs to (b) achieve high-quality video encoding while (c) maintaining the parameter-efficiency. To meet all requirements (a), (b), and (c) simultaneously, we propose neural video representations with learnable positional features (NVP), a novel CNR by introducing \"learnable positional features\" that effectively amortize a video as latent codes. Specifically, we first present a CNR architecture based on designing 2D latent keyframes to learn the common video contents across each spatio-temporal axis, which dramatically improves all of those three requirements. Then, we propose to utilize existing powerful image and video codecs as a compute-/memory-efficient compression procedure of latent codes. We demonstrate the superiority of NVP on the popular UVG benchmark; compared with prior arts, NVP not only trains 2 times faster (less than 5 minutes) but also exceeds their encoding quality as 34.07$\\rightarrow$34.57 (measured with the PSNR metric), even using $>$8 times fewer parameters. We also show intriguing properties of NVP, e.g., video inpainting, video frame interpolation, etc.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-modal Learning for Image-Guided Point Cloud Shape Completion",
        "paper_url": "https://openreview.net/pdf?id=bi1BTcXa8Q",
        "paper_authors": [
            "Emanuele Aiello",
            "Diego Valsesia",
            "Enrico Magli"
        ],
        "paper_abstract": "In this paper we explore the recent topic of point cloud completion, guided by an auxiliary image. We show how it is possible to effectively combine the information from the two modalities in a localized latent space, thus avoiding the need for complex point cloud reconstruction methods from single views used by the state-of-the-art. We also investigate a novel self-supervised setting where the auxiliary image provides a supervisory signal to the training process by using a differentiable renderer on the completed point cloud to measure fidelity in the image space. Experiments show significant improvements over state-of-the-art supervised methods for both unimodal and multimodal completion. We also show the effectiveness of the self-supervised approach which outperforms a number of supervised methods and is competitive with the latest supervised models only exploiting point cloud information.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Retrieve, Reason, and Refine: Generating Accurate and Faithful Patient Instructions",
        "paper_url": "https://openreview.net/pdf?id=dp0zWsdOV1h",
        "paper_authors": [
            "Fenglin Liu",
            "Bang Yang",
            "Chenyu You",
            "Xian Wu",
            "Shen Ge",
            "Zhangdaihong Liu",
            "Xu Sun",
            "Yang Yang",
            "David A. Clifton"
        ],
        "paper_abstract": "The \"Patient Instruction\" (PI), which contains critical instructional information provided both to carers and to the patient at the time of discharge, is essential for the patient to manage their condition outside hospital. An accurate and easy-to-follow PI can improve the self-management of patients which can in turn reduce hospital readmission rates. However, writing an appropriate PI can be extremely time consuming for physicians, and is subject to being incomplete or error-prone for (potentially overworked) physicians. Therefore, we propose a new task that can provide an objective means of avoiding incompleteness, while reducing clinical workload: the automatic generation of the PI, which is imagined as being a document that the clinician can review, modify, and approve as necessary (rather than taking the human \"out of the loop\"). We build a benchmark clinical dataset and propose the Re$^3$Writer, which imitates the working patterns of physicians to first retrieve related working experience from historical PIs written by physicians, then reason related medical knowledge. Finally, it refines the retrieved working experience and reasoned medical knowledge to extract useful information, which is used to generate the PI for previously-unseen patient according to their health records during hospitalization. Our experiments show that, using our method, the performance of 6 different models can be substantially boosted across all metrics, with up to 20%, 11%, and 19% relative improvements in BLEU-4, ROUGE-L, and METEOR, respectively. Meanwhile, we show results from human evaluations to measure the effectiveness in terms of its usefulness for clinical practice. The code is available at https://github.com/AI-in-Health/Patient-Instructions.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking the compositionality of point clouds through regularization in the hyperbolic space",
        "paper_url": "https://openreview.net/pdf?id=Z9ldMhplBrT",
        "paper_authors": [
            "Antonio Montanaro",
            "Diego Valsesia",
            "Enrico Magli"
        ],
        "paper_abstract": "Point clouds of 3D objects exhibit an inherent compositional nature where simple parts can be assembled into progressively more complex shapes to form whole objects. Explicitly capturing such part-whole hierarchy is a long-sought objective in order to build effective models, but its tree-like nature has made the task elusive. In this paper, we propose to embed the features of a point cloud classifier into the hyperbolic space and explicitly regularize the space to account for the part-whole hierarchy. The hyperbolic space is the only space that can successfully embed the tree-like nature of the hierarchy. This leads to substantial improvements in the performance of state-of-art supervised models for point cloud classification.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Redistribution of Weights and Activations for AdderNet Quantization",
        "paper_url": "https://openreview.net/pdf?id=ZuSiW0EixjX",
        "paper_authors": [
            "Ying Nie",
            "Kai Han",
            "Haikang Diao",
            "Chuanjian Liu",
            "Enhua Wu",
            "Yunhe Wang"
        ],
        "paper_abstract": "Adder Neural Network (AdderNet) provides a new way for developing energy-efficient neural networks by replacing the expensive multiplications in convolution with cheaper additions (i.e., L1-norm). To achieve higher hardware efficiency, it is necessary to further study the low-bit quantization of AdderNet. Due to the limitation that the commutative law in multiplication does not hold in L1-norm, the well-established quantization methods on convolutional networks cannot be applied on AdderNets. Thus, the existing AdderNet quantization techniques propose to use only one shared scale to quantize both the weights and activations simultaneously. Admittedly, such an approach can keep the commutative law in the  L1-norm quantization process, while the accuracy drop after low-bit quantization cannot be ignored. To this end, we first thoroughly analyze the difference on distributions of weights and activations in AdderNet and then propose a new quantization algorithm by redistributing the weights and the activations. Specifically, the pre-trained full-precision weights in different kernels are clustered into different groups, then the intra-group sharing and inter-group independent scales can be adopted. To further compensate the accuracy drop caused by the distribution difference, we then develop a lossless range clamp scheme for weights and a simple yet effective outliers clamp strategy for activations. Thus, the functionality of full-precision weights and the representation ability of full-precision activations can be fully preserved. The effectiveness of the proposed quantization method for AdderNet is well verified on several benchmarks, e.g., our 4-bit post-training quantized adder ResNet-18 achieves an 66.5% top-1 accuracy on the ImageNet with comparable energy efficiency,  which is about 8.5% higher than that of the previous AdderNet quantization methods. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/AdderQuant.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking Variational Inference for Probabilistic Programs with Stochastic Support",
        "paper_url": "https://openreview.net/pdf?id=wjClgX-muzB",
        "paper_authors": [
            "Tim Reichelt",
            "Luke Ong",
            "Tom Rainforth"
        ],
        "paper_abstract": "We introduce Support Decomposition Variational Inference (SDVI), a new variational inference (VI) approach for probabilistic programs with stochastic support. Existing approaches to this problem rely on designing a single global variational guide on a variable-by-variable basis, while maintaining the stochastic control flow of the original program. SDVI instead breaks the program down into sub-programs with static support, before automatically building separate sub-guides for each. This decomposition significantly aids in the construction of suitable variational families, enabling, in turn, substantial improvements in inference performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Convex Optimization with Hard Constraints: Towards the Best of Two Worlds and Beyond",
        "paper_url": "https://openreview.net/pdf?id=rwdpFgfVpvN",
        "paper_authors": [
            "Hengquan Guo",
            "Xin Liu",
            "Honghao Wei",
            "Lei Ying"
        ],
        "paper_abstract": "This paper considers online convex optimization with hard constraints and analyzes achievable regret and cumulative hard constraint violation (violation for short). The problem distinguishes itself from online convex optimization with soft constraints, where a violation at one round can be compensated/cancelled by a conservative decision at a different round. We propose a RECtified Online Optimization algorithm (RECOO) and consider two settings: fixed constraints and adversarial constraints. Both settings have been considered in the literature. Compared with existing results, {\\em RECOO achieves the best of two worlds and beyond.}  For the fixed-constraints setting, RECOO achieves $O\\left(\\sqrt{T}\\right)$ regret and $O(1)$  violation, where $T$ is the learning horizon. The best known results in this case are $O(\\sqrt{T})$ regret and $O\\left(T^{1/4}\\right)$ violation. For the adversarial-constraints setting, it guarantees $O(\\sqrt{T})$ regret and $O(T^{3/4})$ violation, which match the best existing results.  When the loss functions are strongly convex,  RECOO can guarantee $O(\\log T)$ regret and $O(1)$ violation for fixed constraints, and $O(\\log T)$ regret and $O(\\sqrt{T\\log T})$ violation for adversarial constraints. Both these results are order-wise better than the existing bounds. The regret and violation bounds mentioned above use the best fixed decision in hindsight as the baseline. This paper further considers a dynamic baseline where the comparator sequence is time-varying. This paper shows that RECOO not only improves the existing results in the fixed-constraints setting  but also {\\em for the first time,} guarantees dynamic regret and violation bounds in the adversarial-constraints setting. Our experiment results confirm that RECOO outperforms several existing algorithms for both fixed and adversarial constraints.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Information-Theoretic GAN Compression with Variational Energy-based Model",
        "paper_url": "https://openreview.net/pdf?id=sRKNkpUMQNr",
        "paper_authors": [
            "Minsoo Kang",
            "Hyewon Yoo",
            "Eunhee Kang",
            "Sehwan Ki",
            "Hyong-Euk Lee",
            "Bohyung Han"
        ],
        "paper_abstract": "We propose an information-theoretic knowledge distillation approach for the compression of generative adversarial networks, which aims to maximize the mutual information between teacher and student networks via a variational optimization based on an energy-based model. Because the direct computation of the mutual information in continuous domains is intractable, our approach alternatively optimizes the student network by maximizing the variational lower bound of the mutual information. To achieve a tight lower bound, we introduce an energy-based model relying on a deep neural network to represent a flexible variational distribution that deals with high-dimensional images and consider spatial dependencies between pixels, effectively. Since the proposed method is a generic optimization algorithm, it can be conveniently incorporated into arbitrary generative adversarial networks and even dense prediction networks, e.g., image enhancement models. We demonstrate that the proposed algorithm achieves outstanding performance in model compression of generative adversarial networks consistently when combined with several existing models. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Less-forgetting Multi-lingual Fine-tuning",
        "paper_url": "https://openreview.net/pdf?id=7vmyjUHgm9_",
        "paper_authors": [
            "Yuren Mao",
            "Yaobo Liang",
            "Nan Duan",
            "Haobo Wang",
            "Kai Wang",
            "Lu Chen",
            "Yunjun Gao"
        ],
        "paper_abstract": "Multi-lingual fine-tuning (MLF), which fine-tunes a multi-lingual language model (MLLM) with multiple source languages, aims to gain good zero-shot performance on target languages. In MLF, the fine-tuned model tends to fit the source languages while forgetting its cross-lingual knowledge obtained from the pre-training stage. This forgetting phenomenon degenerates the zero-shot performance of MLF, which remains under-explored. To fill this gap, this paper proposes a multi-lingual fine-tuning method, dubbed Less-forgetting Multi-lingual Fine-tuning (LF-MLF). In LF-MLF, we cast multi-lingual fine-tuning as a constrained optimization problem, where the optimization objective is to minimize forgetting, and constraints are reducing the fine-tuning loss. The proposed method has superior zero-shot performance; furthermore, it can achieve the Pareto stationarity. Extensive experiments on Named Entity Recognition, Question Answering and Natural Language Inference back up our theoretical analysis and validate the superiority of our proposals.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Figure-Ground Assignment Mechanism in Perceptual Organization",
        "paper_url": "https://openreview.net/pdf?id=c3HrNgQE7d",
        "paper_authors": [
            "Wei Zhai",
            "Yang Cao",
            "Jing Zhang",
            "Zheng-Jun Zha"
        ],
        "paper_abstract": "Perceptual organization is a challenging visual task that aims to perceive and group the individual visual element so that it is easy to understand the meaning of the scene as a whole. Most recent methods building upon advanced Convolutional Neural Network (CNN) come from learning discriminative representation and modeling context hierarchically. However, when the visual appearance difference between foreground and background is obscure, the performance of existing methods degrades significantly due to the visual ambiguity in the discrimination process. In this paper, we argue that the figure-ground assignment mechanism, which conforms to human vision cognitive theory, can be explored to empower CNN to achieve a robust perceptual organization despite visual ambiguity. Specifically, we present a novel Figure-Ground-Aided (FGA) module to learn the configural statistics of the visual scene and leverage it for the reduction of visual ambiguity. Particularly, we demonstrate the benefit of using stronger supervisory signals by teaching (FGA) module to perceive configural cues, \\ie, convexity and lower region, that human deem important for the perceptual organization. Furthermore, an Interactive Enhancement Module (IEM) is devised to leverage such configural priors to assist representation learning, thereby achieving robust perception organization with complex visual ambiguities. In addition, a well-founded visual segregation test is designed to validate the capability of the proposed FGA mechanism explicitly. Comprehensive evaluation results demonstrate our proposed FGA mechanism can effectively enhance the capability of perception organization on various baseline models. Nevertheless, the model augmented via our proposed FGA mechanism also outperforms state-of-the-art approaches on four challenging real-world applications.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Language Conditioned Spatial Relation Reasoning for 3D Object Grounding",
        "paper_url": "https://openreview.net/pdf?id=8li9SYYY3eQ",
        "paper_authors": [
            "Shizhe Chen",
            "Pierre-Louis Guhur",
            "Makarand Tapaswi",
            "Cordelia Schmid",
            "Ivan Laptev"
        ],
        "paper_abstract": "Localizing objects in 3D scenes based on natural language requires understanding and reasoning about spatial relations. In particular, it is often crucial to distinguish similar objects referred by the text, such as \"the left most chair\" and \"a chair next to the window\". In this work we propose a language-conditioned transformer model for grounding 3D objects and their spatial relations. To this end, we design a spatial self-attention layer that accounts for relative distances and orientations between objects in input 3D point clouds. Training such a layer with visual and language inputs enables to disambiguate spatial relations and to localize objects referred by the text. To facilitate the cross-modal learning of relations, we further propose a teacher-student approach where the teacher model is first trained using ground-truth object labels, and then helps to train a student model using point cloud inputs. We perform ablation studies showing advantages of our approach. We also demonstrate our model to significantly outperform the state of the art on the challenging Nr3D, Sr3D and ScanRefer 3D object grounding datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly supervised causal representation learning",
        "paper_url": "https://openreview.net/pdf?id=dz79MhQXWvg",
        "paper_authors": [
            "Johann Brehmer",
            "Pim De Haan",
            "Phillip Lippe",
            "Taco Cohen"
        ],
        "paper_abstract": "Learning high-level causal representations together with a causal model from unstructured low-level data such as pixels is impossible from observational data alone. We prove under mild assumptions that this representation is however identifiable in a weakly supervised setting. This involves a dataset with paired samples before and after random, unknown interventions, but no further labels. We then introduce implicit latent causal models, variational autoencoders that represent causal variables and causal structure without having to optimize an explicit discrete graph structure. On simple image data, including a novel dataset of simulated robotic manipulation, we demonstrate that such models can reliably identify the causal structure and disentangle causal variables.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions",
        "paper_url": "https://openreview.net/pdf?id=tro0_OqIVde",
        "paper_authors": [
            "Yongming Rao",
            "Wenliang Zhao",
            "Yansong Tang",
            "Jie Zhou",
            "Ser-Nam Lim",
            "Jiwen Lu"
        ],
        "paper_abstract": "Recent progress in vision Transformers exhibits great success in various tasks driven by the new spatial modeling mechanism based on dot-product self-attention. In this paper, we show that the key ingredients behind the vision Transformers, namely input-adaptive, long-range and high-order spatial interactions, can also be efficiently implemented with a convolution-based framework. We present the Recursive Gated Convolution ($\\textit{g}^\\textit{n}$Conv) that performs high-order spatial interactions with gated convolutions and recursive designs. The new operation is highly flexible and customizable, which is compatible with various variants of convolution and extends the two-order interactions in self-attention to arbitrary orders without introducing significant extra computation. $\\textit{g}^\\textit{n}$Conv can serve as a plug-and-play module to improve various vision Transformers and convolution-based models. Based on the operation, we construct a new family of generic vision backbones named HorNet. Extensive experiments on ImageNet classification, COCO object detection and ADE20K semantic segmentation show HorNet outperform Swin Transformers and ConvNeXt by a significant margin with similar overall architecture and training configurations. HorNet also shows favorable scalability to more training data and larger model sizes. Apart from the effectiveness in visual encoders, we also show $\\textit{g}^\\textit{n}$Conv can be applied to task-specific decoders and consistently improve dense prediction performance with less computation. Our results demonstrate that $\\textit{g}^\\textit{n}$Conv can be a new basic module for visual modeling that effectively combines the merits of both vision Transformers and CNNs. Code is available at https://github.com/raoyongming/HorNet.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What You See is What You Classify: Black Box Attributions",
        "paper_url": "https://openreview.net/pdf?id=I-ggHgon-Az",
        "paper_authors": [
            "Steven Stalder",
            "Nathana\u00ebl Perraudin",
            "Radhakrishna Achanta",
            "Fernando Perez-Cruz",
            "Michele Volpi"
        ],
        "paper_abstract": "An important step towards explaining deep image classifiers lies in the identification of image regions that contribute to individual class scores in the model's output. However, doing this accurately is a difficult task due to the black-box nature of such networks. Most existing approaches find such attributions either using activations and gradients or by repeatedly perturbing the input. We instead address this challenge by training a second deep network, the Explainer, to predict attributions for a pre-trained black-box classifier, the Explanandum. These attributions are provided in the form of masks that only show the classifier-relevant parts of an image, masking out the rest. Our approach produces sharper and more boundary-precise masks when compared to the saliency maps generated by other methods. Moreover, unlike most existing approaches, ours is capable of directly generating very distinct class-specific masks in a single forward pass. This makes the proposed method very efficient during inference. We show that our attributions are superior to established methods both visually and quantitatively with respect to the PASCAL VOC-2007 and Microsoft COCO-2014 datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Amortized Mixing Coupling Processes for Clustering",
        "paper_url": "https://openreview.net/pdf?id=p9_Z4m2Vyvr",
        "paper_authors": [
            "Huafeng Liu",
            "Liping Jing"
        ],
        "paper_abstract": "Considering the ever-increasing scale of data, which may contain tens of thousands of data points or complicated latent structures, the issue of scalability and algorithmic efficiency becomes of vital importance for clustering. In this paper, we propose cluster-wise amortized mixing coupling processes (AMCP), which is able to achieve efficient amortized clustering in a well-defined non-parametric Bayesian posterior. Specifically, AMCP learns clusters sequentially with the aid of the proposed intra-cluster mixing (IntraCM) and inter-cluster coupling (InterCC) strategies, which investigate the relationship between data points and reference distribution in a linear optimal transport mixing view, and coupling the unassigned set and assigned set to generate new cluster. IntraCM and InterCC avoid pairwise calculation of distances between clusters and reduce the computational complexity from quadratic to linear in the current number of clusters. Furthermore, cluster-wise sequential process is able to improve the quick adaptation ability for the next cluster generation. In this case, AMCP simultaneously learns what makes a cluster, how to group data points into clusters, and how to adaptively control the number of clusters. To illustrate the superiority of the proposed method, we perform experiments on both synthetic data and real-world data in terms of clustering performance and computational efficiency. The source code is available at https://github.com/HuafengHK/AMCP.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revisiting Sparse Convolutional Model for Visual Recognition",
        "paper_url": "https://openreview.net/pdf?id=INzRLBAA4JX",
        "paper_authors": [
            "Xili Dai",
            "Mingyang Li",
            "Pengyuan Zhai",
            "Shengbang Tong",
            "Xingjian Gao",
            "Shao-Lun Huang",
            "Zhihui Zhu",
            "Chong You",
            "Yi Ma"
        ],
        "paper_abstract": "Despite strong empirical performance for image classification, deep neural networks are often regarded as ``black boxes'' and they are difficult to interpret. On the other hand, sparse convolutional models, which assume that a signal can be expressed by a linear combination of a few elements from a convolutional dictionary, are powerful tools for analyzing natural images with good theoretical interpretability and biological plausibility. However, such principled models have not demonstrated competitive performance when compared with empirically designed deep networks. This paper revisits the sparse convolutional modeling for image classification and bridges the gap between good empirical performance (of deep learning) and good interpretability (of sparse convolutional models). Our method uses differentiable optimization layers that are defined from convolutional sparse coding as drop-in replacements of standard convolutional layers in conventional deep neural networks. We show that such models have equally strong empirical performance on CIFAR-10, CIFAR-100 and ImageNet datasets when compared to conventional neural networks. By leveraging stable recovery property of sparse modeling, we further show that such models can be much more robust to input corruptions as well as adversarial perturbations in testing through a simple proper trade-off between sparse regularization and data reconstruction terms. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cache-Augmented Inbatch Importance Resampling for Training Recommender Retriever",
        "paper_url": "https://openreview.net/pdf?id=vt516zga8m",
        "paper_authors": [
            "Jin Chen",
            "Defu Lian",
            "Yucheng Li",
            "Baoyun Wang",
            "Kai Zheng",
            "Enhong Chen"
        ],
        "paper_abstract": "Recommender retrievers aim to rapidly retrieve a fraction of items from the entire item corpus when a user query requests, with the representative two-tower model trained with the log softmax loss. For efficiently training recommender retrievers on modern hardwares, inbatch sampling, where the items in the mini-batch are shared as negatives to estimate the softmax function, has attained growing interest. However, existing inbatch sampling based strategies just correct the sampling bias of inbatch items with item frequency, being unable to distinguish the user queries within the mini-batch and still incurring significant bias from the softmax. In this paper, we propose a Cache-Augmented Inbatch Importance Resampling (XIR) for training recommender retrievers, which not only offers different negatives to user queries with inbatch items, but also adaptively achieves a more accurate estimation of the softmax distribution. Specifically, XIR resamples items from the given mini-batch training pairs based on certain probabilities, where a cache with more frequently sampled items is adopted to augment the candidate item set, with the purpose of reusing the historical informative samples. XIR enables to sample query-dependent negatives based on inbatch items and to capture dynamic changes of model training, which leads to a better approximation of the softmax and further contributes to better convergence. Finally, we conduct experiments to validate the superior performance of the proposed XIR compared with competitive approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Attentive Belief Propagation: Integrating Reasoning and Learning for Solving Constraint Optimization Problems",
        "paper_url": "https://openreview.net/pdf?id=SZDqCOv6vTB",
        "paper_authors": [
            "Yanchen Deng",
            "Shufeng Kong",
            "Caihua Liu",
            "Bo An"
        ],
        "paper_abstract": "Belief Propagation (BP) is an important message-passing algorithm for various reasoning tasks over graphical models, including solving the Constraint Optimization Problems (COPs). It has been shown that BP can achieve state-of-the-art performance on various benchmarks by mixing old and new messages before sending the new one, i.e., damping. However, existing methods on tuning a static damping factor for BP not only is laborious but also harms their performance. Moreover, existing BP  algorithms treat each variable node's neighbors equally when composing a new message, which also limits their exploration ability. To address these issues, we seamlessly integrate BP, Gated Recurrent Units (GRUs), and Graph Attention Networks (GATs) within the massage-passing framework to reason about dynamic weights and damping factors for composing new BP messages. Our model, Deep Attentive Belief Propagation (DABP), takes the factor graph and the BP messages in each iteration as the input and infers the optimal weights and damping factors through GRUs and GATs, followed by a multi-head attention layer. Furthermore, unlike existing neural-based BP variants, we propose a novel self-supervised learning algorithm for DABP with a smoothed solution cost, which does not require expensive training labels and also avoids the common out-of-distribution issue through efficient online learning. Extensive experiments show that our model significantly outperforms state-of-the-art baselines.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Category-Level 6D Object Pose Estimation in the Wild: A Semi-Supervised Learning Approach and A New Dataset",
        "paper_url": "https://openreview.net/pdf?id=FgDzS8_Fz7c",
        "paper_authors": [
            "Yang Fu",
            "Xiaolong Wang"
        ],
        "paper_abstract": "6D object pose estimation is one of the fundamental problems in computer vision and robotics research. While a lot of recent efforts have been made on generalizing pose estimation to novel object instances within the same category, namely category-level 6D pose estimation, it is still restricted in constrained environments given the limited number of annotated data. In this paper, we collect Wild6D, a new unlabeled RGBD object video dataset with diverse instances and backgrounds. We utilize this data to generalize category-level 6D object pose estimation in the wild with semi-supervised learning. We propose a new model, called Rendering for Pose estimation network RePoNet), that is jointly trained using the free ground-truths with the synthetic data, and a silhouette matching objective function on the real-world data. Without using any 3D annotations on real data, our method outperforms state-of-the-art methods on the previous dataset and our Wild6D test set (with manual annotations for evaluation) by a large margin.  Project page with Wild6D data:  \\url{https://oasisyang.github.io/semi-pose/}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Factored DRO: Factored Distributionally Robust Policies for Contextual Bandits",
        "paper_url": "https://openreview.net/pdf?id=k6WzeLZjxuP",
        "paper_authors": [
            "Tong Mu",
            "Yash Chandak",
            "Tatsunori Hashimoto",
            "Emma Brunskill"
        ],
        "paper_abstract": "While there has been extensive work on learning from offline data for contextual multi-armed bandit settings, existing methods typically assume there is no environment shift: that the learned policy will operate in the same environmental process as that of data collection. However, this assumption may limit the use of these methods for many practical situations where there may be distribution shifts. In this work we propose Factored Distributionally Robust Optimization (Factored-DRO), which is able to separately handle distribution shifts in the context distribution and shifts in the reward generating process. Prior work that either ignores potential shifts in the context, or considers them jointly, can lead to performance that is too conservative, especially under certain forms of reward feedback. Our Factored-DRO objective mitigates this by considering the shifts separately, and our proposed estimators are consistent and converge asymptotically. We also introduce a practical algorithm and demonstrate promising empirical results in environments based on real-world datasets, such as voting outcomes and scene classification.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SecureFedYJ: a safe feature Gaussianization protocol for Federated Learning",
        "paper_url": "https://openreview.net/pdf?id=25XIE30VHZE",
        "paper_authors": [
            "Tanguy Marchand",
            "Boris Muzellec",
            "Constance B\u00e9guier",
            "Jean Du Terrail",
            "Mathieu Andreux"
        ],
        "paper_abstract": "The Yeo-Johnson (YJ) transformation is a standard parametrized per-feature unidimensional transformation often used to Gaussianize features in machine learning. In this paper, we investigate the problem of applying the YJ transformation in a cross-silo Federated Learning setting under privacy constraints. For the first time, we prove that the YJ negative log-likelihood is in fact convex, which allows us to optimize it with exponential search. We numerically show that the resulting algorithm is more stable than the state-of-the-art approach based on the Brent minimization method. Building on this simple algorithm and Secure Multiparty Computation routines, we propose SECUREFEDYJ, a federated algorithm that performs a pooled-equivalent YJ transformation without leaking more information than the final fitted parameters do. Quantitative experiments on real data demonstrate that, in addition to being secure, our approach reliably normalizes features across silos as well as if data were pooled, making it a viable approach for safe federated feature Gaussianization.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fixed-Distance Hamiltonian Monte Carlo",
        "paper_url": "https://openreview.net/pdf?id=Fytzfxj3Bq7",
        "paper_authors": [
            "Hadi Mohasel Afshar",
            "Sally Cripps"
        ],
        "paper_abstract": "We propose a variation of the Hamiltonian Monte Carlo sampling (HMC) where the equations of motion are simulated for a fixed traversed distance rather than the conventional fixed simulation time. This new mechanism tends to generate proposals that have higher target probability values. The momentum distribution that is naturally joint with our Fixed-Distance HMC (FDHMC), and keeps the proposal acceptance probability close to 1, is not Gaussian and generates momentums that have  a higher expected magnitude. This translates into a reduced correlation between the successive MCMC states and according to our experimental results, leads to an  improvement in terms of the effective sample size per gradient when compared to the baseline HMC and No-U-Turn (NUTS) samplers.  \n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Investigation into Whitening Loss for Self-supervised Learning",
        "paper_url": "https://openreview.net/pdf?id=BbUxkmrstyk",
        "paper_authors": [
            "Xi Weng",
            "Lei Huang",
            "Lei Zhao",
            "Rao Muhammad Anwer",
            "Salman Khan",
            "Fahad Khan"
        ],
        "paper_abstract": "A desirable objective in self-supervised learning (SSL) is to avoid feature collapse.  Whitening loss guarantees collapse avoidance by minimizing the distance between embeddings of positive pairs under the conditioning that the embeddings from different views are whitened. In this paper, we propose a framework with an informative indicator to analyze whitening loss, which provides a clue to demystify several interesting phenomena as well as a pivoting point connecting to other SSL methods. We reveal that batch whitening (BW) based methods do not impose whitening constraints on the embedding, but they only require the embedding to be full-rank. This full-rank constraint is also sufficient to avoid dimensional collapse. Based on our analysis, we propose channel whitening with random group partition (CW-RGP), which exploits the advantages of BW-based methods in preventing collapse and avoids their disadvantages requiring large batch size.  Experimental results on ImageNet classification and COCO object detection reveal that the proposed CW-RGP possesses a promising potential for learning good representations. The code is available at https://github.com/winci-ai/CW-RGP.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Beyond the Best:  Distribution Functional Estimation in Infinite-Armed Bandits",
        "paper_url": "https://openreview.net/pdf?id=q16HXpXtjJn",
        "paper_authors": [
            "Yifei Wang",
            "Tavor Baharav",
            "Yanjun Han",
            "Jiantao Jiao",
            "David Tse"
        ],
        "paper_abstract": "In the infinite-armed bandit problem, each arm's average reward is sampled from an unknown distribution, and each arm can be sampled further to obtain noisy estimates of the average reward of that arm. Prior work focuses on the best arm, i.e. estimating the maximum of the average reward distribution. We consider a general class of distribution functionals beyond the maximum and obtain optimal sample complexities in both offline and online settings. We show that online estimation, where the learner can sequentially choose whether to sample a new or existing arm, offers no advantage over the offline setting for estimating the mean functional, but significantly reduces the sample complexity for other functionals such as the median, maximum, and trimmed mean. We propose unified meta algorithms for the online and offline settings and derive matching lower bounds using different Wasserstein distances. For the special case of median estimation, we identify a curious thresholding phenomenon on the indistinguishability between Gaussian convolutions with respect to the noise level, which may be of independent interest.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "\ud83c\udfd8\ufe0f ProcTHOR: Large-Scale Embodied AI Using Procedural Generation",
        "paper_url": "https://openreview.net/pdf?id=4-bV1bi74M",
        "paper_authors": [
            "Matt Deitke",
            "Eli VanderBilt",
            "Alvaro Herrasti",
            "Luca Weihs",
            "Kiana Ehsani",
            "Jordi Salvador",
            "Winson Han",
            "Eric Kolve",
            "Aniruddha Kembhavi",
            "Roozbeh Mottaghi"
        ],
        "paper_abstract": "Massive datasets and high-capacity models have driven many recent advancements in computer vision and natural language understanding. This work presents a platform to enable similar success stories in Embodied AI. We propose ProcTHOR, a framework for procedural generation of Embodied AI environments. ProcTHOR enables us to sample arbitrarily large datasets of diverse, interactive, customizable, and performant virtual environments to train and evaluate embodied agents across navigation, interaction, and manipulation tasks. We demonstrate the power and potential of ProcTHOR via a sample of 10,000 generated houses and a simple neural model. Models trained using only RGB images on ProcTHOR, with no explicit mapping and no human task supervision produce state-of-the-art results across 6 embodied AI benchmarks for navigation, rearrangement, and arm manipulation, including the presently running Habitat 2022, AI2-THOR Rearrangement 2022, and RoboTHOR challenges. We also demonstrate strong 0-shot results on these benchmarks, via pre-training on ProcTHOR with no fine-tuning on the downstream benchmark, often beating previous state-of-the-art systems that access the downstream training data.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "M$^4$I: Multi-modal Models Membership Inference",
        "paper_url": "https://openreview.net/pdf?id=2GsQ8dyfe45",
        "paper_authors": [
            "Pingyi Hu",
            "Zihan Wang",
            "Ruoxi Sun",
            "Hu Wang",
            "Minhui Xue"
        ],
        "paper_abstract": "With the development of machine learning techniques, the attention of research has been moved from single-modal learning to multi-modal learning, as real-world data exist in the form of different modalities. However, multi-modal models often carry more information than single-modal models and they are usually applied in sensitive scenarios, such as medical report generation or disease identification. Compared with the existing membership inference against machine learning classifiers, we focus on the problem that the input and output of the multi-modal models are in different modalities, such as image captioning. This work studies the privacy leakage of multi-modal models through the lens of membership inference attack, a process of determining whether a data record involves in the model training process or not. To achieve this, we propose Multi-modal Models Membership Inference (M$^4$I) with two attack methods to infer the membership status, named metric-based (MB) M$^4$I and feature-based (FB) M$^4$I, respectively. More specifically, MB M$^4$I adopts similarity metrics while attacking to infer target data membership. FB M$^4$I uses a pre-trained shadow multi-modal feature extractor to achieve the purpose of data inference attack by comparing the similarities from extracted input and output features. Extensive experimental results show that both attack methods can achieve strong performances. Respectively, 72.5% and 94.83% of attack success rates on average can be obtained under unrestricted scenarios. Moreover, we evaluate multiple defense mechanisms against our attacks. The source code of M$^4$I attacks is publicly available at https://github.com/MultimodalMI/Multimodal-membership-inference.git.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FOF: Learning Fourier Occupancy Field for Monocular Real-time Human Reconstruction",
        "paper_url": "https://openreview.net/pdf?id=qtQ9thon9fV",
        "paper_authors": [
            "Qiao Feng",
            "Yebin Liu",
            "Yu-Kun Lai",
            "Jingyu Yang",
            "Kun Li"
        ],
        "paper_abstract": "The advent of deep learning has led to significant progress in monocular human reconstruction. However, existing representations, such as parametric models, voxel grids, meshes and implicit neural representations, have difficulties achieving high-quality results and real-time speed at the same time. In this paper, we propose Fourier Occupancy Field (FOF), a novel, powerful, efficient and flexible 3D geometry representation, for monocular real-time and accurate human reconstruction. A FOF represents a 3D object with a 2D field orthogonal to the view direction where at each 2D position the occupancy field of the object along the view direction is compactly represented with the first few terms of Fourier series, which retains the topology and neighborhood relation in the 2D domain. A FOF can be stored as a multi-channel image, which is compatible with 2D convolutional neural networks and can bridge the gap between 3D geometries and 2D images. A FOF is very flexible and extensible, \\eg, parametric models can be easily integrated into a FOF as a prior to generate more robust results. Meshes and our FOF can be easily inter-converted. Based on FOF, we design the first 30+FPS high-fidelity real-time monocular human reconstruction framework. We demonstrate the potential of FOF on both public datasets and real captured data. The code is available for research purposes at http://cic.tju.edu.cn/faculty/likun/projects/FOF.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-rigid Point Cloud Registration with Neural Deformation Pyramid",
        "paper_url": "https://openreview.net/pdf?id=pfEIGgDstz0",
        "paper_authors": [
            "YANG LI",
            "Tatsuya Harada"
        ],
        "paper_abstract": "Non-rigid point cloud registration is a key component in many computer vision and computer graphics applications. The high complexity of the unknown non-rigid motion make this task a challenging problem. In this paper, we break down this problem via hierarchical motion decomposition. Our method called Neural Deformation Pyramid (NDP) represents non-rigid motion using a pyramid architecture. Each pyramid level, denoted by a Multi-Layer Perception (MLP), takes as input a sinusoidally encoded 3D point and outputs its motion increments from the previous level. The sinusoidal function starts with a low input frequency and gradually increases when the pyramid level goes down. This allows a multi-level rigid to nonrigid motion decomposition and also speeds up the solving by \u00d750 times compared to the existing MLP-based approach. Our method achieves advanced partial-to-partial non-rigid point cloud registration results on the 4DMatch/4DLoMatch\nbenchmark under both no-learned and supervised settings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Green Hierarchical Vision Transformer for Masked Image Modeling",
        "paper_url": "https://openreview.net/pdf?id=YgK1wNnoCWy",
        "paper_authors": [
            "Lang Huang",
            "Shan You",
            "Mingkai Zheng",
            "Fei Wang",
            "Chen Qian",
            "Toshihiko Yamasaki"
        ],
        "paper_abstract": "We present an efficient approach for Masked Image Modeling (MIM) with hierarchical Vision Transformers (ViTs), allowing the hierarchical ViTs to discard masked patches and operate only on the visible ones. Our approach consists of three key designs. First, for window attention, we propose a Group Window Attention scheme following the Divide-and-Conquer strategy. To mitigate the quadratic complexity of the self-attention w.r.t. the number of patches, group attention encourages a uniform partition that visible patches within each local window of arbitrary size can be grouped with equal size, where masked self-attention is then performed within each group. Second, we further improve the grouping strategy via the Dynamic Programming algorithm to minimize the overall computation cost of the attention on the grouped patches. Third, as for the convolution layers, we convert them to the Sparse Convolution that works seamlessly with the sparse data, i.e., the visible patches in MIM. As a result, MIM can now work on most, if not all, hierarchical ViTs in a green and efficient way. For example, we can train the hierarchical ViTs, e.g., Swin Transformer and Twins Transformer, about 2.7$\\times$ faster and reduce the GPU memory usage by 70%, while still enjoying competitive performance on ImageNet classification and the superiority on downstream COCO object detection benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hub-Pathway: Transfer Learning from A Hub of Pre-trained Models",
        "paper_url": "https://openreview.net/pdf?id=L8ESR8IQ7Gb",
        "paper_authors": [
            "Yang Shu",
            "Zhangjie Cao",
            "Ziyang Zhang",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "paper_abstract": "Transfer learning aims to leverage knowledge from pre-trained models to benefit the target task. Prior transfer learning work mainly transfers from a single model. However, with the emergence of deep models pre-trained from different resources, model hubs consisting of diverse models with various architectures, pre-trained datasets and learning paradigms are available. Directly applying single-model transfer learning methods to each model wastes the abundant knowledge of the model hub and suffers from high computational cost. In this paper, we propose a Hub-Pathway framework to enable knowledge transfer from a model hub. The framework generates data-dependent pathway weights, based on which we assign the pathway routes at the input level to decide which pre-trained models are activated and passed through, and then set the pathway aggregation at the output level to aggregate the knowledge from different models to make predictions. The proposed framework can be trained end-to-end with the target task-specific loss, where it learns to explore better pathway configurations and exploit the knowledge in pre-trained models for each target datum. We utilize a noisy pathway generator and design an exploration loss to further explore different pathways throughout the model hub. To fully exploit the knowledge in pre-trained models, each model is further trained by specific data that activate it, which ensures its performance and enhances knowledge transfer. Experiment results on computer vision and reinforcement learning tasks demonstrate that the proposed Hub-Pathway framework achieves the state-of-the-art performance for model hub transfer learning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cost-efficient Gaussian tensor network embeddings for tensor-structured inputs",
        "paper_url": "https://openreview.net/pdf?id=rcrY85WLAKU",
        "paper_authors": [
            "Linjian Ma",
            "Edgar Solomonik"
        ],
        "paper_abstract": "This work discusses tensor network embeddings, which are random matrices ($S$) with tensor network structure. These embeddings have been used to perform dimensionality reduction of tensor network structured inputs $x$ and accelerate applications such as tensor decomposition and kernel regression. Existing works have designed embeddings for inputs $x$ with specific structures, such as the Kronecker product or Khatri-Rao product, such that the computational cost for calculating $Sx$ is efficient. We provide a systematic way to design tensor network embeddings consisting of Gaussian random tensors, such that for inputs with more general tensor network structures, both the sketch size (row size of $S$) and the sketching computational cost are low.\nWe analyze general tensor network embeddings that can be reduced to a sequence of sketching matrices. We provide a sufficient condition to quantify the accuracy of such embeddings and derive sketching asymptotic cost lower bounds using embeddings that satisfy this condition and have a sketch size lower than any input dimension. We then provide an algorithm to efficiently sketch input data using such embeddings. The sketch size of the embedding used in the algorithm has a linear dependence on the number of sketching dimensions of the input. Assuming tensor contractions are performed with classical dense matrix multiplication algorithms, this algorithm achieves asymptotic cost within a factor of $O(\\sqrt{m})$ of our cost lower bound, where $m$ is the sketch size. Further, when each tensor in the input has a dimension that needs to be sketched, this algorithm yields the optimal sketching asymptotic cost. We apply our sketching analysis to inexact tensor decomposition optimization algorithms. We provide a sketching algorithm for CP decomposition that is asymptotically faster than existing work in multiple regimes, and show the optimality of an existing algorithm for tensor train rounding.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Biologically-plausible backpropagation through arbitrary timespans via local neuromodulators",
        "paper_url": "https://openreview.net/pdf?id=jPx7vYUNUCt",
        "paper_authors": [
            "Yuhan Helena Liu",
            "Stephen Smith",
            "Stefan Mihalas",
            "Eric Todd SheaBrown",
            "Uygar S\u00fcmb\u00fcl"
        ],
        "paper_abstract": "The spectacular successes of recurrent neural network models where key parameters are adjusted via backpropagation-based gradient descent have inspired much thought as to how biological neuronal networks might solve the corresponding synaptic credit assignment problem [1, 2, 3]. There is so far little agreement, however, as to how biological networks could implement the necessary backpropagation through time, given widely recognized constraints of biological synaptic network signaling architectures. Here, we propose that extra-synaptic diffusion of local neuromodulators such as neuropeptides may afford an effective mode of backpropagation lying within the bounds of biological plausibility. Going beyond existing temporal truncation-based gradient approximations [4, 5, 6], our approximate gradient-based update rule, ModProp, propagates credit information through arbitrary time steps. ModProp suggests that modulatory signals can act on receiving cells by convolving their eligibility traces via causal, time-invariant and synapse-type-specific filter taps. Our mathematical analysis of ModProp learning, together with simulation results on benchmark temporal tasks, demonstrate the advantage of ModProp over existing biologically-plausible temporal credit assignment rules. These results suggest a potential neuronal mechanism for signaling credit information related to recurrent interactions over a longer time horizon. Finally, we derive an in-silico implementation of ModProp that could serve as a low-complexity and causal alternative to backpropagation through time. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Wasserstein $K$-means for clustering probability distributions",
        "paper_url": "https://openreview.net/pdf?id=OlGu-BXgJ-",
        "paper_authors": [
            "Yubo Zhuang",
            "Xiaohui Chen",
            "Yun Yang"
        ],
        "paper_abstract": "Clustering is an important exploratory data analysis technique to group objects based on their similarity. The widely used $K$-means clustering method relies on some notion of distance to partition data into a fewer number of groups. In the Euclidean space, centroid-based and distance-based formulations of the $K$-means are equivalent. In modern machine learning applications, data often arise as probability distributions and a natural generalization to handle measure-valued data is to use the optimal transport metric. Due to non-negative Alexandrov curvature of the Wasserstein space, barycenters suffer from regularity and non-robustness issues. The peculiar behaviors of Wasserstein barycenters may make the centroid-based formulation fail to represent the within-cluster data points, while the more direct distance-based $K$-means approach and its semidefinite program (SDP) relaxation are capable of recovering the true cluster labels. In the special case of clustering Gaussian distributions, we show that the SDP relaxed Wasserstein $K$-means can achieve exact recovery given the clusters are well-separated under the $2$-Wasserstein metric. Our simulation and real data examples also demonstrate that distance-based $K$-means can achieve better classification performance over the standard centroid-based $K$-means for clustering probability distributions and images.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules",
        "paper_url": "https://openreview.net/pdf?id=_4xg5moXVg",
        "paper_authors": [
            "Yuhan Helena Liu",
            "Arna Ghosh",
            "Blake Aaron Richards",
            "Eric Todd SheaBrown",
            "Guillaume Lajoie"
        ],
        "paper_abstract": "To unveil how the brain learns, ongoing work seeks  biologically-plausible approximations of gradient descent algorithms for training recurrent neural networks (RNNs). Yet, beyond task accuracy, it is unclear if such learning rules converge to solutions that exhibit different levels of generalization than their non-biologically-plausible counterparts. Leveraging results from deep learning theory based on loss landscape curvature, we ask: how do biologically-plausible gradient approximations affect generalization? We first demonstrate that state-of-the-art biologically-plausible learning rules for training RNNs exhibit worse and more variable generalization performance compared to their machine learning counterparts that follow the true gradient more closely. Next, we verify that such generalization performance is correlated significantly with loss landscape curvature, and we show that biologically-plausible learning rules tend to approach high-curvature regions in synaptic weight space. Using tools from dynamical systems, we derive theoretical arguments and present a theorem explaining this phenomenon. This predicts our numerical results, and explains why biologically-plausible rules lead to worse and more variable generalization properties. Finally, we suggest potential remedies that could be used by the brain to mitigate this effect. To our knowledge, our analysis is the first to identify the reason for this generalization gap between artificial and biologically-plausible learning rules, which can help guide future investigations into how the brain learns solutions that generalize.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Model-Based Offline Reinforcement Learning with Pessimism-Modulated Dynamics Belief",
        "paper_url": "https://openreview.net/pdf?id=oDWyVsHBzNT",
        "paper_authors": [
            "Kaiyang Guo",
            "yunfeng shao",
            "Yanhui Geng"
        ],
        "paper_abstract": "Model-based offline reinforcement learning (RL) aims to find highly rewarding policy, by leveraging a previously collected static dataset and a dynamics model. While the dynamics model learned through reuse of the static dataset, its generalization ability hopefully promotes policy learning if properly utilized. To that end, several works propose to quantify the uncertainty of predicted dynamics, and explicitly apply it to penalize reward. However, as the dynamics and the reward are  intrinsically different factors in context of MDP, characterizing the impact of dynamics uncertainty through reward penalty may incur unexpected tradeoff between model utilization and risk avoidance. In this work, we instead maintain a belief distribution over dynamics, and evaluate/optimize policy through biased sampling from the belief. The sampling procedure, biased towards pessimism, is derived based on an alternating Markov game formulation of offline RL. We formally show that the biased sampling naturally induces an updated dynamics belief with policy-dependent reweighting factor, termed Pessimism-Modulated Dynamics Belief. To improve policy, we devise an iterative regularized policy optimization algorithm for the game, with guarantee of monotonous improvement under certain condition. To make practical, we further devise an offline RL algorithm to approximately find the solution. Empirical results show that the proposed approach achieves state-of-the-art performance on a wide range of benchmark tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical classification at multiple operating points",
        "paper_url": "https://openreview.net/pdf?id=mNtFhoNRr4i",
        "paper_authors": [
            "Jack Valmadre"
        ],
        "paper_abstract": "Many classification problems consider classes that form a hierarchy. Classifiers that are aware of this hierarchy may be able to make confident predictions at a coarse level despite being uncertain at the fine-grained level. While it is generally possible to vary the granularity of predictions using a threshold at inference time, most contemporary work considers only leaf-node prediction, and almost no prior work has compared methods at multiple operating points. We present an efficient algorithm to produce operating characteristic curves for any method that assigns a score to every class in the hierarchy. Applying this technique to evaluate existing methods reveals that top-down classifiers are dominated by a naive flat softmax classifier across the entire operating range. We further propose two novel loss functions and show that a soft variant of the structured hinge loss is able to significantly outperform the flat baseline. Finally, we investigate the poor accuracy of top-down classifiers and demonstrate that they perform relatively well on unseen classes.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CLEAR: Generative Counterfactual Explanations on Graphs",
        "paper_url": "https://openreview.net/pdf?id=YR-s5leIvh",
        "paper_authors": [
            "Jing Ma",
            "Ruocheng Guo",
            "Saumitra Mishra",
            "Aidong Zhang",
            "Jundong Li"
        ],
        "paper_abstract": "Counterfactual explanations promote explainability in machine learning models by answering the question \u201chow should the input instance be altered to obtain a desired predicted label?\". The comparison of this instance before and after perturbation can enhance human interpretation. Most existing studies on counterfactual explanations are limited in tabular data or image data. In this paper, we study the problem of counterfactual explanation generation on graphs. A few studies have explored to generate counterfactual explanations on graphs, but many challenges of this problem are still not well-addressed: 1) optimizing in the discrete and disorganized space of graphs; 2) generalizing on unseen graphs; 3) maintaining the causality\u00a0in the generated counterfactuals without prior knowledge of the causal model. To tackle these challenges, we propose a novel framework CLEAR which aims to generate counterfactual explanations on graphs for graph-level prediction models. Specifically, CLEAR leverages a graph variational autoencoder based mechanism to facilitate its optimization and generalization, and promotes causality by leveraging an auxiliary variable to better identify the causal model. Extensive experiments on both synthetic and real-world graphs validate the superiority of CLEAR over state-of-the-art counterfactual explanation methods on graphs in different aspects. \u2028",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Symmetry Teleportation for Accelerated Optimization",
        "paper_url": "https://openreview.net/pdf?id=MHjxpvMzf2x",
        "paper_authors": [
            "Bo Zhao",
            "Nima Dehmamy",
            "Robin Walters",
            "Rose Yu"
        ],
        "paper_abstract": "Existing gradient-based optimization methods update parameters locally, in a direction that minimizes the loss function. We study a different approach, symmetry teleportation, that allows parameters to travel a large distance on the loss level set, in order to improve the convergence speed in subsequent steps. Teleportation exploits symmetries in the loss landscape of optimization problems. We derive loss-invariant group actions for test functions in optimization and multi-layer neural networks, and prove a necessary condition for teleportation to improve convergence rate. We also show that our algorithm is closely related to second order methods. Experimentally, we show that teleportation improves the convergence speed of gradient descent and AdaGrad for several optimization problems including test functions, multi-layer regressions, and MNIST classification.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fused Orthogonal Alternating Least Squares for Tensor Clustering",
        "paper_url": "https://openreview.net/pdf?id=y8FN4dHdxOE",
        "paper_authors": [
            "Jiacheng Wang",
            "Dan L Nicolae"
        ],
        "paper_abstract": "We introduce a multi-modes tensor clustering method that implements a fused version of the alternating least squares algorithm (Fused-Orth-ALS) for simultaneous tensor factorization and clustering.  The statistical convergence rates of recovery and clustering are established when the data are a noise contaminated tensor with a latent low rank CP decomposition structure. Furthermore, we show that a modified alternating least squares algorithm can provably recover the true latent low rank factorization structure when the data form an asymmetric tensor with perturbation. Clustering consistency is also established. Finally, we illustrate the accuracy and computational efficient implementation of the Fused-Orth-ALS algorithm by using both simulations and real datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improving Variational Autoencoders with Density Gap-based Regularization",
        "paper_url": "https://openreview.net/pdf?id=GjWDguPZRmr",
        "paper_authors": [
            "Jianfei Zhang",
            "Jun Bai",
            "Chenghua Lin",
            "Yanmeng Wang",
            "Wenge Rong"
        ],
        "paper_abstract": "Variational autoencoders (VAEs) are one of the most powerful unsupervised learning frameworks in NLP for latent representation learning and latent-directed generation. The classic optimization goal of VAEs is to maximize the Evidence Lower Bound (ELBo), which consists of a conditional likelihood for generation and a negative Kullback-Leibler (KL) divergence for regularization. In practice, optimizing ELBo often leads the posterior distribution of all samples converging to the same degenerated local optimum, namely posterior collapse or KL vanishing. There are effective ways proposed to prevent posterior collapse in VAEs, but we observe that they in essence make trade-offs between posterior collapse and the hole problem, i.e., the mismatch between the aggregated posterior distribution and the prior distribution. To this end, we introduce new training objectives to tackle both problems through a novel regularization based on the probabilistic density gap between the aggregated posterior distribution and the prior distribution. Through experiments on language modeling, latent space visualization, and interpolation, we show that our proposed method can solve both problems effectively and thus outperforms the existing methods in latent-directed generation. To the best of our knowledge, we are the first to jointly solve the hole problem and posterior collapse.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Inherently Explainable Reinforcement Learning in Natural Language",
        "paper_url": "https://openreview.net/pdf?id=DSEP9rCvZln",
        "paper_authors": [
            "XIANGYU PENG",
            "Mark Riedl",
            "Prithviraj Ammanabrolu"
        ],
        "paper_abstract": "We focus on the task of creating a reinforcement learning agent that is inherently explainable---with the ability to produce immediate local explanations by thinking out loud while performing a task and analyzing entire trajectories post-hoc to produce temporally extended explanations. This Hierarchically Explainable Reinforcement Learning agent (HEX-RL), operates in Interactive Fictions, text-based game environments in which an agent perceives and acts upon the world using textual natural language. These games are usually structured as puzzles or quests with long-term dependencies in which an agent must complete a sequence of actions to succeed---providing ideal environments in which to test an agent's ability to explain its actions. Our agent is designed to treat explainability as a first-class citizen, using an extracted symbolic knowledge graph-based state representation coupled with a Hierarchical Graph Attention mechanism that points to the facts in the internal graph representation that most influenced the choice of actions. Experiments show that this agent provides significantly improved explanations over strong baselines, as rated by human participants generally unfamiliar with the environment, while also matching state-of-the-art task performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BagFlip: A Certified Defense Against Data Poisoning",
        "paper_url": "https://openreview.net/pdf?id=ZidkM5b92G",
        "paper_authors": [
            "Yuhao Zhang",
            "Aws Albarghouthi",
            "Loris D'Antoni"
        ],
        "paper_abstract": "Machine learning models are vulnerable to data-poisoning attacks, in which an attacker maliciously modifies the training set to change the prediction of a learned model. In a trigger-less attack, the attacker can modify the training set but not the test inputs, while in a backdoor attack the attacker can also modify test inputs. Existing model-agnostic defense approaches either cannot handle backdoor attacks or do not provide effective certificates (i.e., a proof of a defense). We present BagFlip, a model-agnostic certified approach that can effectively defend against both trigger-less and backdoor attacks. We evaluate BagFlip on image classification and malware detection datasets. BagFlip is equal to or more effective than the state-of-the-art approaches for trigger-less attacks and more effective than the state-of-the-art approaches for backdoor attacks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction",
        "paper_url": "https://openreview.net/pdf?id=JvIFpZOjLF4",
        "paper_authors": [
            "Qiancheng Fu",
            "Qingshan Xu",
            "Yew-Soon Ong",
            "Wenbing Tao"
        ],
        "paper_abstract": "Recently, neural implicit surfaces learning by volume rendering has become popular for multi-view reconstruction. However, one key challenge remains: existing approaches lack explicit multi-view geometry constraints, hence usually fail to generate geometry-consistent surface reconstruction. To address this challenge, we propose geometry-consistent neural implicit surfaces learning for multi-view reconstruction. We theoretically analyze that there exists a gap between the volume rendering integral and point-based signed distance function (SDF) modeling. To bridge this gap, we directly locate the zero-level set of SDF networks and explicitly perform multi-view geometry optimization by leveraging the sparse geometry from structure from motion (SFM) and photometric consistency in multi-view stereo. This makes our SDF optimization unbiased and allows the multi-view geometry constraints to focus on the true surface optimization. Extensive experiments show that our proposed method achieves high-quality surface reconstruction in both complex thin structures and large smooth regions, thus outperforming the state-of-the-arts by a large margin.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection",
        "paper_url": "https://openreview.net/pdf?id=P6uZ7agiyCT",
        "paper_authors": [
            "Tianyu Wang",
            "Xiaowei Hu",
            "Zhengzhe Liu",
            "Chi-Wing Fu"
        ],
        "paper_abstract": "LiDAR-produced point clouds are the major source for most state-of-the-art 3D object detectors. Yet, small, distant, and incomplete objects with sparse or few points are often hard to detect. We present Sparse2Dense, a new framework to efficiently boost 3D detection performance by learning to densify point clouds in latent space. Specifically, we first train a dense point 3D detector (DDet) with a dense point cloud as input and design a sparse point 3D detector (SDet) with a regular point cloud as input. Importantly, we formulate the lightweight plug-in S2D module and the point cloud reconstruction module in SDet to densify 3D features and train SDet to produce 3D features, following the dense 3D features in DDet. So, in inference, SDet can simulate dense 3D features from regular (sparse) point cloud inputs without requiring dense inputs. We evaluate our method on the large-scale Waymo Open Dataset and the Waymo Domain Adaptation Dataset, showing its high performance and efficiency over the state of the arts.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Multi-Modal Structural Equations For Causal Effect Estimation With Unstructured Proxies",
        "paper_url": "https://openreview.net/pdf?id=ByYFpTwgLGO",
        "paper_authors": [
            "Shachi Deshpande",
            "Kaiwen Wang",
            "Dhruv Sreenivas",
            "Zheng Li",
            "Volodymyr Kuleshov"
        ],
        "paper_abstract": "Estimating the effect of intervention from observational data while accounting for confounding variables is a key task in causal inference. Oftentimes, the confounders are unobserved, but we have access to large amounts of additional unstructured data (images, text) that contain valuable proxy signal about the missing confounders. This paper argues that leveraging this unstructured data can greatly improve the accuracy of causal effect estimation. Specifically, we introduce deep multi-modal structural equations, a generative model for causal effect estimation in which confounders are latent variables and unstructured data are proxy variables. This model supports multiple multimodal proxies (images, text) as well as missing data. We empirically demonstrate that our approach outperforms existing methods based on propensity scores and corrects for confounding using unstructured inputs on tasks in genomics and healthcare. Our methods can potentially support the use of large amounts of data that were previously not used in causal inference",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NOTE: Robust Continual Test-time Adaptation Against Temporal Correlation",
        "paper_url": "https://openreview.net/pdf?id=E9HNxrCFZPV",
        "paper_authors": [
            "Taesik Gong",
            "Jongheon Jeong",
            "Taewon Kim",
            "Yewon Kim",
            "Jinwoo Shin",
            "Sung-Ju Lee"
        ],
        "paper_abstract": "Test-time adaptation (TTA) is an emerging paradigm that addresses distributional shifts between training and testing phases without additional data acquisition or labeling cost; only unlabeled test data streams are used for continual model adaptation. Previous TTA schemes assume that the test samples are independent and identically distributed (i.i.d.), even though they are often temporally correlated (non-i.i.d.) in application scenarios, e.g., autonomous driving. We discover that most existing TTA methods fail dramatically under such scenarios. Motivated by this, we present a new test-time adaptation scheme that is robust against non-i.i.d. test data streams. Our novelty is mainly two-fold: (a) Instance-Aware Batch Normalization (IABN) that corrects normalization for out-of-distribution samples, and (b) Prediction-balanced Reservoir Sampling (PBRS) that simulates i.i.d. data stream from non-i.i.d. stream in a class-balanced manner. Our evaluation with various datasets, including real-world non-i.i.d. streams, demonstrates that the proposed robust TTA not only outperforms state-of-the-art TTA algorithms in the non-i.i.d. setting, but also achieves comparable performance to those algorithms under the i.i.d. assumption. Code is available at https://github.com/TaesikGong/NOTE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Deep Learning Dataloader with Shared Data Preparation",
        "paper_url": "https://openreview.net/pdf?id=tZUOiVGO6jN",
        "paper_authors": [
            "Jian Xie",
            "Jingwei Xu",
            "Guochang Wang",
            "Yuan Yao",
            "Zenan Li",
            "Chun Cao",
            "Hanghang Tong"
        ],
        "paper_abstract": "Executing a family of Deep Neural Networks (DNNs) training jobs on the same or similar datasets in parallel is typical in current deep learning scenarios. It is time-consuming and resource-intensive because each job repetitively prepares (i.e., loads and preprocesses) the data independently, causing redundant consumption of I/O and computations. Although the page cache or a centralized cache component can alleviate the redundancies by reusing the data prep work, each job's data sampled uniformly at random presents a low sampling locality in the shared dataset that causes the heavy cache thrashing. Prior work tries to solve the problem by enforcing all training jobs iterating over the dataset in the same order and requesting each data in lockstep, leading to strong constraints: all jobs must have the same dataset and run simultaneously. In this paper, we propose a dependent sampling algorithm (DSA) and domain-specific cache policy to relax the constraints. Besides, a novel tree data structure is designed to efficiently implement DSA. Based on the proposed technologies, we implemented a prototype system, named Joader, which can share data prep work as long as the datasets share partially. We evaluate the proposed Joader in practical scenarios, showing a greater versatility and superiority over training speed improvement (up to 500% in ResNet18).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Squeezeformer: An Efficient Transformer for Automatic Speech Recognition",
        "paper_url": "https://openreview.net/pdf?id=gE_vt-w4LhL",
        "paper_authors": [
            "Sehoon Kim",
            "Amir Gholami",
            "Albert Eaton Shaw",
            "Nicholas Lee",
            "Karttikeya Mangalam",
            "Jitendra Malik",
            "Michael W. Mahoney",
            "Kurt Keutzer"
        ],
        "paper_abstract": "The recently proposed Conformer model has become the de facto backbone model for various downstream speech tasks based on its hybrid attention-convolution architecture that captures both local and global features. However, through a series of systematic studies, we find that the Conformer architecture\u2019s design choices are not optimal. After re-examining the design choices for both the macro and micro-architecture of Conformer, we propose Squeezeformer which consistently outperforms the state-of-the-art ASR models under the same training schemes. In particular, for the macro-architecture, Squeezeformer incorporates (i) the Temporal U-Net structure which reduces the cost of the multi-head attention modules on long sequences, and (ii) a simpler block structure of multi-head attention or convolution modules followed up by feed-forward module instead of the Macaron structure proposed in Conformer. Furthermore, for the micro-architecture, Squeezeformer (i) simplifies the activations in the convolutional block, (ii) removes redundant Layer Normalization operations, and (iii) incorporates an efficient depthwise down-sampling layer to efficiently sub-sample the input signal. Squeezeformer achieves state-of-the-art results of 7.5%, 6.5%, and 6.0% word-error-rate (WER) on LibriSpeech test-other without external language models, which are 3.1%, 1.4%, and 0.6% better than Conformer-CTC with the same number of FLOPs. Our code is open-sourced and available online.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Basis Models for Interpretability",
        "paper_url": "https://openreview.net/pdf?id=fpfDusqKZF",
        "paper_authors": [
            "Filip Radenovic",
            "Abhimanyu Dubey",
            "Dhruv Mahajan"
        ],
        "paper_abstract": "Due to the widespread use of complex machine learning models in real-world applications, it is becoming critical to explain model predictions. However, these models are typically black-box deep neural networks, explained post-hoc via methods with known faithfulness limitations. Generalized Additive Models (GAMs) are an inherently interpretable class of models that address this limitation by learning a non-linear shape function for each feature separately, followed by a linear model on top. However, these models are typically difficult to train, require numerous parameters, and are difficult to scale. \n    We propose an entirely new subfamily of GAMs that utilizes basis decomposition of shape functions. A small number of basis functions are shared among all features, and are learned jointly for a given task, thus making our model scale much better to large-scale data with high-dimensional features, especially when features are sparse. We propose an architecture denoted as the Neural Basis Model (NBM) which uses a single neural network to learn these bases. On a variety of tabular and image datasets, we demonstrate that for interpretable machine learning, NBMs are the state-of-the-art in accuracy, model size, and, throughput and can easily model all higher-order feature interactions.\n    Source code is available at \\href{https://github.com/facebookresearch/nbm-spam}{\\ttfamily github.com/facebookresearch/nbm-spam}. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scalable Interpretability via Polynomials",
        "paper_url": "https://openreview.net/pdf?id=TwuColwZAVj",
        "paper_authors": [
            "Abhimanyu Dubey",
            "Filip Radenovic",
            "Dhruv Mahajan"
        ],
        "paper_abstract": "Generalized Additive Models (GAMs) have quickly become the leading choice for interpretable machine learning. However, unlike uninterpretable methods such as DNNs, they lack expressive power and easy scalability, and are hence not a feasible alternative for real-world tasks. We present a new class of GAMs that use tensor rank decompositions of polynomials to learn powerful, {\\em inherently-interpretable} models. Our approach, titled Scalable Polynomial Additive Models (SPAM) is effortlessly scalable and models {\\em all} higher-order feature interactions without a combinatorial parameter explosion. SPAM outperforms all current interpretable approaches, and matches DNN/XGBoost performance on a series of real-world benchmarks with up to hundreds of thousands of features. We demonstrate by human subject evaluations that SPAMs are demonstrably more interpretable in practice, and are hence an effortless replacement for DNNs for creating interpretable and high-performance systems suitable for large-scale machine learning.\nSource code is available at \\href{https://github.com/facebookresearch/nbm-spam}{\\ttfamily github.com/facebookresearch/nbm-spam}. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NS3: Neuro-symbolic Semantic Code Search",
        "paper_url": "https://openreview.net/pdf?id=kHeotl7q9dU",
        "paper_authors": [
            "Shushan Arakelyan",
            "Anna Hakhverdyan",
            "Miltiadis Allamanis",
            "Luis Antonio Garcia",
            "Christophe Hauser",
            "Xiang Ren"
        ],
        "paper_abstract": "Semantic code search is the task of retrieving a code snippet given a textual description of its functionality. Recent work has been focused on using similarity metrics between neural embeddings of text and code. However, current language models are known to struggle with longer, compositional sentences, and multi-step reasoning. To overcome this limitation, we propose supplementing the query sentence with a layout of its semantic structure. The semantic layout is used to break down the final reasoning decision into a series of lower-level decisions. We use a Neural Module Network architecture to implement this idea. We compare our model - $NS^3$  (Neuro-Symbolic Semantic Search) - to a number of baselines, including state-of-the-art semantic code retrieval methods, such as CodeBERT, CuBERT and GraphCodeBERT, and evaluate on two datasets - Code Search Net (CSN) and Code Search and Question Answering (CoSQA). On these datasets, we demonstrate that our approach results in higher performance. We also perform additional studies to show the effectiveness of our modular design when handling compositional queries.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the consistent estimation of optimal Receiver Operating Characteristic (ROC) curve",
        "paper_url": "https://openreview.net/pdf?id=Ijq1_a6DESm",
        "paper_authors": [
            "Renxiong Liu",
            "Yunzhang Zhu"
        ],
        "paper_abstract": "Under a standard binary classification setting with possible model misspecification, we study the problem of estimating general Receiver Operating Characteristic (ROC) curve, which is an arbitrary set of false positive rate (FPR) and true positive rate (TPR) pairs. We formally introduce the notion of \\textit{optimal ROC curve} over a general model space. It is argued that any ROC curve estimation methods implemented over the given model space should target the optimal ROC curve over that space. Three popular ROC curve estimation methods are then analyzed at the population level (i.e., when there are infinite number of samples) under both correct and incorrect model specification. Based on our analysis, they are all consistent when the surrogate loss function satisfies certain conditions and the given model space includes all measurable classifiers. Interestingly, some of these conditions are similar to those that are required to ensure classification consistency. When the model space is incorrectly specified, however, we show that only one method leads to consistent estimation of the ROC curve over the chosen model space. We present some numerical results to demonstrate the effects of model misspecification on the performance of various methods in terms of their ROC curve estimates.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parallel Tempering With a Variational Reference",
        "paper_url": "https://openreview.net/pdf?id=-o0kPsyzErW",
        "paper_authors": [
            "Nikola Surjanovic",
            "Saifuddin Syed",
            "Alexandre Bouchard-Cote",
            "Trevor Campbell"
        ],
        "paper_abstract": "Sampling from complex target distributions is a challenging task fundamental to Bayesian inference. Parallel tempering (PT) addresses this problem by constructing a Markov chain on the expanded state space of a sequence of distributions interpolating between the posterior distribution and a fixed reference distribution, which is typically chosen to be the prior. However, in the typical case where the prior and posterior are nearly mutually singular, PT methods are computationally prohibitive. In this work we address this challenge by constructing a generalized annealing path connecting the posterior to an adaptively tuned variational reference. The reference distribution is tuned to minimize the forward (inclusive) KL divergence to the posterior distribution using a simple, gradient-free moment-matching procedure. We show that our adaptive procedure converges to the forward KL minimizer, and that the forward KL divergence serves as a good proxy to a previously developed measure of PT performance. We also show that in the large-data limit in typical Bayesian models, the proposed  method improves in performance, while traditional PT deteriorates arbitrarily. Finally, we introduce PT with two references---one fixed, one  variational---with a novel split annealing path that ensures stable variational reference adaptation. The paper concludes with experiments that demonstrate the large empirical gains achieved by our method in a wide range of realistic Bayesian inference scenarios.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Periodic Graph Transformers for Crystal Material Property Prediction",
        "paper_url": "https://openreview.net/pdf?id=pqCT3L-BU9T",
        "paper_authors": [
            "Keqiang Yan",
            "Yi Liu",
            "Yuchao Lin",
            "Shuiwang Ji"
        ],
        "paper_abstract": "We consider representation learning on periodic graphs encoding crystal materials. Different from regular graphs, periodic graphs consist of a minimum unit cell repeating itself on a regular lattice in 3D space. How to effectively encode these periodic structures poses unique challenges not present in regular graph representation learning. In addition to being E(3) invariant, periodic graph representations need to be periodic invariant. That is, the learned representations should be invariant to shifts of cell boundaries as they are artificially imposed. Furthermore, the periodic repeating patterns need to be captured explicitly as lattices of different sizes and orientations may correspond to different materials. In this work, we propose a transformer architecture, known as Matformer, for periodic graph representation learning. Our Matformer is designed to be invariant to periodicity and can capture repeating patterns explicitly. In particular, Matformer encodes periodic patterns by efficient use of geometric distances between the same atoms in neighboring cells. Experimental results on multiple common benchmark datasets show that our Matformer outperforms baseline methods consistently. In addition, our results demonstrate the importance of periodic invariance and explicit repeating pattern encoding for crystal representation learning. Our code is publicly available at https://github.com/YKQ98/Matformer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GAUDI: A Neural Architect for Immersive 3D Scene Generation",
        "paper_url": "https://openreview.net/pdf?id=xijYyYFlRIf",
        "paper_authors": [
            "Miguel \u00c1ngel Bautista",
            "Pengsheng Guo",
            "Samira Abnar",
            "Walter Talbott",
            "Alexander T Toshev",
            "Zhuoyuan Chen",
            "Laurent Dinh",
            "Shuangfei Zhai",
            "Hanlin Goh",
            "Daniel Ulbricht",
            "Afshin Dehghan",
            "Joshua M. Susskind"
        ],
        "paper_abstract": "We introduce GAUDI, a generative model capable of capturing the distribution of complex and realistic 3D scenes that can be rendered immersively from a moving camera. We tackle this challenging problem with a scalable yet powerful approach, where we first optimize a latent representation that disentangles radiance fields and camera poses. This latent representation is then used to learn a generative model that enables both unconditional and conditional generation of 3D scenes. Our model generalizes previous works that focus on single objects by removing the assumption that the camera pose distribution can be shared across samples. We show that GAUDI obtains state-of-the-art performance in the unconditional generative setting across multiple datasets and allows for conditional generation of 3D scenes given conditioning variables like sparse image observations or text that describes the scene.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "3DB: A Framework for Debugging Computer Vision Models",
        "paper_url": "https://openreview.net/pdf?id=dRgHxaOJsiV",
        "paper_authors": [
            "Guillaume Leclerc",
            "Hadi Salman",
            "Andrew Ilyas",
            "Sai Vemprala",
            "Logan Engstrom",
            "Vibhav Vineet",
            "Kai Yuanqing Xiao",
            "Pengchuan Zhang",
            "Shibani Santurkar",
            "Greg Yang",
            "Ashish Kapoor",
            "Aleksander Madry"
        ],
        "paper_abstract": "We introduce 3DB: an extendable, unified framework for testing and debugging vision models using photorealistic simulation.  We demonstrate, through a wide range of use cases, that 3DB allows users to discover vulnerabilities in computer vision systems and gain insights into how models make decisions. 3DB captures and generalizes many robustness analyses from prior work, and enables one to study their interplay. Finally, we find that the insights generated by the system transfer to the physical world. 3DB will be released as a library alongside a set of examples and documentation. We attach 3DB to the submission.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploration via Elliptical Episodic Bonuses",
        "paper_url": "https://openreview.net/pdf?id=Xg-yZos9qJQ",
        "paper_authors": [
            "Mikael Henaff",
            "Roberta Raileanu",
            "Minqi Jiang",
            "Tim Rockt\u00e4schel"
        ],
        "paper_abstract": "In recent years, a number of reinforcement learning (RL) methods have been pro- posed to explore complex environments which differ across episodes. In this work, we show that the effectiveness of these methods critically relies on a count-based episodic term in their exploration bonus. As a result, despite their success in relatively simple, noise-free settings, these methods fall short in more realistic scenarios where the state space is vast and prone to noise. To address this limitation, we introduce Exploration via Elliptical Episodic Bonuses (E3B), a new method which extends count-based episodic bonuses to continuous state spaces and encourages an agent to explore states that are diverse under a learned embed- ding within each episode. The embedding is learned using an inverse dynamics model in order to capture controllable aspects of the environment. Our method sets a new state-of-the-art across 16 challenging tasks from the MiniHack suite, without requiring task-specific inductive biases. E3B also outperforms existing methods in reward-free exploration on Habitat, demonstrating that it can scale to high-dimensional pixel-based observations and realistic environments.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Probabilistic Missing Value Imputation for Mixed Categorical and Ordered Data",
        "paper_url": "https://openreview.net/pdf?id=h4kN_apci_R",
        "paper_authors": [
            "Yuxuan Zhao",
            "Alex Townsend",
            "Madeleine Udell"
        ],
        "paper_abstract": "Many real-world datasets contain missing entries and mixed data types including categorical and ordered (e.g. continuous and ordinal) variables. Imputing the missing entries is necessary, since many data analysis pipelines require complete data, but challenging especially for mixed data. This paper proposes a probabilistic imputation method using an extended Gaussian copula model that supports both single and multiple imputation. The method models mixed categorical and ordered data using a latent Gaussian distribution. The unordered characteristics of categorical variables is explicitly modeled using the argmax operator. The method makes no assumptions on the data marginals nor does it require tuning any hyperparameters. Experimental results on synthetic and real datasets show that imputation with the extended Gaussian copula outperforms the current state-of-the-art for both categorical and ordered variables in mixed data.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Near-Optimal Multi-Agent Learning for Safe Coverage Control",
        "paper_url": "https://openreview.net/pdf?id=_L7f0ySKMWY",
        "paper_authors": [
            "Manish Prajapat",
            "Matteo Turchetta",
            "Melanie Zeilinger",
            "Andreas Krause"
        ],
        "paper_abstract": "In multi-agent coverage control problems, agents navigate their environment to reach locations that maximize the coverage of some density. In practice, the density is rarely known $\\textit{a priori}$, further complicating the original NP-hard problem. Moreover, in many applications, agents cannot visit arbitrary locations due to $\\textit{a priori}$ unknown safety constraints. In this paper, we aim to efficiently learn the density to approximately solve the coverage problem while preserving the agents' safety. We first propose a conditionally linear submodular coverage function that facilitates theoretical analysis. Utilizing this structure, we develop MacOpt, a novel algorithm that efficiently trades off the exploration-exploitation dilemma due to partial observability, and show that it achieves sublinear regret. Next, we extend results on single-agent safe exploration to our multi-agent setting and propose SafeMac for safe coverage and exploration. We analyze SafeMac and give first of its kind results: near optimal coverage in finite time while provably guaranteeing safety. We extensively evaluate our algorithms on synthetic and real problems, including a bio-diversity monitoring task under safety constraints, where SafeMac outperforms competing methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning State-Aware Visual Representations from Audible Interactions",
        "paper_url": "https://openreview.net/pdf?id=AhbTKBlM7X",
        "paper_authors": [
            "Himangi Mittal",
            "Pedro Morgado",
            "Unnat Jain",
            "Abhinav Gupta"
        ],
        "paper_abstract": "We propose a self-supervised algorithm to learn representations from egocentric video data. Recently, significant efforts have been made to capture humans interacting with their own environments as they go about their daily activities. In result, several large egocentric datasets of interaction-rich multi-modal data have emerged. However, learning representations from videos can be challenging. First, given the uncurated nature of long-form continuous videos, learning effective representations require focusing on moments in time when interactions take place. Second, visual representations of daily activities should be sensitive to changes in the state of the environment. However, current successful multi-modal learning frameworks encourage representation invariance over time. To address these challenges, we leverage audio signals to identify moments of likely interactions which are conducive to better learning. We also propose a novel self-supervised objective that learns from audible state changes caused by interactions. We validate these contributions extensively on two large-scale egocentric datasets, EPIC-Kitchens-100 and the recently released Ego4D, and show improvements on several downstream tasks, including action recognition, long-term action anticipation, and object state change classification.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Geometric Order Learning for Rank Estimation",
        "paper_url": "https://openreview.net/pdf?id=agNTJU1QNw",
        "paper_authors": [
            "Seon-Ho Lee",
            "Nyeong Ho Shin",
            "Chang-Su Kim"
        ],
        "paper_abstract": "A novel approach to rank estimation, called geometric order learning (GOL), is proposed in this paper. First, we construct an embedding space, in which the direction and distance between objects represent order and metric relations between their ranks, by enforcing two geometric constraints: the order constraint compels objects to be sorted according to their ranks, while the metric constraint makes the distance between objects reflect their rank difference. Then, we perform the simple $k$ nearest neighbor ($k$-NN) search in the embedding space to estimate the rank of a test object. Moreover, to assess the quality of embedding spaces for rank estimation, we propose a metric called discriminative ratio for ranking (DRR). Extensive experiments on facial age estimation, historical color image (HCI) classification, and aesthetic score regression demonstrate that GOL constructs effective embedding spaces and thus yields excellent rank estimation performances. The source codes are available at https://github.com/seon92/GOL",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhanced Bilevel Optimization via Bregman Distance",
        "paper_url": "https://openreview.net/pdf?id=pBpwRkEIjR3",
        "paper_authors": [
            "Feihu Huang",
            "Junyi Li",
            "Shangqian Gao",
            "Heng Huang"
        ],
        "paper_abstract": "Bilevel optimization has been recently used in many machine learning problems such as hyperparameter optimization, policy optimization, and meta learning. Although many bilevel optimization methods have been proposed, they still suffer from the high computational complexities and do not consider the more general bilevel problems with nonsmooth regularization. In the paper, thus, we propose a class of enhanced bilevel optimization methods with using Bregman distance to solve bilevel optimization problems, where the outer subproblem is nonconvex and possibly nonsmooth, and the inner subproblem is strongly convex. Specifically, we propose a bilevel optimization method based on Bregman distance (BiO-BreD) to solve deterministic bilevel problems, which achieves a lower computational complexity than the best known results. Meanwhile, we also propose a stochastic bilevel optimization method (SBiO-BreD) to solve stochastic bilevel problems based on stochastic approximated gradients and Bregman distance. Moreover, we further propose an accelerated version of SBiO-BreD method (ASBiO-BreD) using the variance-reduced technique, which can achieve a lower computational complexity than the best known computational complexities with respect to condition number $\\kappa$ and target accuracy $\\epsilon$ for finding an $\\epsilon$-stationary point. We conduct data hyper-cleaning task and hyper-representation learning task to demonstrate that our new algorithms outperform related bilevel optimization approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimal Comparator Adaptive Online Learning with Switching Cost",
        "paper_url": "https://openreview.net/pdf?id=Vg_02McCRnY",
        "paper_authors": [
            "Zhiyu Zhang",
            "Ashok Cutkosky",
            "Ioannis Paschalidis"
        ],
        "paper_abstract": "Practical online learning tasks are often naturally defined on unconstrained domains, where optimal algorithms for general convex losses are characterized by the notion of comparator adaptivity. In this paper, we design such algorithms in the presence of switching cost - the latter penalizes the typical optimism in adaptive algorithms, leading to a delicate design trade-off. Based on a novel dual space scaling strategy discovered by a continuous-time analysis, we propose a simple algorithm that improves the existing comparator adaptive regret bound [ZCP22a] to the optimal rate. The obtained benefits are further extended to the expert setting, and the practicality of the proposed algorithm is demonstrated through a sequential investment task.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-objective Deep Data Generation with Correlated Property Control",
        "paper_url": "https://openreview.net/pdf?id=3uj_8G7fxgs",
        "paper_authors": [
            "Shiyu Wang",
            "Xiaojie Guo",
            "Xuanyang Lin",
            "Bo Pan",
            "Yuanqi Du",
            "Yinkai Wang",
            "Yanfang Ye",
            "Ashley Ann Petersen",
            "Austin Leitgeb",
            "Saleh AlKhalifa",
            "Kevin Minbiole",
            "William Wuest",
            "Amarda Shehu",
            "Liang Zhao"
        ],
        "paper_abstract": "Developing deep generative models has been an emerging field due to the ability to model and generate complex data for various purposes, such as image synthesis and molecular design. However, the advance of deep generative models is limited by the challenges to generate objects that possess multiple desired properties because: 1) the existence of complex correlation among real-world properties is common but hard to identify; 2) controlling individual property enforces an implicit partially control of its correlated properties, which is difficult to model; 3) controlling multiple properties under variour manners simultaneously is hard and underexplored. We address these challenges by proposing a novel deep generative framework that recovers semantics and correlation of properties through disentangled latent vectors. The correlation is handled via an explainable mask pooling layer, and properties are precisely retained by the generated objects via the mutual dependence between latent vectors and properties. Our generative model preserves properties of interest while handles correlation and conflicts of properties under a multi-objective optimization framework. The experiments demonstrate our model's superior performance in generating objects with desired properties.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Generative Model for Periodic Graphs",
        "paper_url": "https://openreview.net/pdf?id=lgNGDjWRTo-",
        "paper_authors": [
            "Shiyu Wang",
            "Xiaojie Guo",
            "Liang Zhao"
        ],
        "paper_abstract": "Periodic graphs are graphs consisting of repetitive local structures, such as crystal nets and polygon mesh. Their generative modeling has great potential in real-world applications such as material design and graphics synthesis. Classical models either rely on domain-specific predefined generation principles (e.g., in crystal net design), or follow geometry-based prescribed rules. Recently, deep generative models have shown great promise in automatically generating general graphs. However, their advancement into periodic graphs has not been well explored due to several key challenges in 1) maintaining graph periodicity; 2) disentangling local and global patterns; and 3) efficiency in learning repetitive patterns. To address them, this paper proposes Periodical-Graph Disentangled Variational Auto-encoder (PGD-VAE), a new deep generative model for periodic graphs that can automatically learn, disentangle, and generate local and global graph patterns. Specifically, we develop a new periodic graph encoder consisting of global-pattern encoder and local-pattern encoder that ensures to disentangle the representation into global and local semantics. We then propose a new periodic graph decoder consisting of local structure decoder, neighborhood decoder, and global structure decoder, as well as the assembler of their outputs that guarantees periodicity. Moreover, we design a new model learning objective that helps ensure the invariance of local-semantic representations for the graphs with the same local structure. Comprehensive experimental evaluations have been conducted to demonstrate the effectiveness of the proposed method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Generalized Schr\u00f6dinger Bridge",
        "paper_url": "https://openreview.net/pdf?id=fp33Nsh0O5",
        "paper_authors": [
            "Guan-Horng Liu",
            "Tianrong Chen",
            "Oswin So",
            "Evangelos Theodorou"
        ],
        "paper_abstract": "Mean-Field Game (MFG) serves as a crucial mathematical framework in modeling the collective behavior of individual agents interacting stochastically with a large population. In this work, we aim at solving a challenging class of MFGs in which the differentiability of these interacting preferences may not be available to the solver, and the population is urged to converge exactly to some desired distribution. These setups are, despite being well-motivated for practical purposes, complicated enough to paralyze most (deep) numerical solvers. Nevertheless, we show that Schr\u00f6dinger Bridge \u2014 as an entropy-regularized optimal transport model \u2014 can be generalized to accepting mean-field structures, hence solving these MFGs. This is achieved via the application of Forward-Backward Stochastic Differential Equations theory, which, intriguingly, leads to a computational framework with a similar structure to Temporal Difference learning. As such, it opens up novel algorithmic connections to Deep Reinforcement Learning that we leverage to facilitate practical training. We show that our proposed objective function provides necessary and sufficient conditions to the mean-field problem. Our method, named Deep Generalized Schr\u00f6dinger Bridge (DeepGSB), not only outperforms prior methods in solving classical population navigation MFGs, but is also capable of solving 1000-dimensional opinion depolarization, setting a new state-of-the-art numerical solver for high-dimensional MFGs. Our code will be made available at https://github.com/ghliu/DeepGSB.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Biologically-Plausible Determinant Maximization Neural Networks for Blind Separation of Correlated Sources",
        "paper_url": "https://openreview.net/pdf?id=espX_4CLr46",
        "paper_authors": [
            "Bariscan Bozkurt",
            "Cengiz Pehlevan",
            "Alper Tunga Erdogan"
        ],
        "paper_abstract": "Extraction of latent sources of complex stimuli is critical for making sense of the world. While the brain solves this blind source separation (BSS) problem continuously, its algorithms remain unknown. Previous work on biologically-plausible BSS algorithms assumed that observed signals are linear mixtures of statistically independent or uncorrelated sources, limiting the domain of applicability of these algorithms. To overcome this limitation, we propose novel biologically-plausible neural networks for the blind separation of potentially dependent/correlated sources. Differing from previous work, we assume some general geometric, not statistical, conditions on the source vectors allowing separation of potentially dependent/correlated sources. Concretely, we assume that the source vectors are sufficiently scattered in their domains which can be described by certain polytopes. Then, we consider recovery of these sources by the Det-Max criterion, which maximizes the determinant of the output correlation matrix to enforce a similar spread for the source estimates. Starting from this normative principle, and using a weighted similarity matching approach that enables arbitrary linear transformations adaptable by local learning rules, we derive two-layer biologically-plausible neural network algorithms that can separate mixtures into sources coming from a variety of source domains. We demonstrate that our algorithms outperform other biologically-plausible BSS algorithms on correlated source separation problems.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Practical Adversarial Multivalid Conformal Prediction",
        "paper_url": "https://openreview.net/pdf?id=QNjyrDBx6tz",
        "paper_authors": [
            "Osbert Bastani",
            "Varun Gupta",
            "Christopher Jung",
            "Georgy Noarov",
            "Ramya Ramalingam",
            "Aaron Roth"
        ],
        "paper_abstract": "We give a simple, generic conformal prediction method for sequential prediction that achieves target empirical coverage guarantees on adversarial data. It is computationally lightweight --- comparable to split conformal prediction --- but does not require having a held-out validation set, and so all data can be used for training models from which to derive a conformal score. Furthermore, it gives stronger than marginal coverage guarantees in two ways. First, it gives threshold-calibrated prediction sets that have correct empirical coverage even conditional on the threshold used to form the prediction set from the conformal score. Second, the user can specify an arbitrary collection of subsets of the feature space --- possibly intersecting --- and the coverage guarantees will also hold conditional on membership in each of these subsets. We call our algorithm MVP, short for MultiValid Prediction. We give both theory and an extensive set of empirical evaluations. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Constrained Langevin Algorithms with L-mixing External Random Variables",
        "paper_url": "https://openreview.net/pdf?id=KxVSnZVuZZ",
        "paper_authors": [
            "Yuping Zheng",
            "Andrew Lamperski"
        ],
        "paper_abstract": "Langevin algorithms are gradient descent methods augmented with additive noise, and are widely used in Markov Chain Monte Carlo (MCMC) sampling, optimization, and machine learning. In recent years, the non-asymptotic analysis of Langevin algorithms for non-convex learning has been extensively explored. For constrained problems with non-convex losses over a compact convex domain with IID data variables, the projected Langevin algorithm achieves a deviation of $O(T^{-1/4} (\\log T)^{1/2})$ from its target distribution \\cite{lamperski2021projected} in $1$-Wasserstein distance. In this paper, we obtain a deviation of $O(T^{-1/2} \\log T)$ in $1$-Wasserstein distance for non-convex losses with $L$-mixing data variables and polyhedral constraints (which are not necessarily bounded). This improves on the previous bound for constrained problems and matches the best-known bound for unconstrained problems.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Equivariant Networks for Zero-Shot Coordination",
        "paper_url": "https://openreview.net/pdf?id=Jupoos_K4xt",
        "paper_authors": [
            "Darius Muglich",
            "Christian Schroeder de Witt",
            "Elise van der Pol",
            "Shimon Whiteson",
            "Jakob Nicolaus Foerster"
        ],
        "paper_abstract": "Successful coordination in Dec-POMDPs requires agents to adopt robust strategies and interpretable styles of play for their partner. A common failure mode is symmetry breaking, when agents arbitrarily converge on one out of many equivalent but mutually incompatible policies. Commonly these examples include partial observability, e.g. waving your right hand vs. left hand to convey a covert message. In this paper, we present a novel equivariant network architecture for use in Dec-POMDPs that prevents the agent from learning policies which break symmetries, doing so more effectively than prior methods. Our method also acts as a \"coordination-improvement operator\" for generic, pre-trained policies, and thus may be applied at test-time in conjunction with any self-play algorithm. We provide theoretical guarantees of our work and test on the AI benchmark task of Hanabi, where we demonstrate our methods outperforming other symmetry-aware baselines in zero-shot coordination, as well as able to improve the coordination ability of a variety of pre-trained policies. In particular, we show our method can be used to improve on the state of the art for zero-shot coordination on the Hanabi benchmark.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simple Mechanisms for Welfare Maximization in Rich Advertising Auctions",
        "paper_url": "https://openreview.net/pdf?id=ylila4AYSpV",
        "paper_authors": [
            "Gagan Aggarwal",
            "Kshipra Bhawalkar",
            "Aranyak Mehta",
            "Divyarthi Mohan",
            "Alexandros Psomas"
        ],
        "paper_abstract": "Internet ad auctions have evolved from a few lines of text to richer informational layouts that include images, sitelinks, videos, etc. Ads in these new formats occupy varying amounts of space, and an advertiser can provide multiple formats, only one of which can be shown.\nThe seller is now faced with a multi-parameter mechanism design problem.\nComputing an efficient allocation is computationally intractable, and therefore the standard Vickrey-Clarke-Groves (VCG) auction, while truthful and welfare-optimal, is impractical. \n\nIn this paper, we tackle a fundamental problem in the design of modern ad auctions. We adopt a ``Myersonian'' approach and study allocation rules that are monotone both in the bid and set of rich ads. We show that such rules can be paired with a payment function to give a truthful auction. Our main technical challenge is designing a monotone rule that yields a good approximation to the optimal welfare. Monotonicity doesn't hold for standard algorithms, e.g. the incremental bang-per-buck order, that give good approximations to ``knapsack-like'' problems such as ours. In fact, we show that no deterministic monotone rule can approximate the optimal welfare within a factor better than $2$ (while there is a non-monotone FPTAS). Our main result is a new, simple, greedy and monotone allocation rule that guarantees a $3$ approximation. In ad auctions in practice, monotone allocation rules are often paired with the so-called \\emph{Generalized Second Price (GSP)} payment rule, which charges the minimum threshold price below which the allocation changes. We prove that, even though our monotone allocation rule paired with GSP is not truthful, its Price of Anarchy (PoA) is bounded. Under standard no-overbidding assumptions, we prove bounds on the a pure and Bayes-Nash PoA. Finally, we experimentally test our algorithms on real-world data.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One-shot Neural Backdoor Erasing via Adversarial Weight Masking",
        "paper_url": "https://openreview.net/pdf?id=Yb3dRKY170h",
        "paper_authors": [
            "Shuwen Chai",
            "Jinghui Chen"
        ],
        "paper_abstract": "Recent studies show that despite achieving high accuracy on a number of real-world applications, deep neural networks (DNNs) can be backdoored: by injecting triggered data samples into the training dataset, the adversary can mislead the trained model into classifying any test data to the target class as long as the trigger pattern is presented. To nullify such backdoor threats, various methods have been proposed. Particularly, a line of research aims to purify the potentially compromised model. However, one major limitation of this line of work is the requirement to access sufficient original training data: the purifying performance is a lot worse when the available training data is limited. In this work, we propose Adversarial Weight Masking (AWM), a novel method capable of erasing the neural backdoors even in the one-shot setting. The key idea behind our method is to formulate this into a min-max optimization problem: first, adversarially recover the non-robust perturbation patterns and then (soft) mask the network weights that are sensitive to the recovered patterns. Comprehensive evaluations of several benchmark datasets suggest that AWM can largely improve the purifying effects over other state-of-the-art methods on various available training dataset sizes. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ASPiRe: Adaptive Skill Priors for  Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=sr0289wAUa",
        "paper_authors": [
            "Mengda Xu",
            "Manuela Veloso",
            "Shuran Song"
        ],
        "paper_abstract": "We introduce ASPiRe (Adaptive Skill Prior for RL), a new approach that leverages prior experience to accelerate reinforcement learning. Unlike existing methods that learn a single skill prior from a large and diverse dataset, our framework learns a library of different distinction skill priors (i.e., behavior priors) from a collection of specialized datasets, and learns how to combine them to solve a new task. This formulation allows the algorithm to acquire a set of specialized skill priors that are more reusable for downstream tasks; however, it also brings up additional challenges of how to effectively combine these unstructured sets of skill priors to form a new prior for new tasks. Specifically, it requires the agent not only to identify which skill prior(s) to use but also how to combine them (either sequentially or concurrently) to form a new prior. To achieve this goal, ASPiRe includes Adaptive Weight Module (AWM) that learns to infer an adaptive weight assignment between different skill priors and uses them to guide policy learning for downstream tasks via weighted Kullback-Leibler divergences. Our experiments demonstrate that ASPiRe can significantly accelerate the learning of new downstream tasks in the presence of multiple priors and show improvement on competitive baselines.    ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone ",
        "paper_url": "https://openreview.net/pdf?id=o4neHaKMlse",
        "paper_authors": [
            "Zi-Yi Dou",
            "Aishwarya Kamath",
            "Zhe Gan",
            "Pengchuan Zhang",
            "Jianfeng Wang",
            "Linjie Li",
            "Zicheng Liu",
            "Ce Liu",
            "Yann LeCun",
            "Nanyun Peng",
            "Jianfeng Gao",
            "Lijuan Wang"
        ],
        "paper_abstract": "Vision-language (VL) pre-training has recently received considerable attention. However, most existing end-to-end pre-training approaches either only aim to tackle VL tasks such as image-text retrieval, visual question answering (VQA) and image captioning that test high-level understanding of images, or only target region-level understanding for tasks such as phrase grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based transformER), a new VL model architecture that can seamlessly handle both these types of tasks. Instead of having dedicated transformer layers for fusion after the uni-modal backbones, FIBER pushes multimodal fusion deep into the model by inserting cross-attention into the image and text backbones to better capture multimodal interactions. In addition, unlike previous work that is either only pre-trained on image-text data or on fine-grained data with box-level annotations, we present a two-stage pre-training strategy that uses both these kinds of data efficiently: (i) coarse-grained pre-training based on image-text data; followed by (ii) fine-grained pre-training based on image-text-box data. We conduct comprehensive experiments on a wide range of VL tasks, ranging from VQA, image captioning, and retrieval, to phrase grounding, referring expression comprehension, and object detection. Using deep multimodal fusion coupled with the two-stage pre-training, FIBER provides consistent performance improvements over strong baselines across all tasks, often outperforming methods using magnitudes more data. Code is released at https://github.com/microsoft/FIBER.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Gaussian Tensor Programs",
        "paper_url": "https://openreview.net/pdf?id=AcHUIG2wA8-",
        "paper_authors": [
            "Eugene Golikov",
            "Greg Yang"
        ],
        "paper_abstract": "Does it matter whether one randomly initializes a neural network (NN) from Gaussian, uniform, or other distributions? We show the answer is \u201dyes\u201d in some parameter tensors (the so-called matrix-like parameters) but \u201dno\u201d in others when the NN is wide. This is a specific instance of a more general universality principle for Tensor Programs (TP) that informs precisely when the limit of a program depends on the distribution of its initial matrices and vectors. To obtain this principle, we develop the theory of non-Gaussian Tensor Programs. As corollaries, we obtain all previous consequences of the TP framework (such as NNGP/NTK correspondence, Free Independence Principle, Dynamical Dichotomy Theorem, and \u03bc-parametrization) for NNs with non-Gaussian weights.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Ask4Help: Learning to Leverage an Expert for Embodied Tasks",
        "paper_url": "https://openreview.net/pdf?id=_bqtjfpj8h",
        "paper_authors": [
            "Kunal Pratap Singh",
            "Luca Weihs",
            "Alvaro Herrasti",
            "Jonghyun Choi",
            "Aniruddha Kembhavi",
            "Roozbeh Mottaghi"
        ],
        "paper_abstract": "Embodied AI agents continue to become more capable every year with the advent of new models, environments, and benchmarks, but are still far away from being performant and reliable enough to be deployed in real, user-facing, applications. In this paper, we ask: can we bridge this gap by enabling agents to ask for assistance from an expert such as a human being? To this end, we propose the Ask4Help policy that augments agents with the ability to request, and then use expert assistance. Ask4Help policies can be efficiently trained without modifying the original agent's parameters and learn a desirable trade-off between task performance and the amount of requested help, thereby reducing the cost of querying the expert. We evaluate Ask4Help on two different tasks -- object goal navigation and room rearrangement and see substantial improvements in performance using minimal help. On object navigation, an agent that achieves a $52\\%$ success rate is raised to $86\\%$ with $13\\%$ help and for rearrangement, the state-of-the-art model with a $7\\%$ success rate is dramatically improved to $90.4\\%$ using $39\\%$ help. Human trials with Ask4Help demonstrate the efficacy of our approach in practical scenarios.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization",
        "paper_url": "https://openreview.net/pdf?id=WV1ZXTH0OIn",
        "paper_authors": [
            "Sam Daulton",
            "Xingchen Wan",
            "David Eriksson",
            "Maximilian Balandat",
            "Michael A Osborne",
            "Eytan Bakshy"
        ],
        "paper_abstract": "Optimizing expensive-to-evaluate black-box functions of discrete (and potentially continuous) design parameters is a ubiquitous problem in scientific and engineering applications. Bayesian optimization (BO) is a popular, sample-efficient method that leverages a probabilistic surrogate model and  an acquisition function (AF) to select promising designs to evaluate. However, maximizing the AF over mixed or high-cardinality discrete search spaces is challenging standard gradient-based methods cannot be used directly or evaluating the AF at every point in the search space would be computationally prohibitive. To address this issue, we propose using probabilistic reparameterization (PR). Instead of directly optimizing the AF over the search space containing discrete parameters, we instead maximize the expectation of the AF over a probability distribution defined by continuous parameters. We prove that under suitable reparameterizations, the BO policy that maximizes the probabilistic objective is the same as that which maximizes the AF, and therefore, PR enjoys the same regret bounds as the original BO policy using the underlying AF. Moreover, our approach provably converges to a stationary point of the probabilistic objective under gradient ascent using scalable, unbiased estimators of both the probabilistic objective and its gradient. Therefore, as the number of starting points and gradient steps increase, our approach will recover of a maximizer of the AF (an often-neglected requisite for commonly used BO regret bounds). We validate our approach empirically and demonstrate state-of-the-art optimization performance on a wide range of real-world applications. PR is complementary to (and benefits) recent work and naturally generalizes to settings with multiple objectives and black-box constraints.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "When to Update Your Model: Constrained Model-based Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=9a1oV7UunyP",
        "paper_authors": [
            "Tianying Ji",
            "Yu Luo",
            "Fuchun Sun",
            "Mingxuan Jing",
            "Fengxiang He",
            "Wenbing Huang"
        ],
        "paper_abstract": "Designing and analyzing model-based RL (MBRL) algorithms with guaranteed monotonic improvement has been challenging, mainly due to the interdependence between policy optimization and model learning. Existing discrepancy bounds generally ignore the impacts of model shifts, and their corresponding algorithms are prone to degrade performance by drastic model updating. In this work, we first propose a novel and general theoretical scheme for a non-decreasing performance guarantee of MBRL. Our follow-up derived bounds reveal the relationship between model shifts and performance improvement. These discoveries encourage us to formulate a constrained lower-bound optimization problem to permit the monotonicity of MBRL. A further example demonstrates that learning models from a dynamically-varying number of explorations benefit the eventual returns. Motivated by these analyses, we design a simple but effective algorithm CMLO (Constrained Model-shift Lower-bound Optimization), by introducing an event-triggered mechanism that flexibly determines when to update the model.  Experiments show that CMLO surpasses other state-of-the-art methods and produces a boost when various policy optimization methods are employed.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distributed Methods with Compressed Communication for Solving Variational Inequalities, with Theoretical Guarantees",
        "paper_url": "https://openreview.net/pdf?id=J0nhRuMkdGf",
        "paper_authors": [
            "Aleksandr Beznosikov",
            "Peter Richt\u00e1rik",
            "Michael Diskin",
            "Max Ryabinin",
            "Alexander Gasnikov"
        ],
        "paper_abstract": "Variational inequalities in general and saddle point problems in particular are increasingly relevant in machine learning applications, including adversarial learning, GANs, transport and robust optimization. With increasing data and problem sizes necessary to train high performing models across various applications, we need to rely on parallel and distributed computing. However, in distributed training, communication among the compute nodes is a key bottleneck during training, and this problem is exacerbated for high dimensional and over-parameterized models. Due to these considerations, it is important to equip existing methods with strategies that would allow to reduce the volume of transmitted information during training while obtaining a model of comparable quality. In this paper, we present the first theoretically grounded distributed methods for solving variational inequalities and saddle point problems using compressed communication: MASHA1 and MASHA2. Our theory and methods allow for the use of both unbiased (such as Rand$k$; MASHA1) and contractive (such as Top$k$; MASHA2) compressors. New algorithms support bidirectional compressions, and also can be modified for stochastic setting with batches and for federated learning with partial participation of clients. We empirically validated our conclusions using two experimental setups: a standard bilinear min-max problem, and large-scale distributed adversarial training of transformers.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Noise Attention Learning: Enhancing Noise Robustness by Gradient Scaling",
        "paper_url": "https://openreview.net/pdf?id=yfNSUQ3yRo",
        "paper_authors": [
            "Yangdi Lu",
            "Yang Bo",
            "Wenbo He"
        ],
        "paper_abstract": "Machine learning has been highly successful in data-driven applications but is often hampered when the data contains noise, especially label noise. When trained on noisy labels, deep neural networks tend to fit all noisy labels, resulting in poor generalization. To handle this problem, a common idea is to force the model to fit only clean samples rather than mislabeled ones. In this paper, we propose a simple yet effective method that automatically distinguishes the mislabeled samples and prevents the model from memorizing them, named Noise Attention Learning. In our method, we introduce an attention branch to produce attention weights based on representations of samples. This attention branch is learned to divide the samples according to the predictive power in their representations. We design the corresponding loss function that incorporates the attention weights for training the model without affecting the original learning direction. Empirical results show that most of the mislabeled samples yield significantly lower weights than the clean ones. Furthermore, our theoretical analysis shows that the gradients of training samples are dynamically scaled by the attention weights, implicitly preventing memorization of the mislabeled samples. Experimental results on two benchmarks (CIFAR-10 and CIFAR-100) with simulated label noise and three real-world noisy datasets (ANIMAL-10N, Clothing1M and Webvision) demonstrate that our approach outperforms state-of-the-art methods.\n\t ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exponential Family Model-Based Reinforcement Learning via Score Matching",
        "paper_url": "https://openreview.net/pdf?id=G1uywu6vNZe",
        "paper_authors": [
            "Gene Li",
            "Junbo Li",
            "Anmol Kabra",
            "Nathan Srebro",
            "Zhaoran Wang",
            "Zhuoran Yang"
        ],
        "paper_abstract": "We propose an optimistic model-based algorithm, dubbed SMRL, for finite-horizon episodic reinforcement learning (RL) when the transition model is specified by exponential family distributions with $d$ parameters and the reward is bounded and known. SMRL uses score matching, an unnormalized density estimation technique that enables efficient estimation of the model parameter by ridge regression. Under standard regularity assumptions, SMRL achieves $\\tilde O(d\\sqrt{H^3T})$ online regret, where $H$ is the length of each episode and $T$ is the total number of interactions (ignoring polynomial dependence on structural scale parameters). ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the inability of Gaussian process regression to optimally learn compositional functions",
        "paper_url": "https://openreview.net/pdf?id=fhO6vCGuuag",
        "paper_authors": [
            "Matteo Giordano",
            "Kolyan Ray",
            "Johannes Schmidt-Hieber"
        ],
        "paper_abstract": "We rigorously prove that deep Gaussian process priors can outperform Gaussian process priors if the target function has a compositional structure. To this end, we study information-theoretic lower bounds for posterior contraction rates for Gaussian process regression in a continuous regression model. We show that if the true function is a generalized additive function, then the posterior based on any mean-zero Gaussian process can only recover the truth at a rate that is strictly slower than the minimax rate by a factor that is polynomially suboptimal in the sample size $n$.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding the Eluder Dimension",
        "paper_url": "https://openreview.net/pdf?id=jHIn0U9U6RO",
        "paper_authors": [
            "Gene Li",
            "Pritish Kamath",
            "Dylan J Foster",
            "Nathan Srebro"
        ],
        "paper_abstract": "We provide new insights on eluder dimension, a complexity measure that has been extensively used to bound the regret of algorithms for online bandits and reinforcement learning with function approximation. First, we study the relationship between the eluder dimension for a function class and a generalized notion of \\emph{rank}, defined for any monotone ``activation'' $\\sigma : \\mathbb{R}\\to \\mathbb{R}$, which corresponds to the minimal dimension required to represent the class as a generalized linear model. It is known that when $\\sigma$ has derivatives bounded away from $0$, $\\sigma$-rank gives rise to an upper bound on eluder dimension for any function class; we show however that eluder dimension can be exponentially smaller than $\\sigma$-rank. We also show that the condition on the derivative is necessary; namely, when $\\sigma$ is the $\\mathsf{relu}$ activation, the eluder dimension can be exponentially larger than $\\sigma$-rank. For Boolean-valued function classes, we obtain a characterization of the eluder dimension in terms of star number and threshold dimension, quantities which are relevant in active learning and online learning respectively.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pessimism for Offline Linear Contextual Bandits using $\\ell_p$ Confidence Sets",
        "paper_url": "https://openreview.net/pdf?id=jcIIVkbCaHO",
        "paper_authors": [
            "Gene Li",
            "Cong Ma",
            "Nathan Srebro"
        ],
        "paper_abstract": "We present a family $\\{\\widehat{\\pi}_p\\}_{p\\ge 1}$ of pessimistic learning rules for offline learning of linear contextual bandits, relying on confidence sets with respect to different $\\ell_p$ norms, where $\\widehat{\\pi}_2$ corresponds to Bellman-consistent pessimism (BCP), while $\\widehat{\\pi}_\\infty$ is a novel generalization of lower confidence bound (LCB) to the linear setting.  We show that the novel $\\widehat{\\pi}_\\infty$ learning rule is, in a sense, adaptively optimal, as it achieves the minimax performance (up to log factors) against all $\\ell_q$-constrained problems, and as such it strictly dominates all other predictors in the family, including $\\widehat{\\pi}_2$.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding and Extending Subgraph GNNs by Rethinking Their Symmetries",
        "paper_url": "https://openreview.net/pdf?id=sc7bBHAmcN",
        "paper_authors": [
            "Fabrizio Frasca",
            "Beatrice Bevilacqua",
            "Michael M. Bronstein",
            "Haggai Maron"
        ],
        "paper_abstract": "Subgraph GNNs are a recent class of expressive Graph Neural Networks (GNNs) which model graphs as collections of subgraphs. So far, the design space of possible Subgraph GNN architectures as well as their basic theoretical properties are still largely unexplored. In this paper, we study the most prominent form of subgraph methods, which employs node-based subgraph selection policies such as ego-networks or node marking and deletion. We address two central questions: (1) What is the upper-bound of the expressive power of these methods? and (2) What is the family of equivariant message passing layers on these sets of subgraphs?. Our first step in answering these questions is a novel symmetry analysis which shows that modelling the symmetries of node-based subgraph collections requires a significantly smaller symmetry group than the one adopted in previous works. This analysis is then used to establish a link between Subgraph GNNs and Invariant Graph Networks (IGNs). We answer the questions above by first bounding the expressive power of subgraph methods by 3-WL, and then proposing a general family of message-passing layers for subgraph methods that generalises all previous node-based Subgraph GNNs. Finally, we design a novel Subgraph GNN dubbed SUN, which theoretically unifies previous architectures while providing better empirical performance on multiple benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-supervised Semantic Segmentation with Prototype-based Consistency Regularization",
        "paper_url": "https://openreview.net/pdf?id=e3qH65r_eZS",
        "paper_authors": [
            "Haiming Xu",
            "Lingqiao Liu",
            "Qiuchen Bian",
            "Zhen Yang"
        ],
        "paper_abstract": "Semi-supervised semantic segmentation requires the model to effectively propagate the label information from limited annotated images to unlabeled ones. A challenge for such a per-pixel prediction task is the large intra-class variation, i.e., regions belonging to the same class may exhibit a very different appearance even in the same picture. This diversity will make the label propagation hard from pixels to pixels. To address this problem, we propose a novel approach to regularize the distribution of within-class features to ease label propagation difficulty. Specifically, our approach encourages the consistency between the prediction from a linear predictor and the output from a prototype-based predictor, which implicitly encourages features from the same pseudo-class to be close to at least one within-class prototype while staying far from the other between-class prototypes. By further incorporating CutMix operations and a carefully-designed prototype maintenance strategy, we create a semi-supervised semantic segmentation algorithm that demonstrates superior performance over the state-of-the-art methods from extensive experimental evaluation on both Pascal VOC and Cityscapes benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CoupAlign: Coupling Word-Pixel with Sentence-Mask Alignments for Referring Image Segmentation",
        "paper_url": "https://openreview.net/pdf?id=5L-wxm0YLcZ",
        "paper_authors": [
            "Zicheng Zhang",
            "Yi Zhu",
            "Jianzhuang Liu",
            "Xiaodan Liang",
            "Wei Ke"
        ],
        "paper_abstract": "Referring image segmentation aims at localizing all pixels of the visual objects described by a natural language sentence. Previous works learn to straightforwardly align the sentence embedding and pixel-level embedding for highlighting the referred objects, but ignore the semantic consistency of pixels within the same object, leading to incomplete masks and localization errors in predictions. To tackle this problem, we propose CoupAlign, a simple yet effective multi-level visual-semantic alignment method, to couple sentence-mask alignment with word-pixel alignment to enforce object mask constraint for achieving more accurate localization and segmentation. Specifically, the Word-Pixel Alignment (WPA) module performs early fusion of linguistic and pixel-level features in intermediate layers of the vision and language encoders. Based on the word-pixel aligned embedding, a set of mask proposals are generated to hypothesize possible objects. Then in the Sentence-Mask Alignment (SMA) module, the masks are weighted by the sentence embedding to localize the referred object, and finally projected back to aggregate the pixels for the target. To further enhance the learning of the two alignment modules, an auxiliary loss is designed to contrast the foreground and background pixels. By hierarchically aligning pixels and masks with linguistic features, our CoupAlign captures the pixel coherence at both visual and semantic levels, thus generating more accurate predictions. Extensive experiments on popular datasets (e.g., RefCOCO and G-Ref) show that our method achieves consistent improvements over state-of-the-art methods, e.g., about 2% oIoU increase on the validation and testing set of RefCOCO. Especially, CoupAlign has remarkable ability in distinguishing the target from multiple objects of the same class. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/CoupAlign.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "coVariance Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=noyKGZYvHH",
        "paper_authors": [
            "Saurabh Sihag",
            "Gonzalo Mateos",
            "Corey McMillan",
            "Alejandro Ribeiro"
        ],
        "paper_abstract": "Graph neural networks (GNN) are an effective framework that exploit inter-relationships within graph-structured data for learning. Principal component analysis (PCA) involves the projection of data on the eigenspace of the covariance matrix and draws similarities with the graph convolutional filters in GNNs. Motivated by this observation, we study a GNN architecture, called coVariance neural network (VNN), that operates on sample covariance matrices as graphs. We theoretically establish the stability of VNNs to perturbations in the covariance matrix, thus, implying an advantage over standard PCA-based data analysis approaches that are prone to instability due to principal components associated with close eigenvalues. Our experiments on real-world datasets validate our theoretical results and show that VNN performance is indeed more stable than PCA-based statistical approaches. Moreover, our experiments on multi-resolution datasets also demonstrate that VNNs are amenable to transferability of performance over covariance matrices of different dimensions; a feature that is infeasible for PCA-based approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Cross-Task Generalization via Retrieval Augmentation",
        "paper_url": "https://openreview.net/pdf?id=kB9jrZDenff",
        "paper_authors": [
            "Bill Yuchen Lin",
            "Kangmin Tan",
            "Chris Scott Miller",
            "Beiwen Tian",
            "Xiang Ren"
        ],
        "paper_abstract": "Humans can perform unseen tasks by recalling relevant skills acquired previously and then generalizing them to the target tasks, even if there is no supervision at all. In this paper, we aim to improve this kind of cross-task generalization ability of massive multi-task language models, such as T0 and FLAN, in an unsupervised setting. We propose a retrieval-augmentation method named ReCross that takes a few unlabelled examples as queries to retrieve a small subset of upstream data and uses them to update the multi-task model for better generalization. ReCross is a straightforward yet effective retrieval method that combines both efficient dense retrieval and effective pair-wise reranking. Our results and analysis show that it significantly outperforms both non-retrieval methods and other baseline methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fast Stochastic Composite Minimization and an Accelerated Frank-Wolfe Algorithm under Parallelization",
        "paper_url": "https://openreview.net/pdf?id=WESmKHEH5nJ",
        "paper_authors": [
            "Benjamin Dubois-Taine",
            "Francis Bach",
            "Quentin Berthet",
            "Adrien Taylor"
        ],
        "paper_abstract": "We consider the problem of minimizing the sum of two convex functions. One of those functions has Lipschitz-continuous gradients, and can be accessed via stochastic oracles, whereas the other is ``simple''. We provide a Bregman-type algorithm with accelerated convergence in function values to a ball containing the minimum. The radius of this ball depends on problem-dependent constants, including the variance of the stochastic oracle. We further show that this algorithmic setup naturally leads to a variant of Frank-Wolfe achieving acceleration under parallelization. More precisely, when minimizing a smooth convex function on a bounded domain, we show that one can achieve an $\\epsilon$ primal-dual gap (in expectation) in $\\tilde{O}(1 /\\sqrt{\\epsilon})$ iterations, by only accessing gradients of the original function and a linear maximization oracle with $O(1 / \\sqrt{\\epsilon})$ computing units in parallel. We illustrate this fast convergence on synthetic numerical experiments.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sampling without Replacement Leads to Faster Rates in Finite-Sum Minimax Optimization",
        "paper_url": "https://openreview.net/pdf?id=CTqjKUAyRBt",
        "paper_authors": [
            "Aniket Das",
            "Bernhard Sch\u00f6lkopf",
            "Michael Muehlebach"
        ],
        "paper_abstract": "We analyze the convergence rates of stochastic gradient algorithms for smooth finite-sum minimax optimization and show that, for many such algorithms, sampling the data points \\emph{without replacement} leads to faster convergence compared to sampling with replacement. For the smooth and strongly convex-strongly concave setting, we consider gradient descent ascent and the proximal point method, and present a unified analysis of two popular without-replacement sampling strategies, namely \\emph{Random Reshuffling} (RR), which shuffles the data every epoch, and \\emph{Single Shuffling} or \\emph{Shuffle Once} (SO), which shuffles only at the beginning. We obtain tight convergence rates for RR and SO and demonstrate that these strategies lead to faster convergence than uniform sampling. Moving beyond convexity, we obtain similar results for smooth nonconvex-nonconcave objectives satisfying a two-sided Polyak-\\L{}ojasiewicz inequality. Finally, we demonstrate that our techniques are general enough to analyze the effect of \\emph{data-ordering attacks}, where an adversary manipulates the order in which data points are supplied to the optimizer. Our analysis also recovers tight rates for the \\emph{incremental gradient} method, where the data points are not shuffled at all.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Beyond spectral gap: the role of the topology in decentralized learning",
        "paper_url": "https://openreview.net/pdf?id=AQgmyyEWg8",
        "paper_authors": [
            "Thijs Vogels",
            "Hadrien Hendrikx",
            "Martin Jaggi"
        ],
        "paper_abstract": "In data-parallel optimization of machine learning models, workers collaborate to improve their estimates of the model: more accurate gradients allow them to use larger learning rates and optimize faster. We consider the setting in which all workers sample from the same dataset, and communicate over a sparse graph (decentralized). In this setting, current theory fails to capture important aspects of real-world behavior. First, the \u2018spectral gap\u2019 of the communication graph is not predictive of its empirical performance in (deep) learning. Second, current theory does not explain that collaboration enables larger learning rates than training alone. In fact, it prescribes smaller learning rates, which further decrease as graphs become larger, failing to explain convergence in infinite graphs. This paper aims to paint an accurate picture of sparsely-connected distributed optimization when workers share the same data distribution. We quantify how the graph topology influences convergence in a quadratic toy problem and provide theoretical results for general smooth and (strongly) convex objectives. Our theory matches empirical observations in deep learning, and accurately describes the relative merits of different graph topologies.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Are GANs overkill for NLP?",
        "paper_url": "https://openreview.net/pdf?id=F02H1zNl213",
        "paper_authors": [
            "David Alvarez-Melis",
            "Vikas K Garg",
            "Adam Tauman Kalai"
        ],
        "paper_abstract": "This work offers a novel theoretical perspective on why, despite numerous attempts, adversarial approaches to generative modeling (e.g., GANs) have not been as successful for certain generation tasks, particularly sequential tasks such as Natural Language Generation, as they have in others, such as Computer Vision. In particular, on sequential data such as text, maximum-likelihood approaches are significantly more utilized than GANs. We show that,  while it may seem that maximizing likelihood is inherently different than minimizing distinguishability, this distinction is largely an artifact of the limited representational capacity of the model family, for a wide class of adversarial objectives. We give a theoretical model in which minimizing KL-divergence (i.e., maximizing likelihood) is a more efficient approach to effectively minimizing the same distinguishability criteria that adversarial models seek to optimize. Reductions show that minimizing distinguishability can be seen as simply boosting likelihood for certain families of models including n-gram models and neural networks with a softmax output layer. To achieve a full polynomial-time reduction, a novel next-token distinguishability model is considered. Some preliminary empirical evidence is also provided to substantiate our theoretical analyses.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Relational Proxies: Emergent Relationships as Fine-Grained Discriminators",
        "paper_url": "https://openreview.net/pdf?id=xONqm0NUJc",
        "paper_authors": [
            "Abhra Chaudhuri",
            "Massimiliano Mancini",
            "Zeynep Akata",
            "Anjan Dutta"
        ],
        "paper_abstract": "Fine-grained categories that largely share the same set of parts cannot be discriminated based on part information alone, as they mostly differ in the way the local parts relate to the overall global structure of the object. We propose Relational Proxies, a novel approach that leverages the relational information between the global and local views of an object for encoding its semantic label. Starting with a rigorous formalization of the notion of distinguishability between fine-grained categories, we prove the necessary and sufficient conditions that a model must satisfy in order to learn the underlying decision boundaries in the fine-grained setting. We design Relational Proxies based on our theoretical findings and evaluate it on seven challenging fine-grained benchmark datasets and achieve state-of-the-art results on all of them, surpassing the performance of all existing works with a margin exceeding 4% in some cases. We also experimentally validate our theory on fine-grained distinguishability and obtain consistent results across multiple benchmarks. Implementation is available at https://github.com/abhrac/relational-proxies.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Out-of-Distribution Detection with An Adaptive Likelihood Ratio on Informative Hierarchical VAE",
        "paper_url": "https://openreview.net/pdf?id=vMQ1V_z0TxU",
        "paper_authors": [
            "Yewen Li",
            "Chaojie Wang",
            "Xiaobo Xia",
            "Tongliang Liu",
            "Xin Miao",
            "Bo An"
        ],
        "paper_abstract": "Unsupervised out-of-distribution (OOD) detection is essential for the reliability of machine learning. In the literature, existing work has shown that higher-level semantics captured by hierarchical VAEs can be used to detect OOD instances.\nHowever, we empirically show that, the inherent issue of hierarchical VAEs, i.e., ``posterior collapse'', would seriously limit their capacity for OOD detection.\nBased on a thorough analysis for `posterior collapse'', we propose a novel informative hierarchical VAE to alleviate this issue through enhancing the connections between the data sample and its multi-layer stochastic latent representations during training.\nFurthermore, we propose a novel score function for unsupervised OOD detection, referred to as Adaptive Likelihood Ratio. With this score function, one can selectively aggregate the semantic information on multiple hidden layers of hierarchical VAEs, leading to a strong separability between in-distribution and OOD samples. \nExperimental results demonstrate that our method can significantly outperform existing state-of-the-art unsupervised OOD detection approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Reliable Simulation-Based Inference with Balanced Neural Ratio Estimation",
        "paper_url": "https://openreview.net/pdf?id=o762mMj4XK",
        "paper_authors": [
            "Arnaud Delaunoy",
            "Joeri Hermans",
            "Fran\u00e7ois Rozet",
            "Antoine Wehenkel",
            "Gilles Louppe"
        ],
        "paper_abstract": "Modern approaches for simulation-based inference build upon deep learning surrogates to enable approximate Bayesian inference with computer simulators. In practice, the estimated posteriors' computational faithfulness is, however, rarely guaranteed. For example, Hermans et al., 2021 have shown that current simulation-based inference algorithms can produce posteriors that are overconfident, hence risking false inferences. In this work, we introduce Balanced Neural Ratio Estimation (BNRE), a variation of the NRE algorithm designed to produce posterior approximations that tend to be more conservative, hence improving their reliability, while sharing the same Bayes optimal solution. We achieve this by enforcing a balancing condition that increases the quantified uncertainty in low simulation budget regimes while still converging to the exact posterior as the budget increases. We provide theoretical arguments showing that BNRE tends to produce posterior surrogates that are more conservative than NRE's. We evaluate BNRE on a wide variety of tasks and show that it produces conservative posterior surrogates on all tested benchmarks and simulation budgets. Finally, we emphasize that BNRE is straightforward to implement over NRE and does not introduce any computational overhead.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adv-Attribute: Inconspicuous and Transferable Adversarial Attack on Face Recognition",
        "paper_url": "https://openreview.net/pdf?id=d229wqASHOT",
        "paper_authors": [
            "Shuai Jia",
            "Bangjie Yin",
            "Taiping Yao",
            "Shouhong Ding",
            "Chunhua Shen",
            "Xiaokang Yang",
            "Chao Ma"
        ],
        "paper_abstract": "Deep learning models have shown their vulnerability when dealing with adversarial attacks. Existing attacks almost perform on low-level instances, such as pixels and super-pixels, and rarely exploit semantic clues. For face recognition attacks, existing methods typically generate the l_p-norm perturbations on pixels, however, resulting in low attack transferability and high vulnerability to denoising defense models. In this work, instead of performing perturbations on the low-level pixels, we propose to generate attacks through perturbing on the high-level semantics to improve attack transferability. Specifically, a unified flexible framework, Adversarial Attributes (Adv-Attribute), is designed to generate inconspicuous and transferable attacks on face recognition, which crafts the adversarial noise and adds it into different attributes based on the guidance of the difference in face recognition features from the target. Moreover, the importance-aware attribute selection and the multi-objective optimization strategy are introduced to further ensure the balance of stealthiness and attacking strength. Extensive experiments on the FFHQ and CelebA-HQ datasets show that the proposed Adv-Attribute method achieves the state-of-the-art attacking success rates while maintaining better visual effects against recent attack methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Gold-standard solutions to the Schr\u00f6dinger equation using deep learning: How much physics do we need?",
        "paper_url": "https://openreview.net/pdf?id=nX-gReQ0OT",
        "paper_authors": [
            "Leon Gerard",
            "Michael Scherbela",
            "Philipp Marquetand",
            "Philipp Grohs"
        ],
        "paper_abstract": "Finding accurate solutions to the Schr\u00f6dinger equation is the key unsolved challenge of computational chemistry. Given its importance for the development of new chemical compounds, decades of research have been dedicated to this problem, but due to the large dimensionality even the best available methods do not yet reach the desired accuracy.\nRecently the combination of deep learning with Monte Carlo methods has emerged as a promising way to obtain highly accurate energies and moderate scaling of computational cost. In this paper we significantly contribute towards this goal by introducing a novel deep-learning architecture that achieves 40-70% lower energy error at 6x lower computational cost compared to previous approaches. Using our method we establish a new benchmark by calculating the most accurate variational ground state energies ever published for a number of different atoms and molecules.\nWe systematically break down and measure our improvements, focusing in particular on the effect of increasing physical prior knowledge.\nWe surprisingly find that increasing the prior knowledge given to the architecture can actually decrease accuracy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Query Attacks",
        "paper_url": "https://openreview.net/pdf?id=7hhH95QKKDX",
        "paper_authors": [
            "Sizhe Chen",
            "Zhehao Huang",
            "Qinghua Tao",
            "Yingwen Wu",
            "Cihang Xie",
            "Xiaolin Huang"
        ],
        "paper_abstract": "The score-based query attacks (SQAs) pose practical threats to deep neural networks by crafting adversarial perturbations within dozens of queries, only using the model's output scores. Nonetheless, we note that if the loss trend of the outputs is slightly perturbed, SQAs could be easily misled and thereby become much less effective. Following this idea, we propose a novel defense, namely Adversarial Attack on Attackers (AAA), to confound SQAs towards incorrect attack directions by slightly modifying the output logits. In this way, (1) SQAs are prevented regardless of the model's worst-case robustness; (2) the original model predictions are hardly changed, i.e., no degradation on clean accuracy; (3) the calibration of confidence scores can be improved simultaneously. Extensive experiments are provided to verify the above advantages. For example, by setting $\\ell_\\infty=8/255$ on CIFAR-10, our proposed AAA helps WideResNet-28 secure 80.59% accuracy under Square attack (2500 queries), while the best prior defense (i.e., adversarial training) only attains 67.44%. Since AAA attacks SQA's general greedy strategy, such advantages of AAA over 8 defenses can be consistently observed on 8 CIFAR-10/ImageNet models under 6 SQAs, using different attack targets, bounds, norms, losses, and strategies. Moreover, AAA calibrates better without hurting the accuracy. Our code is available at https://github.com/Sizhe-Chen/AAA.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Outlier Suppression: Pushing the Limit of Low-bit Transformer Language Models",
        "paper_url": "https://openreview.net/pdf?id=yW5zeRSFdZ",
        "paper_authors": [
            "Xiuying Wei",
            "Yunchen Zhang",
            "Xiangguo Zhang",
            "Ruihao Gong",
            "Shanghang Zhang",
            "Qi Zhang",
            "Fengwei Yu",
            "Xianglong Liu"
        ],
        "paper_abstract": "Transformer architecture has become the fundamental element of the widespread natural language processing~(NLP) models. With the trends of large NLP models, the increasing memory and computation costs hinder their efficient deployment on resource-limited devices. Therefore, transformer quantization attracts wide research interest. Recent work recognizes that structured outliers are the critical bottleneck for quantization performance. However, their proposed methods increase the computation overhead and still leave the outliers there. To fundamentally address this problem, this paper delves into the inherent inducement and importance of the outliers. We discover that $\\boldsymbol \\gamma$ in LayerNorm (LN) acts as a sinful amplifier for the outliers, and the importance of outliers varies greatly where some outliers provided by a few tokens cover a large area but can be clipped sharply without negative impacts. Motivated by these findings, we propose an outlier suppression framework including two components: Gamma Migration and Token-Wise Clipping. The Gamma Migration migrates the outlier amplifier to subsequent modules in an equivalent transformation, contributing to a more quantization-friendly model without any extra burden. The Token-Wise Clipping takes advantage of the large variance of token range and designs a token-wise coarse-to-fine pipeline, obtaining a clipping range with minimal final quantization loss in an efficient way. This framework effectively suppresses the outliers and can be used in a plug-and-play mode. Extensive experiments prove that our framework surpasses the existing works and, for the first time, pushes the 6-bit post-training BERT quantization to the full-precision (FP) level. Our code is available at https://github.com/wimh966/outlier_suppression.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fine-Grained Analysis of Stability and Generalization for Modern Meta Learning Algorithms",
        "paper_url": "https://openreview.net/pdf?id=aAs8KTbZvc9",
        "paper_authors": [
            "Jiechao Guan",
            "Yong Liu",
            "Zhiwu Lu"
        ],
        "paper_abstract": "The support/query episodic training strategy has been widely applied in modern meta learning algorithms. Supposing the $n$ training episodes and the test episodes are sampled independently from the same environment, previous work has derived a generalization bound of $O(1/\\sqrt{n})$ for smooth non-convex functions via algorithmic stability analysis. In this paper, we provide fine-grained analysis of stability and generalization for modern meta learning algorithms by considering more general situations. Firstly, we develop matching lower and upper stability bounds for meta learning algorithms with two types of loss functions: (1) nonsmooth convex functions with $\\alpha$-H{\\\"o}lder continuous subgradients $(\\alpha \\in [0,1))$; (2) smooth (including convex and non-convex) functions. Our tight stability bounds show that, in the nonsmooth convex case, meta learning algorithms can be inherently less stable than in the smooth convex case. For the smooth non-convex functions, our stability bound is sharper than the existing one, especially in the setting where the number of iterations is larger than the number $n$ of training episodes. Secondly, we derive improved generalization bounds for meta learning algorithms that hold with high probability. Specifically, we first demonstrate that, under the independent episode environment assumption, the generalization bound of $O(1/\\sqrt{n})$ via algorithmic stability analysis is near optimal. To attain faster convergence rate, we show how to yield a deformed generalization bound of $O(\\ln{n}/n)$ with the curvature condition of loss functions. Finally, we obtain a generalization bound for meta learning with dependent episodes whose dependency relation is characterized by a graph. Experiments on regression problems are conducted to verify our theoretical results.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean Function Perspective",
        "paper_url": "https://openreview.net/pdf?id=xaWO6bAY0xM",
        "paper_authors": [
            "Bohang Zhang",
            "Du Jiang",
            "Di He",
            "Liwei Wang"
        ],
        "paper_abstract": "Designing neural networks with bounded Lipschitz constant is a promising way to obtain certifiably robust classifiers against adversarial examples. However, the relevant progress for the important $\\ell_\\infty$ perturbation setting is rather limited, and a principled understanding of how to design expressive $\\ell_\\infty$ Lipschitz networks is still lacking. In this paper, we bridge the gap by studying certified $\\ell_\\infty$ robustness from a novel perspective of representing Boolean functions. We derive two fundamental impossibility results that hold for any standard Lipschitz network: one for robust classification on finite datasets, and the other for Lipschitz function approximation. These results identify that networks built upon norm-bounded affine layers and Lipschitz activations intrinsically lose expressive power even in the two-dimensional case, and shed light on how recently proposed Lipschitz networks (e.g., GroupSort and $\\ell_\\infty$-distance nets) bypass these impossibilities by leveraging order statistic functions. Finally, based on these insights, we develop a unified Lipschitz network that generalizes prior works, and design a practical version that can be efficiently trained (making certified robust training free). Extensive experiments show that our approach is scalable, efficient, and consistently yields better certified robustness across multiple datasets and perturbation radii than prior Lipschitz networks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deconfounded Representation Similarity for Comparison of Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=mMdRZipvld2",
        "paper_authors": [
            "Tianyu Cui",
            "Yogesh Kumar",
            "Pekka Marttinen",
            "Samuel Kaski"
        ],
        "paper_abstract": "Similarity metrics such as representational similarity analysis (RSA) and centered kernel alignment (CKA) have been used to understand neural networks by comparing their layer-wise representations. However, these metrics are confounded by the population structure of data items in the input space, leading to inconsistent conclusions about the \\emph{functional} similarity between neural networks, such as spuriously high similarity of completely random neural networks and inconsistent domain relations in transfer learning. We introduce a simple and generally applicable fix to adjust for the confounder with covariate adjustment regression, which improves the ability of CKA and RSA to reveal functional similarity and also retains the intuitive invariance properties of the original similarity measures. We show that deconfounding the similarity metrics increases the resolution of detecting functionally similar neural networks across domains. Moreover, in real-world applications, deconfounding improves the consistency between CKA and domain similarity in transfer learning, and increases the correlation between CKA and model out-of-distribution accuracy similarity.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mirror Descent with Relative Smoothness in Measure Spaces, with application to Sinkhorn and EM",
        "paper_url": "https://openreview.net/pdf?id=kCU2pUrmMih",
        "paper_authors": [
            "Pierre-Cyril Aubin-Frankowski",
            "Anna Korba",
            "Flavien L\u00e9ger"
        ],
        "paper_abstract": "Many problems in machine learning can be formulated as optimizing a convex functional over a vector space of measures. This paper studies the convergence of the mirror descent algorithm in this infinite-dimensional setting. Defining Bregman divergences through directional derivatives, we derive the convergence of the scheme for relatively smooth and convex pairs of functionals. Such assumptions allow to handle non-smooth functionals such as the Kullback--Leibler (KL) divergence. Applying our result to joint distributions and KL, we show that Sinkhorn's primal iterations for entropic optimal transport in the continuous setting correspond to a mirror descent, and we obtain a new proof of its (sub)linear convergence. We also show that Expectation Maximization (EM) can always formally be written as a mirror descent. When optimizing only on the latent distribution while fixing the mixtures parameters -- which corresponds to the Richardson--Lucy deconvolution scheme in signal processing -- we derive sublinear rates of convergence.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Energy Networks with Generalized Fenchel-Young Losses",
        "paper_url": "https://openreview.net/pdf?id=CmD5z_2DVuM",
        "paper_authors": [
            "Mathieu Blondel",
            "Felipe Llinares-L\u00f3pez",
            "Robert Dadashi",
            "Leonard Hussenot",
            "Matthieu Geist"
        ],
        "paper_abstract": "Energy-based models, a.k.a. energy networks, perform inference by optimizing \nan energy function, typically parametrized by a neural network. \nThis allows one to capture potentially complex relationships between inputs and\noutputs.\nTo learn the parameters of the energy function, the solution to that\noptimization problem is typically fed into a loss function.\nThe key challenge for training energy networks lies in computing loss gradients,\nas this typically requires argmin/argmax differentiation.\nIn this paper, building upon a generalized notion of conjugate function,\nwhich replaces the usual bilinear pairing with a general energy function,\nwe propose generalized Fenchel-Young losses, a natural loss construction for\nlearning energy networks. Our losses enjoy many desirable properties and their\ngradients can be computed efficiently without argmin/argmax differentiation.\nWe also prove the calibration of their excess risk in the case of linear-concave\nenergies. We demonstrate our losses on multilabel classification and \nimitation learning tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Universally Expressive Communication in Multi-Agent Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=bBgNsEKUxmJ",
        "paper_authors": [
            "Matthew Morris",
            "Thomas D Barrett",
            "Arnu Pretorius"
        ],
        "paper_abstract": "Allowing agents to share information through communication is crucial for solving complex tasks in multi-agent reinforcement learning. In this work, we consider the question of whether a given communication protocol can express an arbitrary policy. By observing that many existing protocols can be viewed as instances of graph neural networks (GNNs), we demonstrate the equivalence of joint action selection to node labelling. With standard GNN approaches provably limited in their expressive capacity, we draw from existing GNN literature and consider augmenting agent observations with: (1) unique agent IDs and (2) random noise. We provide a theoretical analysis as to how these approaches yield universally expressive communication, and also prove them capable of targeting arbitrary sets of actions for identical agents. Empirically, these augmentations are found to improve performance on tasks where expressive communication is required, whilst, in general, the optimal communication protocol is found to be task-dependent.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient and Modular Implicit Differentiation",
        "paper_url": "https://openreview.net/pdf?id=Q-HOv_zn6G",
        "paper_authors": [
            "Mathieu Blondel",
            "Quentin Berthet",
            "marco cuturi",
            "Roy Frostig",
            "Stephan Hoyer",
            "Felipe Llinares-L\u00f3pez",
            "Fabian Pedregosa",
            "Jean-Philippe Vert"
        ],
        "paper_abstract": "Automatic differentiation (autodiff) has revolutionized machine learning.  It\nallows to express complex computations by composing elementary ones in creative\nways and removes the burden of computing their derivatives by hand. More\nrecently, differentiation of optimization problem solutions has attracted\nwidespread attention with applications such as optimization layers, and in\nbi-level problems such as hyper-parameter optimization and meta-learning.\nHowever, so far, implicit differentiation remained difficult to use for\npractitioners, as it often required case-by-case tedious mathematical\nderivations and implementations. In this paper, we propose\nautomatic implicit differentiation, an efficient\nand modular approach for implicit differentiation of optimization problems. In\nour approach, the user defines directly in Python a function $F$ capturing the\noptimality conditions of the problem to be differentiated. Once this is done, we\nleverage autodiff of $F$ and the implicit function theorem to automatically\ndifferentiate the optimization problem.  Our approach thus combines the benefits\nof implicit differentiation and autodiff.  It is efficient as it can be added on\ntop of any state-of-the-art solver and modular as the optimality condition\nspecification is decoupled from the implicit differentiation mechanism.  We show\nthat seemingly simple principles allow to recover many existing implicit\ndifferentiation methods and create new ones easily.  We demonstrate the ease of\nformulating and solving bi-level optimization problems using our framework. We\nalso showcase an application to the sensitivity analysis of molecular dynamics.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
        "paper_url": "https://openreview.net/pdf?id=Z4kZxAjg8Y",
        "paper_authors": [
            "Michele Bevilacqua",
            "Giuseppe Ottaviano",
            "Patrick Lewis",
            "Scott Yih",
            "Sebastian Riedel",
            "Fabio Petroni"
        ],
        "paper_abstract": "Knowledge-intensive language tasks require NLP systems to both provide the correct answer and retrieve supporting evidence for it in a given corpus. Autoregressive language models are emerging as the de-facto standard for generating answers, with newer and more powerful systems emerging at an astonishing pace. In this paper we argue that all this (and future) progress can be directly applied to the retrieval problem with minimal intervention to the models' architecture. Previous work has explored ways to partition the search space into hierarchical structures and retrieve documents by autoregressively generating their unique identifier. In this work we propose an alternative that doesn't force any structure in the search space: using all ngrams in a passage as its possible identifiers. This setup allows us to use an autoregressive model to generate and score distinctive ngrams, that are then mapped to full passages through an efficient data structure. Empirically, we show this not only outperforms prior autoregressive approaches but also leads to an average improvement of at least 10 points over more established retrieval solutions for passage-level retrieval on the KILT benchmark, establishing new state-of-the-art downstream performance on some datasets, while using a considerably lighter memory footprint than competing systems. Code available in the supplementary materials. Pre-trained models will be made available.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Heatmap Distribution Matching for Human Pose Estimation",
        "paper_url": "https://openreview.net/pdf?id=7-bMGPCQCm7",
        "paper_authors": [
            "Haoxuan Qu",
            "Li Xu",
            "Yujun Cai",
            "Lin Geng Foo",
            "Jun Liu"
        ],
        "paper_abstract": "For tackling the task of 2D human pose estimation, the great majority of the recent methods regard this task as a heatmap estimation problem, and optimize the heatmap prediction using the Gaussian-smoothed heatmap as the optimization objective and using the pixel-wise loss (e.g. MSE) as the loss function. In this paper, we show that optimizing the heatmap prediction in such a way, the model performance of body joint localization, which is the intrinsic objective of this task, may not be consistently improved during the optimization process of the heatmap prediction. To address this problem, from a novel perspective, we propose to formulate the optimization of the heatmap prediction as a distribution matching problem between the predicted heatmap and the dot annotation of the body joint directly. By doing so, our proposed method does not need to construct the Gaussian-smoothed heatmap and can achieve a more consistent model performance improvement during the optimization of the heatmap prediction. We show the effectiveness of our proposed method through extensive experiments on the COCO dataset and the MPII dataset.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SageMix: Saliency-Guided Mixup for Point Clouds",
        "paper_url": "https://openreview.net/pdf?id=q-FRENiEP_d",
        "paper_authors": [
            "Sanghyeok Lee",
            "Minkyu Jeon",
            "Injae Kim",
            "Yunyang Xiong",
            "Hyunwoo J. Kim"
        ],
        "paper_abstract": "Data augmentation is key to improving the generalization ability of deep learning models. Mixup is a simple and widely-used data augmentation technique that has proven effective in alleviating the problems of overfitting and data scarcity. Also, recent studies of saliency-aware Mixup in the image domain show that preserving discriminative parts is beneficial to improving the generalization performance. However, these Mixup-based data augmentations are underexplored in 3D vision, especially in point clouds. In this paper, we propose SageMix, a saliency-guided Mixup for point clouds to preserve salient local structures. Specifically, we extract salient regions from two point clouds and smoothly combine them into one continuous shape. With a simple sequential sampling by re-weighted saliency scores, SageMix preserves the local structure of salient regions. Extensive experiments demonstrate that the proposed method consistently outperforms existing Mixup methods in various benchmark point cloud datasets. With PointNet++, our method achieves an accuracy gain of 2.6% and 4.0% over standard training in ModelNet40 and ScanObjectNN, respectively. In addition to generalization performance, SageMix improves robustness and uncertainty calibration. Moreover, when adopting our method to various tasks including part segmentation and standard image classification, our method achieves competitive performance. Code is available at https://github.com/mlvlab/SageMix.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient and Effective Optimal Transport-Based Biclustering",
        "paper_url": "https://openreview.net/pdf?id=yQDC5ZcqX6l",
        "paper_authors": [
            "Chakib Fettal",
            "lazhar labiod",
            "Mohamed Nadif"
        ],
        "paper_abstract": "Bipartite graphs can be used to model a wide variety of dyadic information such as user-rating, document-term, and gene-disorder pairs. Biclustering is an extension of clustering to the underlying bipartite graph induced from this kind of data. In this paper, we leverage optimal transport (OT) which has gained momentum in the machine learning community to propose a novel and scalable biclustering model that generalizes several classical biclustering approaches. We perform extensive experimentation to show the validity of our approach compared to other OT biclustering algorithms along both dimensions of the dyadic datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spending Thinking Time Wisely: Accelerating MCTS with Virtual Expansions",
        "paper_url": "https://openreview.net/pdf?id=B_LdLljS842",
        "paper_authors": [
            "Weirui Ye",
            "Pieter Abbeel",
            "Yang Gao"
        ],
        "paper_abstract": "One of the most important AI research questions is to trade off computation versus performance since ``perfect rationality\" exists in theory but is impossible to achieve in practice. Recently, Monte-Carlo tree search (MCTS) has attracted considerable attention due to the significant performance improvement in various challenging domains. However, the expensive time cost during search severely restricts its scope for applications. This paper proposes the Virtual MCTS (V-MCTS), a variant of MCTS that spends more search time on harder states and less search time on simpler states adaptively. We give theoretical bounds of the proposed method and evaluate the performance and computations on $9 \\times 9$ Go board games and Atari games. Experiments show that our method can achieve comparable performances to the original search algorithm while requiring less than $50\\%$ search time on average. We believe that this approach is a viable alternative for tasks under limited time and resources. The code is available at \\url{https://github.com/YeWR/V-MCTS.git}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Local Linear Convergence of Gradient Methods for  Subspace Optimization via Strict Complementarity",
        "paper_url": "https://openreview.net/pdf?id=4MT-e8mn3X",
        "paper_authors": [
            "Ron Fisher",
            "Dan Garber"
        ],
        "paper_abstract": "We consider optimization problems in which the goal is to find a $k$-dimensional subspace of $\\mathbb{R}^n$, $k<<n$, which minimizes a convex and smooth loss. Such problems generalize the fundamental task of principal component analysis (PCA) to include robust and sparse counterparts, and logistic PCA for binary data, among others. This problem could be approached either via nonconvex gradient methods with highly-efficient iterations, but for which arguing about fast convergence to a global minimizer is difficult or, via a convex relaxation for which arguing about convergence to a global minimizer is straightforward, but the corresponding methods are often inefficient. In this work we bridge these two approaches under a strict complementarity assumption, which in particular implies that the optimal solution to the convex relaxation is unique and is also the optimal solution to the original nonconvex problem. Our main result is a proof that a natural nonconvex gradient method which is \\textit{SVD-free} and requires only a single QR-factorization of an $n\\times k$ matrix per iteration, converges locally with a linear rate. We also establish linear convergence results for the nonconvex projected gradient method, and the Frank-Wolfe method when applied to the convex relaxation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs",
        "paper_url": "https://openreview.net/pdf?id=mSiPuHIP7t8",
        "paper_authors": [
            "Zenan Li",
            "Qitian Wu",
            "Fan Nie",
            "Junchi Yan"
        ],
        "paper_abstract": "Despite the remarkable success of graph neural networks (GNNs) for graph representation learning, they are generally built on the (unreliable) i.i.d. assumption across training and testing data. However, real-world graph data are universally comprised of outliers in training set and out-of-distribution (OOD) testing samples from unseen domains, which solicits effective models for i) debiased learning and ii) OOD detection, towards general trustworthy purpose. In this paper, we first mathematically formulate the two challenging problems for graph data and take an initiative on tackling them under a unified probabilistic model. Specifically, we model the graph generative process to characterize the distribution shifts of graph data together with an additionally introduced latent environment variable as an indicator. We then define a variational distribution, i.e., a recognition model, to infer the environment during training of GNN. By instantiating the generative models as two-component mixtures, we derive a tractable learning objective and theoretically justify that the model can i) automatically identify and down-weight outliers in the training procedure, and ii) induce an effective OOD detector simultaneously. Experiments on diverse datasets with different types of OOD data prove that our model consistently outperforms strong baselines for both debiasing and OOD detection tasks. The source code has been made publicly available at https://github.com/Emiyalzn/GraphDE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Frank-Wolfe-based Algorithms for Approximating Tyler's M-estimator",
        "paper_url": "https://openreview.net/pdf?id=AREqvTvv6gG",
        "paper_authors": [
            "Lior Danon",
            "Dan Garber"
        ],
        "paper_abstract": "Tyler's M-estimator is a well known procedure for robust and heavy-tailed covariance estimation. Tyler himself suggested an iterative fixed-point algorithm  for computing his estimator however, it requires super-linear (in the size of the data) runtime per iteration, which maybe prohibitive in large scale. In this work we propose, to the best of our knowledge, the first Frank-Wolfe-based algorithms for computing Tyler's estimator. One variant uses standard Frank-Wolfe steps, the second also considers \\textit{away-steps} (AFW), and the third is a \\textit{geodesic} version of AFW (GAFW). AFW provably requires, up to a log factor, only linear time per iteration, while GAFW runs in linear time (up to a log factor) in a large $n$ (number of data-points) regime.  All three variants are shown to provably converge to the optimal solution with sublinear rate, under standard assumptions, despite the fact that the underlying optimization problem is not convex nor smooth. Under an additional fairly mild assumption, that holds with probability 1 when the (normalized) data-points are i.i.d. samples from a continuous distribution supported on the entire unit sphere, AFW and GAFW are proved to converge with linear rates. Importantly, all three variants are  parameter-free and use adaptive step-sizes.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Object-Category Aware Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=9Qjn_3gWLDc",
        "paper_authors": [
            "Qi Yi",
            "Rui Zhang",
            "Shaohui Peng",
            "Jiaming Guo",
            "Xing Hu",
            "Zidong Du",
            "Xishan Zhang",
            "Qi Guo",
            "Yunji Chen"
        ],
        "paper_abstract": "Object-oriented reinforcement learning (OORL) is a promising way to improve the sample efficiency and generalization ability over standard RL.  Recent works that try to solve OORL tasks without additional feature engineering mainly focus on learning the object representations and then solving tasks via reasoning based on these object representations. However, none of these works tries to explicitly model the inherent similarity between different object instances of the same category.  Objects of the same category should share similar functionalities; therefore, the category is the most critical property of an object. Following this insight, we propose a novel framework named Object-Category Aware Reinforcement Learning (OCARL), which utilizes the category information of objects to facilitate both perception and reasoning. OCARL consists of three parts: (1) Category-Aware Unsupervised Object Discovery (UOD),  which discovers the objects as well as their corresponding categories; (2) Object-Category Aware Perception, which encodes the category information and is also robust to the incompleteness of (1) at the same time; (3) Object-Centric Modular Reasoning, which adopts multiple independent and object-category-specific networks when reasoning based on objects. Our experiments show that OCARL can improve both the sample efficiency and generalization in the OORL domain.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Risk-Averse Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=LdAxczs3m0",
        "paper_authors": [
            "Ido Greenberg",
            "Yinlam Chow",
            "Mohammad Ghavamzadeh",
            "Shie Mannor"
        ],
        "paper_abstract": "In risk-averse reinforcement learning (RL), the goal is to optimize some risk measure of the returns. A risk measure often focuses on the worst returns out of the agent's experience. As a result, standard methods for risk-averse RL often ignore high-return strategies. We prove that under certain conditions this inevitably leads to a local-optimum barrier, and propose a mechanism we call soft risk to bypass it. We also devise a novel cross entropy module for sampling, which (1) preserves risk aversion despite the soft risk; (2) independently improves sample efficiency. By separating the risk aversion of the sampler and the optimizer, we can sample episodes with poor conditions, yet optimize with respect to successful strategies. We combine these two concepts in CeSoR - Cross-entropy Soft-Risk optimization algorithm - which can be applied on top of any risk-averse policy gradient (PG) method. We demonstrate improved risk aversion in maze navigation, autonomous driving, and resource allocation benchmarks, including in scenarios where standard risk-averse PG completely fails.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhance the Visual Representation via Discrete Adversarial Training",
        "paper_url": "https://openreview.net/pdf?id=qtZac7A3-F",
        "paper_authors": [
            "Xiaofeng Mao",
            "YueFeng Chen",
            "Ranjie Duan",
            "Yao Zhu",
            "Gege Qi",
            "Shaokai Ye",
            "Xiaodan Li",
            "Rong Zhang",
            "Hui Xue'"
        ],
        "paper_abstract": "Adversarial Training (AT), which is commonly accepted as one of the most effective approaches defending against adversarial examples, can largely harm the standard performance, thus has limited usefulness on industrial-scale production and applications. Surprisingly, this phenomenon is totally opposite in Natural Language Processing (NLP) task, where AT can even benefit for generalization. We notice the merit of AT in NLP tasks could derive from the discrete and symbolic input space. For borrowing the advantage from NLP-style AT, we propose Discrete Adversarial Training (DAT). DAT leverages VQGAN to reform the image data to discrete text-like inputs, i.e. visual words. Then it minimizes the maximal risk on such discrete images with symbolic adversarial perturbations. We further give an explanation from the perspective of distribution to demonstrate the effectiveness of DAT. As a plug-and-play technique for enhancing the visual representation, DAT achieves significant improvement on multiple tasks including image classification, object detection and self-supervised learning. Especially, the model pre-trained with Masked Auto-Encoding (MAE) and fine-tuned by our DAT without extra data can get 31.40 mCE on ImageNet-C and 32.77% top-1 accuracy on Stylized-ImageNet, building the new state-of-the-art. The code will be available at https://github.com/alibaba/easyrobust.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Concept Activation Regions: A Generalized Framework For Concept-Based Explanations",
        "paper_url": "https://openreview.net/pdf?id=8AB7AXaLIX5",
        "paper_authors": [
            "Jonathan Crabb\u00e9",
            "Mihaela van der Schaar"
        ],
        "paper_abstract": "Concept-based explanations permit to understand the predictions of a deep neural network (DNN) through the lens of concepts specified by users. Existing methods assume that the examples illustrating a concept are mapped in a fixed direction of the DNN's latent space. When this holds true, the concept can be represented by a concept activation vector (CAV) pointing in that direction. In this work, we propose to relax this assumption by allowing concept examples to be scattered across different clusters in the DNN's latent space. Each concept is then represented by a region of the DNN's latent space that includes these clusters and that we call concept activation region (CAR). To formalize this idea, we introduce an extension of the CAV formalism that is based on the kernel trick and support vector classifiers. This CAR formalism yields global concept-based explanations and local concept-based feature importance. We prove that CAR explanations built with radial kernels are invariant under latent space isometries. In this way, CAR assigns the same explanations to latent spaces that have the same geometry. We further demonstrate empirically that CARs offer (1) more accurate descriptions of how concepts are scattered in the DNN's latent space; (2) global explanations that are closer to human concept annotations and (3) concept-based feature importance that meaningfully relate concepts with each other. Finally, we use CARs to show that DNNs can autonomously rediscover known scientific concepts, such as the prostate cancer grading system. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ZIN: When and How to Learn Invariance Without Environment Partition?",
        "paper_url": "https://openreview.net/pdf?id=pUPFRSxfACD",
        "paper_authors": [
            "LIN Yong",
            "Shengyu Zhu",
            "Lu Tan",
            "Peng Cui"
        ],
        "paper_abstract": "It is commonplace to encounter heterogeneous data, of which some aspects of the data distribution may vary  but the underlying causal mechanisms remain constant.  When data are divided into distinct environments according to the heterogeneity, recent invariant learning methods have proposed to learn robust and invariant models using this environment partition. It is hence tempting to utilize the inherent heterogeneity even when environment partition is not provided. Unfortunately, in this work, we show that learning invariant features under this circumstance is fundamentally impossible without further inductive biases or additional information. Then, we propose a framework to jointly learn environment partition and invariant representation, assisted by additional auxiliary information. We derive sufficient and necessary conditions for our framework to provably identify invariant features under a fairly general setting. Experimental results on both synthetic and real world datasets validate our analysis and demonstrate an improved performance of the proposed framework. Our findings also raise the need of making the role of  inductive biases more explicit when learning invariant models without environment partition in future works. Codes are available at https://github.com/linyongver/ZIN_official .",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EfficientFormer: Vision Transformers at MobileNet Speed",
        "paper_url": "https://openreview.net/pdf?id=NXHXoYMLIG",
        "paper_authors": [
            "Yanyu Li",
            "Geng Yuan",
            "Yang Wen",
            "Eric Hu",
            "Georgios Evangelidis",
            "Sergey Tulyakov",
            "Yanzhi Wang",
            "Jian Ren"
        ],
        "paper_abstract": "Vision Transformers (ViT) have shown rapid progress in computer vision tasks, achieving promising results on various benchmarks. \nHowever, due to the massive number of parameters and model design, e.g., attention mechanism, ViT-based models are generally times slower than lightweight convolutional networks. Therefore, the deployment of ViT for real-time applications is particularly challenging, especially on resource-constrained hardware such as mobile devices. Recent efforts try to reduce the computation complexity of ViT through network architecture search or hybrid design with MobileNet block, yet the inference speed is still unsatisfactory. This leads to an important question: can transformers run as fast as MobileNet while obtaining high performance? To answer this, we first revisit the network architecture and operators used in ViT-based models and identify inefficient designs. Then we introduce a dimension-consistent pure transformer (without MobileNet blocks) as a design paradigm. Finally, we perform latency-driven slimming to get a series of final models dubbed EfficientFormer. Extensive experiments show the superiority of EfficientFormer in performance and speed on mobile devices. Our fastest model, EfficientFormer-L1, achieves $79.2\\%$ top-1 accuracy on ImageNet-1K with only $1.6$ ms inference latency on iPhone 12 (compiled with CoreML), which runs as fast as MobileNetV2$\\times 1.4$ ($1.6$ ms, $74.7\\%$ top-1), and our largest model, EfficientFormer-L7, obtains $83.3\\%$ accuracy with only $7.0$ ms latency. Our work proves that properly designed transformers can reach extremely low latency on mobile devices while maintaining high performance. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Near-Optimal Primal-Dual Method for Off-Policy Learning in CMDP",
        "paper_url": "https://openreview.net/pdf?id=MIhgxhsJMtY",
        "paper_authors": [
            "Fan Chen",
            "Junyu Zhang",
            "Zaiwen Wen"
        ],
        "paper_abstract": "As an important framework for safe Reinforcement Learning, the Constrained Markov Decision Process (CMDP) has been extensively studied in the recent literature. However, despite the rich results under various on-policy learning settings, there still lacks some essential understanding of the offline CMDP problems, in terms of both the algorithm design and the information theoretic sample complexity lower bound. In this paper, we focus on solving the CMDP problems where only offline data are available. By adopting the concept of the single-policy concentrability coefficient $C^*$, we establish an $\\Omega\\left(\\frac{\\min\\left\\{|\\mathcal{S}||\\mathcal{A}|,|\\mathcal{S}|+I\\right\\} C^*}{(1-\\gamma)^3\\epsilon^2}\\right)$ sample complexity lower bound for the offline CMDP problem, where $I$ stands for the number of constraints. By introducing a simple but novel deviation control mechanism, we propose a near-optimal primal-dual learning algorithm called DPDL. This algorithm provably guarantees zero constraint violation and its sample complexity matches the above lower bound except for an $\\tilde{\\mathcal{O}}((1-\\gamma)^{-1})$ factor. Comprehensive discussion on how to deal with the unknown constant $C^*$ and the potential asynchronous structure on the offline dataset are also included. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distributional Reward Estimation for Effective Multi-agent Deep Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=4qR780g2Mg",
        "paper_authors": [
            "Jifeng Hu",
            "Yanchao Sun",
            "Hechang Chen",
            "Sili Huang",
            "haiyin piao",
            "Yi Chang",
            "Lichao Sun"
        ],
        "paper_abstract": "Multi-agent reinforcement learning has drawn increasing attention in practice, e.g., robotics and automatic driving, as it can explore optimal policies using samples generated by interacting with the environment. However, high reward uncertainty still remains a problem when we want to train a satisfactory model, because obtaining high-quality reward feedback is usually expensive and even infeasible. To handle this issue, previous methods mainly focus on passive reward correction. At the same time, recent active reward estimation methods have proven to be a recipe for reducing the effect of reward uncertainty. In this paper, we propose a novel Distributional Reward Estimation framework for effective Multi-Agent Reinforcement Learning (DRE-MARL). Our main idea is to design the multi-action-branch reward estimation and policy-weighted reward aggregation for stabilized training. Specifically, we design the multi-action-branch reward estimation to model reward distributions on all action branches. Then we utilize reward aggregation to obtain stable updating signals during training. Our intuition is that consideration of all possible consequences of actions could be useful for learning policies. The superiority of the DRE-MARL is demonstrated using benchmark multi-agent scenarios, compared with the SOTA baselines in terms of both effectiveness and robustness.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "KSD Aggregated Goodness-of-fit Test",
        "paper_url": "https://openreview.net/pdf?id=9-SZkJLkCcB",
        "paper_authors": [
            "Antonin Schrab",
            "Benjamin Guedj",
            "Arthur Gretton"
        ],
        "paper_abstract": "We investigate properties of goodness-of-fit tests based on the Kernel Stein Discrepancy (KSD). We introduce a strategy to construct a test, called KSDAgg, which aggregates multiple tests with different kernels. KSDAgg avoids splitting the data to perform kernel selection (which leads to a loss in test power), and rather maximises the test power over a collection of kernels. We provide theoretical guarantees on the power of KSDAgg: we show it achieves the smallest uniform separation rate of the collection, up to a logarithmic term. For compactly supported densities with bounded score function for the model, we derive the rate for KSDAgg over restricted Sobolev balls; this rate corresponds to the minimax optimal rate over unrestricted Sobolev balls, up to an iterated logarithmic term. KSDAgg can be computed exactly in practice as it relies either on a parametric bootstrap or on a wild bootstrap to estimate the quantiles and the level corrections. In particular, for the crucial choice of bandwidth of a fixed kernel, it avoids resorting to arbitrary heuristics (such as median or standard deviation) or to data splitting. We find on both synthetic and real-world data that KSDAgg outperforms other state-of-the-art quadratic-time adaptive KSD-based goodness-of-fit testing procedures.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Aggregated Kernel Tests using Incomplete $U$-statistics",
        "paper_url": "https://openreview.net/pdf?id=pkzwYftNcqY",
        "paper_authors": [
            "Antonin Schrab",
            "Ilmun Kim",
            "Benjamin Guedj",
            "Arthur Gretton"
        ],
        "paper_abstract": "We propose a series of computationally efficient, nonparametric tests for the two-sample, independence and goodness-of-fit problems, using the  Maximum Mean Discrepancy (MMD), Hilbert Schmidt Independence Criterion (HSIC), and Kernel Stein Discrepancy (KSD), respectively. Our test statistics are incomplete $U$-statistics, with a computational cost that interpolates between linear time in the number of samples, and quadratic time, as associated with classical $U$-statistic tests. The three proposed tests aggregate over several kernel bandwidths to detect departures from the null on various scales: we call the resulting tests MMDAggInc, HSICAggInc and KSDAggInc. This procedure provides a solution to the fundamental kernel selection problem as we can aggregate a large number of kernels with several bandwidths without incurring a significant loss of test power. For the test thresholds, we derive a quantile bound for wild bootstrapped incomplete $U$-statistics, which is of independent interest. We derive non-asymptotic uniform separation rates for MMDAggInc and HSICAggInc, and quantify exactly the trade-off between computational efficiency and the attainable rates: this result is novel for tests based on incomplete $U$-statistics, to our knowledge. We further show that in the quadratic-time case, the wild bootstrap incurs no penalty to test power over more widespread permutation-based approaches, since both attain the same minimax optimal rates (which in turn match the rates that use oracle quantiles). We support our claims with numerical experiments on the trade-off between computational efficiency and test power. In all three testing frameworks, our proposed linear-time tests outperform the current linear-time state-of-the-art tests (or at least match their test power).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OST: Improving Generalization of DeepFake Detection via One-Shot Test-Time Training",
        "paper_url": "https://openreview.net/pdf?id=YPoRoad6gzY",
        "paper_authors": [
            "Liang Chen",
            "Yong Zhang",
            "Yibing Song",
            "Jue Wang",
            "Lingqiao Liu"
        ],
        "paper_abstract": "State-of-the-art deepfake detectors perform well in identifying forgeries when they are evaluated on a test set similar to the training set, but struggle to maintain good performance when the test forgeries exhibit different characteristics from the training images e.g., forgeries are created by unseen deepfake methods. Such a weak generalization capability hinders the applicability of deepfake detectors. In this paper, we introduce a new learning paradigm specially designed for the generalizable deepfake detection task. Our key idea is to construct a test-sample-specific auxiliary task to update the model before applying it to the sample. Specifically, we synthesize pseudo-training samples from each test image and create a test-time training objective to update the model. Moreover, we proposed to leverage meta-learning to ensure that a fast single-step test-time gradient descent, dubbed one-shot test-time training (OST), can be sufficient for good deepfake detection performance. Extensive results across several benchmark datasets demonstrate that our approach performs favorably against existing arts in terms of generalization to unseen data and robustness to different post-processing steps. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fuzzy Learning Machine",
        "paper_url": "https://openreview.net/pdf?id=adFLKRqRu1h",
        "paper_authors": [
            "Junbiao Cui",
            "Jiye Liang"
        ],
        "paper_abstract": "Classification is one of the most important problems in machine learning and the nature of it is concept cognition. So far, dozens of different classifiers have been designed. Although their working mechanisms vary widely, few of them fully consider concept cognition. In this paper, a new learning machine, fuzzy learning machine (FLM), is proposed from the perspective of concept cognition. Inspired by cognitive science, its working mechanism is of strong interpretability. At the same time, FLM roots in set theory and fuzzy set theory, so FLM has a solid mathematical foundation. The systematic experimental results on a large number of data sets show that FLM can achieve excellent performance, even with the simple implementation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Simulation-guided Beam Search for Neural Combinatorial Optimization",
        "paper_url": "https://openreview.net/pdf?id=tYAS1Rpys5",
        "paper_authors": [
            "Jinho Choo",
            "Yeong-Dae Kwon",
            "Jihoon Kim",
            "Jeongwoo Jae",
            "Andr\u00e9 Hottung",
            "Kevin Tierney",
            "Youngjune Gwon"
        ],
        "paper_abstract": "Neural approaches for combinatorial optimization (CO) equip a learning mechanism to discover powerful heuristics for solving complex real-world problems. While neural approaches capable of high-quality solutions in a single shot are emerging, state-of-the-art approaches are often unable to take full advantage of the solving time available to them. In contrast, hand-crafted heuristics perform highly effective search well and exploit the computation time given to them, but contain heuristics that are difficult to adapt to a dataset being solved. With the goal of providing a powerful search procedure to neural CO approaches, we propose simulation-guided beam search (SGBS), which examines candidate solutions within a fixed-width tree search that both a neural net-learned policy and a simulation (rollout) identify as promising. We further hybridize SGBS with efficient active search (EAS), where SGBS enhances the quality of solutions backpropagated in EAS, and EAS improves the quality of the policy used in SGBS. We evaluate our methods on well-known CO benchmarks and show that SGBS significantly improves the quality of the solutions found under reasonable runtime assumptions.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Quo Vadis: Is Trajectory Forecasting the Key Towards Long-Term Multi-Object Tracking?",
        "paper_url": "https://openreview.net/pdf?id=3r0yLLCo4fF",
        "paper_authors": [
            "Patrick Dendorfer",
            "Vladimir Yugay",
            "Aljosa Osep",
            "Laura Leal-Taix\u00e9"
        ],
        "paper_abstract": "Recent developments in monocular multi-object tracking have been very successful in tracking visible objects and bridging short occlusion gaps, mainly relying on data-driven appearance models. \nWhile significant advancements have been made in short-term tracking performance, bridging longer occlusion gaps remains elusive: state-of-the-art object trackers only bridge less than 10% of occlusions longer than three seconds. \nWe suggest that the missing key is reasoning about future trajectories over a longer time horizon. Intuitively, the longer the occlusion gap, the larger the search space for possible associations. \nIn this paper, we show that even a small yet diverse set of trajectory predictions for moving agents will significantly reduce this search space and thus improve long-term tracking robustness. Our experiments suggest that the crucial components of our approach are reasoning in a bird's-eye view space and generating a small yet diverse set of forecasts while accounting for their localization uncertainty. This way, we can advance state-of-the-art trackers on the MOTChallenge dataset and significantly improve their long-term tracking performance. This paper's source code and experimental data are available at https://github.com/dendorferpatrick/QuoVadis.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Meta-Reinforcement Learning with Self-Modifying Networks",
        "paper_url": "https://openreview.net/pdf?id=cYeYzaP-5AF",
        "paper_authors": [
            "Mathieu Chalvidal",
            "Thomas Serre",
            "Rufin VanRullen"
        ],
        "paper_abstract": "Deep Reinforcement Learning has demonstrated the potential of neural networks tuned with gradient descent for solving complex tasks in well-delimited environments. However, these neural systems are slow learners producing specialized agents with no mechanism to continue learning beyond their training curriculum. On the contrary, biological synaptic plasticity is persistent and manifold, and has been hypothesized to play a key role in executive functions such as working memory and cognitive flexibility, potentially supporting more efficient and generic learning abilities. Inspired by this, we propose to build networks with dynamic weights, able to continually perform self-reflexive modification as a function of their current synaptic state and action-reward feedback, rather than a fixed network configuration. The resulting model, MetODS (for Meta-Optimized Dynamical Synapses) is a broadly applicable meta-reinforcement learning system able to learn efficient and powerful control rules in the agent policy space. A single layer with dynamic synapses can perform one-shot learning, generalize navigation principles to unseen environments and demonstrates a strong ability to learn adaptive motor policies, comparing favorably with previous meta-reinforcement learning approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Models are less Over-Confident",
        "paper_url": "https://openreview.net/pdf?id=5K3uopkizS",
        "paper_authors": [
            "Julia Grabinski",
            "Paul Gavrikov",
            "Janis Keuper",
            "Margret Keuper"
        ],
        "paper_abstract": "Despite the success of convolutional neural networks (CNNs) in many academic benchmarks for computer vision tasks, their application in the real-world is still facing fundamental challenges. One of these open problems is the inherent lack of robustness, unveiled by the striking effectiveness of adversarial attacks. Current attack methods are able to manipulate the network's prediction by adding specific but small amounts of noise to the input. In turn, adversarial training (AT) aims to achieve robustness against such attacks and ideally a better model generalization ability by including adversarial samples in the trainingset. However, an in-depth analysis of the resulting robust models beyond adversarial robustness is still pending. In this paper, we empirically analyze a variety of adversarially trained models that achieve high robust accuracies when facing state-of-the-art attacks and we show that AT has an interesting side-effect: it leads to models that are significantly less overconfident with their decisions, even on clean data than non-robust models. Further, our analysis of robust models shows that not only AT but also the model's building blocks (like activation functions and pooling) have a strong influence on the models' prediction confidences. Data & Project website: https://github.com/GeJulia/robustness_confidences_evaluation",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalizing Bayesian Optimization with Decision-theoretic Entropies",
        "paper_url": "https://openreview.net/pdf?id=tmUGnBjchSC",
        "paper_authors": [
            "Willie Neiswanger",
            "Lantao Yu",
            "Shengjia Zhao",
            "Chenlin Meng",
            "Stefano Ermon"
        ],
        "paper_abstract": "Bayesian optimization (BO) is a popular method for efficiently inferring optima of an expensive black-box function via a sequence of queries. Existing information-theoretic BO procedures aim to make queries that most reduce the uncertainty about optima, where the uncertainty is captured by Shannon entropy. However, an optimal measure of uncertainty would, ideally, factor in how we intend to use the inferred quantity in some downstream procedure. In this paper, we instead consider a generalization of Shannon entropy from work in statistical decision theory (DeGroot 1962, Rao 1984), which contains a broad class of uncertainty measures parameterized by a problem-specific loss function corresponding to a downstream task. We first show that special cases of this entropy lead to popular acquisition functions used in BO procedures such as knowledge gradient, expected improvement, and entropy search. We then show how alternative choices for the loss yield a flexible family of acquisition functions that can be customized for use in novel optimization settings. Additionally, we develop gradient-based methods to efficiently optimize our proposed family of acquisition functions, and demonstrate strong empirical performance on a diverse set of sequential decision making tasks, including variants of top-$k$ optimization, multi-level set estimation, and sequence search.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Hierarchical Planning from Pixels",
        "paper_url": "https://openreview.net/pdf?id=wZk69kjy9_d",
        "paper_authors": [
            "Danijar Hafner",
            "Kuang-Huei Lee",
            "Ian Fischer",
            "Pieter Abbeel"
        ],
        "paper_abstract": "Intelligent agents need to select long sequences of actions to solve complex tasks. While humans easily break down tasks into subgoals and reach them through millions of muscle commands, current artificial intelligence is limited to tasks with horizons of a few hundred decisions, despite large compute budgets. Research on hierarchical reinforcement learning aims to overcome this limitation but has proven to be challenging, current methods rely on manually specified goal spaces or subtasks, and no general solution exists. We introduce Director, a practical method for learning hierarchical behaviors directly from pixels by planning inside the latent space of a learned world model. The high-level policy maximizes task and exploration rewards by selecting latent goals and the low-level policy learns to achieve the goals. Despite operating in latent space, the decisions are interpretable because the world model can decode goals into images for visualization. Director learns successful behaviors across a wide range of environments, including visual control, Atari games, and DMLab levels and outperforms exploration methods on tasks with very sparse rewards, including 3D maze traversal with a quadruped robot from an egocentric camera and proprioception, without access to the global position or top-down view used by prior work.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Scale Adaptive Network for Single Image Denoising",
        "paper_url": "https://openreview.net/pdf?id=HFm7AxNa9Wo",
        "paper_authors": [
            "Yuanbiao Gou",
            "Peng Hu",
            "Jiancheng Lv",
            "Joey Tianyi Zhou",
            "Xi Peng"
        ],
        "paper_abstract": "Multi-scale architectures have shown effectiveness in a variety of tasks thanks to appealing cross-scale complementarity. However, existing architectures treat different scale features equally without considering the scale-specific characteristics, \\textit{i.e.}, the within-scale characteristics are ignored in the architecture design. In this paper, we reveal this missing piece for multi-scale architecture design and accordingly propose a novel Multi-Scale Adaptive Network (MSANet) for single image denoising. Specifically, MSANet simultaneously embraces the within-scale characteristics and the cross-scale complementarity thanks to three novel neural blocks, \\textit{i.e.}, adaptive feature block (AFeB), adaptive multi-scale block (AMB), and adaptive fusion block (AFuB). In brief, AFeB is designed to adaptively preserve image details and filter noises, which is highly expected for the features with mixed details and noises. AMB could enlarge the receptive field and aggregate the multi-scale information, which meets the need of contextually informative features. AFuB devotes to adaptively sampling and transferring the features from one scale to another scale, which fuses the multi-scale features with varying characteristics from coarse to fine. Extensive experiments on both three real and six synthetic noisy image datasets show the superiority of MSANet compared with 12 methods. The code could be accessed from https://github.com/XLearning-SCU/2022-NeurIPS-MSANet.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=NyAJzgHLAr",
        "paper_authors": [
            "Yuanwei Liu",
            "Nian Liu",
            "Xiwen Yao",
            "Junwei Han"
        ],
        "paper_abstract": "Few-shot semantic segmentation aims to segment the target objects in query under the condition of a few annotated support images. Most previous works strive to mine more effective category information from the support to match with the corresponding objects in query. However, they all ignored the category information gap between query and support images. If the objects in them show large intra-class diversity, forcibly migrating the category information from the support to the query is ineffective. To solve this problem, we are the first to introduce an intermediate prototype for mining both deterministic category information from the support and adaptive category knowledge from the query. Specifically, we design an Intermediate Prototype Mining Transformer (IPMT) to learn the prototype in an iterative way. In each IPMT layer, we propagate the object information in both support and query features to the prototype and then use it to activate the query feature map. By conducting this process iteratively, both the intermediate prototype and the query feature can be progressively improved. At last, the final query feature is used to yield precise segmentation prediction. Extensive experiments on both PASCAL-5i and COCO-20i datasets clearly verify the effectiveness of our IPMT and show that it outperforms previous state-of-the-art methods by a large margin. Code is available at https://github.com/LIUYUANWEI98/IPMT",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DTG-SSOD: Dense Teacher Guidance for Semi-Supervised Object Detection",
        "paper_url": "https://openreview.net/pdf?id=0-uBrFiOVf",
        "paper_authors": [
            "Gang Li",
            "Xiang Li",
            "Yujie Wang",
            "Yichao Wu",
            "Ding Liang",
            "Shanshan Zhang"
        ],
        "paper_abstract": "The Mean-Teacher (MT) scheme is widely adopted in semi-supervised object detection (SSOD). In MT, sparse pseudo labels, offered by the final predictions of the teacher (e.g., after Non Maximum Suppression (NMS) post-processing), are adopted for the dense supervision for the student via hand-crafted label assignment. However, the \"sparse-to-dense'' paradigm complicates the pipeline of SSOD, and simultaneously neglects the powerful direct, dense teacher supervision. In this paper, we attempt to directly leverage the dense guidance of teacher to supervise student training, i.e., the \"dense-to-dense'' paradigm. Specifically, we propose the Inverse NMS Clustering (INC) and Rank Matching (RM) to instantiate the dense supervision, without the widely used, conventional sparse pseudo labels. INC leads the student to group candidate boxes into clusters in NMS as the teacher does, which is implemented by learning grouping information revealed in NMS procedure of the teacher. After obtaining the same grouping scheme as the teacher via INC, the student further imitates the rank distribution of the teacher over clustered candidates through Rank Matching. With the proposed INC and RM, we integrate Dense Teacher Guidance into Semi-Supervised Object Detection (termed \"DTG-SSOD''), successfully abandoning sparse pseudo labels and enabling more informative learning on unlabeled data. On COCO benchmark, our DTG-SSOD achieves state-of-the-art performance under various labelling ratios. For example, under 10% labelling ratio, DTG-SSOD improves the supervised baseline from 26.9 to 35.9 mAP, outperforming the previous best method Soft Teacher by 1.9 points. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contact-aware Human Motion Forecasting",
        "paper_url": "https://openreview.net/pdf?id=LIKlL1Br9AT",
        "paper_authors": [
            "Wei Mao",
            "miaomiao Liu",
            "Richard Hartley",
            "Mathieu Salzmann"
        ],
        "paper_abstract": "In this paper, we tackle the task of scene-aware 3D human motion forecasting, which consists of predicting future human poses given a 3D scene and a past human motion. A key challenge of this task is to ensure consistency between the human and the scene, accounting for human-scene interactions. Previous attempts to do so model such interactions only implicitly, and thus tend to produce artifacts such as ``ghost motion\" because of the lack of explicit constraints between the local poses and the global motion. Here, by contrast, we propose to explicitly model the human-scene contacts. To this end, we introduce distance-based contact maps that capture the contact relationships between every joint and every 3D scene point at each time instant. We then develop a two-stage pipeline that first predicts the future contact maps from the past ones and the scene point cloud, and then forecasts the future human poses by conditioning them on the predicted contact maps. During training, we explicitly encourage consistency between the global motion and the local poses via a prior defined using the contact maps and future poses. Our approach outperforms the state-of-the-art human motion forecasting and human synthesis methods on both synthetic and real datasets. Our code is available at https://github.com/wei-mao-2019/ContAwareMotionPred.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding Programmatic Weak Supervision via Source-aware Influence Function",
        "paper_url": "https://openreview.net/pdf?id=7CONgGdxsV",
        "paper_authors": [
            "Jieyu Zhang",
            "Haonan Wang",
            "Cheng-Yu Hsieh",
            "Alexander Ratner"
        ],
        "paper_abstract": "Programmatic Weak Supervision (PWS) aggregates the source votes of multiple weak supervision sources into probabilistic training labels, which are in turn used to train an end model. With its increasing popularity, it is critical to have some tool for users to understand the influence of each component (\\eg, the source vote or training data) in the pipeline and interpret the end model behavior. To achieve this, we build on Influence Function (IF) and propose source-aware IF, which leverages the generation process of the probabilistic labels to decompose the end model's training objective and then calculate the influence associated with each (data, source, class) tuple. These primitive influence score can then be used to estimate the influence of individual component of PWS, such as source vote, supervision source, and training data. On datasets of diverse domains, we demonstrate multiple use cases: (1) interpreting incorrect predictions from multiple angles that reveals insights for debugging the PWS pipeline, (2) identifying mislabeling of sources with a gain of 9\\%-37\\% over baselines, and (3) improving the end model's generalization performance by removing harmful components in the training objective (13\\%-24\\% better than ordinary IF).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Elucidating the Design Space of Diffusion-Based Generative Models",
        "paper_url": "https://openreview.net/pdf?id=k7FuTOWMOc7",
        "paper_authors": [
            "Tero Karras",
            "Miika Aittala",
            "Timo Aila",
            "Samuli Laine"
        ],
        "paper_abstract": "We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices. This lets us identify several changes to both the sampling and training processes, as well as preconditioning of the score networks. Together, our improvements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in an unconditional setting, with much faster sampling (35 network evaluations per image) than prior designs. To further demonstrate their modular nature, we show that our design changes dramatically improve both the efficiency and quality obtainable with pre-trained score networks from previous work, including improving the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after re-training with our proposed improvements to a new SOTA of 1.36.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech",
        "paper_url": "https://openreview.net/pdf?id=HEcYYV5MPxa",
        "paper_authors": [
            "Ziyue Jiang",
            "Zhe Su",
            "Zhou Zhao",
            "Qian Yang",
            "Yi Ren",
            "Jinglin Liu",
            "Zhenhui Ye"
        ],
        "paper_abstract": "Polyphone disambiguation aims to capture accurate pronunciation knowledge from natural text sequences for reliable Text-to-speech (TTS) systems. However, previous approaches require substantial annotated training data and additional efforts from language experts, making it difficult to extend high-quality neural TTS systems to out-of-domain daily conversations and countless languages worldwide. This paper tackles the polyphone disambiguation problem from a concise and novel perspective: we propose Dict-TTS, a semantic-aware generative text-to-speech model with an online website dictionary (the existing prior information in the natural language). Specifically, we design a semantics-to-pronunciation attention (S2PA) module to match the semantic patterns between the input text sequence and the prior semantics in the dictionary and obtain the corresponding pronunciations; The S2PA module can be easily trained with the end-to-end TTS model without any annotated phoneme labels. Experimental results in three languages show that our model outperforms several strong baseline models in terms of pronunciation accuracy and improves the prosody modeling of TTS systems. Further extensive analyses demonstrate that each design in Dict-TTS is effective. The code is available at https://github.com/Zain-Jiang/Dict-TTS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GhostNetV2: Enhance Cheap Operation with Long-Range Attention",
        "paper_url": "https://openreview.net/pdf?id=vhKaBdOOobB",
        "paper_authors": [
            "Yehui Tang",
            "Kai Han",
            "Jianyuan Guo",
            "Chang Xu",
            "Chao Xu",
            "Yunhe Wang"
        ],
        "paper_abstract": "Light-weight convolutional neural networks (CNNs) are specially designed for applications on mobile devices with faster inference speed. The convolutional operation can only capture local information in a window region, which prevents  performance from being further improved. Introducing self-attention into convolution can capture global information well, but it will largely encumber the actual speed. In this paper, we propose a hardware-friendly attention mechanism (dubbed DFC attention) and then present a new GhostNetV2 architecture for mobile applications. The proposed DFC attention is constructed based on fully-connected layers, which can not only execute fast on common hardware but also capture the dependence between long-range pixels. We further revisit the expressiveness bottleneck in previous GhostNet and propose to enhance expanded features produced by cheap operations with DFC attention, so that a GhostNetV2 block can aggregate local and long-range information simultaneously. Extensive experiments demonstrate the superiority of GhostNetV2 over existing architectures. For example, it achieves 75.3% top-1 accuracy on ImageNet with 167M FLOPs, significantly suppressing GhostNetV1 (74.5%) with a similar computational cost. The source code will be available at https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/ghostnetv2_pytorch and https://gitee.com/mindspore/models/tree/master/research/cv/ghostnetv2. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CASA: Category-agnostic Skeletal Animal Reconstruction",
        "paper_url": "https://openreview.net/pdf?id=-zYfrOl2I6O",
        "paper_authors": [
            "Yuefan Wu",
            "Zeyuan Chen",
            "Shaowei Liu",
            "Zhongzheng Ren",
            "Shenlong Wang"
        ],
        "paper_abstract": "Recovering a skeletal shape from a monocular video is a longstanding challenge. Prevailing nonrigid animal reconstruction methods often adopt a control-point driven animation model and optimize bone transforms individually without considering skeletal topology, yielding unsatisfactory shape and articulation. In contrast, humans can easily infer the articulation structure of an unknown character by associating it with a seen articulated object in their memory.  Inspired by this fact, we present CASA, a novel category-agnostic articulated animal reconstruction method. Our method consists of two components, a video-to-shape retrieval process and a neural inverse graphics framework. During inference, CASA first finds a matched articulated shape from a 3D character assets bank so that the input video scores highly with the rendered image, according to a pretrained image-language model. It then integrates the retrieved character into an inverse graphics framework and jointly infers the shape deformation, skeleton structure, and skinning weights through optimization. Experiments validate the efficacy of our method in shape reconstruction and articulation. We further show that we can use the resulting skeletal-animated character for re-animation. \n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fair and Efficient Allocations Without Obvious Manipulations",
        "paper_url": "https://openreview.net/pdf?id=6H00JM-DZjU",
        "paper_authors": [
            "Alexandros Psomas",
            "Paritosh Verma"
        ],
        "paper_abstract": "We consider the fundamental problem of allocating a set of indivisible goods among strategic agents with additive valuation functions. It is well known that, in the absence of monetary transfers, Pareto efficient and truthful rules are dictatorial, while there is no deterministic truthful mechanism that allocates all items and achieves envy-freeness up to one item (EF1), even for the case of two agents. In this paper, we investigate the interplay of fairness and efficiency under a relaxation of truthfulness called non-obvious manipulability (NOM), recently proposed by~\\citep{troyan2020obvious}. We show that this relaxation allows us to bypass the aforementioned negative results in a very strong sense. Specifically, we prove that there are deterministic and EF1 algorithms that are not obviously manipulable, and the algorithm that maximizes utilitarian social welfare (the sum of agents' utilities), which is Pareto efficient but not dictatorial, is not obviously manipulable for $n \\geq 3$ agents (but obviously manipulable for $n=2$ agents). At the same time, maximizing the egalitarian social welfare (the minimum of agents' utilities) or the Nash social welfare (the product of agents' utilities) is obviously manipulable for any number of agents and items. Our main result is an approximation preserving black-box reduction from the problem of designing EF1 and NOM mechanisms to the problem of designing EF1 algorithms. En route, we prove an interesting structural result about EF1 allocations, as well as new ``best-of-both-worlds'' results (for the problem without incentives), that might be of independent interest.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SNN-RAT: Robustness-enhanced Spiking Neural Network through Regularized Adversarial Training",
        "paper_url": "https://openreview.net/pdf?id=xwBdjfKt7_W",
        "paper_authors": [
            "Jianhao Ding",
            "Tong Bu",
            "Zhaofei Yu",
            "Tiejun Huang",
            "Jian K Liu"
        ],
        "paper_abstract": "Spiking neural networks (SNNs) are promising to be widely deployed in real-time and safety-critical applications with the advance of neuromorphic computing. Recent work has demonstrated the insensitivity of SNNs to small random perturbations due to the discrete internal information representation. The variety of training algorithms and the involvement of the temporal dimension pose more threats to the robustness of SNNs than that of typical neural networks. We account for the vulnerability of SNNs by constructing adversaries based on different differentiable approximation techniques. By deriving a Lipschitz constant specifically for the spike representation, we first theoretically answer the question of how much adversarial invulnerability is retained in SNNs. Hence, to defend against the broad attack methods, we propose a regularized adversarial training scheme with low computational overheads. SNNs can benefit from the constraint of the perturbed spike distance's amplification and the generalization on multiple adversarial $\\epsilon$-neighbourhoods. Our experiments on the image recognition benchmarks have proven that our training scheme can defend against powerful adversarial attacks crafted from strong differentiable approximations. To be specific, our approach makes the black-box attacks of the Projected Gradient Descent attack nearly ineffective. We believe that our work will facilitate the spread of SNNs for safety-critical applications and help understand the robustness of the human brain.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "M\u00b3ViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-design",
        "paper_url": "https://openreview.net/pdf?id=cFOhdl1cyU-",
        "paper_authors": [
            "hanxue liang",
            "Zhiwen Fan",
            "Rishov Sarkar",
            "Ziyu Jiang",
            "Tianlong Chen",
            "Kai Zou",
            "Yu Cheng",
            "Cong Hao",
            "Zhangyang Wang"
        ],
        "paper_abstract": "Multi-task learning (MTL) encapsulates multiple learned tasks in a single model and often lets those tasks learn better jointly. Multi-tasking models have become successful and often essential for many sophisticated systems such as autonomous driving and indoor robots. However, when deploying MTL onto those real-world systems that are often resource-constrained or latency-sensitive, two prominent challenges arise: (i) during training, simultaneously optimizing all tasks is often difficult due to gradient conflicts across tasks, and the challenge is amplified when a growing number of tasks have to be squeezed into one compact model; (ii) at inference, current MTL regimes have to activate nearly the entire model even to just execute a single task. Yet most real systems demand only one or two tasks at each moment, while flexibly switching between tasks per need: therefore such \u201call tasks activated\u201d inference is also highly inefficient and non-scalable in practice. \nIn this paper, we present a model-accelerator co-design framework to enable efficient on-device MTL, that tackles both training and inference bottlenecks. Our framework, dubbed M\u00b3ViT, customizes mixture-of-experts (MoE) layers into a vision transformer (ViT) backbone for MTL, and sparsely activates task-specific experts during training, which effectively disentangles the parameter spaces to avoid different tasks\u2019 training conflicts. Then at inference with any task of interest, the same design allows for activating only the task-corresponding sparse \u201cexpert\u201d pathway, instead of the full model. Our new model design is further enhanced by hardware-level innovations, in particular, a novel computation reordering scheme tailored for memory-constrained MTL that achieves zero-overhead switching between tasks and can scale to any number of experts. Extensive experiments on PASCAL-Context and NYUD-v2 datasets at both software and hardware levels are conducted to demonstrate the effectiveness of the proposed design. When executing the practical scenario of single-task inference, M\u00b3ViT achieves higher accuracies than encoder-focused MTL methods, while significantly reducing 88% inference FLOPs. When implemented on a hardware platform of one Xilinx ZCU104 FPGA, our co-design framework reduces the memory requirement by 2.40\u00d7, while achieving energy efficiency (as the product of latency and power) up to 9.23\u00d7 times higher than a comparable FPGA baseline.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training Uncertainty-Aware Classifiers with Conformalized Deep Learning",
        "paper_url": "https://openreview.net/pdf?id=NaZwgxp-mT_",
        "paper_authors": [
            "Bat-Sheva Einbinder",
            "Yaniv Romano",
            "Matteo Sesia",
            "Yanfei Zhou"
        ],
        "paper_abstract": "Deep neural networks are powerful tools to detect hidden patterns in data and leverage them to make predictions, but they are not designed to understand uncertainty and estimate reliable probabilities. In particular, they tend to be overconfident. We begin to address this problem in the context of multi-class classification by developing a novel training algorithm producing models with more dependable uncertainty estimates, without sacrificing predictive power. The idea is to mitigate overconfidence by minimizing a loss function, inspired by advances in conformal inference, that quantifies model uncertainty by carefully leveraging hold-out data. Experiments with synthetic and real data demonstrate this method can lead to smaller conformal prediction sets with higher conditional coverage, after exact calibration with hold-out data, compared to state-of-the-art alternatives.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Compressible-composable NeRF via Rank-residual Decomposition",
        "paper_url": "https://openreview.net/pdf?id=aPXMGv7aeOn",
        "paper_authors": [
            "Jiaxiang Tang",
            "Xiaokang Chen",
            "Jingbo Wang",
            "Gang Zeng"
        ],
        "paper_abstract": "Neural Radiance Field (NeRF) has emerged as a compelling method to represent 3D objects and scenes for photo-realistic rendering. \nHowever, its implicit representation causes difficulty in manipulating the models like the explicit mesh representation.\nSeveral recent advances in NeRF manipulation are usually restricted by a shared renderer network, or suffer from large model size. \nTo circumvent the hurdle, in this paper, we present a neural field representation that enables efficient and convenient manipulation of models.\nTo achieve this goal, we learn a hybrid tensor rank decomposition of the scene without neural networks. \nMotivated by the low-rank approximation property of the SVD algorithm, we propose a rank-residual learning strategy to encourage the preservation of primary information in lower ranks. \nThe model size can then be dynamically adjusted by rank truncation to control the levels of detail, achieving near-optimal compression without extra optimization.\nFurthermore, different models can be arbitrarily transformed and composed into one scene by concatenating along the rank dimension.\nThe growth of storage cost can also be mitigated by compressing the unimportant objects in the composed scene. \nWe demonstrate that our method is able to achieve comparable rendering quality to state-of-the-art methods, while enabling extra capability of compression and composition.\nCode is available at https://github.com/ashawkey/CCNeRF.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Can Hybrid Geometric Scattering Networks Help Solve the Maximum Clique Problem?",
        "paper_url": "https://openreview.net/pdf?id=uxc8hDSs_xh",
        "paper_authors": [
            "Yimeng Min",
            "Frederik Wenkel",
            "Michael Perlmutter",
            "Guy Wolf"
        ],
        "paper_abstract": "We propose a geometric scattering-based graph neural network (GNN) for approximating solutions of the NP-hard maximum clique (MC) problem. We construct a loss function with two terms, one which encourages the network to find highly connected nodes and the other which acts as a surrogate for the constraint that the nodes form a clique. We then use this loss to train an efficient GNN architecture that outputs a vector representing the probability for each node to be part of the MC and apply a rule-based decoder to make our final prediction. The incorporation of the scattering transform alleviates the so-called oversmoothing problem that is often encountered in GNNs and would degrade the performance of our proposed setup. Our empirical results demonstrate that our method outperforms representative GNN baselines in terms of solution accuracy and inference speed as well as conventional solvers like Gurobi with limited time budgets. Furthermore, our scattering model is very parameter efficient with only $\\sim$ 0.1\\% of the number of parameters compared to previous GNN baseline models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CEIP: Combining Explicit and Implicit Priors for Reinforcement Learning with Demonstrations",
        "paper_url": "https://openreview.net/pdf?id=R5KjUket6w",
        "paper_authors": [
            "Kai Yan",
            "Alex Schwing",
            "Yu-Xiong Wang"
        ],
        "paper_abstract": "Although reinforcement learning has found widespread use in dense reward settings, training autonomous agents with sparse rewards remains challenging. To address this difficulty, prior work has shown promising results when using not only task-specific demonstrations but also task-agnostic albeit somewhat related demonstrations. In most cases, the available demonstrations are distilled into an implicit prior, commonly represented via a single deep net. Explicit priors in the form of a database that can be queried have also been shown to lead to encouraging results. To better benefit from available demonstrations, we develop a method to Combine Explicit and Implicit Priors (CEIP). CEIP exploits multiple implicit priors in the form of normalizing flows in parallel to form a single complex prior. Moreover, CEIP uses an effective explicit retrieval and push-forward mechanism to condition the implicit priors. In three challenging environments, we find the proposed CEIP method to improve upon sophisticated state-of-the-art techniques.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recipe for a General, Powerful, Scalable Graph Transformer",
        "paper_url": "https://openreview.net/pdf?id=lMMaNf6oxKM",
        "paper_authors": [
            "Ladislav Rampasek",
            "Mikhail Galkin",
            "Vijay Prakash Dwivedi",
            "Anh Tuan Luu",
            "Guy Wolf",
            "Dominique Beaini"
        ],
        "paper_abstract": "We propose a recipe on how to build a general, powerful, scalable (GPS) graph Transformer with linear complexity and state-of-the-art results on a diverse set of benchmarks. Graph Transformers (GTs) have gained popularity in the field of graph representation learning with a variety of recent publications but they lack a common foundation about what constitutes a good positional or structural encoding, and what differentiates them. In this paper, we summarize the different types of encodings with a clearer definition and categorize them as being $\\textit{local}$, $\\textit{global}$ or $\\textit{relative}$. The prior GTs are constrained to small graphs with a few hundred nodes, here we propose the first architecture with a complexity linear in the number of nodes and edges $O(N+E)$ by decoupling the local real-edge aggregation from the fully-connected Transformer. We argue that this decoupling does not negatively affect the expressivity, with our architecture being a universal function approximator on graphs. Our GPS recipe consists of choosing 3 main ingredients: (i) positional/structural encoding, (ii) local message-passing mechanism, and (iii) global attention mechanism. We provide a modular framework $\\textit{GraphGPS}$ that supports multiple types of encodings and that provides efficiency and scalability both in small and large graphs. We test our architecture on 16 benchmarks and show highly competitive results in all of them, show-casing the empirical benefits gained by the modularity and the combination of different strategies.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Revisiting Heterophily For Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=NjeEfP7e3KZ",
        "paper_authors": [
            "Sitao Luan",
            "Chenqing Hua",
            "Qincheng Lu",
            "Jiaqi Zhu",
            "Mingde Zhao",
            "Shuyuan Zhang",
            "Xiao-Wen Chang",
            "Doina Precup"
        ],
        "paper_abstract": "Graph Neural Networks (GNNs) extend basic Neural Networks (NNs) by using graph structures based on the relational inductive bias (homophily assumption). While GNNs have been commonly believed to outperform NNs in real-world tasks, recent work has identified a non-trivial set of datasets where their performance compared to NNs is not satisfactory. Heterophily has been considered the main cause of this empirical observation and numerous works have been put forward to address it. In this paper, we first revisit the widely used homophily metrics and point out that their consideration of only graph-label consistency is a shortcoming. Then, we study heterophily from the  perspective of post-aggregation node similarity and define new homophily metrics, which are potentially advantageous compared to existing ones. Based on this investigation, we prove that some harmful cases of heterophily can be effectively addressed by local diversification operation. Then, we propose the Adaptive Channel Mixing (ACM), a framework to adaptively exploit aggregation, diversification and identity channels to extract richer localized information in each baseline GNN layer. ACM is more powerful than the commonly used uni-channel framework for node classification tasks on heterophilic graphs. When evaluated on 10 benchmark node classification tasks, ACM-augmented baselines consistently achieve significant performance gain, exceeding state-of-the-art GNNs on most  tasks without incurring significant computational burden. (Code: https://github.com/SitaoLuan/ACM-GNN)",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hamiltonian Latent Operators for content and motion disentanglement in image sequences",
        "paper_url": "https://openreview.net/pdf?id=2vYmjZVT29T",
        "paper_authors": [
            "Asif Khan",
            "Amos Storkey"
        ],
        "paper_abstract": "We introduce \\textit{HALO} -- a deep generative model utilising HAmiltonian Latent Operators to reliably disentangle content and motion information in image sequences. The \\textit{content} represents summary statistics of a sequence, and \\textit{motion} is a dynamic process that determines how information is expressed in any part of the sequence. By modelling the dynamics as a Hamiltonian motion, important desiderata are ensured: (1) the motion is reversible, (2) the symplectic, volume-preserving structure in phase space means paths are continuous and are not divergent in the latent space. Consequently, the nearness of sequence frames is realised by the nearness of their coordinates in the phase space, which proves valuable for disentanglement and long-term sequence generation. The sequence space is generally comprised of different types of dynamical motions. To ensure long-term separability and allow controlled generation, we associate every motion with a unique Hamiltonian that acts in its respective subspace. We demonstrate the utility of \\textit{HALO} by swapping the motion of a pair of sequences, controlled generation, and image rotations.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimizing Relevance Maps of Vision Transformers Improves Robustness",
        "paper_url": "https://openreview.net/pdf?id=upuYKQiyxa_",
        "paper_authors": [
            "Hila Chefer",
            "Idan Schwartz",
            "Lior Wolf"
        ],
        "paper_abstract": "It has been observed that visual classification models often rely mostly on spurious cues such as the image background, which hurts their robustness to distribution changes.  \nTo alleviate this shortcoming, we propose to monitor the model's relevancy signal and direct the model to base its prediction on the foreground object.\nThis is done as a finetuning step, involving relatively few samples consisting of pairs of images and their associated foreground masks. Specifically, we encourage the model's relevancy map (i) to assign lower relevance to background regions, (ii) to consider as much information as possible from the foreground, and (iii) we encourage the decisions to have high confidence. When applied to Vision Transformer (ViT) models, a marked improvement in robustness to domain-shifts is observed. Moreover, the foreground masks can be obtained automatically, from a self-supervised variant of the ViT model itself; therefore no additional supervision is required. Our code is available at: https://github.com/hila-chefer/RobustViT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decision-Focused Learning without Decision-Making: Learning Locally Optimized Decision Losses",
        "paper_url": "https://openreview.net/pdf?id=eN2lQxjWL05",
        "paper_authors": [
            "Sanket Shah",
            "Kai Wang",
            "Bryan Wilder",
            "Andrew Perrault",
            "Milind Tambe"
        ],
        "paper_abstract": "Decision-Focused Learning (DFL) is a paradigm for tailoring a predictive model to a downstream optimization task that uses its predictions in order to perform better \\textit{on that specific task}. The main technical challenge associated with DFL is that it requires being able to differentiate through the optimization problem, which is difficult due to discontinuous solutions and other challenges. Past work has largely gotten around this this issue by \\textit{handcrafting} task-specific surrogates to the original optimization problem that provide informative gradients when differentiated through. However, the need to handcraft surrogates for each new task limits the usability of DFL. In addition, there are often no guarantees about the convexity of the resulting surrogates and, as a result, training a predictive model using them can lead to inferior local optima. In this paper, we do away with surrogates altogether and instead \\textit{learn} loss functions that capture task-specific information. To the best of our knowledge, ours is the first approach that entirely replaces the optimization component of decision-focused learning with a loss that is automatically learned. Our approach (a) only requires access to a black-box oracle that can solve the optimization problem and is thus \\textit{generalizable}, and (b) can be \\textit{convex by construction} and so can be easily optimized over. We evaluate our approach on three resource allocation problems from the literature and find that our approach outperforms learning without taking into account task-structure in all three domains, and even hand-crafted surrogates from the literature.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning General World Models in a Handful of Reward-Free Deployments",
        "paper_url": "https://openreview.net/pdf?id=RuNhbvX9o9S",
        "paper_authors": [
            "Yingchen Xu",
            "Jack Parker-Holder",
            "Aldo Pacchiano",
            "Philip J. Ball",
            "Oleh Rybkin",
            "Stephen J. Roberts",
            "Tim Rockt\u00e4schel",
            "Edward Grefenstette"
        ],
        "paper_abstract": "Building generally capable agents is a grand challenge for deep reinforcement learning (RL). To approach this challenge practically, we outline two key desiderata: 1) to facilitate generalization, exploration should be task agnostic; 2) to facilitate scalability, exploration policies should collect large quantities of data without costly centralized retraining. Combining these two properties, we introduce the reward-free deployment efficiency setting, a new paradigm for RL research. We then present CASCADE, a novel approach for self-supervised exploration in this new setting. CASCADE seeks to learn a world model by collecting data with a population of agents, using an information theoretic objective inspired by Bayesian Active Learning. CASCADE achieves this by specifically maximizing the diversity of trajectories sampled by the population through a novel cascading objective. We provide theoretical intuition for CASCADE which we show in a tabular setting improves upon na\u00efve approaches that do not account for population diversity. We then demonstrate that CASCADE collects diverse task-agnostic datasets and learns agents that generalize zero-shot to novel, unseen downstream tasks on Atari, MiniGrid, Crafter and the DM Control Suite. Code and videos are available at https://ycxuyingchen.github.io/cascade/",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Is a Modular Architecture Enough?",
        "paper_url": "https://openreview.net/pdf?id=3-3XMModtrx",
        "paper_authors": [
            "Sarthak Mittal",
            "Yoshua Bengio",
            "Guillaume Lajoie"
        ],
        "paper_abstract": "Inspired from human cognition, machine learning systems are gradually revealing advantages of sparser and more modular architectures. Recent work demonstrates that not only do some modular architectures generalize well, but they also lead to better out of distribution generalization, scaling properties, learning speed, and interpretability. A key intuition behind the success of such systems is that the data generating system for most real-world settings is considered to consist of sparse modular connections, and endowing models with similar inductive biases will be helpful. However, the field has been lacking in a rigorous quantitative assessment of such systems because these real-world data distributions are complex and unknown. In this work, we provide a thorough assessment of common modular architectures, through the lens of simple and known modular data distributions. We highlight the benefits of modularity and sparsity and reveal insights on the challenges faced while optimizing modular systems. In doing so, we propose evaluation metrics that highlight the benefits of modularity, the regimes in which these benefits are substantial, as well as the sub-optimality of current end-to-end learned modular systems as opposed to their claimed potential.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Differentially Private Model Compression",
        "paper_url": "https://openreview.net/pdf?id=68EuccCtO5i",
        "paper_authors": [
            "Fatemehsadat Mireshghallah",
            "Arturs Backurs",
            "Huseyin A Inan",
            "Lukas Wutschitz",
            "Janardhan Kulkarni"
        ],
        "paper_abstract": "Recent papers have shown that large pre-trained language models (LLMs) such as BERT, GPT-2 can be fine-tuned on private data to achieve performance comparable to non-private models for many downstream Natural Language Processing (NLP) tasks while simultaneously guaranteeing differential privacy. The inference cost of these models -- which consist of hundreds of millions of parameters -- however, can be prohibitively large.  Hence, often in practice, LLMs are compressed before they are deployed in specific applications. In this paper, we initiate the study of differentially private model compression and propose frameworks for achieving 50% sparsity levels while maintaining nearly full performance. We demonstrate these ideas on standard GLUE benchmarks using BERT models, setting benchmarks for future research on this topic.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering",
        "paper_url": "https://openreview.net/pdf?id=wwyiEyK-G5D",
        "paper_authors": [
            "Leroy Lin",
            "Yujia Xie",
            "Dongdong Chen",
            "Yichong Xu",
            "Chenguang Zhu",
            "Lu Yuan"
        ],
        "paper_abstract": "This paper revisits visual representation in knowledge-based visual question answering (VQA) and demonstrates that using regional information in a better way can significantly improve the performance. While visual representation is extensively studied in  traditional VQA, it is under-explored in knowledge-based VQA even though these two tasks share the common spirit, i.e., rely on visual input to answer the question. Specifically, we observe in most state-of-the-art knowledge-based VQA methods: 1) visual features are  extracted either from the whole image or in a sliding window manner for retrieving knowledge, and the important relationship within/among object regions is neglected; 2) visual features are not well utilized in the final answering model, which is counter-intuitive to some extent. Based on these observations, we propose a new knowledge-based VQA method REVIVE, which tries to utilize the explicit information of object regions not only in the knowledge retrieval stage but also in the answering model. The key motivation is that object regions and inherent relationship are important for knowledge-based VQA. We perform extensive experiments on the standard OK-VQA dataset and achieve new state-of the-art performance, i.e., 58.0 accuracy, surpassing previous state-of-the-art method by a large margin (+3.6%). We also conduct detailed analysis and show the necessity of regional information in different framework components for knowledge-based VQA. Code is publicly available at https://github.com/yzleroy/REVIVE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generative Neural Articulated Radiance Fields",
        "paper_url": "https://openreview.net/pdf?id=_keb_XuP5oI",
        "paper_authors": [
            "Alexander William Bergman",
            "Petr Kellnhofer",
            "Wang Yifan",
            "Eric Ryan Chan",
            "David B. Lindell",
            "Gordon Wetzstein"
        ],
        "paper_abstract": "Unsupervised learning of 3D-aware generative adversarial networks (GANs) using only collections of single-view 2D photographs has very recently made much progress. These 3D GANs, however, have not been demonstrated for human bodies and the generated radiance fields of existing frameworks are not directly editable, limiting their applicability in downstream tasks. We propose a solution to these challenges by developing a 3D GAN framework that learns to generate radiance fields of human bodies or faces in a canonical pose and warp them using an explicit deformation field into a desired body pose or facial expression. Using our framework, we demonstrate the first high-quality radiance field generation results for human bodies. Moreover, we show that our deformation-aware training procedure significantly improves the quality of generated bodies or faces when editing their poses or facial expressions compared to a 3D GAN that is not trained with explicit deformations.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Individualized Treatment Rules with Many Treatments: A Supervised Clustering Approach Using Adaptive Fusion",
        "paper_url": "https://openreview.net/pdf?id=nYrFghNHzz",
        "paper_authors": [
            "Haixu Ma",
            "Donglin Zeng",
            "Yufeng Liu"
        ],
        "paper_abstract": "Learning an optimal Individualized Treatment Rule (ITR) is a very important problem in precision medicine. This paper is concerned with the challenge when the number of treatment arms is large, and some groups of treatments in the large treatment space may work similarly for the patients. Motivated by the recent development of supervised clustering, we propose a novel adaptive fusion based method to cluster the treatments with similar treatment effects together and estimate the optimal ITR simultaneously through a single convex optimization. The problem is formulated as balancing \\textit{loss}$+$\\textit{penalty} terms with a tuning parameter, which allows the entire solution path of the treatment clustering process to be clearly visualized hierarchically. For computation, we propose an efficient  algorithm based on  accelerated proximal gradient and further conduct a novel group-lasso based algorithm for variable selection to boost the performance. Moreover, we demonstrate the theoretical guarantee of recovering the underlying true clustering structure of the treatments for our method. Finally, we demonstrate the superior performance of our method via both simulations and a real data application on cancer treatment, which may assist the decision making process for doctors.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=sipwrPCrIS",
        "paper_authors": [
            "Blake Bordelon",
            "Cengiz Pehlevan"
        ],
        "paper_abstract": "We analyze feature learning in infinite-width neural networks trained with gradient flow through a self-consistent dynamical field theory. We construct a collection of deterministic dynamical order parameters which are inner-product kernels for hidden unit activations and gradients in each layer at pairs of time points, providing a reduced description of network activity through training. These kernel order parameters collectively define the hidden layer activation distribution, the evolution of the neural tangent kernel, and consequently output predictions. We show that the field theory derivation recovers the recursive stochastic process of infinite-width feature learning networks obtained from Yang & Hu with Tensor Programs. For deep linear networks, these kernels satisfy a set of algebraic matrix equations. For nonlinear networks, we provide an alternating sampling procedure to self-consistently solve for the kernel order parameters. We provide comparisons of the self-consistent solution to various approximation schemes including the static NTK approximation, gradient independence assumption, and leading order perturbation theory, showing that each of these approximations can break down in regimes where general self-consistent solutions still provide an accurate description. Lastly, we provide experiments in more realistic settings which demonstrate that the loss and kernel dynamics of CNNs at fixed feature learning strength is preserved across different widths on a CIFAR classification task.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parametrically Retargetable Decision-Makers Tend To Seek Power",
        "paper_url": "https://openreview.net/pdf?id=GFgjnk2Q-ju",
        "paper_authors": [
            "Alexander Matt Turner",
            "Prasad Tadepalli"
        ],
        "paper_abstract": "If capable AI agents are generally incentivized to seek power in service of the objectives we specify for them, then these systems will pose enormous risks, in addition to enormous benefits. In fully observable environments, most reward functions have an optimal policy which seeks power by keeping options open and staying alive. However, the real world is neither fully observable, nor must trained agents be even approximately reward-optimal. We consider a range of models of AI decision-making, from optimal, to random, to choices informed by learning and interacting with an environment. We discover that many decision-making functions are retargetable, and that retargetability is sufficient to cause power-seeking tendencies. Our functional criterion is simple and broad. We show that a range of qualitatively dissimilar decision-making procedures incentivize agents to seek power. We demonstrate the flexibility of our results by reasoning about learned policy incentives in Montezuma's Revenge. These results suggest a safety risk: Eventually, retargetable training procedures may train real-world agents which seek power over humans.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bayesian Persuasion for Algorithmic Recourse",
        "paper_url": "https://openreview.net/pdf?id=Z6BFQqzwuS4",
        "paper_authors": [
            "Keegan Harris",
            "Valerie Chen",
            "Joon Sik Kim",
            "Ameet Talwalkar",
            "Hoda Heidari",
            "Steven Wu"
        ],
        "paper_abstract": "When subjected to automated decision-making, decision subjects may strategically modify their observable features in ways they believe will maximize their chances of receiving a favorable decision. In many practical situations, the underlying assessment rule is deliberately kept secret to avoid gaming and maintain competitive advantage. The resulting opacity forces the decision subjects to rely on incomplete information when making strategic feature modifications. We capture such settings as a game of Bayesian persuasion, in which the decision maker offers a form of recourse to the decision subject by providing them with an action recommendation (or signal) to incentivize them to modify their features in desirable ways. We show that when using persuasion, the decision maker and decision subject are never worse off in expectation, while the decision maker can be significantly better off. While the decision maker\u2019s problem of finding the optimal Bayesian incentive compatible (BIC) signaling policy takes the form of optimization over infinitely many variables, we show that this optimization can be cast as a linear program over finitely-many regions of the space of possible assessment rules. While this reformulation simplifies the problem dramatically, solving the linear program requires reasoning about exponentially-many variables, even in relatively simple cases. Motivated by this observation, we provide a polynomial-time approximation scheme that recovers a near-optimal signaling policy. Finally, our numerical simulations on semi-synthetic data empirically demonstrate the benefits of using persuasion in the algorithmic recourse setting.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Thompson Sampling Efficiently Learns to Control Diffusion Processes",
        "paper_url": "https://openreview.net/pdf?id=kRgOlgFW9aP",
        "paper_authors": [
            "Mohamad Kazem Shirani Faradonbeh",
            "Mohamad Sadegh Shirani Faradonbeh",
            "Mohsen Bayati"
        ],
        "paper_abstract": "Diffusion processes that evolve according to linear stochastic differential equations are an important family of continuous-time dynamic decision-making models. Optimal policies are well-studied for them, under full certainty about the drift matrices. However, little is known about data-driven control of diffusion processes with uncertain drift matrices as conventional discrete-time analysis techniques are not applicable. In addition, while the task can be viewed as a reinforcement learning problem involving exploration and exploitation trade-off, ensuring system stability is a fundamental component of designing optimal policies. We establish that the popular Thompson sampling algorithm learns optimal actions fast, incurring only a square-root of time regret, and also stabilizes the system in a short time period. To the best of our knowledge, this is the first such result for Thompson sampling in a diffusion process control problem. We validate our theoretical results through empirical simulations with real matrices. Moreover, we observe that Thompson sampling significantly improves (worst-case) regret, compared to the state-of-the-art algorithms, suggesting Thompson sampling explores in a more guarded fashion. Our theoretical analysis involves characterization of a certain \\emph{optimality manifold} that ties the local geometry of the drift parameters to the optimal control of the diffusion process. We expect this technique to be of broader interest.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Is this the Right Neighborhood? Accurate and Query Efficient Model Agnostic Explanations",
        "paper_url": "https://openreview.net/pdf?id=lJHkZbX6Ic1",
        "paper_authors": [
            "Amit Dhurandhar",
            "Karthikeyan Natesan Ramamurthy",
            "Karthikeyan Shanmugam"
        ],
        "paper_abstract": "There have been multiple works that try to ascertain explanations for decisions of black box models on particular inputs by perturbing the input or by sampling around it, creating a neighborhood and then fitting a sparse (linear) model (e.g. LIME). Many of these methods are unstable and so more recent work tries to find stable or robust alternatives. However, stable solutions may not accurately represent the behavior of the model around the input. Thus, the question we ask in this paper is are we approximating the local boundary around the input accurately? In particular, are we sampling the right neighborhood so that a linear approximation of the black box is faithful to its true behavior around that input given that the black box can be highly non-linear (viz. deep relu network with many linear pieces). It is difficult to know the correct neighborhood width (or radius) as too small a width can lead to a bad condition number of the inverse covariance matrix of function fitting procedures resulting in unstable predictions, while too large a width may lead to accounting for multiple linear pieces and consequently a poor local approximation. We in this paper propose a simple approach that is robust across neighborhood widths in recovering faithful local explanations. In addition to a naive implementation of our approach which can still be accurate, we propose a novel adaptive neighborhood sampling scheme (ANS) that we formally show can be much more sample and query efficient. We then empirically evaluate our approach on  real data where our explanations are significantly more sample and query efficient than the competitors, while also being faithful and stable across different widths.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Quantitative Geometric Approach to Neural-Network Smoothness",
        "paper_url": "https://openreview.net/pdf?id=ZQcpYaE1z1r",
        "paper_authors": [
            "Zi Wang",
            "Gautam Prakriya",
            "Somesh Jha"
        ],
        "paper_abstract": "Fast and precise Lipschitz constant estimation of neural networks is an important task for deep learning. Researchers have recently found an intrinsic trade-off between the accuracy and smoothness of neural networks, so training a network with a loose Lipschitz constant estimation imposes a strong regularization, and can hurt the model accuracy significantly. In this work, we provide a unified theoretical framework, a quantitative geometric approach, to address the Lipschitz constant estimation. By adopting this framework, we can immediately obtain several theoretical results, including the computational hardness of Lipschitz constant estimation and its approximability. We implement the algorithms induced from this quantitative geometric approach, which are based on semidefinite programming (SDP). Our empirical evaluation demonstrates that they are more scalable and precise than existing tools on Lipschitz constant estimation for $\\ell_\\infty$-perturbations. Furthermore, we also show their intricate relations with other recent SDP-based techniques, both theoretically and empirically. We believe that this unified quantitative geometric perspective can bring new insights and theoretical tools to the investigation of neural-network smoothness and robustness.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SCONE: Surface Coverage Optimization in Unknown Environments by Volumetric Integration",
        "paper_url": "https://openreview.net/pdf?id=foNVYPnQbhk",
        "paper_authors": [
            "Antoine Guedon",
            "Pascal Monasse",
            "Vincent Lepetit"
        ],
        "paper_abstract": "Next Best View computation (NBV) is a long-standing problem in robotics, and consists in identifying the next most informative sensor position(s) for reconstructing a 3D object or scene efficiently and accurately. Like most current methods, we consider NBV prediction from a depth sensor like Lidar systems. Learning-based methods relying on a volumetric representation of the scene are suitable for path planning, but have lower accuracy than methods using a surface-based representation. However, the latter do not scale well with the size of the scene and constrain the camera to a small number of poses. To obtain the advantages of both representations, we show that we can maximize surface metrics by Monte Carlo integration over a volumetric representation. In particular, we propose an approach, SCONE, that relies on two neural modules: The first module predicts occupancy probability in the entire volume of the scene. Given any new camera pose, the second module samples points in the scene based on their occupancy probability and leverages a self-attention mechanism to predict the visibility of the samples. Finally, we integrate the visibility to evaluate the gain in surface coverage for the new camera pose. NBV is selected as the pose that maximizes the gain in total surface coverage. Our method scales to large scenes and handles free camera motion: It takes as input an arbitrarily large point cloud gathered by a depth sensor as well as camera poses to predict NBV. We demonstrate our approach on a novel dataset made of large and complex 3D scenes.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Respecting Transfer Gap in Knowledge Distillation",
        "paper_url": "https://openreview.net/pdf?id=jQR9YF2-Jhg",
        "paper_authors": [
            "Yulei Niu",
            "Long Chen",
            "Chang Zhou",
            "Hanwang Zhang"
        ],
        "paper_abstract": "Knowledge distillation (KD) is essentially a process of transferring a teacher model's behavior, e.g., network response, to a student model. The network response serves as additional supervision to formulate the machine domain, which uses the data collected from the human domain as a transfer set. Traditional KD methods hold an underlying assumption that the data collected in both human domain and machine domain are both independent and identically distributed (IID). We point out that this naive assumption is unrealistic and there is indeed a transfer gap between the two domains. Although the gap offers the student model external knowledge from the machine domain, the imbalanced teacher knowledge would make us incorrectly estimate how much to transfer from teacher to student per sample on the non-IID transfer set. To tackle this challenge, we propose Inverse Probability Weighting Distillation (IPWD) that estimates the propensity of a training sample belonging to the machine domain, and assigns its inverse amount to compensate for under-represented samples. Experiments on CIFAR-100 and ImageNet demonstrate the effectiveness of \\ours~for both two-stage distillation and one-stage self-distillation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized One-shot Domain Adaptation of Generative Adversarial Networks",
        "paper_url": "https://openreview.net/pdf?id=mfxq7BrMfga",
        "paper_authors": [
            "Zicheng Zhang",
            "Yinglu Liu",
            "Congying Han",
            "Tiande Guo",
            "Ting Yao",
            "Tao Mei"
        ],
        "paper_abstract": "The adaptation of a Generative Adversarial Network (GAN) aims to transfer a pre-trained GAN to a target domain with limited training data. In this paper, we focus on the one-shot case, which is more challenging and rarely explored in previous works. We consider that the adaptation from a source domain to a target domain can be decoupled into two parts: the transfer of global style like texture and color, and the emergence of new entities that do not belong to the source domain. While previous works mainly focus on style transfer, we propose a novel and concise framework to address the \\textit{generalized one-shot adaptation} task for both style and entity transfer, in which a reference image and its binary entity mask are provided. Our core idea is to constrain the gap between the internal distributions of the reference and syntheses by sliced Wasserstein distance. To better achieve it, style fixation is used at first to roughly obtain the exemplary style, and an auxiliary network is introduced to the generator to disentangle entity and style transfer. Besides, to realize cross-domain correspondence, we propose the variational Laplacian regularization to constrain the smoothness of the adapted generator. Both quantitative and qualitative experiments demonstrate the effectiveness of our method in various scenarios. Code is available at \\url{https://github.com/zhangzc21/Generalized-One-shot-GAN-adaptation}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Random Sharpness-Aware Minimization",
        "paper_url": "https://openreview.net/pdf?id=htUvh7xPoa",
        "paper_authors": [
            "Yong Liu",
            "Siqi Mai",
            "Minhao Cheng",
            "Xiangning Chen",
            "Cho-Jui Hsieh",
            "Yang You"
        ],
        "paper_abstract": "Currently, Sharpness-Aware Minimization (SAM) is proposed to seek the parameters that lie in a flat region to improve the generalization when training neural networks. In particular, a minimax optimization objective is defined to find the maximum loss value centered on the weight, out of the purpose of simultaneously minimizing loss value and loss sharpness. For the sake of simplicity, SAM applies one-step gradient ascent to approximate the solution of the inner maximization.  However, one-step gradient ascent may not be sufficient and multi-step gradient ascents will cause additional training costs.  Based on this observation, we propose a novel random smoothing based SAM (R-SAM) algorithm. To be specific, R-SAM essentially smooths the loss landscape, based on which we are able to apply the one-step gradient ascent on the smoothed weights to improve the approximation of the inner maximization. Further, we evaluate our proposed R-SAM on CIFAR and ImageNet datasets. The experimental results illustrate that R-SAM can consistently improve the performance on ResNet and Vision Transformer (ViT) training. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Expediting Large-Scale Vision Transformer for Dense Prediction without Fine-tuning",
        "paper_url": "https://openreview.net/pdf?id=9ND8fMUzOAr",
        "paper_authors": [
            "Weicong Liang",
            "Yuhui Yuan",
            "Henghui Ding",
            "Xiao Luo",
            "Weihong Lin",
            "Ding Jia",
            "Zheng Zhang",
            "Chao Zhang",
            "Han Hu"
        ],
        "paper_abstract": "Vision transformers have recently achieved competitive results across various vision tasks but still suffer from heavy computation costs when processing a large number of tokens. Many advanced approaches have been developed to reduce the total number of tokens in the large-scale vision transformers, especially for image classification tasks. Typically, they select a small group of essential tokens according to their relevance with the [\\texttt{class}] token, then fine-tune the weights of the vision transformer. Such fine-tuning is less practical for dense prediction due to the much heavier computation and GPU memory cost than image classification.\n\nIn this paper, we focus on a more challenging problem, \\ie, accelerating large-scale vision transformers for dense prediction without any additional re-training or fine-tuning. In response to the fact that high-resolution representations are necessary for dense prediction, we present two non-parametric operators, a \\emph{token clustering layer} to decrease the number of tokens and a \\emph{token reconstruction layer} to increase the number of tokens. The following steps are performed to achieve this: (i) we use the token clustering layer to cluster the neighboring tokens together, resulting in low-resolution representations that maintain the spatial structures; (ii) we apply the following transformer layers only to these low-resolution representations or clustered tokens; and (iii) we use the token reconstruction layer to re-create the high-resolution representations from the refined low-resolution representations. The results obtained by our method are promising on five dense prediction tasks including object detection, semantic segmentation, panoptic segmentation, instance segmentation, and depth estimation. Accordingly, our method accelerates $40\\%\\uparrow$ FPS and saves $30\\%\\downarrow$ GFLOPs of ``Segmenter+ViT-L/$16$'' while maintaining $99.5\\%$ of the performance on ADE$20$K without fine-tuning the official weights.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "When Privacy Meets Partial Information: A Refined Analysis of Differentially Private Bandits",
        "paper_url": "https://openreview.net/pdf?id=TjVU5Lipt8F",
        "paper_authors": [
            "Achraf Azize",
            "Debabrota Basu"
        ],
        "paper_abstract": "We study the problem of multi-armed bandits with \u03b5-global Differential Privacy (DP). First, we prove the minimax and problem-dependent regret lower bounds for stochastic and linear bandits that quantify the hardness of bandits with \u03b5-global DP. These bounds suggest the existence of two hardness regimes depending on the privacy budget \u03b5. In the high-privacy regime (small \u03b5), the hardness depends on a coupled effect of privacy and partial information about the reward distributions. In the low-privacy regime (large \u03b5), bandits with \u03b5-global DP are not harder than the bandits without privacy. For stochastic bandits, we further propose a generic framework to design a near-optimal \u03b5 global DP extension of an index-based optimistic bandit algorithm. The framework consists of three ingredients: the Laplace mechanism, arm-dependent adaptive episodes, and usage of only the rewards collected in the last episode for computing private statistics. Specifically, we instantiate \u03b5-global DP extensions of UCB and KL-UCB algorithms, namely AdaP-UCB and AdaP-KLUCB. AdaP-KLUCB is the first algorithm that both satisfies \u03b5-global DP and yields a regret upper bound that matches the problem-dependent lower bound up to multiplicative constants.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What is Where by Looking: Weakly-Supervised Open-World Phrase-Grounding without Text Inputs",
        "paper_url": "https://openreview.net/pdf?id=uOQNvEfjpaC",
        "paper_authors": [
            "Tal Shaharabany",
            "Yoad Tewel",
            "Lior Wolf"
        ],
        "paper_abstract": "Given an input image, and nothing else, our method returns the bounding boxes of objects in the image and phrases that describe the objects. This is achieved within an open world paradigm, in which the objects in the input image may not have been encountered during the training of the localization mechanism. Moreover, training takes place in a weakly supervised setting, where no bounding boxes are provided. To achieve this, our method combines two pre-trained networks: the CLIP image-to-text matching score and the BLIP image captioning tool. Training takes place on COCO images and their captions and is based on CLIP. Then, during inference, BLIP is used to generate a hypothesis regarding various regions of the current image. Our work generalizes weakly supervised segmentation and phrase grounding and is shown empirically to outperform the state of the art in both domains. It also shows very convincing results in the novel task of weakly-supervised open-world purely visual phrase-grounding presented in our work.\nFor example, on the datasets used for benchmarking phrase-grounding, our method results in a very modest degradation in comparison to methods that employ human captions as an additional input.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SAPA: Similarity-Aware Point Affiliation for Feature Upsampling",
        "paper_url": "https://openreview.net/pdf?id=hFni381edL",
        "paper_authors": [
            "Hao Lu",
            "Wenze Liu",
            "Zixuan Ye",
            "Hongtao Fu",
            "Yuliang Liu",
            "Zhiguo Cao"
        ],
        "paper_abstract": "We introduce point affiliation into feature upsampling, a notion that describes the affiliation of each upsampled point to a semantic cluster formed by local decoder feature points with semantic similarity. By rethinking point affiliation, we present a generic formulation for generating upsampling kernels. The kernels encourage not only semantic smoothness but also boundary sharpness in the upsampled feature maps. Such properties are particularly useful for some dense prediction tasks such as semantic segmentation. The key idea of our formulation is to generate similarity-aware kernels by comparing the similarity between each encoder feature point and the spatially associated local region of decoder features. In this way, the encoder feature point can function as a cue to inform the semantic cluster of upsampled feature points. To embody the formulation, we further instantiate a lightweight upsampling operator, termed Similarity-Aware Point Affiliation (SAPA), and investigate its variants. SAPA invites consistent performance improvements on a number of dense prediction tasks, including semantic segmentation, object detection, depth estimation, and image matting. Code is available at: https://github.com/poppinace/sapa",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections",
        "paper_url": "https://openreview.net/pdf?id=iQpaHC7cPfR",
        "paper_authors": [
            "Mark Boss",
            "Andreas Engelhardt",
            "Abhishek Kar",
            "Yuanzhen Li",
            "Deqing Sun",
            "Jonathan T. Barron",
            "Hendrik Lensch",
            "Varun Jampani"
        ],
        "paper_abstract": "Inverse rendering of an object under entirely unknown capture conditions is a fundamental challenge in computer vision and graphics. Neural approaches such as NeRF have achieved photorealistic results on novel view synthesis, but they require known camera poses. Solving this problem with unknown camera poses is highly challenging as it requires joint optimization over shape, radiance, and pose. This problem is exacerbated when the input images are captured in the wild with varying backgrounds and illuminations. Standard pose estimation techniques fail in such image collections in the wild due to very few estimated correspondences across images. Furthermore, NeRF cannot relight a scene under any illumination, as it operates on radiance (the product of reflectance and illumination). We propose a joint optimization framework to estimate the shape,  BRDF, and per-image camera pose and illumination. Our method works on in-the-wild online image collections of an object and produces relightable 3D assets for several use-cases such as AR/VR. To our knowledge, our method is the first to tackle this severely unconstrained task with minimal user interaction.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Laplacian Eigenmaps",
        "paper_url": "https://openreview.net/pdf?id=HjicdpP-Nth",
        "paper_authors": [
            "Hao Zhu",
            "Piotr Koniusz"
        ],
        "paper_abstract": "Graph contrastive learning attracts/disperses node representations for similar/dissimilar node pairs under some notion of similarity. It may be combined with a low-dimensional embedding of nodes to preserve intrinsic and structural properties of a graph. COLES, a recent graph contrastive method combines traditional graph embedding and negative sampling into one framework. COLES in fact minimizes the trace difference between the within-class scatter matrix encapsulating the graph connectivity and the total scatter matrix encapsulating negative sampling. In this paper, we propose a more essential framework for graph embedding, called Generalized Laplacian EigeNmaps (GLEN), which learns a graph representation by maximizing the rank difference between the  total scatter matrix and the within-class scatter matrix, resulting in the minimum class separation guarantee. However, the rank difference minimization is an NP-hard problem. Thus, we replace the trace difference that corresponds to the difference of nuclear norms by the difference of LogDet expressions, which we argue is a more accurate surrogate for the NP-hard rank difference than the trace difference.  While enjoying a lesser computational cost, the difference of LogDet terms is lower-bounded by the Affine-invariant Riemannian metric (AIRM) and  Jesen-Bregman the LogDet Divergence (JBLD), and upper-bounded by AIRM scaled by the factor of $\\sqrt{m}$. We show that GLEN offers favourable accuracy/scalability compared to  state-of-the-art baselines.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PatchComplete: Learning Multi-Resolution Patch Priors for 3D Shape Completion on Unseen Categories",
        "paper_url": "https://openreview.net/pdf?id=g_bqn4ewVG",
        "paper_authors": [
            "Yuchen Rao",
            "Yinyu Nie",
            "Angela Dai"
        ],
        "paper_abstract": "While 3D shape representations enable powerful reasoning in many visual and perception applications, learning  3D shape priors tends to be constrained to the specific categories trained on, leading to an inefficient learning process, particularly for general applications with unseen categories. Thus, we propose PatchComplete, which learns effective shape priors based on multi-resolution local patches, which are often more general than full shapes (e.g., chairs and tables often both share legs) and thus enable geometric reasoning about unseen class categories. To learn these shared substructures, we learn multi-resolution patch priors across all train categories, which are then associated to input partial shape observations by attention across the patch priors, and finally decoded into a complete shape reconstruction. Such patch-based priors avoid overfitting to specific train categories and enable reconstruction on entirely unseen categories at test time. We demonstrate the effectiveness of our approach on synthetic ShapeNet data as well as challenging real-scanned objects from ScanNet, which include noise and clutter, improving over state of the art in novel-category shape completion by 19.3% in chamfer distance on ShapeNet, and 9.0% for ScanNet.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Shape Deformation Priors",
        "paper_url": "https://openreview.net/pdf?id=pkfpkWU536D",
        "paper_authors": [
            "Jiapeng Tang",
            "Lev Markhasin",
            "Bi Wang",
            "Justus Thies",
            "Matthias Nie\u00dfner"
        ],
        "paper_abstract": "We present Neural Shape Deformation Priors, a novel method for shape manipulation that predicts mesh deformations of non-rigid objects from user-provided handle movements. State-of-the-art methods cast this problem as an optimization task, where the input source mesh is iteratively deformed to minimize an objective function according to hand-crafted regularizers such as ARAP. In this work, we learn the deformation behavior based on the underlying geometric properties of a shape, while leveraging a large-scale dataset containing a diverse set of non-rigid deformations. Specifically, given a source mesh and desired target locations of handles that describe the partial surface deformation, we predict a continuous deformation field that is defined in 3D space to describe the space deformation. To this end, we introduce transformer-based deformation networks that represent a shape deformation as a composition of local surface deformations. It learns a set of local latent codes anchored in 3D space, from which we can learn a set of continuous deformation functions for local surfaces. \nOur method can be applied to challenging deformations and generalizes well to unseen deformations. We validate our approach in experiments using the DeformingThing4D dataset, and compare to both classic optimization-based and recent neural network-based methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Retrieval-Augmented Diffusion Models",
        "paper_url": "https://openreview.net/pdf?id=Bqk9c0wBNrZ",
        "paper_authors": [
            "Andreas Blattmann",
            "Robin Rombach",
            "Kaan Oktay",
            "Jonas M\u00fcller",
            "Bj\u00f6rn Ommer"
        ],
        "paper_abstract": "Novel architectures have recently improved generative image synthesis leading to excellent visual quality in various tasks. Much of this success is due to the scalability of these architectures and hence caused by a dramatic increase in model complexity and in the computational resources invested in training these models. Our work questions the underlying paradigm of compressing large training data into ever growing parametric representations. We rather present an orthogonal, semi-parametric approach. We complement comparably small diffusion or autoregressive models with a separate image database and a retrieval strategy. During training we retrieve a set of nearest neighbors from this external database for each training instance and condition the generative model on these informative samples. While the retrieval approach is providing the (local) content, the model is focusing on learning the composition of scenes based on this content. As demonstrated by our experiments, simply swapping the database for one with different contents transfers a trained model post-hoc to a novel domain. The evaluation shows competitive performance on tasks which the generative model has not been trained on, such as class-conditional synthesis, zero-shot stylization or text-to-image synthesis without requiring paired text-image data. With negligible memory and computational overhead for the external database and retrieval we can significantly reduce the parameter count of the generative model and still outperform the state-of-the-art.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recommender Forest for Efficient Retrieval",
        "paper_url": "https://openreview.net/pdf?id=Yc4MjP2Mnob",
        "paper_authors": [
            "Chao Feng",
            "Wuchao Li",
            "Defu Lian",
            "Zheng Liu",
            "Enhong Chen"
        ],
        "paper_abstract": "Recommender systems (RS) have to select the top-N items from a massive item set. For the sake of efficient recommendation, RS usually represents user and item as latent embeddings, and relies on approximate nearest neighbour search (ANNs) to retrieve the recommendation result. Despite the reduction of running time, the representation learning is independent of ANNs index construction; thus, the two operations can be incompatible, which results in potential loss of recommendation accuracy. To overcome the above problem, we propose the Recommender Forest (a.k.a., RecForest), which jointly learns latent embedding and index for efficient and high-fidelity recommendation. RecForest consists of multiple k-ary trees, each of which is a partition of the item set via hierarchical balanced clustering such that each item is uniquely represented by a path from the root to a leaf. Given such a data structure, an encoder-decoder based routing network is developed: it first encodes the context, i.e., user information, into hidden states; then, leveraging a transformer-based decoder, it identifies the top-N items via beam search. Compared with the existing methods, RecForest brings in the following advantages: 1) the false partition of the boundary items can be effectively alleviated by the use of multiple trees; 2) the routing operation becomes much more accurate thanks to the powerful transformer decoder; 3) the tree parameters are shared across different tree levels, making the index to be extremely memory-efficient. The experimental studies are performed on five popular recommendation datasets: with a significantly simplified training cost, RecForest outperforms competitive baseline approaches in terms of both recommendation accuracy and efficiency. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Image Restoration with Blurry and Noisy Pairs",
        "paper_url": "https://openreview.net/pdf?id=lkrnoLxX1Do",
        "paper_authors": [
            "Zhilu Zhang",
            "RongJian Xu",
            "Ming Liu",
            "Zifei Yan",
            "Wangmeng Zuo"
        ],
        "paper_abstract": "When taking photos under an environment with insufficient light, the exposure time and the sensor gain usually require to be carefully chosen to obtain images with satisfying visual quality. For example, the images with high ISO usually have inescapable noise, while the long-exposure ones may be blurry due to camera shake or object motion. Existing solutions generally suggest to seek a balance between noise and blur, and learn denoising or deblurring models under either full- or self-supervision. However, the real-world training pairs are difficult to collect, and the self-supervised methods merely rely on blurry or noisy images are limited in performance. In this work, we tackle this problem by jointly leveraging the short-exposure noisy image and the long-exposure blurry image for better image restoration. Such setting is practically feasible due to that short-exposure and long-exposure images can be either acquired by two individual cameras or synthesized by a long burst of images. Moreover, the short-exposure images are hardly blurry, and the long-exposure ones have negligible noise. Their complementarity makes it feasible to learn restoration model in a self-supervised manner. Specifically, the noisy images can be used as the supervision information for deblurring, while the sharp areas in the blurry images can be utilized as the auxiliary supervision information for self-supervised denoising. By learning in a collaborative manner, the deblurring and denoising tasks in our method can benefit each other. Experiments on synthetic and real-world images show the effectiveness and practicality of the proposed method. Codes are available at https://github.com/cszhilu1998/SelfIR.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Non-asymptotic Analysis of Non-parametric Temporal-Difference Learning",
        "paper_url": "https://openreview.net/pdf?id=dO11Niyc225",
        "paper_authors": [
            "Elo\u00efse Berthier",
            "Ziad Kobeissi",
            "Francis Bach"
        ],
        "paper_abstract": "Temporal-difference learning is a popular algorithm for policy evaluation. In this paper, we study the convergence of the regularized non-parametric TD(0) algorithm, in both the independent and Markovian observation settings. In particular, when TD is performed in a universal reproducing kernel Hilbert space (RKHS), we prove convergence of the averaged iterates to the optimal value function, even when it does not belong to the RKHS. We provide explicit convergence rates that depend on a source condition relating the regularity of the optimal value function to the RKHS. We illustrate this convergence numerically on a simple continuous-state Markov reward process.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Unreasonable Effectiveness of Fully-Connected Layers for Low-Data Regimes",
        "paper_url": "https://openreview.net/pdf?id=_zPG0ShaZTc",
        "paper_authors": [
            "Peter Kocsis",
            "Peter S\u00faken\u00edk",
            "Guillem Braso",
            "Matthias Nie\u00dfner",
            "Laura Leal-Taix\u00e9",
            "Ismail Elezi"
        ],
        "paper_abstract": "Convolutional neural networks were the standard for solving many computer vision tasks until recently, when Transformers of MLP-based architectures have started to show competitive performance. These architectures typically have a vast number of weights and need to be trained on massive datasets; hence, they are not suitable for their use in low-data regimes. In this work, we propose a simple yet effective framework to improve generalization from small amounts of data. We augment modern CNNs with fully-connected (FC) layers and show the massive impact this architectural change has in low-data regimes. We further present an online joint knowledge-distillation method to utilize the extra FC layers at train time but avoid them during test time. This allows us to improve the generalization of a CNN-based model without any increase in the number of weights at test time. We perform classification experiments for a large range of network backbones and several standard datasets on supervised learning and active learning. Our experiments significantly outperform the networks without fully-connected layers, reaching a relative improvement of up to $16\\%$ validation accuracy in the supervised setting without adding any extra parameters during inference. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The alignment property of SGD noise and how it helps select flat minima: A stability analysis",
        "paper_url": "https://openreview.net/pdf?id=rUc8peDIM45",
        "paper_authors": [
            "Lei Wu",
            "Mingze Wang",
            "Weijie J Su"
        ],
        "paper_abstract": "The phenomenon that stochastic gradient descent (SGD) favors flat minima has played a critical role in   understanding the implicit regularization of SGD. In this paper, we provide an explanation of this striking phenomenon by relating the particular noise structure  of SGD to its \\emph{linear stability}  (Wu et al., 2018). Specifically, we consider training over-parameterized models with square loss. We prove that if a global minimum $\\theta^*$ is linearly stable for SGD, then it must satisfy $\\|H(\\theta^*)\\|_F\\leq O(\\sqrt{B}/\\eta)$, where $\\|H(\\theta^*)\\|_F, B,\\eta$ denote the Frobenius norm of Hessian at $\\theta^*$, batch size, and learning rate, respectively. Otherwise, SGD will escape from that minimum \\emph{exponentially} fast. Hence, for minima accessible to SGD, the sharpness---as measured by the Frobenius norm of the Hessian---is bounded \\emph{independently} of the model size and sample size.   The key to obtaining these results is exploiting the particular structure of SGD noise: The noise concentrates in sharp directions of local landscape and  the magnitude is proportional to loss value. This alignment property of SGD noise provably holds for linear networks and random feature models (RFMs), and is empirically verified for nonlinear networks. Moreover, the validity and practical relevance of our theoretical findings are also justified by extensive experiments on CIFAR-10 dataset.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mildly Conservative Q-Learning for Offline Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=VYYf6S67pQc",
        "paper_authors": [
            "Jiafei Lyu",
            "Xiaoteng Ma",
            "Xiu Li",
            "Zongqing Lu"
        ],
        "paper_abstract": "Offline reinforcement learning (RL) defines the task of learning from a static logged dataset without continually interacting with the environment. The distribution shift between the learned policy and the behavior policy makes it necessary for the value function to stay conservative such that out-of-distribution (OOD) actions will not be severely overestimated. However, existing approaches, penalizing the unseen actions or regularizing with the behavior policy, are too pessimistic, which suppresses the generalization of the value function and hinders the performance improvement. This paper explores mild but enough conservatism for offline learning while not harming generalization. We propose Mildly Conservative Q-learning (MCQ), where OOD actions are actively trained by assigning them proper pseudo Q values. We theoretically show that MCQ induces a policy that behaves at least as well as the behavior policy and no erroneous overestimation will occur for OOD actions. Experimental results on the D4RL benchmarks demonstrate that MCQ achieves remarkable performance compared with prior work. Furthermore, MCQ shows superior generalization ability when transferring from offline to online, and significantly outperforms baselines. Our code is publicly available at https://github.com/dmksjfl/MCQ.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Contrastive Neural Ratio Estimation",
        "paper_url": "https://openreview.net/pdf?id=kOIaB1hzaLe",
        "paper_authors": [
            "Benjamin Kurt Miller",
            "Christoph Weniger",
            "Patrick Forr\u00e9"
        ],
        "paper_abstract": "Likelihood-to-evidence ratio estimation is usually cast as either a binary (NRE-A) or a multiclass (NRE-B) classification task. In contrast to the binary classification framework, the current formulation of the multiclass version has an intrinsic and unknown bias term, making otherwise informative diagnostics unreliable. We propose a multiclass framework free from the bias inherent to NRE-B at optimum, leaving us in the position to run diagnostics that practitioners depend on. It also recovers NRE-A in one corner case and NRE-B in the limiting case. For fair comparison, we benchmark the behavior of all algorithms in both familiar and novel training regimes: when jointly drawn data is unlimited, when data is fixed but prior draws are unlimited, and in the commonplace fixed data and parameters setting. Our investigations reveal that the highest performing models are distant from the competitors (NRE-A, NRE-B) in hyperparameter space. We make a recommendation for hyperparameters distinct from the previous models. We suggest a bound on the mutual information as a performance metric for simulation-based inference methods, without the need for posterior samples, and provide experimental results.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Muffliato: Peer-to-Peer Privacy Amplification for Decentralized Optimization and Averaging",
        "paper_url": "https://openreview.net/pdf?id=QotmVXC-8T",
        "paper_authors": [
            "Edwige Cyffers",
            "Mathieu Even",
            "Aur\u00e9lien Bellet",
            "Laurent Massouli\u00e9"
        ],
        "paper_abstract": "Decentralized optimization is increasingly popular in machine learning for its scalability and efficiency. Intuitively, it should also provide better privacy guarantees, as nodes only observe the messages sent by their neighbors in the network graph. But formalizing and quantifying this gain is challenging: existing results are typically limited to Local Differential Privacy (LDP) guarantees that overlook the advantages of decentralization. In this work, we introduce pairwise network differential privacy, a relaxation of LDP that captures the fact that the privacy leakage from a node u to a node v may depend on their relative position in the graph. We then analyze the combination of local noise injection with (simple or randomized) gossip averaging protocols on fixed and random communication graphs. We also derive a differentially private decentralized optimization algorithm that alternates between local gradient descent steps and gossip averaging. Our results show that our algorithms amplify privacy guarantees as a function of the distance between nodes in the graph, matching the privacy-utility trade-off of the trusted curator, up to factors that explicitly depend on the graph topology. Remarkably, these factors become constant for expander graphs. Finally, we illustrate our privacy gains with experiments on synthetic and real-world datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UniGAN: Reducing Mode Collapse in GANs using a Uniform Generator",
        "paper_url": "https://openreview.net/pdf?id=IPcgkUgw3t1",
        "paper_authors": [
            "Ziqi Pan",
            "Li Niu",
            "Liqing Zhang"
        ],
        "paper_abstract": "Despite the significant progress that has been made in the training of Generative Adversarial Networks (GANs), the mode collapse problem remains a major challenge in training GANs, which refers to a lack of diversity in generative samples. In this paper, we propose a new type of generative diversity named uniform diversity, which relates to a newly proposed type of mode collapse named $u$-mode collapse where the generative samples distribute nonuniformly over the data manifold. From a geometric perspective, we show that the uniform diversity is closely related with the generator uniformity property, and the maximum uniform diversity is achieved if the generator is uniform. To learn a uniform generator, we propose UniGAN, a generative framework with a Normalizing Flow based generator and a simple yet sample efficient generator uniformity regularization, which can be easily adapted to any other generative framework. A new type of diversity metric named udiv is also proposed to estimate the uniform diversity given a set of generative samples in practice. Experimental results verify the effectiveness of our UniGAN in learning a uniform generator and improving uniform diversity.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Split-kl and PAC-Bayes-split-kl Inequalities for Ternary Random Variables",
        "paper_url": "https://openreview.net/pdf?id=1WZyphXPLwC",
        "paper_authors": [
            "Yi-Shan Wu",
            "Yevgeny Seldin"
        ],
        "paper_abstract": "We present a new concentration of measure inequality for sums of independent bounded random variables, which we name a split-kl inequality. The inequality combines the combinatorial power of the kl inequality with ability to exploit low variance. While for Bernoulli random variables the kl inequality is tighter than the Empirical Bernstein, for random variables taking values inside a bounded interval and having low variance the Empirical Bernstein inequality is tighter than the kl. The proposed split-kl inequality yields the best of both worlds. We discuss an application of the split-kl inequality to bounding excess losses. We also derive a PAC-Bayes-split-kl inequality and use a synthetic example and several UCI datasets to compare it with the PAC-Bayes-kl, PAC-Bayes Empirical Bernstein, PAC-Bayes Unexpected Bernstein, and PAC-Bayes Empirical Bennett inequalities.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Object Detection Pretraining with Joint Object Priors Generation and Detector Learning",
        "paper_url": "https://openreview.net/pdf?id=CTqkruS5Bb",
        "paper_authors": [
            "Yizhou Wang",
            "Meilin Chen",
            "SHIXIANG TANG",
            "Feng Zhu",
            "Haiyang Yang",
            "LEI BAI",
            "Rui Zhao",
            "Yunfeng Yan",
            "Donglian Qi",
            "Wanli Ouyang"
        ],
        "paper_abstract": "Unsupervised pretraining methods for object detection aim to learn object discrimination and localization ability from large amounts of images. Typically, recent works design pretext tasks that supervise the detector to predict the defined object priors. They normally leverage heuristic methods to produce object priors, \\emph{e.g.,} selective search, which separates the prior generation and detector learning and leads to sub-optimal solutions. In this work, we propose a novel object detection pretraining framework that could generate object priors and learn detectors jointly by generating accurate object priors from the model itself. Specifically, region priors are extracted by attention maps from the encoder, which highlights foregrounds. Instance priors are the selected high-quality output bounding boxes of the detection decoder. By assuming objects as instances in the foreground, we can generate object priors with both region and instance priors. Moreover, our object priors are jointly refined along with the detector optimization. With better object priors as supervision, the model could achieve better detection capability, which in turn promotes the object priors generation. Our method improves the competitive approaches by \\textbf{+1.3 AP}, \\textbf{+1.7 AP} in 1\\% and 10\\% COCO low-data regimes object detection. \n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Margins and Generalisation for Voting Classifiers",
        "paper_url": "https://openreview.net/pdf?id=xvLWypz8p8",
        "paper_authors": [
            "Felix Biggs",
            "Valentina Zantedeschi",
            "Benjamin Guedj"
        ],
        "paper_abstract": "We study the generalisation properties of majority voting on finite ensembles of classifiers, proving margin-based generalisation bounds via the PAC-Bayes theory. These provide state-of-the-art guarantees on a number of classification tasks. Our central results leverage the Dirichlet posteriors studied recently by Zantedeschi et al. (2021) for training voting classifiers; in contrast to that work our bounds apply to non-randomised votes via the use of margins. Our contributions add perspective to the debate on the ``margins theory'' proposed by Schapire et al. (1998) for the generalisation of ensemble classifiers.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Open-Ended Reinforcement Learning with Neural Reward Functions",
        "paper_url": "https://openreview.net/pdf?id=NL05_JGVg99",
        "paper_authors": [
            "Robert Meier",
            "Asier Mujika"
        ],
        "paper_abstract": "Inspired by the great success of unsupervised learning in Computer Vision and Natural Language Processing, the Reinforcement Learning community has recently started to focus more on unsupervised discovery of skills. Most current approaches, like DIAYN or DADS, optimize some form of mutual information objective. We propose a different approach that uses reward functions encoded by neural networks. These are trained iteratively to reward more complex behavior. In high-dimensional robotic environments our approach learns a wide range of interesting skills including front-flips for Half-Cheetah and one-legged running for Humanoid. It is the first skill discovery algorithm that can learn such skills without relying on any form of feature engineering. In the pixel-based Montezuma's Revenge environment our method also works with minimal changes and it learns complex skills that involve interacting with items and visiting diverse locations.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Alignment-guided Temporal Attention for Video Action Recognition",
        "paper_url": "https://openreview.net/pdf?id=pcgMNVhRslj",
        "paper_authors": [
            "Yizhou Zhao",
            "Zhenyang Li",
            "Xun Guo",
            "Yan Lu"
        ],
        "paper_abstract": "Temporal modeling is crucial for various video learning tasks. Most recent approaches employ either factorized (2D+1D) or joint (3D) spatial-temporal operations to extract temporal contexts from the input frames. While the former is more efficient in computation, the latter often obtains better performance. In this paper, we attribute this to a dilemma between the sufficiency and the efficiency of interactions among various positions in different frames. These interactions affect the extraction of task-relevant information shared among frames. To resolve this issue, we prove that frame-by-frame alignments have the potential to increase the mutual information between frame representations, thereby including more task-relevant information to boost effectiveness. Then we propose Alignment-guided Temporal Attention (ATA) to extend 1-dimensional temporal attention with parameter-free patch-level alignments between neighboring frames. It can act as a general plug-in for image backbones to conduct the action recognition task without any model-specific design. Extensive experiments on multiple benchmarks demonstrate the superiority and generality of our module.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework",
        "paper_url": "https://openreview.net/pdf?id=zzDrPqn57DL",
        "paper_authors": [
            "Tingting Liang",
            "Hongwei Xie",
            "Kaicheng Yu",
            "Zhongyu Xia",
            "Zhiwei Lin",
            "Yongtao Wang",
            "Tao Tang",
            "Bing Wang",
            "Zhi Tang"
        ],
        "paper_abstract": "Fusing the camera and LiDAR information has become a de-facto standard for 3D object detection tasks. Current methods rely on point clouds from the LiDAR sensor as queries to leverage the feature from the image space. However, people discovered that this underlying assumption makes the current fusion framework infeasible to produce any prediction when there is a LiDAR malfunction, regardless of minor or major. This fundamentally limits the deployment capability to realistic autonomous driving scenarios. In contrast, we propose a surprisingly simple yet novel fusion framework, dubbed BEVFusion, whose camera stream does not depend on the input of LiDAR data, thus addressing the downside of previous methods. We empirically show that our framework surpasses the state-of-the-art methods under the normal training settings. Under the robustness training settings that simulate various LiDAR malfunctions, our framework significantly surpasses the state-of-the-art methods by 15.7% to 28.9% mAP. To the best of our knowledge, we are the first to handle realistic LiDAR malfunction and can be deployed to realistic scenarios without any post-processing procedure. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Active Learning for Multiple Target Models",
        "paper_url": "https://openreview.net/pdf?id=-V1ITIKPH6",
        "paper_authors": [
            "Ying-Peng Tang",
            "Sheng-Jun Huang"
        ],
        "paper_abstract": "We describe and explore a novel setting of active learning (AL), where there are multiple target models to be learned simultaneously. In many real applications, the machine learning system is required to be deployed on diverse devices with varying computational resources (e.g., workstation, mobile phone, edge devices, etc.), which leads to the demand of training multiple target models on the same labeled dataset. However, it is generally believed that AL is model-dependent and untransferable, i.e., the data queried by one model may be less effective for training another model. This phenomenon naturally raises a question \"Does there exist an AL method that is effective for multiple target models?\" In this paper, we answer this question by theoretically analyzing the label complexity of active and passive learning under the setting with multiple target models, and conclude that AL does have potential to achieve better label complexity under this novel setting. Based on this insight, we further propose an agnostic AL sampling strategy to select the examples located in the joint disagreement regions of different target models. The experimental results on the OCR benchmarks show that the proposed method can significantly surpass the traditional active and passive learning methods under this challenging setting.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence",
        "paper_url": "https://openreview.net/pdf?id=bZzS_kkJes",
        "paper_authors": [
            "Sunghwan Hong",
            "Ji Su Nam",
            "Seokju Cho",
            "Susung Hong",
            "Sangryul Jeon",
            "Dongbo Min",
            "Seungryong Kim"
        ],
        "paper_abstract": "Existing pipelines of semantic correspondence commonly include extracting high-level semantic features for the invariance against intra-class variations and background clutters. This architecture, however, inevitably results in a low-resolution matching field that additionally requires an ad-hoc interpolation process as a post-processing for converting it into a high-resolution one, certainly limiting the overall performance of matching results. To overcome this, inspired by recent success of implicit neural representation, we present a novel method for semantic correspondence, called Neural Matching Field (NeMF). However, complicacy and high-dimensionality of a 4D matching field are the major hindrances, which we propose a cost embedding network to process a coarse cost volume to use as a guidance for establishing high-precision matching field through the following fully-connected network. Nevertheless, learning a high-dimensional matching field remains challenging mainly due to computational complexity, since a na\\\"ive exhaustive inference would require querying from all pixels in the 4D space to infer pixel-wise correspondences. To overcome this, we propose adequate training and inference procedures, which in the training phase, we randomly sample matching candidates and in the inference phase, we iteratively performs PatchMatch-based inference and coordinate optimization at test time. With these combined, competitive results are attained on several standard benchmarks for semantic correspondence. Code and pre-trained weights are available at~\\url{https://ku-cvlab.github.io/NeMF/}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Beyond Mahalanobis Distance for Textual OOD Detection",
        "paper_url": "https://openreview.net/pdf?id=ReB7CCByD6U",
        "paper_authors": [
            "Pierre Colombo",
            "Eduardo Dadalto C\u00e2mara Gomes",
            "Guillaume Staerman",
            "Nathan Noiry",
            "Pablo Piantanida"
        ],
        "paper_abstract": "As the number of AI systems keeps growing, it is fundamental to implement and develop efficient control mechanisms to ensure the safe and proper functioning of machine learning (ML) systems. Reliable out-of-distribution (OOD) detection aims to detect test samples that are statistically far from the training distribution, as they might cause failures of in-production systems. In this paper, we propose a new detector called TRUSTED. Different from previous works, TRUSTED key components (i) include a novel OOD score relying on the concept of statistical data depth, (ii) rely on the idea\u2019s full potential that all hidden layers of the network carry information regarding OOD. Our extensive experiments, comparing over 51k model configurations including different checkpoints, seed and various datasets, demonstrate that TRUSTED achieve state-of-the-art performances by producing an improvement of over 3 AUROC points.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ZeroC: A Neuro-Symbolic Model for Zero-shot Concept Recognition and Acquisition at Inference Time",
        "paper_url": "https://openreview.net/pdf?id=T7114JzrwB",
        "paper_authors": [
            "Tailin Wu",
            "Megan Tjandrasuwita",
            "Zhengxuan Wu",
            "Xuelin Yang",
            "Kevin Liu",
            "Rok Sosic",
            "Jure Leskovec"
        ],
        "paper_abstract": "Humans have the remarkable ability to recognize and acquire novel visual concepts in a zero-shot manner. Given a high-level, symbolic description of a novel concept in terms of previously learned visual concepts and their relations, humans can recognize novel concepts without seeing any examples. Moreover, they can acquire new concepts by parsing and communicating symbolic structures using learned visual concepts and relations. Endowing these capabilities in machines is pivotal in improving their generalization capability at inference time. In this work, we introduce Zero-shot Concept Recognition and Acquisition (ZeroC), a neuro-symbolic architecture that can recognize and acquire novel concepts in a zero-shot way.  ZeroC represents concepts as graphs of constituent concept models (as nodes) and their relations (as edges). To allow inference time composition, we employ energy-based models (EBMs) to model concepts and relations. We design ZeroC architecture so that it allows a one-to-one mapping between a symbolic graph structure of a concept and its corresponding EBM, which for the first time, allows acquiring new concepts, communicating its graph structure, and applying it to classification and detection tasks (even across domains) at inference time. We introduce algorithms for learning and inference with ZeroC. We evaluate ZeroC on a challenging grid-world dataset which is designed to probe zero-shot concept recognition and acquisition, and demonstrate its capability.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning to Accelerate Partial Differential Equations via Latent Global Evolution",
        "paper_url": "https://openreview.net/pdf?id=xvZtgp5wyYT",
        "paper_authors": [
            "Tailin Wu",
            "Takashi Maruyama",
            "Jure Leskovec"
        ],
        "paper_abstract": "Simulating the time evolution of Partial Differential Equations (PDEs) of large-scale systems is crucial in many scientific and engineering domains such as fluid dynamics, weather forecasting and their inverse optimization problems. However, both classical solvers and recent deep learning-based surrogate models are typically extremely computationally intensive, because of their local evolution: they need to update the state of each discretized cell at each time step during inference. Here we develop Latent Evolution of PDEs (LE-PDE), a simple, fast and scalable method to accelerate the simulation and inverse optimization of PDEs. LE-PDE learns a compact, global representation of the system and efficiently evolves it fully in the latent space with learned latent evolution models. LE-PDE achieves speedup by having a much smaller latent dimension to update during long rollout as compared to updating in the input space. We introduce new learning objectives to effectively learn such latent dynamics to ensure long-term stability. We further introduce techniques for speeding-up inverse optimization of boundary conditions for PDEs via backpropagation through time in latent space, and an annealing technique to address the non-differentiability and sparse interaction of boundary conditions. We test our method in a 1D benchmark of nonlinear PDEs, 2D  Navier-Stokes flows into turbulent phase and an inverse optimization of boundary conditions in 2D Navier-Stokes flow. Compared to state-of-the-art deep learning-based surrogate models and other strong baselines, we demonstrate up to 128x reduction in the dimensions to update, and up to 15x improvement in speed, while achieving competitive accuracy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
        "paper_url": "https://openreview.net/pdf?id=JY6fLgR8Yq",
        "paper_authors": [
            "Dongki Kim",
            "Jinheon Baek",
            "Sung Ju Hwang"
        ],
        "paper_abstract": "Self-supervised learning of graph neural networks (GNNs) aims to learn an accurate representation of the graphs in an unsupervised manner, to obtain transferable representations of them for diverse downstream tasks. Predictive learning and contrastive learning are the two most prevalent approaches for graph self-supervised learning. However, they have their own drawbacks. While the predictive learning methods can learn the contextual relationships between neighboring nodes and edges, they cannot learn global graph-level similarities. Contrastive learning, while it can learn global graph-level similarities, its objective to maximize the similarity between two differently perturbed graphs may result in representations that cannot discriminate two similar graphs with different properties. To tackle such limitations, we propose a framework that aims to learn the exact discrepancy between the original and the perturbed graphs, coined as Discrepancy-based Self-supervised LeArning (D-SLA). Specifically, we create multiple perturbations of the given graph with varying degrees of similarity, and train the model to predict whether each graph is the original graph or the perturbed one. Moreover, we further aim to accurately capture the amount of discrepancy for each perturbed graph using the graph edit distance. We validate our D-SLA on various graph-related downstream tasks, including molecular property prediction, protein function prediction, and link prediction tasks, on which ours largely outperforms relevant baselines.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tikhonov Regularization is Optimal Transport Robust under Martingale Constraints",
        "paper_url": "https://openreview.net/pdf?id=EQgPNPwREa",
        "paper_authors": [
            "Jiajin Li",
            "Sirui Lin",
            "Jose Blanchet",
            "Viet Anh Nguyen"
        ],
        "paper_abstract": "Distributionally robust optimization (DRO) has been shown to offer a principled way to regularize learning models. In this paper, we find that Tikhonov regularization is distributionally robust in an optimal transport sense (i.e. if an adversary chooses distributions in a suitable optimal transport neighborhood of the empirical measure), provided that suitable martingale constraints are also imposed. Further, we introduce a relaxation of the martingale constraints which not only provide a unified viewpoint to a class of existing robust methods but also lead to new regularization tools. To realize these novel tools,  provably efficient computational algorithms are proposed. As a byproduct, the strong duality theorem proved in this paper can be potentially applied to other problems of independent interest. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Boosting Out-of-distribution Detection with Typical Features",
        "paper_url": "https://openreview.net/pdf?id=4maAiUt0A4",
        "paper_authors": [
            "Yao Zhu",
            "YueFeng Chen",
            "Chuanlong Xie",
            "Xiaodan Li",
            "Rong Zhang",
            "Hui Xue'",
            "Xiang Tian",
            "bolun zheng",
            "Yaowu Chen"
        ],
        "paper_abstract": "Out-of-distribution (OOD) detection is a critical task for ensuring the reliability and safety of deep neural networks in real-world scenarios. Different from most previous OOD detection methods that focus on designing OOD scores or introducing diverse outlier examples to retrain the model, we delve into the obstacle factors in OOD detection from the perspective of typicality and regard the feature's high-probability region of the deep model as the feature's typical set. We propose to rectify the feature into its typical set and calculate the OOD score with the typical features to achieve reliable uncertainty estimation. The feature rectification can be conducted as a plug-and-play module with various OOD scores. We evaluate the superiority of our method on both the commonly used benchmark (CIFAR) and the more challenging high-resolution benchmark with large label space (ImageNet). Notably, our approach outperforms state-of-the-art methods by up to 5.11% in the average FPR95 on the ImageNet benchmark.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Symplectic Spectrum Gaussian Processes: Learning Hamiltonians from Noisy and Sparse Data",
        "paper_url": "https://openreview.net/pdf?id=W4ZlZZwsQmt",
        "paper_authors": [
            "Yusuke Tanaka",
            "Tomoharu Iwata",
            "Naonori Ueda"
        ],
        "paper_abstract": "Hamiltonian mechanics is a well-established theory for modeling the time evolution of systems with conserved quantities (called Hamiltonian), such as the total energy of the system. Recent works have parameterized the Hamiltonian by machine learning models (e.g., neural networks), allowing Hamiltonian dynamics to be obtained from state trajectories without explicit mathematical modeling. However, the performance of existing models is limited as we can observe only noisy and sparse trajectories in practice. This paper proposes a probabilistic model that can learn the dynamics of conservative or dissipative systems from noisy and sparse data. We introduce a Gaussian process that incorporates the symplectic geometric structure of Hamiltonian systems, which is used as a prior distribution for estimating Hamiltonian systems with additive dissipation. We then present its spectral representation, Symplectic Spectrum Gaussian Processes (SSGPs), for which we newly derive random Fourier features with symplectic structures. This allows us to construct an efficient variational inference algorithm for training the models while simulating the dynamics via ordinary differential equation solvers. Experiments on several physical systems show that SSGP offers excellent performance in predicting dynamics that follow the energy conservation or dissipation law from noisy and sparse data.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Plan To Predict: Learning an Uncertainty-Foreseeing Model For Model-Based Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=L9YayWPcHA_",
        "paper_authors": [
            "Zifan Wu",
            "Chao Yu",
            "Chen Chen",
            "Jianye HAO",
            "Hankz Hankui Zhuo"
        ],
        "paper_abstract": " In Model-based Reinforcement Learning (MBRL), model learning is critical since an inaccurate model can bias policy learning via generating misleading samples. However, learning an accurate model can be difficult since the policy is continually updated and the induced distribution over visited states used for model learning shifts accordingly. Prior methods alleviate this issue by quantifying the uncertainty of model-generated samples. However, these methods only quantify the uncertainty passively after the samples were generated, rather than foreseeing the uncertainty before model trajectories fall into those highly uncertain regions. The resulting low-quality samples can induce unstable learning targets and hinder the optimization of the policy. Moreover, while being learned to minimize one-step prediction errors, the model is generally used to predict for multiple steps, leading to a mismatch between the objectives of model learning and model usage. To this end, we propose Plan To Predict (P2P), an MBRL framework that treats the model rollout process as a sequential decision making problem by reversely considering the model as a decision maker and the current policy as the dynamics. In this way, the model can quickly adapt to the current policy and foresee the multi-step future uncertainty when generating trajectories. Theoretically, we show that the performance of P2P can be guaranteed by approximately optimizing a lower bound of the true environment return. Empirical results demonstrate that P2P achieves state-of-the-art performance on several challenging benchmark tasks. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting",
        "paper_url": "https://openreview.net/pdf?id=zTQdHSQUQWc",
        "paper_authors": [
            "Tian Zhou",
            "Ziqing Ma",
            "xue wang",
            "Qingsong Wen",
            "Liang Sun",
            "Tao Yao",
            "Wotao Yin",
            "Rong Jin"
        ],
        "paper_abstract": "Recent studies have shown that deep learning models such as RNNs and Transformers have brought significant performance gains for long-term forecasting of time series because they effectively utilize historical information. We found, however, that there is still great room for improvement in how to preserve historical information in neural networks while avoiding overfitting to noise present in the history. Addressing this allows better utilization of the capabilities of deep learning models. To this end, we design a Frequency improved Legendre Memory model, or FiLM: it applies Legendre polynomial projections to approximate historical information, uses Fourier projection to remove noise, and adds a low-rank approximation to speed up computation. Our empirical studies show that the proposed FiLM significantly improves the accuracy of state-of-the-art models in multivariate and univariate long-term forecasting by (19.2%, 22.6%), respectively. We also demonstrate that the representation module developed in this work can be used as a general plugin to improve the long-term prediction performance of other deep learning modules. Code is available at  https://github.com/tianzhou2011/FiLM/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SAPipe: Staleness-Aware Pipeline for Data Parallel DNN Training",
        "paper_url": "https://openreview.net/pdf?id=3MZnNARib5",
        "paper_authors": [
            "Yangrui Chen",
            "Cong Xie",
            "Meng Ma",
            "Juncheng Gu",
            "Yanghua Peng",
            "Haibin Lin",
            "Chuan Wu",
            "Yibo Zhu"
        ],
        "paper_abstract": "Data parallelism across multiple machines is widely adopted for accelerating distributed deep learning, but it is hard to achieve linear speedup due to the heavy communication. In this paper, we propose SAPipe, a performant system that pushes the training speed of data parallelism to its fullest extent. By introducing partial staleness, the communication overlaps the computation with minimal staleness in SAPipe. To mitigate additional problems incurred by staleness, SAPipe adopts staleness compensation techniques including weight prediction and delay compensation with provably lower error bounds. Additionally, SAPipe presents an algorithm-system co-design with runtime optimization to minimize system overhead for the staleness training pipeline and staleness compensation. We have implemented SAPipe in the BytePS framework, compatible to both TensorFlow and PyTorch. Our experiments show that SAPipe achieves up to 157% speedups over BytePS (non-stale), and outperforms PipeSGD in accuracy by up to 13.7%.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Batch-Size Independent Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms or Independent Arms",
        "paper_url": "https://openreview.net/pdf?id=6hzH8pohyPY",
        "paper_authors": [
            "Xutong Liu",
            "Jinhang Zuo",
            "Siwei Wang",
            "Carlee Joe-Wong",
            "John Lui",
            "Wei Chen"
        ],
        "paper_abstract": "In this paper, we study the combinatorial semi-bandits (CMAB) and focus on reducing the dependency of the batch-size $K$ in the regret bound, where $K$ is the total number of arms that can be pulled or triggered in each round. First, for the setting of CMAB with probabilistically triggered arms (CMAB-T), we discover a novel (directional) triggering probability and variance modulated (TPVM) condition that can replace the previously-used smoothness condition for various applications, such as cascading bandits, online network exploration and online influence maximization. Under this new condition, we propose a BCUCB-T algorithm with variance-aware confidence intervals and conduct regret analysis which reduces the $O(K)$ factor to $O(\\log K)$ or $O(\\log^2 K)$ in the regret bound, significantly improving the regret bounds for the above applications. Second, for the setting of non-triggering CMAB with independent arms, we propose a SESCB algorithm which leverages on the non-triggering version of the TPVM condition and completely removes the dependency on $K$ in the leading regret. As a valuable by-product, the regret analysis used in this paper can improve several existing results by a factor of $O(\\log K)$. Finally, experimental evaluations show our superior performance compared with benchmark algorithms in different applications.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified Diversity Measure for Multiagent Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=H-6iczs__Ro",
        "paper_authors": [
            "Zongkai Liu",
            "Chao Yu",
            "Yaodong Yang",
            "peng sun",
            "Zifan Wu",
            "Yuan Li"
        ],
        "paper_abstract": "Promoting behavioural diversity is of critical importance in multi-agent reinforcement learning, since it helps the agent population maintain robust performance when encountering unfamiliar opponents at test time, or,  when the game is highly non-transitive in the strategy space (e.g., Rock-Paper-Scissor). While a myriad of diversity metrics have been proposed, there are no widely accepted or unified  definitions in the literature, making the consequent diversity-aware learning algorithms difficult to evaluate and the insights elusive. In this work, we propose a novel  metric called the Unified Diversity Measure (UDM) that offers a unified view for existing diversity metrics. Based on UDM, we design the UDM-Fictitious Play (UDM-FP) and UDM-Policy Space Response Oracle (UDM-PSRO) algorithms as efficient solvers for  normal-form games and open-ended games. In theory, we prove that UDM-based methods can enlarge the gamescape by increasing the response capacity of the strategy pool, and have convergence guarantee to two-player Nash equilibrium. We validate our  algorithms on games that show strong non-transitivity, and empirical results show that our algorithms achieve better performances than strong PSRO baselines in terms of the exploitability and population effectivity. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GLIPv2: Unifying Localization and Vision-Language Understanding ",
        "paper_url": "https://openreview.net/pdf?id=wiBEFdAvl8L",
        "paper_authors": [
            "Haotian Zhang",
            "Pengchuan Zhang",
            "Xiaowei Hu",
            "Yen-Chun Chen",
            "Liunian Harold Li",
            "Xiyang Dai",
            "Lijuan Wang",
            "Lu Yuan",
            "Jenq-Neng Hwang",
            "Jianfeng Gao"
        ],
        "paper_abstract": "We present GLIPv2, a grounded VL understanding model, that serves both localization tasks (e.g., object detection, instance segmentation) and Vision-Language (VL) understanding tasks (e.g., VQA, image captioning). GLIPv2 elegantly unifies localization pre-training and Vision-Language Pre-training (VLP) with three pre-training tasks: phrase grounding as a VL reformulation of the detection task, region-word contrastive learning as a novel region-word level contrastive learning task, and the masked language modeling. This unification not only simplifies the previous multi-stage VLP procedure but also achieves mutual benefits between localization and understanding tasks. Experimental results show that a single GLIPv2 model (all model weights are shared) achieves near SoTA performance on various localization and understanding tasks. The model also shows (1) strong zero-shot and few-shot adaption performance on open-vocabulary object detection tasks and (2) superior grounding capability on VL understanding tasks. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
        "paper_url": "https://openreview.net/pdf?id=08Yk-n5l2Al",
        "paper_authors": [
            "Chitwan Saharia",
            "William Chan",
            "Saurabh Saxena",
            "Lala Li",
            "Jay Whang",
            "Emily Denton",
            "Seyed Kamyar Seyed Ghasemipour",
            "Raphael Gontijo-Lopes",
            "Burcu Karagol Ayan\u200e",
            "Tim Salimans",
            "Jonathan Ho",
            "David J. Fleet",
            "Mohammad Norouzi"
        ],
        "paper_abstract": "We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g., T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mutual Information Divergence: A Unified Metric for Multimodal Generative Models",
        "paper_url": "https://openreview.net/pdf?id=wKd2XtSRsjl",
        "paper_authors": [
            "Jin-Hwa Kim",
            "Yunji Kim",
            "Jiyoung Lee",
            "Kang Min Yoo",
            "Sang-Woo Lee"
        ],
        "paper_abstract": "Text-to-image generation and image captioning are recently emerged as a new experimental paradigm to assess machine intelligence. They predict continuous quantity accompanied by their sampling techniques in the generation, making evaluation complicated and intractable to get marginal distributions. Based on a recent trend that multimodal generative evaluations exploit a vison-and-language pre-trained model, we propose the negative Gaussian cross-mutual information using the CLIP features as a unified metric, coined by Mutual Information Divergence (MID). To validate, we extensively compare it with competing metrics using carefully-generated or human-annotated judgments in text-to-image generation and image captioning tasks. The proposed MID significantly outperforms the competitive methods by having consistency across benchmarks, sample parsimony, and robustness toward the exploited CLIP model. We look forward to seeing the underrepresented implications of the Gaussian cross-mutual information in multimodal representation learning and future works based on this novel proposition. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera",
        "paper_url": "https://openreview.net/pdf?id=8RKJj1YDBJT",
        "paper_authors": [
            "Hongrui Cai",
            "Wanquan Feng",
            "Xuetao Feng",
            "Yan Wang",
            "Juyong Zhang"
        ],
        "paper_abstract": "We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera. In NDR, we adopt the neural implicit function for surface representation and rendering such that the captured color and depth can be fully utilized to jointly optimize the surface and deformations. To represent and constrain the non-rigid deformations, we propose a novel neural invertible deforming network such that the cycle consistency between arbitrary two frames is automatically satisfied. Considering that the surface topology of dynamic scene might change over time, we employ a topology-aware strategy to construct the topology-variant correspondence for the fused frames. NDR also further refines the camera poses in a global optimization manner. Experiments on public datasets and our collected dataset demonstrate that NDR outperforms existing monocular dynamic reconstruction methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Variational inference via Wasserstein gradient flows",
        "paper_url": "https://openreview.net/pdf?id=K2PTuvVTF1L",
        "paper_authors": [
            "Marc Lambert",
            "Sinho Chewi",
            "Francis Bach",
            "Silv\u00e8re Bonnabel",
            "Philippe Rigollet"
        ],
        "paper_abstract": "Along with Markov chain Monte Carlo (MCMC) methods, variational inference (VI) has emerged as a central computational approach to large-scale Bayesian inference. Rather than sampling from the true posterior $\\pi$, VI aims at producing a simple but effective approximation $\\hat \\pi$ to $\\pi$ for which summary statistics are easy to compute. However, unlike the well-studied MCMC methodology, algorithmic guarantees for VI are still relatively less well-understood. In this work, we propose principled methods for VI, in which $\\hat \\pi$ is taken to be a Gaussian or a mixture of Gaussians, which rest upon the theory of gradient flows on the Bures--Wasserstein space of Gaussian measures. Akin to MCMC, it comes with strong theoretical guarantees when $\\pi$ is log-concave.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Finite-Time Analysis of Adaptive Temporal Difference Learning with Deep Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=GCNIm4cKoRx",
        "paper_authors": [
            "Tao Sun",
            "Dongsheng Li",
            "Bao Wang"
        ],
        "paper_abstract": "Temporal difference (TD) learning with function approximations (linear functions or neural networks) has achieved remarkable empirical success, giving impetus to the development of finite-time analysis. As an accelerated version of TD, the adaptive TD has been proposed and proved to enjoy finite-time convergence under the linear function approximation. Existing numerical results have demonstrated the superiority of adaptive algorithms to vanilla ones. Nevertheless, the performance guarantee of adaptive TD with neural network approximation remains widely unknown. This paper establishes the finite-time analysis for the adaptive TD with multi-layer ReLU network approximation whose samples are generated from a Markov decision process. Our established theory shows that if the width of the deep neural network is large enough, the adaptive TD using neural network approximation can find the (optimal) value function with high probabilities under the same iteration complexity as TD in general cases. Furthermore, we show that the adaptive TD using neural network approximation, with the same width and searching area, can achieve theoretical acceleration when the stochastic semi-gradients decay fast.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning",
        "paper_url": "https://openreview.net/pdf?id=Yul402KcD5d",
        "paper_authors": [
            "Fuying Wang",
            "Yuyin Zhou",
            "Shujun Wang",
            "Varut Vardhanabhuti",
            "Lequan Yu"
        ],
        "paper_abstract": "Learning medical visual representations directly from paired radiology reports has become an emerging topic in representation learning. However, existing medical image-text joint learning methods are limited by instance or local supervision analysis, ignoring disease-level semantic correspondences. In this paper, we present a novel Multi-Granularity Cross-modal Alignment (MGCA) framework for generalized medical visual representation learning by harnessing the naturally exhibited semantic correspondences between medical image and radiology reports at three different levels, i.e., pathological region-level, instance-level, and disease-level. Specifically, we first incorporate the instance-wise alignment module by maximizing the agreement between image-report pairs. Further, for token-wise alignment, we introduce a bidirectional cross-attention strategy to explicitly learn the matching between fine-grained visual tokens and text tokens, followed by contrastive learning to align them. More important, to leverage the high-level inter-subject relationship semantic (e.g., disease) correspondences, we design a novel cross-modal disease-level alignment paradigm to enforce the cross-modal cluster assignment consistency. Extensive experimental results on seven downstream medical image datasets covering image classification, object detection, and semantic segmentation tasks demonstrate the stable and superior performance of our framework.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Embarrassingly Simple Approach to Semi-Supervised Few-Shot Learning",
        "paper_url": "https://openreview.net/pdf?id=-3Pg7QNIF1S",
        "paper_authors": [
            "Xiu-Shen Wei",
            "He-Yang Xu",
            "Faen Zhang",
            "Yuxin Peng",
            "Wei Zhou"
        ],
        "paper_abstract": "Semi-supervised few-shot learning consists in training a classifier to adapt to new tasks with limited labeled data and a fixed quantity of unlabeled data. Many sophisticated methods have been developed to address the challenges this problem comprises. In this paper, we propose a simple but quite effective approach to predict accurate negative pseudo-labels of unlabeled data from an indirect learning perspective, and then augment the extremely label-constrained support set in few-shot classification tasks. Our approach can be implemented in just few lines of code by only using off-the-shelf operations, yet it is able to outperform state-of-the-art methods on four benchmark datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Geo-SIC: Learning Deformable Geometric Shapes in Deep Image Classifiers",
        "paper_url": "https://openreview.net/pdf?id=FhWQzNY2UYR",
        "paper_authors": [
            "Jian Wang",
            "Miaomiao Zhang"
        ],
        "paper_abstract": "Deformable shapes provide important and complex geometric features of objects presented in images. However, such information is oftentimes missing or underutilized as implicit knowledge in many image analysis tasks. This paper presents Geo-SIC, the first deep learning model to learn deformable shapes in a deformation space for an improved performance of image classification. We introduce a newly designed framework that (i) simultaneously derives features from both image and latent shape spaces with large intra-class variations; and (ii) gains increased model interpretability by allowing direct access to the underlying geometric features of image data. In particular, we develop a boosted classification network, equipped with an unsupervised learning of geometric shape representations characterized by diffeomorphic transformations within each class. In contrast to previous approaches using pre-extracted shapes, our model provides a more fundamental approach by naturally learning the most relevant shape features jointly with an image classifier. We demonstrate the effectiveness of our method on both simulated 2D images and real 3D brain magnetic resonance (MR) images. Experimental results show that our model substantially improves the image classification accuracy with an additional benefit of increased model interpretability.  Our code is publicly available at https://github.com/jw4hv/Geo-SIC.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On-Device Training Under 256KB Memory",
        "paper_url": "https://openreview.net/pdf?id=zGvRdBW06F5",
        "paper_authors": [
            "Ji Lin",
            "Ligeng Zhu",
            "Wei-Ming Chen",
            "Wei-Chen Wang",
            "Chuang Gan",
            "Song Han"
        ],
        "paper_abstract": "On-device training enables the model to adapt to new data collected from the sensors by fine-tuning a pre-trained model. Users can benefit from customized AI models without having to transfer the data to the cloud, protecting the privacy. However, the training memory consumption is prohibitive for IoT devices that have tiny memory resources. We propose an algorithm-system co-design framework to make on-device training possible with only 256KB of memory. On-device training faces two unique challenges: (1) the quantized graphs of neural networks are hard to optimize due to low bit-precision and the lack of normalization; (2) the limited hardware resource (memory and computation) does not allow full backpropagation. To cope with the optimization difficulty, we propose Quantization- Aware Scaling to calibrate the gradient scales and stabilize 8-bit quantized training. To reduce the memory footprint, we propose Sparse Update to skip the gradient computation of less important layers and sub-tensors. The algorithm innovation is implemented by a lightweight training system, Tiny Training Engine, which prunes the backward computation graph to support sparse updates and offload the runtime auto-differentiation to compile time. Our framework is the first practical solution for on-device transfer learning of visual recognition on tiny IoT devices (e.g., a microcontroller with only 256KB SRAM), using less than 1/1000 of the memory of PyTorch and TensorFlow while matching the accuracy. Our study enables IoT devices not only to perform inference but also to continuously adapt to new data for on-device lifelong learning. A video demo can be found here: https://youtu.be/XaDCO8YtmBw.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Independence Testing for Bounded Degree Bayesian Networks",
        "paper_url": "https://openreview.net/pdf?id=StzAAh8RuD",
        "paper_authors": [
            "Arnab Bhattacharyya",
            "Clement Louis Canonne",
            "Qiping Yang"
        ],
        "paper_abstract": "We study the following independence testing problem: given access to samples from a distribution $P$ over $\\{0,1\\}^n$, decide whether $P$ is a product distribution or whether it is $\\varepsilon$-far in total variation distance from any product distribution. For arbitrary distributions, this problem requires $\\exp(n)$ samples. We show in this work that if $P$ has a sparse structure, then in fact only linearly many samples are required.\nSpecifically, if $P$  is Markov with respect to a Bayesian network whose underlying DAG has in-degree bounded by $d$, then $\\tilde{\\Theta}(2^{d/2}\\cdot n/\\varepsilon^2)$ samples are necessary and sufficient for independence testing.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Effect of Pre-training for Transformer in Different Modality on Offline Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=9GXoMs__ckJ",
        "paper_authors": [
            "Shiro Takagi"
        ],
        "paper_abstract": "We empirically investigate how pre-training on data of different modalities, such as language and vision, affects fine-tuning of Transformer-based models to Mujoco offline reinforcement learning tasks. Analysis of the internal representation reveals that the pre-trained Transformers acquire largely different representations before and after pre-training, but acquire less information of data in fine-tuning than the randomly initialized one. A closer look at the parameter changes of the pre-trained Transformers reveals that their parameters do not change that much and that the bad performance of the model pre-trained with image data could partially come from large gradients and gradient clipping. To study what information the Transformer pre-trained with language data utilizes, we fine-tune this model with no context provided, finding that the model learns efficiently even without context information. Subsequent follow-up analysis supports the hypothesis that pre-training with language data is likely to make the Transformer get context-like information and utilize it to solve the downstream task.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Estimating and Explaining Model Performance When Both Covariates and Labels Shift",
        "paper_url": "https://openreview.net/pdf?id=BK0O0xLntFM",
        "paper_authors": [
            "Lingjiao Chen",
            "Matei Zaharia",
            "James Y. Zou"
        ],
        "paper_abstract": "Deployed machine learning (ML) models often encounter new user data that differs from their training data. Therefore, estimating how well a given model might perform on the new data is an important step toward reliable ML applications. This is very challenging, however, as the data distribution can change in flexible ways, and we may not have any labels on the new data, which is often the case in monitoring settings. In this paper, we propose a new distribution shift model, Sparse Joint Shift (SJS), which considers the joint shift of both labels and a few features. This unifies and generalizes several existing shift models including label shift and sparse covariate shift, where only marginal feature or label distribution shifts are considered. We describe mathematical conditions under which SJS is identifiable. We further propose SEES, an algorithmic framework to characterize the distribution shift under SJS and to estimate a model\u2019s performance on new data without any labels. We conduct extensive experiments on several real-world datasets with various ML models. Across different datasets and distribution shifts, SEES achieves significant (up to an order of magnitude) shift estimation error improvements over existing approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PopArt: Efficient Sparse Regression and Experimental Design for Optimal Sparse Linear Bandits",
        "paper_url": "https://openreview.net/pdf?id=GWcdXz0M6a",
        "paper_authors": [
            "Kyoungseok Jang",
            "Chicheng Zhang",
            "Kwang-Sung Jun"
        ],
        "paper_abstract": "In sparse linear bandits, a learning agent sequentially selects an action from a fixed action set and receives reward feedback, and the reward function depends linearly on a few coordinates of the covariates of the actions. This has applications in many real-world sequential decision making problems. In this paper, we devise a simple, novel sparse linear estimation method called $\\textrm{PopArt}$ that enjoys a tighter $\\ell_1$ recovery guarantee compared to Lasso (Tibshirani, 1996). Our bound naturally motivates an experimental design criterion that is convex and thus computationally efficient to solve. Based on our novel estimator and design criterion, we derive sparse linear bandit algorithms that enjoy improved regret upper bounds upon the state of the art (Hao et al., 2020), especially in terms of the geometry of the given action set. Finally, we prove a matching lower bound for sparse linear bandits in the data-poor regime, which closes the gap between upper and lower bounds in prior work.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Distinguishing Learning Rules with Brain Machine Interfaces",
        "paper_url": "https://openreview.net/pdf?id=UDmPRm-P1nL",
        "paper_authors": [
            "Jacob Portes",
            "Christian Schmid",
            "James M Murray"
        ],
        "paper_abstract": "Despite extensive theoretical work on biologically plausible learning rules, clear evidence about whether and how such rules are implemented in the brain has been difficult to obtain. We consider biologically plausible supervised- and reinforcement-learning rules and ask whether changes in network activity during learning can be used to determine which learning rule is being used. Supervised learning requires a credit-assignment model estimating the mapping from neural activity to behavior, and, in a biological organism, this model will inevitably be an imperfect approximation of the ideal mapping, leading to a bias in the direction of the weight updates relative to the true gradient. Reinforcement learning, on the other hand, requires no credit-assignment model and tends to make weight updates following the true gradient direction. We derive a metric to distinguish between learning rules by observing changes in the network activity during learning, given that the mapping from brain to behavior is known by the experimenter. Because brain-machine interface (BMI) experiments allow for precise knowledge of this mapping, we model a cursor-control BMI task using recurrent neural networks, showing that  learning rules can be distinguished in simulated experiments using only observations that a  neuroscience experimenter would plausibly have access to. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BiT: Robustly Binarized Multi-distilled Transformer",
        "paper_url": "https://openreview.net/pdf?id=wYgRIJ-oK6M",
        "paper_authors": [
            "Zechun Liu",
            "Barlas Oguz",
            "Aasish Pappu",
            "Lin Xiao",
            "Scott Yih",
            "Meng Li",
            "Raghuraman Krishnamoorthi",
            "Yashar Mehdad"
        ],
        "paper_abstract": "Modern pre-trained transformers have rapidly advanced the state-of-the-art in machine learning, but have also grown in parameters and computational complexity, making them increasingly difficult to deploy in resource-constrained environments. Binarization of the weights and activations of the network can significantly alleviate these issues, however, is technically challenging from an optimization perspective. In this work, we identify a series of improvements that enables binary transformers at a much higher accuracy than what was possible previously. These include a two-set binarization scheme, a novel elastic binary activation function with learned parameters, and a method to quantize a network to its limit by successively distilling higher precision models into lower precision students. These approaches allow for the first time, fully binarized transformer models that are at a practical level of accuracy, approaching a full-precision BERT baseline on the GLUE language understanding benchmark within as little as 5.9%. Code and models are available at:https://github.com/facebookresearch/bit.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Chaotic Dynamics in Dissipative Systems",
        "paper_url": "https://openreview.net/pdf?id=1C36tFZn7sR",
        "paper_authors": [
            "Zongyi Li",
            "Miguel Liu-Schiaffini",
            "Nikola Borislavov Kovachki",
            "Kamyar Azizzadenesheli",
            "Burigede Liu",
            "Kaushik Bhattacharya",
            "Andrew Stuart",
            "Anima Anandkumar"
        ],
        "paper_abstract": "Chaotic systems are notoriously challenging to predict because of their sensitivity to perturbations and errors due to time stepping. Despite this unpredictable behavior, for many dissipative systems the statistics of the long term trajectories are governed by an invariant measure supported on a set, known as the global attractor; for many problems this set is finite dimensional, even if the state space is infinite dimensional. For Markovian systems, the statistical properties of long-term trajectories are uniquely determined by the solution operator that maps the evolution of the system over arbitrary positive time increments. In this work, we propose a machine learning framework to learn the underlying solution operator for dissipative chaotic systems, showing that the resulting learned operator accurately captures short-time trajectories and long-time statistical behavior. Using this framework, we are able to predict various statistics of the invariant measure for the turbulent Kolmogorov Flow dynamics with Reynolds numbers up to $5000$.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trading off Image Quality for Robustness is not Necessary with Regularized Deterministic Autoencoders",
        "paper_url": "https://openreview.net/pdf?id=9YasTgzma8c",
        "paper_authors": [
            "Amrutha Saseendran",
            "Kathrin Skubch",
            "Stefan Falkner",
            "Margret Keuper"
        ],
        "paper_abstract": "The susceptibility of Variational Autoencoders (VAEs) to adversarial attacks indicates the necessity to evaluate the robustness of the learned representations along with the generation performance. The vulnerability of VAEs has been attributed to the limitations associated with their variational formulation. Deterministic autoencoders could overcome the practical limitations associated with VAEs and offer a promising alternative for image generation applications. In this work, we propose an adversarially robust deterministic autoencoder with superior performance in terms of both generation and robustness of the learned representations. We introduce a regularization scheme to incorporate adversarially perturbed data points to the training pipeline without increasing the computational complexity or compromising the generation fidelity by leveraging a loss based on the two-point Kolmogorov\u2013Smirnov test between representations. We conduct extensive experimental studies on popular image benchmark datasets to quantify the robustness of the proposed approach based on the adversarial attacks targeted at VAEs. Our empirical findings show that the proposed method achieves significant performance in both robustness and fidelity when compared to the robust VAE models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mean Estimation in High-Dimensional Binary Markov Gaussian Mixture Models",
        "paper_url": "https://openreview.net/pdf?id=Upt5wsECVJe",
        "paper_authors": [
            "Yihan Zhang",
            "Nir Weinberger"
        ],
        "paper_abstract": "We consider a high-dimensional mean estimation problem over a binary hidden Markov model, which illuminates the interplay between memory in data, sample size, dimension, and signal strength in statistical inference. In this model, an estimator observes $n$ samples of a $d$-dimensional parameter vector $\\theta_{*}\\in\\mathbb{R}^{d}$, multiplied by a random sign $ S_i $ ($1\\le i\\le n$), and corrupted by isotropic standard Gaussian noise. The sequence of signs $\\{S_{i}\\}_{i\\in[n]}\\in\\{-1,1\\}^{n}$ is drawn from a stationary homogeneous Markov chain with flip probability $\\delta\\in[0,1/2]$. As $\\delta$ varies, this model smoothly interpolates two well-studied models: the Gaussian Location Model for which $\\delta=0$ and the Gaussian Mixture Model for which $\\delta=1/2$. Assuming that the estimator knows $\\delta$, we establish a nearly minimax optimal (up to logarithmic factors) estimation error rate, as a function of $\\|\\theta_{*}\\|,\\delta,d,n$. We then provide an upper bound to the case of estimating $\\delta$, assuming a (possibly inaccurate) knowledge of $\\theta_{*}$. The bound is proved to be tight when $\\theta_{*}$ is an accurately known constant. These results are then combined to an algorithm which estimates $\\theta_{*}$ with $\\delta$ unknown a priori, and theoretical guarantees on its error are stated.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploration via Planning for Information about the Optimal Trajectory",
        "paper_url": "https://openreview.net/pdf?id=d0stFTU2dTI",
        "paper_authors": [
            "Viraj Mehta",
            "Ian Char",
            "Joseph Abbate",
            "Rory Conlin",
            "Mark D Boyer",
            "Stefano Ermon",
            "Jeff Schneider",
            "Willie Neiswanger"
        ],
        "paper_abstract": "Many potential applications of reinforcement learning (RL) are stymied by the large numbers of samples required to learn an effective policy. This is especially true when applying RL to real-world control tasks, e.g. in the sciences or robotics, where executing a policy in the environment is costly. In popular RL algorithms, agents typically explore either by adding stochasticity to a reward-maximizing policy or by attempting to gather maximal information about environment dynamics without taking the given task into account. In this work, we develop a method that allows us to plan for exploration while taking both the task and the current knowledge about the dynamics into account.  The key insight to our approach is to plan an action sequence that maximizes the expected information gain about the optimal trajectory for the task at hand. We demonstrate that our method learns strong policies with 2x fewer samples than strong exploration baselines and 200x fewer samples than model free methods on a diverse set of low-to-medium dimensional control tasks in both the open-loop and closed-loop control settings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Calibration with Multi-domain Temperature Scaling",
        "paper_url": "https://openreview.net/pdf?id=UZJHudsQ7d",
        "paper_authors": [
            "Yaodong Yu",
            "Stephen Bates",
            "Yi Ma",
            "Michael Jordan"
        ],
        "paper_abstract": "Uncertainty quantification is essential for the reliable deployment of machine learning models to high-stakes application domains. Uncertainty quantification is all the more challenging when training distribution and test distribution are different, even if the distribution shifts are mild. Despite the ubiquity of distribution shifts in real-world applications, existing uncertainty quantification approaches mainly study the in-distribution setting where the train and test distributions are the same. In this paper, we develop a systematic calibration model to handle distribution shifts by leveraging data from multiple domains. Our proposed method---multi-domain temperature scaling---uses the heterogeneity in the domains to improve calibration robustness under distribution shift. Through experiments on three benchmark data sets, we find our proposed method outperforms existing methods as measured on both in-distribution and out-of-distribution test sets. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sparse Interaction Additive Networks via Feature Interaction Detection and Sparse Selection",
        "paper_url": "https://openreview.net/pdf?id=Q6DJ12oQjrp",
        "paper_authors": [
            "James Enouen",
            "Yan Liu"
        ],
        "paper_abstract": "There is currently a large gap in performance between the statistically rigorous methods like linear regression or additive splines and the powerful deep methods using neural networks.  Previous works attempting to close this gap have failed to fully consider the exponentially growing number of feature combinations which deep networks consider automatically during training.  In this work, we develop a tractable selection algorithm to efficiently identify the necessary feature combinations by leveraging techniques in feature interaction detection.\nOur proposed Sparse Interaction Additive Networks (SIAN) construct a bridge from these simple and interpretable models to a fully connected neural network.  SIAN achieves competitive performance against state-of-the-art methods across multiple large-scale tabular datasets and consistently finds an optimal tradeoff between the modeling capacity of neural networks and the generalizability of simpler methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient and Effective Multi-task Grouping via Meta Learning on Task Combinations",
        "paper_url": "https://openreview.net/pdf?id=Rqe-fJQtExY",
        "paper_authors": [
            "Xiaozhuang Song",
            "Shun Zheng",
            "Wei Cao",
            "James Yu",
            "Jiang Bian"
        ],
        "paper_abstract": "As a longstanding learning paradigm, multi-task learning has been widely applied into a variety of machine learning applications. Nonetheless, identifying which tasks should be learned together is still a challenging fundamental problem because the possible task combinations grow exponentially with the number of tasks, and existing solutions heavily relying on heuristics may probably lead to ineffective groupings with severe performance degradation. To bridge this gap, we develop a systematic multi-task grouping framework with a new meta-learning problem on task combinations, which is to predict the per-task performance gains of multi-task learning over single-task learning for any combination. Our underlying assumption is that no matter how large the space of task combinations is, the relationships between task combinations and performance gains lie in some low-dimensional manifolds and thus can be learnable. Accordingly, we develop a neural meta learner, MTG-Net, to capture these relationships, and design an active learning strategy to progressively select meta-training samples. In this way, even with limited meta samples, MTG-Net holds the potential to produce reasonable gain estimations on arbitrary task combinations. Extensive experiments on diversified multi-task scenarios demonstrate the efficiency and effectiveness of our method. Specifically, in a large-scale evaluation with $27$ tasks, which produce over one hundred million task combinations, our method almost doubles the performance obtained by the existing best solution given roughly the same computational cost. Data and code are available at https://github.com/ShawnKS/MTG-Net.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds",
        "paper_url": "https://openreview.net/pdf?id=nLKkHwYP4Au",
        "paper_authors": [
            "Haiyang Wang",
            "Lihe Ding",
            "Shaocong Dong",
            "Shaoshuai Shi",
            "Aoxue Li",
            "Jianan Li",
            "Zhenguo Li",
            "Liwei Wang"
        ],
        "paper_abstract": "We present a novel two-stage fully sparse convolutional 3D object detection framework, named CAGroup3D. Our proposed method first generates some high-quality 3D proposals by leveraging the class-aware local group strategy on the object surface voxels with the same semantic predictions, which considers semantic consistency and diverse locality abandoned in previous bottom-up approaches. Then, to recover the features of missed voxels due to incorrect voxel-wise segmentation, we build a fully sparse convolutional RoI pooling module to directly aggregate fine-grained spatial information from backbone for further proposal refinement. It is memory-and-computation efficient and can better encode the geometry-specific features of each 3D proposal. Our model achieves state-of-the-art 3D detection performance with remarkable gains of +3.6% on ScanNet V2 and +2.6%  on SUN RGB-D in term of mAP@0.25. Code will be available at https://github.com/Haiyang-W/CAGroup3D.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptive Data Debiasing through Bounded Exploration",
        "paper_url": "https://openreview.net/pdf?id=Fm7Dt3lC_s2",
        "paper_authors": [
            "Yifan Yang",
            "Yang Liu",
            "Parinaz Naghizadeh"
        ],
        "paper_abstract": "Biases in existing datasets used to train algorithmic decision rules can raise ethical and economic concerns due to the resulting disparate treatment of different groups. We propose an algorithm for sequentially debiasing such datasets through adaptive and bounded exploration in a classification problem with costly and censored feedback. Exploration in this context means that at times, and to a judiciously-chosen extent, the decision maker deviates from its (current) loss-minimizing rule, and instead accepts some individuals that would otherwise be rejected, so as to reduce statistical data biases. Our proposed algorithm includes parameters that can be used to balance between the ultimate goal of removing data biases -- which will in turn lead to more accurate and fair decisions, and the exploration risks incurred to achieve this goal. We analytically show that such exploration can help debias data in certain distributions. We further investigate how fairness criteria can work in conjunction with our data debiasing algorithm. We illustrate the performance of our algorithm using experiments on synthetic and real-world datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bridging the Gap Between Vision Transformers and Convolutional Neural Networks on Small Datasets",
        "paper_url": "https://openreview.net/pdf?id=bfz-jhJ8wn",
        "paper_authors": [
            "Zhiying Lu",
            "Hongtao Xie",
            "Chuanbin Liu",
            "Yongdong Zhang"
        ],
        "paper_abstract": "There still remains an extreme performance gap between Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs) when training from scratch on small datasets, which is concluded to the lack of inductive bias. In this paper, we further consider this problem and point out two weaknesses of ViTs in inductive biases, that is, the spatial relevance and diverse channel representation. First, on spatial aspect, objects are locally compact and relevant, thus fine-grained feature needs to be extracted from a token and its neighbors. While the lack of data hinders ViTs to attend the spatial relevance. Second, on channel aspect, representation exhibits diversity on different channels. But the scarce data can not enable ViTs to learn strong enough representation for accurate recognition. To this end, we propose Dynamic Hybrid Vision Transformer (DHVT) as the solution to enhance the two inductive biases. On spatial aspect, we adopt a hybrid structure, in which convolution is integrated into patch embedding and multi-layer perceptron module, forcing the model to capture the token features as well as their neighboring features. On channel aspect, we introduce a dynamic feature aggregation module in MLP and a brand new \"head token\" design in multi-head self-attention module to help re-calibrate channel representation and make different channel group representation interacts with each other. The fusion of weak channel representation forms a strong enough representation for classification. With this design, we successfully eliminate the performance gap between CNNs and ViTs, and our DHVT achieves a series of state-of-the-art performance with a lightweight model, 85.68% on CIFAR-100 with 22.8M parameters, 82.3% on ImageNet-1K with 24.0M parameters. Code is available at https://github.com/ArieSeirack/DHVT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MultiGuard: Provably Robust Multi-label Classification against Adversarial Examples",
        "paper_url": "https://openreview.net/pdf?id=hcVlMF3Nvxg",
        "paper_authors": [
            "Jinyuan Jia",
            "Wenjie Qu",
            "Neil Zhenqiang Gong"
        ],
        "paper_abstract": "Multi-label classification, which predicts a set of labels for an input, has many applications.  However, multiple recent studies showed that multi-label classification is vulnerable to adversarial examples. In particular, an attacker can manipulate the labels predicted by a multi-label classifier for an input via adding carefully crafted, human-imperceptible perturbation to it. Existing provable defenses for multi-class classification achieve sub-optimal provable robustness guarantees when generalized to multi-label classification. In this work, we propose MultiGuard, the first provably robust defense against adversarial examples to multi-label classification. Our MultiGuard leverages randomized smoothing, which is the state-of-the-art technique to build provably robust classifiers. Specifically, given an arbitrary multi-label classifier, our MultiGuard builds a smoothed multi-label classifier via adding random noise to the input. We consider isotropic Gaussian noise in this work. Our major theoretical contribution is that we show a certain number of ground truth labels of an input are provably in the set of labels predicted by our MultiGuard when the $\\ell_2$-norm of the adversarial perturbation added to the input is bounded. Moreover, we design an algorithm to compute our provable robustness guarantees. Empirically, we evaluate our MultiGuard on VOC 2007, MS-COCO, and NUS-WIDE benchmark datasets. Our code is available at: https://github.com/quwenjie/MultiGuard",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Natural gradient enables fast sampling in spiking neural networks",
        "paper_url": "https://openreview.net/pdf?id=Yopob26XjmL",
        "paper_authors": [
            "Paul Masset",
            "Jacob A Zavatone-Veth",
            "J. Patrick Connor",
            "Venkatesh N Murthy",
            "Cengiz Pehlevan"
        ],
        "paper_abstract": "For animals to navigate an uncertain world, their brains need to estimate uncertainty at the timescales of sensations and actions. Sampling-based algorithms afford a theoretically-grounded framework for probabilistic inference in neural circuits, but it remains unknown how one can implement fast sampling algorithms in biologically-plausible spiking networks. Here, we propose to leverage the population geometry, controlled by the neural code and the neural dynamics, to implement fast samplers in spiking neural networks. We first show that two classes of spiking samplers---efficient balanced spiking networks that simulate Langevin sampling, and networks with probabilistic spike rules that implement Metropolis-Hastings sampling---can be unified within a common framework. We then show that careful choice of population geometry, corresponding to the natural space of parameters, enables rapid inference of parameters drawn from strongly-correlated high-dimensional distributions in both networks. Our results suggest design principles for algorithms for sampling-based probabilistic inference in spiking neural networks, yielding potential inspiration for neuromorphic computing and testable predictions for neurobiology.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model Behavior",
        "paper_url": "https://openreview.net/pdf?id=3AbigH4s-ml",
        "paper_authors": [
            "Eldar David Abraham",
            "Karel D'Oosterlinck",
            "Amir Feder",
            "Yair Ori Gat",
            "Atticus Geiger",
            "Christopher Potts",
            "Roi Reichart",
            "Zhengxuan Wu"
        ],
        "paper_abstract": "The increasing size and complexity of modern ML systems has improved their predictive capabilities but made their behavior harder to explain. Many techniques for model explanation have been developed in response, but we lack clear criteria for assessing these techniques. In this paper, we cast model explanation as the causal inference problem of estimating causal effects of real-world concepts on the output behavior of ML models given actual input data. We introduce CEBaB, a new benchmark dataset for assessing concept-based explanation methods in Natural Language Processing (NLP). CEBaB consists of short restaurant reviews with human-generated counterfactual reviews in which an aspect (food, noise, ambiance, service) of the dining experience was modified. Original and counterfactual reviews are annotated with multiply-validated sentiment ratings at the aspect-level and review-level. The rich structure of CEBaB allows us to go beyond input features to study the effects of abstract, real-world concepts on model behavior. We use CEBaB to compare the quality of a range of concept-based explanation methods covering different assumptions and conceptions of the problem, and we seek to establish natural metrics for comparative assessments of these methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GAR: Generalized Autoregression for Multi-Fidelity Fusion",
        "paper_url": "https://openreview.net/pdf?id=aLNWp0pn1Ij",
        "paper_authors": [
            "Yuxin Wang",
            "Zheng Xing",
            "WEI W. XING"
        ],
        "paper_abstract": "In many scienti\ufb01c research and engineering applications, where repeated simulations of complex systems are conducted, a surrogate is commonly adopted to quickly estimate the whole system. To reduce the expensive cost of generating training examples, it has become a promising approach to combine the results of low-\ufb01delity (fast but inaccurate) and high-\ufb01delity (slow but accurate) simulations. Despite the fast developments of multi-\ufb01delity fusion techniques, most existing methods require particular data structures and do not scale well to high-dimensional output. To resolve these issues, we generalize the classic autoregression (AR), which is wildly used due to its simplicity, robustness, accuracy, and tractability, and propose generalized autoregression (GAR) using tensor formulation and latent features. GAR can deal with arbitrary dimensional outputs and arbitrary multi\ufb01delity data structure to satisfy the demand of multi-\ufb01delity fusion for complex problems; it admits a fully tractable likelihood and posterior requiring no approximate inference and scales well to high-dimensional problems. Furthermore, we prove the autokrigeability theorem based on GAR in the multi-\ufb01delity case and develop CIGAR, a simpli\ufb01ed GAR with the same predictive mean accuracy but requires signi\ufb01cantly less computation. In experiments of canonical PDEs and scienti\ufb01c computational examples, the proposed method consistently outperforms the SOTA methods with a large margin (up to 6x improvement in RMSE) with only a few high-\ufb01delity training samples.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=nrksGSRT7kX",
        "paper_authors": [
            "Marc Rigter",
            "Bruno Lacerda",
            "Nick Hawes"
        ],
        "paper_abstract": "Offline reinforcement learning (RL) aims to find performant policies from logged data without further environment interaction. Model-based algorithms, which learn a model of the environment from the dataset and perform conservative policy optimisation within that model, have emerged as a promising approach to this problem. In this work, we present Robust Adversarial Model-Based Offline RL (RAMBO), a novel approach to model-based offline RL. We formulate the problem as a two-player zero sum game against an adversarial environment model. The model is trained to minimise the value function while still accurately predicting the transitions in the dataset, forcing the policy to act conservatively in areas not covered by the dataset. To approximately solve the two-player game, we alternate between optimising the policy and adversarially optimising the model. The problem formulation that we address is theoretically grounded, resulting in a probably approximately correct (PAC) performance guarantee and a pessimistic value function which lower bounds the value function in the true environment. We evaluate our approach on widely studied offline RL benchmarks, and demonstrate that it outperforms existing state-of-the-art baselines.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large-Scale Differentiable Causal Discovery of Factor Graphs",
        "paper_url": "https://openreview.net/pdf?id=k713e8vXzwR",
        "paper_authors": [
            "Romain Lopez",
            "Jan-Christian Huetter",
            "Jonathan Pritchard",
            "Aviv Regev"
        ],
        "paper_abstract": "A common theme in causal inference is learning causal relationships between observed variables, also known as causal discovery. This is usually a daunting task, given the large number of candidate causal graphs and the combinatorial nature of the search space. Perhaps for this reason, most research has so far focused on relatively small causal graphs, with up to hundreds of nodes. However, recent advances in fields like biology enable generating experimental data sets with thousands of interventions followed by rich profiling of thousands of variables, raising the opportunity and urgent need for large causal graph models.  Here, we introduce the notion of factor directed acyclic graphs ($f$-DAGs) as a way to restrict the search space to non-linear low-rank causal interaction models. Combining this novel structural assumption with recent advances that bridge the gap between causal discovery and continuous optimization, we achieve causal discovery on thousands of variables. Additionally, as a model for the impact of statistical noise on this estimation procedure, we study a model of edge perturbations of the $f$-DAG skeleton based on random graphs and quantify the effect of such perturbations on the $f$-DAG rank. This theoretical analysis suggests that the set of candidate $f$-DAGs is much smaller than the whole DAG space and thus may be more suitable as a search space in the high-dimensional regime where the underlying skeleton is hard to assess. We propose Differentiable Causal Discovery of Factor Graphs (DCD-FG), a scalable implementation of $f$-DAG constrained causal discovery for high-dimensional interventional data. DCD-FG uses a Gaussian non-linear low-rank structural equation model and shows significant improvements compared to state-of-the-art methods in both simulations as well as a recent large-scale single-cell RNA sequencing data set with hundreds of genetic interventions.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generating Long Videos of Dynamic Scenes",
        "paper_url": "https://openreview.net/pdf?id=VnAwNNJiwDb",
        "paper_authors": [
            "Tim Brooks",
            "Janne Hellsten",
            "Miika Aittala",
            "Ting-chun Wang",
            "Timo Aila",
            "Jaakko Lehtinen",
            "Ming-Yu Liu",
            "Alexei A Efros",
            "Tero Karras"
        ],
        "paper_abstract": "We present a video generation model that accurately reproduces object motion, changes in camera viewpoint, and new content that arises over time. Existing video generation methods often fail to produce new content as a function of time while maintaining consistencies expected in real environments, such as plausible dynamics and object persistence. A common failure case is for content to never change due to over-reliance on inductive bias to provide temporal consistency, such as a single latent code that dictates content for the entire video. On the other extreme, without long-term consistency, generated videos may morph unrealistically between different scenes. To address these limitations, we prioritize the time axis by redesigning the temporal latent representation and learning long-term consistency from data by training on longer videos. We leverage a two-phase training strategy, where we separately train using longer videos at a low resolution and shorter videos at a high resolution. To evaluate the capabilities of our model, we introduce two new benchmark datasets with explicit focus on long-term temporal dynamics.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adaptively Exploiting d-Separators with Causal Bandits",
        "paper_url": "https://openreview.net/pdf?id=-e2SBzFDE8x",
        "paper_authors": [
            "Blair Bilodeau",
            "Linbo Wang",
            "Daniel M. Roy"
        ],
        "paper_abstract": "Multi-armed bandit problems provide a framework to identify the optimal intervention over a sequence of repeated experiments. Without additional assumptions, minimax optimal performance (measured by cumulative regret) is well-understood. With access to additional observed variables that d-separate the intervention from the outcome (i.e., they are a d-separator), recent \"causal bandit\" algorithms provably incur less regret. However, in practice it is desirable to be agnostic to whether observed variables are a d-separator. Ideally, an algorithm should be adaptive; that is, perform nearly as well as an algorithm with oracle knowledge of the presence or absence of a d-separator. In this work, we formalize and study this notion of adaptivity, and provide a novel algorithm that simultaneously achieves (a) optimal regret when a d-separator is observed, improving on classical minimax algorithms, and (b) significantly smaller regret than recent causal bandit algorithms when the observed variables are not a d-separator. Crucially, our algorithm does not require any oracle knowledge of whether a d-separator is observed. We also generalize this adaptivity to other conditions, such as the front-door criterion.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction",
        "paper_url": "https://openreview.net/pdf?id=dMK7EwoTYp",
        "paper_authors": [
            "Zehao Yu",
            "Songyou Peng",
            "Michael Niemeyer",
            "Torsten Sattler",
            "Andreas Geiger"
        ],
        "paper_abstract": "In recent years, neural implicit surface reconstruction methods have become popular for multi-view 3D reconstruction. In contrast to traditional multi-view stereo methods, these approaches tend to produce smoother and more complete reconstructions due to the inductive smoothness bias of neural networks. State-of-the-art neural implicit methods allow for high-quality reconstructions of simple scenes from many input views. Yet, their performance drops significantly for larger and more complex scenes and scenes captured from sparse viewpoints. This is caused primarily by the inherent ambiguity in the RGB reconstruction loss that does not provide enough constraints, in particular in less-observed and textureless areas. Motivated by recent advances in the area of monocular geometry prediction, we systematically explore the utility these cues provide for improving neural implicit surface reconstruction. We demonstrate that depth and normal cues, predicted by general-purpose monocular estimators, significantly improve reconstruction quality and optimization time. Further, we analyse and investigate multiple design choices for representing neural implicit surfaces, ranging from monolithic MLP models over single-grid to multi-resolution grid representations. We observe that geometric monocular priors improve performance both for small-scale single-object as well as large-scale multi-object scenes, independent of the choice of representation. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TarGF: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification",
        "paper_url": "https://openreview.net/pdf?id=Euv1nXN98P3",
        "paper_authors": [
            "Mingdong Wu",
            "fangwei zhong",
            "Yulong Xia",
            "Hao Dong"
        ],
        "paper_abstract": "Object Rearrangement is to move objects from an initial state to a goal state. Here, we focus on a more practical setting in object rearrangement, i.e., rearranging objects from shuffled layouts to a normative target distribution without explicit goal specification. However, it remains challenging for AI agents, as it is hard to describe the target distribution (goal specification) for reward engineering or collect expert trajectories as demonstrations. Hence, it is infeasible to directly employ reinforcement learning or imitation learning algorithms to address the task. This paper aims to search for a policy only with a set of examples from a target distribution instead of a handcrafted reward function. We employ the score-matching objective to train a Target Gradient Field (TarGF), indicating a direction on each object to increase the likelihood of the target distribution. For object rearrangement, the TarGF can be used in two ways: 1) For model-based planning, we can cast the target gradient into a reference control and output actions with a distributed path planner; 2) For model-free reinforcement learning, the TarGF is not only used for estimating the likelihood-change as a reward but also provides suggested actions in residual policy learning. Experimental results in ball and room rearrangement demonstrate that our method significantly outperforms the state-of-the-art methods in the quality of the terminal state, the efficiency of the control process, and scalability.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking Resolution in the Context of Efficient Video Recognition",
        "paper_url": "https://openreview.net/pdf?id=rnJzy8JnaX",
        "paper_authors": [
            "Chuofan Ma",
            "Qiushan Guo",
            "Yi Jiang",
            "Ping Luo",
            "Zehuan Yuan",
            "XIAOJUAN QI"
        ],
        "paper_abstract": "In this paper, we empirically study how to make the most of low-resolution frames for efficient video recognition. Existing methods mainly focus on developing compact networks or alleviating temporal redundancy of video inputs to increase efficiency, whereas compressing frame resolution has rarely been considered a promising solution. A major concern is the poor recognition accuracy on low-resolution frames. We thus start by analyzing the underlying causes of performance degradation on low-resolution frames. Our key finding is that the major cause of degradation is not information loss in the down-sampling process, but rather the mismatch between network architecture and input scale. Motivated by the success of knowledge distillation (KD), we propose to bridge the gap between network and input size via cross-resolution KD (ResKD). Our work shows that ResKD is a simple but effective method to boost recognition accuracy on low-resolution frames. Without bells and whistles, ResKD considerably surpasses all competitive methods in terms of efficiency and accuracy on four large-scale benchmark datasets, i.e., ActivityNet, FCVID, Mini-Kinetics, Something-Something V2. In addition, we extensively demonstrate its effectiveness over state-of-the-art architectures, i.e., 3D-CNNs and Video Transformers, and scalability towards super low-resolution frames. The results suggest ResKD can serve as a general inference acceleration method for state-of-the-art video recognition. Our code will be available at https://github.com/CVMI-Lab/ResKD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Feature-Proxy Transformer for Few-Shot Segmentation",
        "paper_url": "https://openreview.net/pdf?id=hBaI5MY0CBz",
        "paper_authors": [
            "Jian-Wei Zhang",
            "Yifan Sun",
            "Yi Yang",
            "Wei Chen"
        ],
        "paper_abstract": "Few-shot segmentation~(FSS) aims at performing semantic segmentation on novel classes given a few annotated support samples. With a rethink of recent advances, we find that the current FSS framework has deviated far from the supervised segmentation framework: Given the deep features, FSS methods typically use an intricate decoder to perform sophisticated pixel-wise matching, while the supervised segmentation methods use a simple linear classification head. Due to the intricacy of the decoder and its matching pipeline, it is not easy to follow such an FSS framework. This paper revives the straightforward framework of ``feature extractor $+$ linear classification head'' and proposes a novel Feature-Proxy Transformer (FPTrans) method, in which the ``proxy'' is the vector representing a semantic class in the linear classification head. FPTrans has two keypoints for learning discriminative features and representative proxies: 1) To better utilize the limited support samples, the feature extractor makes the query interact with the support features from bottom to top layers using a novel prompting strategy. 2) FPTrans uses multiple local background proxies (instead of a single one) because the background is not homogeneous and may contain some novel foreground regions. These two keypoints are easily integrated into the vision transformer backbone with the prompting mechanism in the transformer. Given the learned features and proxies, FPTrans directly compares their cosine similarity for segmentation. Although the framework is straightforward, we show that FPTrans achieves competitive FSS accuracy on par with state-of-the-art decoder-based methods. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Private Synthetic Data for Multitask Learning and Marginal Queries",
        "paper_url": "https://openreview.net/pdf?id=5JdyRvTrK0q",
        "paper_authors": [
            "Giuseppe Vietri",
            "Cedric Archambeau",
            "Sergul Aydore",
            "William Brown",
            "Michael Kearns",
            "Aaron Roth",
            "Ankit Siva",
            "Shuai Tang",
            "Steven Wu"
        ],
        "paper_abstract": "We provide a differentially private algorithm for producing  synthetic data simultaneously useful for multiple tasks: marginal queries and multitask machine learning (ML). A key innovation in our algorithm is the ability to directly handle numerical features, in contrast to a number of related prior approaches which require numerical features to be first converted into {high cardinality} categorical features via {a binning strategy}. Higher binning granularity is required for better accuracy, but this negatively impacts scalability. Eliminating the need for binning allows us to produce synthetic data preserving large numbers of statistical queries such as marginals on numerical features, and class conditional linear threshold queries. Preserving the latter means that the fraction of points of each class label above a particular half-space is roughly the same in both the real and synthetic data. This is the property that is needed to train a linear classifier in a multitask setting. Our algorithm also allows us to produce high quality synthetic data for mixed marginal queries, that combine both categorical  and numerical features. Our method consistently runs 2-5x faster than the best comparable techniques, and provides significant accuracy improvements in both marginal queries and linear prediction tasks for mixed-type datasets.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Implicit Warping for Animation with Image Sets",
        "paper_url": "https://openreview.net/pdf?id=TrsAkAbC96",
        "paper_authors": [
            "Arun Mallya",
            "Ting-chun Wang",
            "Ming-Yu Liu"
        ],
        "paper_abstract": "We present a new implicit warping framework for image animation using sets of source images through the transfer of motion of a driving video. A single cross-modal attention layer is used to find correspondences between the source images and the driving image, choose the most appropriate features from different source images, and warp the selected features. This is in contrast to the existing methods that use explicit flow-based warping, which is designed for animation using a single source and does not extend well to multiple sources. The pick-and-choose capability of our framework helps it achieve state-of-the-art results on multiple datasets for image animation using both single and multiple source images.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AttCAT: Explaining Transformers via Attentive Class Activation Tokens",
        "paper_url": "https://openreview.net/pdf?id=cA8Zor8wFr5",
        "paper_authors": [
            "Yao Qiang",
            "Deng Pan",
            "Chengyin Li",
            "Xin Li",
            "Rhongho Jang",
            "Dongxiao Zhu"
        ],
        "paper_abstract": "Transformers have improved the state-of-the-art in various natural language processing and computer vision tasks. However, the success of the Transformer model has not yet been duly explained. Current explanation techniques, which dissect either the self-attention mechanism or gradient-based attribution, do not necessarily provide a faithful explanation of the inner workings of Transformers due to the following reasons: first, attention weights alone without considering the magnitudes of feature values are not adequate to reveal the self-attention mechanism; second, whereas most Transformer explanation techniques utilize self-attention module, the skip-connection module, contributing a significant portion of information flows in Transformers, has not yet been sufficiently exploited in explanation; third, the gradient-based attribution of individual feature does not incorporate interaction among features in explaining the model's output. In order to tackle the above problems, we propose a novel Transformer explanation technique via attentive class activation tokens, aka, AttCAT, leveraging encoded features, their gradients, and their attention weights to generate a faithful and confident explanation for Transformer's output. Extensive experiments are conducted to demonstrate the superior performance of AttCAT, which generalizes well to different Transformer architectures, evaluation metrics, datasets, and tasks, to the baseline methods. Our code is available at: https://github.com/qiangyao1988/AttCAT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trading off Utility, Informativeness, and Complexity in Emergent Communication",
        "paper_url": "https://openreview.net/pdf?id=O5arhQvBdH",
        "paper_authors": [
            "Mycal Tucker",
            "Roger P. Levy",
            "Julie Shah",
            "Noga Zaslavsky"
        ],
        "paper_abstract": "Emergent communication (EC) research often focuses on optimizing task-specific utility as a driver for communication. However, there is increasing evidence that human languages are shaped by task-general communicative constraints and evolve under pressure to optimize the Information Bottleneck (IB) tradeoff between the informativeness and complexity of the lexicon. Here, we integrate these two approaches by trading off utility, informativeness, and complexity in EC. To this end, we propose Vector-Quantized Variational Information Bottleneck (VQ-VIB), a method for training neural agents to encode inputs into discrete signals embedded in a continuous space. We evaluate our approach in multi-agent reinforcement learning settings and in color reference games and show that: (1) VQ-VIB agents can continuously adapt to changing communicative needs and, in the color domain, align with human languages; (2) the emergent VQ-VIB embedding spaces are semantically meaningful and perceptually grounded; and (3) encouraging informativeness leads to faster convergence rates and improved utility, both in VQ-VIB and in prior neural architectures for symbolic EC, with VQ-VIB achieving higher utility for any given complexity. This work offers a new framework for EC that is grounded in information-theoretic principles that are believed to characterize human language evolution and that may facilitate human-agent interaction.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online PAC-Bayes Learning",
        "paper_url": "https://openreview.net/pdf?id=4pwCvvel8or",
        "paper_authors": [
            "Maxime Haddouche",
            "Benjamin Guedj"
        ],
        "paper_abstract": "Most PAC-Bayesian bounds hold in the batch learning setting where data is collected at once, prior to inference or prediction. This somewhat departs from many contemporary learning problems where data streams are collected and the algorithms must dynamically adjust. We prove new PAC-Bayesian bounds in this online learning framework, leveraging an updated definition of regret, and we revisit classical PAC-Bayesian results with a batch-to-online conversion, extending their remit to the case of dependent data. Our results hold for bounded losses, potentially \\emph{non-convex}, paving the way to promising developments in online learning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Physical Dynamics with Subequivariant Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=siG_S8mUWxf",
        "paper_authors": [
            "Jiaqi Han",
            "Wenbing Huang",
            "Hengbo Ma",
            "Jiachen Li",
            "Joshua B. Tenenbaum",
            "Chuang Gan"
        ],
        "paper_abstract": "Graph Neural Networks (GNNs) have become a prevailing tool for learning physical dynamics. However, they still encounter several challenges: 1) Physical laws abide by symmetry,  which is a vital inductive bias accounting for model generalization and should be incorporated into the model design. Existing simulators either consider insufficient symmetry, or enforce excessive equivariance in practice when symmetry is partially broken by gravity. 2) Objects in the physical world possess diverse shapes, sizes, and properties, which should be appropriately processed by the model. To tackle these difficulties, we propose a novel backbone, called Subequivariant Graph Neural Network, which 1) relaxes equivariance to subequivariance by considering external fields like gravity, where the universal approximation ability holds theoretically; 2) introduces a new subequivariant object-aware message passing for learning physical interactions between multiple objects of various shapes in particle-based representation; 3) operates in a hierarchical fashion, allowing for modeling long-range and complex interactions. Our model achieves on average over 3% enhancement in contact prediction accuracy across 8 scenarios on Physion and 2$\\times$ lower rollout MSE on RigidFall compared with state-of-the-art GNN simulators, while exhibiting strong generalization and data efficiency.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning",
        "paper_url": "https://openreview.net/pdf?id=XtyeppctGgc",
        "paper_authors": [
            "Dongze Lian",
            "Zhou Daquan",
            "Jiashi Feng",
            "Xinchao Wang"
        ],
        "paper_abstract": "Existing fine-tuning methods either tune all parameters of the pre-trained model (full fine-tuning), which is not efficient, or only tune the last linear layer (linear probing), which suffers a significant accuracy drop compared to the full fine-tuning. In this paper, we propose a new parameter-efficient fine-tuning method termed as SSF, representing that researchers only need to Scale and Shift the deep Features extracted by a pre-trained model to catch up with the performance of full fine-tuning. In this way, SSF also surprisingly outperforms other parameter-efficient fine-tuning approaches even with a smaller number of tunable parameters. Furthermore, different from some existing parameter-efficient fine-tuning methods (e.g., Adapter or VPT) that introduce the extra parameters and computational cost in the training and inference stages, SSF only adds learnable parameters during the training stage, and these additional parameters can be merged into the original pre-trained model weights via re-parameterization in the inference phase. With the proposed SSF, our model obtains 2.46% (90.72% vs. 88.54%) and 11.48% (73.10% vs. 65.57%) performance improvement on FGVC and VTAB-1k in terms of Top-1 accuracy compared to the full fine-tuning but only fine-tuning about 0.3M parameters. We also conduct amounts of experiments in various model families (CNNs, Transformers, and MLPs) and datasets. Results on 26 image classification datasets in total and 3 robustness & out-of-distribution datasets show the effectiveness of SSF. Code is available at https://github.com/dongzelian/SSF. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MCMAE: Masked Convolution Meets Masked Autoencoders",
        "paper_url": "https://openreview.net/pdf?id=qm5LpHyyOUO",
        "paper_authors": [
            "Peng Gao",
            "Teli Ma",
            "Hongsheng Li",
            "Ziyi Lin",
            "Jifeng Dai",
            "Yu Qiao"
        ],
        "paper_abstract": "Vision Transformers (ViT) become widely-adopted architectures for various vision tasks. Masked auto-encoding for feature pretraining and multi-scale hybrid convolution-transformer architectures can further unleash the potentials of ViT, leading to state-of-the-art performances on image classification, detection and semantic segmentation. In this paper, our MCMAE framework demonstrates that multi-scale hybrid convolution-transformer can learn more discriminative representations via the mask auto-encoding scheme. However, directly using the original masking strategy leads to the heavy computational cost and pretraining-finetuning discrepancy. To tackle the issue, we adopt the masked convolution to prevent information leakage in the convolution blocks. A simple block-wise masking strategy is proposed to ensure computational efficiency. We also propose to more directly supervise the multi-scale features of the encoder to boost multi-scale features. Based on our pretrained MCMAE models, MCMAE-Base improves ImageNet-1K finetuning accuracy by 1.4% compared with MAE-Base. On object detection, MCMAE-Base finetuned for only 25 epochs surpasses MAE-Base fined-tuned for 100 epochs by 2.9% box AP and 2.2% mask AP respectively. Code and pretrained models are available at \\url{https://github.com/Alpha-VL/ConvMAE}. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training Spiking Neural Networks with Event-driven Backpropagation",
        "paper_url": "https://openreview.net/pdf?id=d4JmP1T45WE",
        "paper_authors": [
            "Yaoyu Zhu",
            "Zhaofei Yu",
            "Wei Fang",
            "Xiaodong Xie",
            "Tiejun Huang",
            "Timoth\u00e9e Masquelier"
        ],
        "paper_abstract": "    Spiking Neural networks (SNNs) represent and transmit information by spatiotemporal spike patterns, which bring two major advantages: biological plausibility and suitability for ultralow-power neuromorphic implementation. Despite this, the binary firing characteristic makes training SNNs more challenging. To learn the parameters of deep SNNs in an event-driven fashion as in inference of SNNs, backpropagation with respect to spike timing is proposed. Although this event-driven learning has the advantages of lower computational cost and memory occupation, the accuracy is far below the recurrent neural network-like learning approaches. In this paper, we first analyze the commonly used temporal backpropagation training approach and prove that the sum of gradients remains unchanged between fully-connected and convolutional layers. Secondly, we show that the max pooling layer meets the above invariance rule, while the average pooling layer does not, which will suffer the gradient vanishing problem but can be revised to meet the requirement. Thirdly, we point out the reverse gradient problem for time-based gradients and propose a backward kernel that can solve this problem and keep the property of the invariable sum of gradients. The experimental results show that the proposed approach achieves state-of-the-art performance on CIFAR10 among time-based training methods. Also, this is the first time that the time-based backpropagation approach successfully trains SNN on the CIFAR100 dataset.  Our code is available at https://github.com/zhuyaoyu/SNN-event-driven-learning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "I2DFormer: Learning Image to Document Attention for Zero-Shot Image Classification",
        "paper_url": "https://openreview.net/pdf?id=mjUrg0uKpQ",
        "paper_authors": [
            "Muhammad Ferjad Naeem",
            "Yongqin Xian",
            "Luc Van Gool",
            "Federico Tombari"
        ],
        "paper_abstract": "Despite the tremendous progress in zero-shot learning (ZSL), the majority of existing methods still rely on human-annotated attributes, which are difficult to annotate and scale. An unsupervised alternative is to represent each class using the word embedding associated with its semantic class name. However, word embeddings extracted from pre-trained language models do not necessarily capture visual similarities, resulting in poor zero-shot performance.  In this work, we argue that online textual documents e.g., Wikipedia, contain rich visual descriptions about object classes, therefore can be used as powerful unsupervised side information for ZSL. To this end, we propose I2DFormer, a novel transformer-based ZSL framework that jointly learns to encode images and documents by aligning both modalities in a shared embedding space. In order to distill discriminative visual words from noisy documents, we introduce a new cross-modal attention module that learns fine-grained interactions between image patches and document words. Consequently, our I2DFormer not only learns highly discriminative document embeddings that capture visual similarities but also gains the ability to localize visually relevant words in image regions. Quantitatively, we demonstrate that our I2DFormer significantly outperforms previous unsupervised semantic embeddings under both zero-shot and generalized zero-shot learning settings on three public datasets. Qualitatively, we show that our method leads to highly interpretable results where document words can be grounded in the image regions. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Temporal Effective Batch Normalization in Spiking Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=fLIgyyQiJqz",
        "paper_authors": [
            "Chaoteng Duan",
            "Jianhao Ding",
            "Shiyan Chen",
            "Zhaofei Yu",
            "Tiejun Huang"
        ],
        "paper_abstract": "Spiking Neural Networks (SNNs) are promising in neuromorphic hardware owing to utilizing spatio-temporal information and sparse event-driven signal processing. However, it is challenging to train SNNs due to the non-differentiable nature of the binary firing function. The surrogate gradients alleviate the training problem and make SNNs obtain comparable performance as Artificial Neural Networks (ANNs) with the same structure. Unfortunately, batch normalization, contributing to the success of ANNs, does not play a prominent role in SNNs because of the additional temporal dimension. To this end, we propose an effective normalization method called temporal effective batch normalization (TEBN). By rescaling the presynaptic inputs with different weights at every time-step, temporal distributions become smoother and uniform. Theoretical analysis shows that TEBN can be viewed as a smoother of SNN's optimization landscape and could help stabilize the gradient norm. Experimental results on both static and neuromorphic datasets show that SNNs with TEBN outperform the state-of-the-art accuracy with fewer time-steps, and achieve better robustness to hyper-parameters than other normalizations.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Masked Generative Adversarial Networks are Data-Efficient Generation Learners",
        "paper_url": "https://openreview.net/pdf?id=js2ssA77fX",
        "paper_authors": [
            "Jiaxing Huang",
            "Kaiwen Cui",
            "Dayan Guan",
            "Aoran Xiao",
            "Fangneng Zhan",
            "Shijian Lu",
            "Shengcai Liao",
            "Eric Xing"
        ],
        "paper_abstract": "This paper shows that masked generative adversarial network (MaskedGAN) is robust image generation learners with limited training data. The idea of MaskedGAN is simple: it randomly masks out certain image information for effective GAN training with limited data. We develop two masking strategies that work along orthogonal dimensions of training images, including a shifted spatial masking that masks the images in spatial dimensions with random shifts, and a balanced spectral masking that masks certain image spectral bands with self-adaptive probabilities. The two masking strategies complement each other which together encourage more challenging holistic learning from limited training data, ultimately suppressing trivial solutions and failures in GAN training. Albeit simple, extensive experiments show that MaskedGAN achieves superior performance consistently across different network architectures (e.g., CNNs including BigGAN and StyleGAN-v2 and Transformers including TransGAN and GANformer) and datasets (e.g., CIFAR-10, CIFAR-100, ImageNet, 100-shot, AFHQ, FFHQ and Cityscapes).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SAViT: Structure-Aware Vision Transformer Pruning via Collaborative Optimization",
        "paper_url": "https://openreview.net/pdf?id=w5DacXWzQ-Q",
        "paper_authors": [
            "Zheng Chuanyang",
            "Zheyang Li",
            "Kai Zhang",
            "Zhi Yang",
            "Wenming Tan",
            "Jun Xiao",
            "Ye Ren",
            "Shiliang Pu"
        ],
        "paper_abstract": "Vision Transformers (ViTs) yield impressive performance across various vision tasks. However, heavy computation and memory footprint make them inaccessible for edge devices. Previous works apply importance criteria determined independently by each individual component to prune ViTs. Considering that heterogeneous components in ViTs play distinct roles, these approaches lead to suboptimal performance. In this paper, we introduce joint importance, which integrates essential structural-aware interactions between components for the first time, to perform collaborative pruning. Based on the theoretical analysis, we construct a Taylor-based approximation to evaluate the joint importance. This guides pruning toward a more balanced reduction across all components. To further reduce the algorithm complexity, we incorporate the interactions into the optimization function under some mild assumptions. Moreover, the proposed method can be seamlessly applied to various tasks including object detection. Extensive experiments demonstrate the effectiveness of our method. Notably, the proposed approach outperforms the existing state-of-the-art approaches on ImageNet, increasing accuracy by 0.7% over the DeiT-Base baseline while saving 50% FLOPs. On COCO, we are the first to show that 70% FLOPs of FasterRCNN with ViT backbone can be removed with only 0.3% mAP drop. The code is available at https://github.com/hikvision-research/SAViT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SeqPATE: Differentially Private Text Generation via Knowledge Distillation",
        "paper_url": "https://openreview.net/pdf?id=ZG5Bi1N4V0U",
        "paper_authors": [
            "Zhiliang Tian",
            "Yingxiu Zhao",
            "Ziyue Huang",
            "Yu-Xiang Wang",
            "Nevin Zhang",
            "He He"
        ],
        "paper_abstract": "Protecting the privacy of user data is crucial for text generation models, which can leak sensitive information during generation. Differentially private (DP) learning methods provide guarantees against identifying the existence of a training sample from model outputs. PATE is a recent DP learning algorithm that achieves high utility with strong privacy protection on training samples. However, text generation models output tokens sequentially in a large output space; the classic PATE algorithm is not customized for this setting. Furthermore, PATE works well to protect sample-level privacy, but is not designed to protect phrases in samples. In this paper, we propose SeqPATE, an extension of PATE to text generation that protects the privacy of individual training samples and sensitive phrases in training data. To adapt PATE to text generation, we generate pseudo-contexts and reduce the sequence generation problem to a next-word prediction problem. To handle the large output space, we propose a candidate filtering strategy to dynamically reduce the output space, and refine the teacher aggregation of PATE to avoid low agreement due to voting for a large number of candidates. To further reduce privacy losses, we use knowledge distillation to reduce the number of teacher queries. The experiments verify the effectiveness of SeqPATE in protecting both training samples and sensitive phrases.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A framework for bilevel optimization that enables  stochastic and global variance reduction algorithms",
        "paper_url": "https://openreview.net/pdf?id=wlEOsQ917F",
        "paper_authors": [
            "Mathieu Dagr\u00e9ou",
            "Pierre Ablin",
            "Samuel Vaiter",
            "Thomas Moreau"
        ],
        "paper_abstract": "Bilevel optimization, the problem of minimizing a value function which involves the arg-minimum of another function, appears in many areas of machine learning. In a large scale empirical risk minimization setting where the number of samples is huge, it is crucial to develop stochastic methods, which only use a few samples at a time to progress. However, computing the gradient of the value function involves solving a linear system, which makes it difficult to derive unbiased stochastic estimates.\nTo overcome this problem we introduce a novel framework, in which the solution of the inner problem, the solution of the linear system, and the main variable evolve at the same time. These directions are written as a sum, making it straightforward to derive unbiased estimates.\nThe simplicity of our approach allows us to develop global variance reduction algorithms, where the dynamics of all variables is subject to variance reduction.\nWe demonstrate that SABA, an adaptation of the celebrated SAGA algorithm in our framework, has $O(\\frac1T)$ convergence rate, and that it achieves linear convergence under Polyak-Lojasciewicz assumption.\nThis is the first stochastic algorithm for bilevel optimization that verifies either of these properties.\nNumerical experiments validate the usefulness of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified Model for Multi-class Anomaly Detection",
        "paper_url": "https://openreview.net/pdf?id=bMYU8_qD8PW",
        "paper_authors": [
            "Zhiyuan You",
            "Lei Cui",
            "Yujun Shen",
            "Kai Yang",
            "Xin Lu",
            "Yu Zheng",
            "Xinyi Le"
        ],
        "paper_abstract": "Despite the rapid advance of unsupervised anomaly detection, existing methods require to train separate models for different objects. In this work, we present UniAD that accomplishes anomaly detection for multiple classes with a unified framework. Under such a challenging setting, popular reconstruction networks may fall into an \"identical shortcut\", where both normal and anomalous samples can be well recovered, and hence fail to spot outliers. To tackle this obstacle, we make three improvements. First, we revisit the formulations of fully-connected layer, convolutional layer, as well as attention layer, and confirm the important role of query embedding (i.e., within attention layer) in preventing the network from learning the shortcut. We therefore come up with a layer-wise query decoder to help model the multi-class distribution. Second, we employ a neighbor masked attention module to further avoid the information leak from the input feature to the reconstructed output feature. Third, we propose a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. We evaluate our algorithm on MVTec-AD and CIFAR-10 datasets, where we surpass the state-of-the-art alternatives by a sufficiently large margin. For example, when learning a unified model for 15 categories in MVTec-AD, we surpass the second competitor on the tasks of both anomaly detection (from 88.1% to 96.5%) and anomaly localization (from 89.5% to 96.8%). Code is available at https://github.com/zhiyuanyou/UniAD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning from Future: A Novel Self-Training Framework for Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=0tG59j2efs",
        "paper_authors": [
            "Ye Du",
            "Yujun Shen",
            "Haochen Wang",
            "Jingjing Fei",
            "Wei Li",
            "Liwei Wu",
            "Rui Zhao",
            "Zehua Fu",
            "Qingjie LIU"
        ],
        "paper_abstract": "Self-training has shown great potential in semi-supervised learning. Its core idea is to use the model learned on labeled data to generate pseudo-labels for unlabeled samples, and in turn teach itself. To obtain valid supervision, active attempts typically employ a momentum teacher for pseudo-label prediction yet observe the confirmation bias issue, where the incorrect predictions may provide wrong supervision signals and get accumulated in the training process. The primary cause of such a drawback is that the prevailing self-training framework acts as guiding the current state with previous knowledge because the teacher is updated with the past student only. To alleviate this problem, we propose a novel self-training strategy, which allows the model to learn from the future. Concretely, at each training step, we first virtually optimize the student (i.e., caching the gradients without applying them to the model weights), then update the teacher with the virtual future student, and finally ask the teacher to produce pseudo-labels for the current student as the guidance. In this way, we manage to improve the quality of pseudo-labels and thus boost the performance. We also develop two variants of our future-self-training (FST) framework through peeping at the future both deeply (FST-D) and widely (FST-W). Taking the tasks of unsupervised domain adaptive semantic segmentation and semi-supervised semantic segmentation as the instances, we experimentally demonstrate the effectiveness and superiority of our approach under a wide range of settings. Code is available at https://github.com/usr922/FST.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Don't Roll the Dice, Ask Twice: The Two-Query Distortion of Matching Problems and Beyond",
        "paper_url": "https://openreview.net/pdf?id=gRK9SLQHTDV",
        "paper_authors": [
            "Georgios Amanatidis",
            "Georgios Birmpas",
            "Aris Filos-Ratsikas",
            "Alexandros A. Voudouris"
        ],
        "paper_abstract": "In most social choice settings, the participating agents express their preferences over the different alternatives in the form of linear orderings. While this clearly simplifies preference elicitation, it inevitably leads to poor performance with respect to optimizing a cardinal objective, such as the social welfare, since the values of the agents remain virtually unknown. This loss in performance because of lack of information is measured by distortion. A recent array of works put forward the agenda of designing mechanisms that learn the values of the agents for a small number of alternatives via queries, and use this limited extra information to make better-informed decisions, thus improving distortion. Following this agenda, in this work we focus on a class of combinatorial problems that includes most well-known matching problems and several of their generalizations, such as One-Sided Matching, Two-Sided Matching, General Graph Matching, and k-Constrained Resource Allocation. We design two-query mechanisms that achieve the best-possible worst-case distortion in terms of social welfare, and outperform the best-possible expected distortion achieved by randomized ordinal mechanisms.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Biologically Inspired Dynamic Thresholds for Spiking Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=1bE24ZURBqm",
        "paper_authors": [
            "Jianchuan Ding",
            "Bo Dong",
            "Felix Heide",
            "Yufei Ding",
            "Yunduo Zhou",
            "Baocai Yin",
            "Xin Yang"
        ],
        "paper_abstract": "The dynamic membrane potential threshold, as one of the essential properties of a biological neuron, is a spontaneous regulation mechanism that maintains neuronal homeostasis, i.e., the constant overall spiking firing rate of a neuron. As such, the neuron firing rate is regulated by a dynamic spiking threshold, which has been extensively studied in biology. Existing work in the machine learning community does not employ bioinspired spiking threshold schemes. This work aims at bridging this gap by introducing a novel bioinspired dynamic energy-temporal threshold (BDETT) scheme for spiking neural networks (SNNs). The proposed BDETT scheme mirrors two bioplausible observations: a dynamic threshold has 1) a positive correlation with the average membrane potential and 2) a negative correlation with the preceding rate of depolarization. We validate the effectiveness of the proposed BDETT on robot obstacle avoidance and continuous control tasks under both normal conditions and various degraded conditions, including noisy observations, weights, and dynamic environments. We find that the BDETT outperforms existing static and heuristic threshold approaches by significant margins in all tested conditions, and we confirm that the proposed bioinspired dynamic threshold scheme offers homeostasis to SNNs in complex real-world tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Structural Kernel Search via Bayesian Optimization and Symbolical Optimal Transport",
        "paper_url": "https://openreview.net/pdf?id=-bLLVk-WRPy",
        "paper_authors": [
            "Matthias Bitzer",
            "Mona Meister",
            "Christoph Zimmer"
        ],
        "paper_abstract": "Despite recent advances in automated machine learning, model selection is still a complex and computationally intensive process. For Gaussian processes (GPs), selecting the kernel is a crucial task, often done manually by the expert. Additionally, evaluating the model selection criteria for Gaussian processes typically scales cubically in the sample size, rendering kernel search particularly computationally expensive. We propose a novel, efficient search method through a general, structured kernel space. Previous methods solved this task via Bayesian optimization and relied on measuring the distance between GP's directly in function space to construct a kernel-kernel. We present an alternative approach by defining a kernel-kernel over the symbolic representation of the statistical hypothesis that is associated with a kernel. We empirically show that this leads to a computationally more efficient way of searching through a discrete kernel space.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One-Inlier is First: Towards Efficient Position Encoding for Point Cloud Registration",
        "paper_url": "https://openreview.net/pdf?id=19MmorTQhho",
        "paper_authors": [
            "Fan Yang",
            "Lin Guo",
            "Zhi Chen",
            "Wenbing Tao"
        ],
        "paper_abstract": "Transformer architecture has shown great potential for many visual tasks, including point cloud registration. As an order-aware module, position encoding plays an important role in Transformer architecture applied to point cloud registration task. In this paper, we propose OIF-PCR, a one-inlier based position encoding method for point cloud registration network. Specifically, we first find one correspondence by a differentiable optimal transport layer, and use it to normalize each point for position encoding. It can eliminate the challenges brought by the different reference frames of two point clouds, and mitigate the feature ambiguity by learning the spatial consistency. Then, we propose a joint approach for establishing correspondence and position encoding, presenting an iterative optimization process. Finally, we design a progressive way for point cloud alignment and feature learning to gradually optimize the rigid transformation. The proposed position encoding is very efficient, requiring only a small addition of memory and computing overhead. Extensive experiments demonstrate the proposed method can achieve competitive performance with the state-of-the-art methods in both indoor and outdoor scenes.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Debiased Self-Training for Semi-Supervised Learning",
        "paper_url": "https://openreview.net/pdf?id=NI7moUOKtc",
        "paper_authors": [
            "Baixu Chen",
            "Junguang Jiang",
            "Ximei Wang",
            "Pengfei Wan",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "paper_abstract": "Deep neural networks achieve remarkable performances on a wide range of tasks with the aid of large-scale labeled datasets. Yet these datasets are time-consuming and labor-exhaustive to obtain on realistic tasks. To mitigate the requirement for labeled data, self-training is widely used in semi-supervised learning by iteratively assigning pseudo labels to unlabeled samples. Despite its popularity, self-training is well-believed to be unreliable and often leads to training instability. Our experimental studies further reveal that the bias in semi-supervised learning arises from both the problem itself and the inappropriate training with potentially incorrect pseudo labels, which accumulates the error in the iterative self-training process. To reduce the above bias, we propose Debiased Self-Training (DST). First, the generation and utilization of pseudo labels are decoupled by two parameter-independent classifier heads to avoid direct error accumulation. Second, we estimate the worst case of self-training bias, where the pseudo labeling function is accurate on labeled samples, yet makes as many mistakes as possible on unlabeled samples. We then adversarially optimize the representations to improve the quality of pseudo labels by avoiding the worst case. Extensive experiments justify that DST achieves an average improvement of 6.3% against state-of-the-art methods on standard semi-supervised learning benchmark datasets and 18.9% against FixMatch on 13 diverse tasks. Furthermore, DST can be seamlessly adapted to other self-training methods and help stabilize their training and balance performance across classes in both cases of training from scratch and finetuning from pre-trained models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Transformer-based Working Memory for Multiagent Reinforcement Learning with Action Parsing",
        "paper_url": "https://openreview.net/pdf?id=pd6ipu3jDw",
        "paper_authors": [
            "Yaodong Yang",
            "Guangyong Chen",
            "Weixun Wang",
            "Xiaotian Hao",
            "Jianye HAO",
            "Pheng-Ann Heng"
        ],
        "paper_abstract": "Learning in real-world multiagent tasks is challenging due to the usual partial observability of each agent. Previous efforts alleviate the partial observability by historical hidden states with Recurrent Neural Networks, however, they do not consider the multiagent characters that either the multiagent observation consists of a number of object entities or the action space shows clear entity interactions. To tackle these issues, we propose the Agent Transformer Memory (ATM) network with a transformer-based memory. First, ATM utilizes the transformer to enable the unified processing of the factored environmental entities and memory. Inspired by the human\u2019s working memory process where a limited capacity of information temporarily held in mind can effectively guide the decision-making, ATM updates its fixed-capacity memory with the working memory updating schema. Second, as agents' each action has its particular interaction entities in the environment, ATM parses the action space to introduce this action\u2019s semantic inductive bias by binding each action with its specified involving entity to predict the state-action value or logit. Extensive experiments on the challenging SMAC and Level-Based Foraging environments validate that ATM could boost existing multiagent RL algorithms with impressive learning acceleration and performance improvement.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sharing Knowledge for Meta-learning with Feature Descriptions",
        "paper_url": "https://openreview.net/pdf?id=kyY4w4IgtM8",
        "paper_authors": [
            "Tomoharu Iwata",
            "Atsutoshi Kumagai"
        ],
        "paper_abstract": "Language is an important tool for humans to share knowledge. We propose a meta-learning method that shares knowledge across supervised learning tasks using feature descriptions written in natural language, which have not been used in the existing meta-learning methods. The proposed method improves the predictive performance on unseen tasks with a limited number of labeled data by meta-learning from various tasks. With the feature descriptions, we can find relationships across tasks even when their feature spaces are different. The feature descriptions are encoded using a language model pretrained with a large corpus, which enables us to incorporate human knowledge stored in the corpus into meta-learning. In our experiments, we demonstrate that the proposed method achieves better predictive performance than the existing meta-learning methods using a wide variety of real-world datasets provided by the statistical office of the EU and Japan.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MultiScan: Scalable RGBD scanning for 3D environments with articulated objects",
        "paper_url": "https://openreview.net/pdf?id=YxUdazpgweG",
        "paper_authors": [
            "Yongsen Mao",
            "Yiming Zhang",
            "Hanxiao Jiang",
            "Angel X Chang",
            "Manolis Savva"
        ],
        "paper_abstract": "We introduce MultiScan, a scalable RGBD dataset construction pipeline leveraging commodity mobile devices to scan indoor scenes with articulated objects and web-based semantic annotation interfaces to efficiently annotate object and part semantics and part mobility parameters. We use this pipeline to collect 273 scans of 117 indoor scenes containing 10957 objects and 5129 parts. The resulting MultiScan dataset provides RGBD streams with per-frame camera poses, textured 3D surface meshes, richly annotated part-level and object-level semantic labels, and part mobility parameters. We validate our dataset on instance segmentation and part mobility estimation tasks and benchmark methods for these tasks from prior work. Our experiments show that part segmentation and mobility estimation in real 3D scenes remain challenging despite recent progress in 3D object segmentation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Toward Equation of Motion for Deep Neural Networks: Continuous-time Gradient Descent and Discretization Error Analysis",
        "paper_url": "https://openreview.net/pdf?id=qq84D17BPu",
        "paper_authors": [
            "Taiki Miyagawa"
        ],
        "paper_abstract": "We derive and solve an ``Equation of Motion'' (EoM) for deep neural networks (DNNs), a differential equation that precisely describes the discrete learning dynamics of DNNs. Differential equations are continuous but have played a prominent role even in the study of discrete optimization (gradient descent (GD) algorithms). However, there still exist gaps between differential equations and the actual learning dynamics of DNNs due to discretization error. In this paper, we start from gradient flow (GF) and derive a counter term that cancels the discretization error between GF and GD. As a result, we obtain EoM, a continuous differential equation that precisely describes the discrete learning dynamics of GD. We also derive discretization error to show to what extent EoM is precise. In addition, we apply EoM to two specific cases: scale- and translation-invariant layers. EoM highlights differences between continuous and discrete GD, indicating the importance of the counter term for a better description of the discrete learning dynamics of GD. Our experimental results support our theoretical findings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DENSE: Data-Free One-Shot Federated Learning",
        "paper_url": "https://openreview.net/pdf?id=QFQoxCFYEkA",
        "paper_authors": [
            "Jie Zhang",
            "Chen Chen",
            "Bo Li",
            "Lingjuan Lyu",
            "Shuang Wu",
            "Shouhong Ding",
            "Chunhua Shen",
            "Chao Wu"
        ],
        "paper_abstract": "One-shot Federated Learning (FL) has recently emerged as a promising approach, which allows the central server to learn a model in a single communication round. Despite the low communication cost, existing one-shot FL methods are mostly impractical or face inherent limitations, \\eg a public dataset is required, clients' models are homogeneous, and additional data/model information need to be uploaded. To overcome these issues, we propose a novel two-stage \\textbf{D}ata-fre\\textbf{E} o\\textbf{N}e-\\textbf{S}hot federated l\\textbf{E}arning (DENSE) framework, which trains the global model by a data generation stage and a model distillation stage. DENSE is a practical one-shot FL method that can be applied in reality due to the following advantages:\n(1) DENSE requires no additional information compared with other methods (except the model parameters) to be transferred between clients and the server;\n(2) DENSE does not require any auxiliary dataset for training;\n(3) DENSE considers model heterogeneity in FL, \\ie different clients can have different model architectures.\nExperiments on a variety of real-world datasets demonstrate the superiority of our method.\nFor example, DENSE outperforms the best baseline method Fed-ADI by 5.08\\% on CIFAR10 dataset. \n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Large-batch Optimization for Dense Visual Predictions: Training Faster R-CNN in 4.2 Minutes",
        "paper_url": "https://openreview.net/pdf?id=kImIIKGqDFA",
        "paper_authors": [
            "Zeyue Xue",
            "Jianming Liang",
            "Guanglu Song",
            "Zhuofan Zong",
            "Liang Chen",
            "Yu Liu",
            "Ping Luo"
        ],
        "paper_abstract": "Training a large-scale deep neural network in a large-scale dataset is challenging and time-consuming. The recent breakthrough of large-batch optimization is a promising way to tackle this challenge. However, although the current advanced algorithms such as LARS and LAMB succeed in classification models, the complicated pipelines of dense visual predictions such as object detection and segmentation still suffer from the heavy performance drop in the large-batch training regime. To address this challenge, we propose a simple yet effective algorithm, named Adaptive Gradient Variance Modulator (AGVM), which can train dense visual predictors with very large batch size, enabling several benefits more appealing than prior arts. Firstly, AGVM can align the gradient variances between different modules in the dense visual predictors, such as backbone, feature pyramid network (FPN), detection, and segmentation heads. We show that training with a large batch size can fail with the gradient variances misaligned among them, which is a phenomenon primarily overlooked in previous work. Secondly, AGVM is a plug-and-play module that generalizes well to many different architectures (e.g., CNNs and Transformers) and different tasks (e.g., object detection, instance segmentation, semantic segmentation, and panoptic segmentation). It is also compatible with different optimizers (e.g., SGD and AdamW). Thirdly, a theoretical analysis of AGVM is provided. Extensive experiments on the COCO and ADE20K datasets demonstrate the superiority of AGVM. For example, AGVM demonstrates more stable generalization performance than prior arts under extremely large batch size (i.e., 10k). AGVM can train Faster R-CNN+ResNet50 in 4.2 minutes without losing performance. It enables training an object detector with one billion parameters in just 3.5 hours, reducing the training time by 20.9\u00d7, whilst achieving 62.2 mAP on COCO. The deliverables will be released at https://github.com/Sense-X/AGVM.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Few-Shot Continual Active Learning by a Robot",
        "paper_url": "https://openreview.net/pdf?id=35I4narr5A",
        "paper_authors": [
            "Ali Ayub",
            "Carter Fendley"
        ],
        "paper_abstract": "In this paper, we consider a challenging but realistic continual learning problem, Few-Shot Continual Active Learning (FoCAL), where a CL agent is provided with unlabeled data for a new or a previously learned task in each increment and the agent only has limited labeling budget available. Towards this, we build on the continual learning and active learning literature and develop a framework that can allow a CL agent to continually learn new object classes from a few labeled training examples. Our framework represents each object class using a uniform Gaussian mixture model (GMM) and uses pseudo-rehearsal to mitigate catastrophic forgetting. The framework also uses uncertainty measures on the Gaussian representations of the previously learned classes to find the most informative samples to be labeled in an increment. We evaluate our approach on the CORe-50 dataset and on a real humanoid robot for the object classification task. The results show that our approach not only produces state-of-the-art results on the dataset but also allows a real robot to continually learn unseen objects in a real environment with limited labeling supervision provided by its user.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Training with Complementary Labels: On the Benefit of Gradually Informative Attacks",
        "paper_url": "https://openreview.net/pdf?id=s7SukMH7ie9",
        "paper_authors": [
            "Jianan Zhou",
            "Jianing Zhu",
            "Jingfeng Zhang",
            "Tongliang Liu",
            "Gang Niu",
            "Bo Han",
            "Masashi Sugiyama"
        ],
        "paper_abstract": "Adversarial training (AT) with imperfect supervision is significant but receives limited attention. To push AT towards more practical scenarios, we explore a brand new yet challenging setting, i.e., AT with complementary labels (CLs), which specify a class that a data sample does not belong to. However, the direct combination of AT with existing methods for CLs results in consistent failure, but not on a simple baseline of two-stage training. In this paper, we further explore the phenomenon and identify the underlying challenges of AT with CLs as intractable adversarial optimization and low-quality adversarial examples. To address the above problems, we propose a new learning strategy using gradually informative attacks, which consists of two critical components: 1) Warm-up Attack (Warm-up) gently raises the adversarial perturbation budgets to ease the adversarial optimization with CLs; 2) Pseudo-Label Attack (PLA) incorporates the progressively informative model predictions into a corrected complementary loss. Extensive experiments are conducted to demonstrate the effectiveness of our method on a range of benchmarked datasets. The code is publicly available at: https://github.com/RoyalSkye/ATCL.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sym-NCO: Leveraging Symmetricity for Neural Combinatorial Optimization",
        "paper_url": "https://openreview.net/pdf?id=kHrE2vi5Rvs",
        "paper_authors": [
            "Minsu Kim",
            "Junyoung Park",
            "Jinkyoo Park"
        ],
        "paper_abstract": "Deep reinforcement learning (DRL)-based combinatorial optimization (CO) methods (i.e., DRL-NCO) have shown significant merit over the conventional CO solvers as DRL-NCO is capable of learning CO solvers less relying on problem-specific expert domain knowledge (heuristic method) and supervised labeled data (supervised learning method). This paper presents a novel training scheme, Sym-NCO, which is a regularizer-based training scheme that leverages universal symmetricities in various CO problems and solutions. Leveraging symmetricities such as rotational and reflectional invariance can greatly improve the generalization capability of DRL-NCO because it allows the learned solver to exploit the commonly shared symmetricities in the same CO problem class. Our experimental results verify that our Sym-NCO greatly improves the performance of DRL-NCO methods in four CO tasks, including the traveling salesman problem (TSP), capacitated vehicle routing problem (CVRP), prize collecting TSP (PCTSP), and orienteering problem (OP), without utilizing problem-specific expert domain knowledge. Remarkably, Sym-NCO outperformed not only the existing DRL-NCO methods but also a competitive conventional solver, the iterative local search (ILS), in PCTSP at 240$\\times$ faster speed. Our source code is available at https://github.com/alstn12088/Sym-NCO. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "List-Decodable Sparse Mean Estimation",
        "paper_url": "https://openreview.net/pdf?id=PZtIiZ43E2R",
        "paper_authors": [
            "Shiwei Zeng",
            "Jie Shen"
        ],
        "paper_abstract": "Robust mean estimation is one of the most important problems in statistics: given a set of samples in $\\mathbb{R}^d$ where an $\\alpha$ fraction are drawn from some distribution $D$ and the rest are adversarially corrupted, we aim to estimate the mean of $D$. A surge of recent research interest has been focusing on the list-decodable setting where $\\alpha \\in (0, \\frac12]$, and the goal is to output a finite number of estimates among which at least one approximates the target mean. In this paper, we consider that the underlying distribution $D$ is Gaussian with $k$-sparse mean. Our main contribution is the first polynomial-time algorithm that enjoys sample complexity $O\\big(\\mathrm{poly}(k, \\log d)\\big)$, i.e. poly-logarithmic in the dimension. One of our core algorithmic ingredients is using low-degree {\\em sparse polynomials} to filter outliers, which may find more applications.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Pitfalls of Regularization in Off-Policy TD Learning",
        "paper_url": "https://openreview.net/pdf?id=vK53GLZJes8",
        "paper_authors": [
            "Gaurav Manek",
            "J Zico Kolter"
        ],
        "paper_abstract": "Temporal Difference (TD) learning is ubiquitous in reinforcement learning, where it is often combined with off-policy sampling and function approximation.  Unfortunately learning with this combination (known as the deadly triad), exhibits instability and unbounded error.  To account for this, modern Reinforcement Learning methods often implicitly (or sometimes explicitly) assume that regularization is sufficient to mitigate the problem in practice; indeed, the standard deadly triad examples from the literature can be ``fixed'' via proper regularization. In this paper, we introduce a series of new counterexamples to show that the instability and unbounded error of TD methods is not solved by regularization. We demonstrate that, in the off-policy setting with linear function approximation, TD methods can fail to learn a non-trivial value function under any amount of regularization; we further show that regularization can induce divergence under common conditions; and we show that one of the most promising methods to mitigate this divergence (Emphatic TD algorithms) may also diverge under regularization. We further demonstrate such divergence when using neural networks as function approximators.  Thus, we argue that the role of regularization in TD methods needs to be reconsidered, given that it is insufficient to prevent divergence and may itself introduce instability. There needs to be much more care in the practical and theoretical application of regularization to Reinforcement Learning methods.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimal Efficiency-Envy Trade-Off via Optimal Transport",
        "paper_url": "https://openreview.net/pdf?id=mvbr8A_eY2n",
        "paper_authors": [
            "Steven Yin",
            "Christian Kroer"
        ],
        "paper_abstract": "We consider the problem of allocating a distribution of items to $n$ recipients where each recipient has to be allocated a fixed, pre-specified fraction of all items, while ensuring that each recipient does not experience too much envy.  We show that this problem can be formulated as a variant of the semi-discrete optimal transport (OT) problem, whose solution structure in this case has a concise representation and a simple geometric interpretation.  Unlike existing literature that treats envy-freeness as a hard constraint, our formulation allows us to \\emph{optimally} trade off efficiency and envy continuously.  Additionally, we study the statistical properties of the space of our OT based allocation policies by showing a polynomial bound on the number of samples needed to approximate the optimal solution from samples.  Our approach is suitable for large-scale fair allocation problems such as the blood donation matching problem, and we show numerically that it performs well on a prior realistic data simulator.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Physically-Based Face Rendering for NIR-VIS Face Recognition",
        "paper_url": "https://openreview.net/pdf?id=NN_TpS5dpo5",
        "paper_authors": [
            "Yunqi Miao",
            "Alexandros Lattas",
            "Jiankang Deng",
            "Jungong Han",
            "Stefanos Zafeiriou"
        ],
        "paper_abstract": "Near infrared (NIR) to Visible (VIS) face matching is challenging due to the significant domain gaps as well as a lack of sufficient data for cross-modality model training. To overcome this problem, we propose a novel method for paired NIR-VIS facial image generation. Specifically, we reconstruct 3D face shape and reflectance from a large 2D facial dataset and introduce a novel method of transforming the VIS reflectance to NIR reflectance. We then use a physically-based renderer to generate a vast, high-resolution and photorealistic dataset consisting of various poses and identities in the NIR and VIS spectra. Moreover, to facilitate the identity feature learning, we propose an IDentity-based Maximum Mean Discrepancy (ID-MMD) loss, which not only reduces the modality gap between NIR and VIS images at the domain level but encourages the network to focus on the identity features instead of facial details, such as poses and accessories. Extensive experiments conducted on four challenging NIR-VIS face recognition benchmarks demonstrate that the proposed method can achieve comparable performance with the state-of-the-art (SOTA) methods without requiring any existing NIR-VIS face recognition datasets. With slightly fine-tuning on the target NIR-VIS face recognition datasets, our method can significantly surpass the SOTA performance. Code and pretrained models are released under the insightface GitHub.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Continual Learning with Evolving Class Ontologies",
        "paper_url": "https://openreview.net/pdf?id=i7WqjtdD0u",
        "paper_authors": [
            "Zhiqiu Lin",
            "Deepak Pathak",
            "Yu-Xiong Wang",
            "Deva Ramanan",
            "Shu Kong"
        ],
        "paper_abstract": "Lifelong learners must recognize concept vocabularies that evolve over time. A common yet underexplored scenario is learning with class labels that continually refine/expand old classes. For example, humans learn to recognize ${\\tt dog}$ before dog breeds. In practical settings, dataset ${\\it versioning}$ often introduces refinement to ontologies, such as autonomous vehicle benchmarks that refine a previous ${\\tt vehicle}$ class into ${\\tt school-bus}$ as autonomous operations expand to new cities. This paper formalizes a protocol for studying the problem of ${\\it Learning with Evolving Class Ontology}$ (LECO). LECO requires learning classifiers in distinct time periods (TPs); each TP introduces a new ontology of \"fine\" labels that refines old ontologies of  \"coarse\" labels (e.g., dog breeds that refine the previous ${\\tt dog}$). LECO explores such questions as whether to annotate new data or relabel the old, how to exploit coarse labels, and whether to finetune the previous TP's model or train from scratch. To answer these questions, we leverage insights from related problems such as  class-incremental learning. We validate them under the LECO protocol through the lens of image classification (on CIFAR and iNaturalist) and semantic segmentation (on Mapillary). Extensive experiments lead to some surprising conclusions; while the current status quo in the field is to relabel existing datasets with new class ontologies (such as COCO-to-LVIS or Mapillary1.2-to-2.0), LECO demonstrates that a far better strategy is to annotate ${\\it new}$ data with the new ontology. However, this produces an aggregate dataset with inconsistent old-vs-new labels, complicating learning. To address this challenge, we adopt methods from semi-supervised and partial-label learning. We demonstrate that such strategies can surprisingly be made near-optimal, in the sense of approaching an \"oracle\" that learns on the aggregate dataset exhaustively labeled with the newest ontology. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stability and Generalization Analysis of Gradient Methods for Shallow Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=BWEGx_GFCbL",
        "paper_authors": [
            "Yunwen Lei",
            "Rong Jin",
            "Yiming Ying"
        ],
        "paper_abstract": "While significant theoretical progress has been achieved,  unveiling the generalization mystery of overparameterized neural networks still remains largely elusive. In this paper, we study the generalization behavior of shallow neural networks (SNNs) by leveraging the concept of algorithmic stability. We consider gradient descent (GD) and stochastic gradient descent (SGD) to train SNNs, for both of which we develop consistent excess risk bounds by balancing the optimization and generalization via early-stopping. As compared to existing analysis on GD, our new analysis requires a relaxed overparameterization assumption and also  applies to SGD. The key for the improvement is a better estimation of the smallest eigenvalues of the Hessian matrices of the empirical risks and the loss function along the trajectories of GD and SGD by providing a refined estimation of their iterates.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Contrastive Framework for Neural Text Generation",
        "paper_url": "https://openreview.net/pdf?id=V88BafmH9Pj",
        "paper_authors": [
            "Yixuan Su",
            "Tian Lan",
            "Yan Wang",
            "Dani Yogatama",
            "Lingpeng Kong",
            "Nigel Collier"
        ],
        "paper_abstract": "Text generation is of great importance to many natural language processing applications. However, maximization-based decoding methods (e.g., beam search) of neural language models often lead to degenerate solutions---the generated text is unnatural and contains undesirable repetitions. Existing approaches introduce stochasticity via sampling or modify training objectives to decrease the probabilities of certain tokens (e.g., unlikelihood training). However, they often lead to solutions that lack coherence. In this work, we show that an underlying reason for model degeneration is the anisotropic distribution of token representations. We present a contrastive solution: (i) SimCTG, a contrastive training objective to calibrate the model's representation space, and (ii) a decoding method---contrastive search---to encourage diversity while maintaining coherence in the generated text. Extensive experiments and analyses on three benchmarks from two languages demonstrate that our proposed approach outperforms state-of-the-art text generation methods as evaluated by both human and automatic metrics.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models",
        "paper_url": "https://openreview.net/pdf?id=Gsbnnc--bnw",
        "paper_authors": [
            "Chen Henry Wu",
            "Saman Motamed",
            "Shaunak Srivastava",
            "Fernando De la Torre"
        ],
        "paper_abstract": "Generative models (e.g., GANs, diffusion models) learn the underlying data distribution in an unsupervised manner. However, many applications of interest require sampling from a particular region of the output space or sampling evenly over a range of characteristics. For efficient sampling in these scenarios, we propose Generative Visual Prompt (PromptGen), a framework for distributional control over pre-trained generative models by incorporating knowledge of other off-the-shelf models. PromptGen defines control as energy-based models (EBMs) and samples images in a feed-forward manner by approximating the EBM with invertible neural networks, avoiding optimization at inference. Our experiments demonstrate how PromptGen can efficiently sample from several unconditional generative models (e.g., StyleGAN2, StyleNeRF, diffusion autoencoder, NVAE) in a controlled or/and de-biased manner using various off-the-shelf models: (1) with the CLIP model as control, PromptGen can sample images guided by text, (2) with image classifiers as control, PromptGen can de-bias generative models across a set of attributes or attribute combinations, and (3) with inverse graphics models as control, PromptGen can sample images of the same identity in different poses. (4) Finally, PromptGen reveals that the CLIP model shows a \"reporting bias\" when used as control, and PromptGen can further de-bias this controlled distribution in an iterative manner. The code is available at https://github.com/ChenWu98/Generative-Visual-Prompt.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Polyhistor: Parameter-Efficient Multi-Task Adaptation for Dense Vision Tasks",
        "paper_url": "https://openreview.net/pdf?id=LCWQ8OYsf-O",
        "paper_authors": [
            "Yen-Cheng Liu",
            "Chih-Yao Ma",
            "Junjiao Tian",
            "Zijian He",
            "Zsolt Kira"
        ],
        "paper_abstract": "Adapting large-scale pretrained models to various downstream tasks via fine-tuning is a standard method in machine learning. Recently, parameter-efficient fine-tuning methods have shown promise in adapting a pretrained model to different tasks while training only a few parameters. Despite their success, most existing methods are proposed in Natural Language Processing tasks with language Transformers, and adaptation to Computer Vision tasks with Vision Transformers remains under-explored, especially for dense vision tasks. Further, in multi-task settings, individually fine-tuning and storing separate models for different tasks is inefficient. In this work, we provide an extensive single- and multi-task parameter-efficient benchmark and examine existing parameter-efficient fine-tuning NLP methods for vision tasks. Our results on four different dense vision tasks showed that existing methods cannot be efficiently integrated due to the hierarchical nature of the Hierarchical Vision Transformers. To overcome this issue, we propose Polyhistor and Polyhistor-Lite, consisting of Decomposed HyperNetworks and Layer-wise Scaling Kernels, to share information across different tasks with a few trainable parameters. This leads to favorable performance improvements against existing parameter-efficient methods while using fewer trainable parameters. Specifically, Polyhistor achieves competitive accuracy compared to the state-of-the-art while only using less than 10% of their trainable parameters. Furthermore, our methods show larger performance gains when large networks and more pretraining data are used. \n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Model-based Safe Deep Reinforcement Learning via a Constrained Proximal Policy Optimization Algorithm",
        "paper_url": "https://openreview.net/pdf?id=hYa_lseXK8",
        "paper_authors": [
            "Ashish Kumar Jayant",
            "Shalabh Bhatnagar"
        ],
        "paper_abstract": "During initial iterations of training in most Reinforcement Learning (RL) algorithms, agents perform a significant number of random exploratory steps. In the real world, this can limit the practicality of these algorithms as it can lead to potentially dangerous behavior. Hence safe exploration is a critical issue in applying RL algorithms in the real world. This problem has been recently well studied under the Constrained Markov Decision Process (CMDP) Framework, where in addition to single-stage rewards, an agent receives single-stage costs or penalties as well depending on the state transitions. The prescribed  cost functions are responsible for mapping undesirable behavior at any given time-step to a scalar value. The goal then is to find a feasible policy that maximizes reward returns while constraining the cost returns to be below a prescribed threshold during training as well as deployment.\n\nWe propose an On-policy Model-based Safe Deep RL algorithm in which we learn the transition dynamics of the environment in an online manner as well as find a feasible optimal policy using the Lagrangian Relaxation-based Proximal Policy Optimization. We use an ensemble of neural networks with different initializations to tackle epistemic and aleatoric uncertainty issues faced during environment model learning.  We compare our approach with relevant model-free and model-based approaches in Constrained RL using the  challenging Safe Reinforcement Learning benchmark - the Open AI Safety Gym.  \nWe demonstrate that our algorithm is more sample efficient and results in lower  cumulative hazard violations as compared to constrained model-free approaches. Further, our approach shows better reward performance than other constrained model-based approaches in the literature. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Generalizability and Predictability of Recommender Systems",
        "paper_url": "https://openreview.net/pdf?id=wO53HILzu65",
        "paper_authors": [
            "Duncan C. McElfresh",
            "Sujay Khandagale",
            "Jonathan Valverde",
            "John P Dickerson",
            "Colin White"
        ],
        "paper_abstract": "While other areas of machine learning have seen more and more automation, designing a high-performing recommender system still requires a high level of human effort. Furthermore, recent work has shown that modern recommender system algorithms do not always improve over well-tuned baselines. A natural follow-up question is, \"how do we choose the right algorithm for a new dataset and performance metric?\" In this work, we start by giving the first large-scale study of recommender system approaches by comparing 24 algorithms and 100 sets of hyperparameters across 85 datasets and 315 metrics. We find that the best algorithms and hyperparameters are highly dependent on the dataset and performance metric. However, there is also a strong correlation between the performance of each algorithm and various meta-features of the datasets. Motivated by these findings, we create RecZilla, a meta-learning approach to recommender systems that uses a model to predict the best algorithm and hyperparameters for new, unseen datasets. By using far more meta-training data than prior work, RecZilla is able to substantially reduce the level of human involvement when faced with a new recommender system application. We not only release our code and pretrained RecZilla models, but also all of our raw experimental results, so that practitioners can train a RecZilla model for their desired performance metric: https://github.com/naszilla/reczilla.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Variational Inference in Function Spaces: Gaussian Measures meet Bayesian Deep Learning",
        "paper_url": "https://openreview.net/pdf?id=mMT8bhVBoUa",
        "paper_authors": [
            "Veit David Wild",
            "Robert Hu",
            "Dino Sejdinovic"
        ],
        "paper_abstract": "We develop a framework for generalized variational inference in infinite-dimensional function spaces and use it to construct a method termed Gaussian Wasserstein inference (GWI). GWI leverages the Wasserstein distance between Gaussian measures on the Hilbert space of square-integrable functions in order to determine a variational posterior using a tractable optimization criterion. It avoids pathologies arising in standard variational function space inference. An exciting application of GWI is the ability to use deep neural networks in the variational parametrization of GWI, combining their superior predictive performance with the principled uncertainty quantification analogous to that of Gaussian processes. The proposed method obtains state-of-the-art performance on several benchmark datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-deep Networks",
        "paper_url": "https://openreview.net/pdf?id=zuL5OYIBgcV",
        "paper_authors": [
            "Ankit Goyal",
            "Alexey Bochkovskiy",
            "Jia Deng",
            "Vladlen Koltun"
        ],
        "paper_abstract": "Latency is of utmost importance in safety-critical systems. In neural networks, lowest theoretical latency is dependent on the depth of the network. This begs the question -- is it possible to build high-performing ``non-deep\" neural networks? We show that it is. To do so, we use parallel subnetworks instead of stacking one layer after another. This helps effectively reduce depth while maintaining high performance. By utilizing parallel substructures, we show, for the first time, that a network with a depth of just 12 can achieve top-1 accuracy over 80% on ImageNet, 96% on CIFAR10, and 81% on CIFAR100. We also show that a network with a low-depth (12) backbone can achieve an AP of 48% on MS-COCO. We analyze the scaling rules for our design and show how to increase performance without changing the network's depth. Finally, we provide a proof of concept for how non-deep networks could be used to build low-latency recognition systems. Code is available at https://github.com/imankgoyal/NonDeepNetworks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Private Estimation with Public Data",
        "paper_url": "https://openreview.net/pdf?id=YpyGV_i8Z_J",
        "paper_authors": [
            "Alex Bie",
            "Gautam Kamath",
            "Vikrant Singhal"
        ],
        "paper_abstract": "We initiate the study of differentially private (DP) estimation with access to a small amount of public data. For private estimation of $d$-dimensional Gaussians, we assume that the public data comes from a Gaussian that may have vanishing similarity in total variation distance with the underlying Gaussian of the private data. We show that under the constraints of pure or concentrated DP, $d+1$ public data samples are sufficient to remove any dependence on the range parameters of the private data distribution from the private sample complexity, which is known to be otherwise necessary without public data. For separated Gaussian mixtures, we assume that the underlying public and private distributions are the same, and we consider two settings: (1) when given a dimension-independent amount of public data, the private sample complexity can be improved polynomially in terms of the number of mixture components, and any dependence on the range parameters of the distribution can be removed in the approximate DP case; (2) when given an amount of public data linear in the dimension, the private sample complexity can be made independent of range parameters even under concentrated DP, and additional improvements can be made to the overall sample complexity.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Graph Scattering beyond Wavelet Shackles",
        "paper_url": "https://openreview.net/pdf?id=ptUZl8xDMMN",
        "paper_authors": [
            "Christian Koke",
            "Gitta Kutyniok"
        ],
        "paper_abstract": "This work develops a flexible and mathematically sound framework for the design and analysis of graph scattering networks with variable branching ratios and generic functional calculus filters.\tSpectrally-agnostic stability guarantees for node- and graph-level perturbations are derived; the vertex-set non-preserving case is treated by utilizing recently developed mathematical-physics based tools. Energy propagation through the network layers is investigated and related to truncation stability. New methods of graph-level feature aggregation are introduced and stability of the resulting composite scattering architectures is established. Finally, scattering transforms are extended to edge- and higher order tensorial input. Theoretical results are complemented by numerical investigations: Suitably chosen scattering networks conforming to the developed theory perform better than traditional graph-wavelet based scattering approaches in social network graph classification tasks and\tsignificantly outperform other graph-based learning approaches to regression of quantum-chemical energies on QM$7$.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PointTAD: Multi-Label Temporal Action Detection with Learnable Query Points",
        "paper_url": "https://openreview.net/pdf?id=_r8pCrHwq39",
        "paper_authors": [
            "Jing Tan",
            "Xiaotong Zhao",
            "Xintian Shi",
            "Bin Kang",
            "Limin Wang"
        ],
        "paper_abstract": "Traditional temporal action detection (TAD) usually handles untrimmed videos with small number of action instances from a single label (e.g., ActivityNet, THUMOS). However, this setting might be unrealistic as different classes of actions often co-occur in practice. In this paper, we focus on the task of multi-label temporal action detection that aims to localize all action instances from a multi-label untrimmed video. Multi-label TAD is more challenging as it requires for fine-grained class discrimination within a single video and precise localization of the co-occurring instances. To mitigate this issue, we extend the sparse query-based detection paradigm from the traditional TAD and propose the multi-label TAD framework of PointTAD. Specifically, our PointTAD introduces a small set of learnable query points to represent the important frames of each action instance. This point-based representation provides a flexible mechanism to localize the discriminative frames at boundaries and as well the important frames inside the action. Moreover, we perform the action decoding process with the Multi-level Interactive Module to capture both point-level and instance-level action semantics. Finally, our PointTAD employs an end-to-end trainable framework simply based on RGB input for easy deployment. We evaluate our proposed method on two popular benchmarks and introduce the new metric of detection-mAP for multi-label TAD. Our model outperforms all previous methods by a large margin under the detection-mAP metric, and also achieves promising results under the segmentation-mAP metric.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "New Lower Bounds for Private Estimation and a Generalized Fingerprinting Lemma",
        "paper_url": "https://openreview.net/pdf?id=c63eTNYh9Y",
        "paper_authors": [
            "Gautam Kamath",
            "Argyris Mouzakis",
            "Vikrant Singhal"
        ],
        "paper_abstract": "We prove new lower bounds for statistical estimation tasks under the constraint of $(\\varepsilon,\\delta)$-differential privacy. First, we provide tight lower bounds for private covariance estimation of Gaussian distributions. We show that estimating the covariance matrix in Frobenius norm requires $\\Omega(d^2)$ samples, and in spectral norm requires $\\Omega(d^{3/2})$ samples, both matching upper bounds up to logarithmic factors. We prove these bounds via our main technical contribution, a broad generalization of the fingerprinting method to exponential families. Additionally, using the private Assouad method of Acharya, Sun, and Zhang, we show a tight $\\Omega(d/(\\alpha^2 \\varepsilon))$ lower bound for estimating the mean of a distribution with bounded covariance to $\\alpha$-error in $\\ell_2$-distance. Prior known lower bounds for all these problems were either polynomially weaker or held under the stricter condition of $(\\varepsilon,0)$-differential privacy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Theory and Approximate Solvers for Branched Optimal Transport with Multiple Sources",
        "paper_url": "https://openreview.net/pdf?id=AezHeiz7eF5",
        "paper_authors": [
            "Peter Lippmann",
            "Enrique Fita Sanmart\u00edn",
            "Fred A Hamprecht"
        ],
        "paper_abstract": "Branched optimal transport (BOT) is a generalization of optimal transport in which transportation costs along an edge are subadditive. This subadditivity models an increase in transport efficiency when shipping mass along the same route, favoring branched transportation networks. We here study the NP-hard optimization of BOT networks connecting a finite number of sources and sinks in $\\mathbb{R}^2$. First, we show how to efficiently find the best geometry of a BOT network for many sources and sinks, given a topology. Second, we argue that a topology with more than three edges meeting at a branching point is never optimal. Third, we show that the results obtained for the Euclidean plane generalize directly to optimal transportation networks on two-dimensional Riemannian manifolds. Finally, we present a simple but effective approximate BOT solver combining geometric optimization with a combinatorial optimization of the network topology.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Is $L^2$ Physics Informed Loss Always Suitable for Training Physics Informed Neural Network?",
        "paper_url": "https://openreview.net/pdf?id=cy1TKLRAEML",
        "paper_authors": [
            "Chuwei Wang",
            "Shanda Li",
            "Di He",
            "Liwei Wang"
        ],
        "paper_abstract": "The Physics-Informed Neural Network (PINN) approach is a new and promising way to solve partial differential equations using deep learning. The $L^2$ Physics-Informed Loss is the de-facto standard in training Physics-Informed Neural Networks. In this paper, we challenge this common practice by investigating the relationship between the loss function and the approximation quality of the learned solution. In particular, we leverage the concept of stability in the literature of partial differential equation to study the asymptotic behavior of the learned solution as the loss approaches zero. With this concept, we study an important class of high-dimensional non-linear PDEs in optimal control, the Hamilton-Jacobi-Bellman (HJB) Equation, and prove that for general $L^p$ Physics-Informed Loss, a wide class of HJB equation is stable only if $p$ is sufficiently large. Therefore, the commonly used $L^2$ loss is not suitable for training PINN on those equations, while $L^{\\infty}$ loss is a better choice. Based on the theoretical insight, we develop a novel PINN training algorithm to minimize the $L^{\\infty}$ loss for HJB equations which is in a similar spirit to adversarial training. The effectiveness of the proposed algorithm is empirically demonstrated through experiments.  Our code is released at https://github.com/LithiumDA/L_inf-PINN.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Infinite-Horizon Average-Reward Restless Multi-Action Bandits via Index Awareness",
        "paper_url": "https://openreview.net/pdf?id=3v44ls_4dbg",
        "paper_authors": [
            "GUOJUN XIONG",
            "Shufan Wang",
            "Jian Li"
        ],
        "paper_abstract": "We consider the online restless bandits with average-reward and multiple actions, where the state of each arm evolves according to a Markov decision process (MDP), and the reward of pulling an arm depends on both the current state of the corresponding MDP and the action taken.  Since finding the optimal control is typically intractable for restless bandits, existing learning algorithms are often computationally expensive or with a regret bound that is exponential in the number of arms and states.  In this paper, we advocate \\textit{index-aware reinforcement learning} (RL) solutions to design RL algorithms operating on a much smaller dimensional subspace by exploiting the inherent structure in restless bandits.  Specifically, we first propose novel index policies to address dimensionality concerns, which are provably optimal.  We then leverage the indices to develop two low-complexity index-aware RL algorithms, namely, (i) GM-R2MAB, which has access to a generative model; and (ii) UC-R2MAB, which learns the model using an upper confidence style online exploitation method.  We prove that both algorithms achieve a sub-linear regret that is only polynomial in the number of arms and states.  A key differentiator between our algorithms and existing ones stems from the fact that our RL algorithms contain a novel exploitation that leverages our proposed provably optimal index policies for decision-makings. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding Robust Learning through the Lens of Representation Similarities",
        "paper_url": "https://openreview.net/pdf?id=SbAaNa97bzp",
        "paper_authors": [
            "Christian Cianfarani",
            "Arjun Nitin Bhagoji",
            "Vikash Sehwag",
            "Ben Zhao",
            "Haitao Zheng",
            "Prateek Mittal"
        ],
        "paper_abstract": "Representation learning, \\textit{i.e.} the generation of representations useful for downstream applications, is a task of fundamental importance that underlies much of the success of deep neural networks (DNNs). Recently, \\emph{robustness to adversarial examples} has emerged as a desirable property for DNNs, spurring the development of robust training methods that account for adversarial\nexamples. In this paper, we aim to understand how the properties of representations learned by robust training differ from those obtained from standard, non-robust training. This is critical to diagnosing numerous salient pitfalls in robust networks, such as, degradation of performance on benign inputs, poor generalization of robustness, and increase in over-fitting. We utilize a powerful set of tools known as representation similarity metrics, across 3 vision datasets, to obtain layer-wise comparisons between robust and non-robust DNNs with different architectures, training procedures and adversarial constraints. Our experiments highlight hitherto unseen properties of robust representations that we posit underlie the behavioral differences of robust networks. We discover a lack of specialization in robust networks' representations along with a disappearance of `block structure'. We also find overfitting during robust training largely impacts deeper layers. These, along with other findings, suggest ways forward for the design and training of better robust networks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Why Do Artificially Generated Data Help Adversarial Robustness",
        "paper_url": "https://openreview.net/pdf?id=W-Z8n9HrWn0",
        "paper_authors": [
            "Yue Xing",
            "Qifan Song",
            "Guang Cheng"
        ],
        "paper_abstract": "In the adversarial training framework of \\cite{carmon2019unlabeled,gowal2021improving}, people use generated/real unlabeled data with pseudolabels to improve adversarial robustness. We provide statistical insights to explain why the artificially generated data improve adversarial training. In particular, we study how the attack strength and the quality of the unlabeled data affect adversarial robustness in this framework. Our results show that with a high-quality unlabeled data generator, adversarial training can benefit greatly from this framework under large attack strength, while a poor generator can still help to some extent. To make adaptions concerning the quality of generated data, we propose an algorithm that performs online adjustment to the weight between the labeled real data and the generated data, aiming to optimize the adversarial risk. Numerical studies are conducted to verify our theories and show the effectiveness of the proposed algorithm.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Kernelised Stein Statistic for Assessing Implicit Generative Models",
        "paper_url": "https://openreview.net/pdf?id=t4vTbQnhM8",
        "paper_authors": [
            "Wenkai Xu",
            "Gesine Reinert"
        ],
        "paper_abstract": "Synthetic data generation has become a key ingredient for training machine learning procedures,  addressing tasks such as data augmentation, analysing privacy-sensitive data, or visualising representative samples. Assessing the quality of such synthetic data generators hence has to be addressed. As (deep) generative models for synthetic data often do not admit explicit probability distributions, classical statistical procedures for assessing model goodness-of-fit may not be applicable. In this paper, we propose a principled procedure to assess the quality of a synthetic data generator. The procedure is a Kernelised Stein Discrepancy-type test which is based on a non-parametric Stein operator for the synthetic data generator of interest. This operator is estimated from samples which are obtained from the synthetic data generator and hence can be applied even when the model is only implicit. In contrast to classical testing, the sample size from the synthetic data generator can be as large as desired, while the size of the observed data that the generator aims to emulate is fixed. Experimental results on synthetic distributions and trained generative models on synthetic and real datasets illustrate that the method shows improved power performance compared to existing approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Consistency-Aware Unsigned Distance Functions Progressively from Raw Point Clouds",
        "paper_url": "https://openreview.net/pdf?id=KqI-bX-TfT",
        "paper_authors": [
            "Junsheng Zhou",
            "Baorui Ma",
            "Yu-Shen Liu",
            "Yi Fang",
            "Zhizhong Han"
        ],
        "paper_abstract": "Surface reconstruction for point clouds is an important task in 3D computer vision. Most of the latest methods resolve this problem by learning signed distance functions (SDF) from point clouds, which are limited to reconstructing shapes or scenes with closed surfaces. Some other methods tried to represent shapes or scenes with open surfaces using unsigned distance functions (UDF) which are learned from large scale ground truth unsigned distances. However, the learned UDF is hard to provide smooth distance fields near the surface due to the noncontinuous character of point clouds. In this paper, we propose a novel method to learn consistency-aware unsigned distance functions directly from raw point clouds. We achieve this by learning to move 3D queries to reach the surface with a field consistency constraint, where we also enable to progressively estimate a more accurate surface. Specifically, we train a neural network to gradually infer the relationship between 3D queries and the approximated surface by searching for the moving target of queries in a dynamic way, which results in a consistent field around the surface. Meanwhile, we introduce a polygonization algorithm to extract surfaces directly from the gradient field of the learned UDF. The experimental results in surface reconstruction for synthetic and real scan data show significant improvements over the state-of-the-art under the widely used benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hiding Images in Deep Probabilistic Models",
        "paper_url": "https://openreview.net/pdf?id=3I8VTXMhuPx",
        "paper_authors": [
            "Haoyu Chen",
            "Linqi Song",
            "Zhenxing Qian",
            "Xinpeng Zhang",
            "Kede Ma"
        ],
        "paper_abstract": "Data hiding with deep neural networks (DNNs) has experienced impressive successes in recent years. A prevailing scheme is to train an autoencoder, consisting of an encoding network to embed (or transform) secret messages in (or into) a carrier, and a decoding network to extract the hidden messages. This scheme may suffer from several limitations regarding practicability, security, and embedding capacity. In this work, we describe a different computational framework to hide images in deep probabilistic models. Specifically, we use a DNN to model the probability density of cover images, and hide a secret image in one particular location of the learned distribution. As an instantiation, we adopt a SinGAN, a pyramid of generative adversarial networks (GANs), to learn the patch distribution of one cover image. We hide the secret image by fitting a deterministic mapping from a fixed set of noise maps (generated by an embedding key) to the secret image during patch distribution learning. The stego SinGAN, behaving as the original SinGAN, is publicly communicated; only the receiver with the embedding key is able to extract the secret image. We demonstrate the feasibility of our SinGAN approach in terms of extraction accuracy and model security. Moreover, we show the flexibility of the proposed method in terms of hiding multiple images for different receivers and obfuscating the secret image. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CUP: Critic-Guided Policy Reuse",
        "paper_url": "https://openreview.net/pdf?id=iMK2LP0AogI",
        "paper_authors": [
            "Jin Zhang",
            "Siyuan Li",
            "Chongjie Zhang"
        ],
        "paper_abstract": "The ability to reuse previous policies is an important aspect of human intelligence. To achieve efficient policy reuse, a Deep Reinforcement Learning (DRL) agent needs to decide when to reuse and which source policies to reuse. Previous methods solve this problem by introducing extra components to the underlying algorithm, such as hierarchical high-level policies over source policies, or estimations of source policies' value functions on the target task. However, training these components induces either optimization non-stationarity or heavy sampling cost, significantly impairing the effectiveness of transfer. To tackle this problem, we propose a novel policy reuse algorithm called Critic-gUided Policy reuse (CUP), which avoids training any extra components and efficiently reuses source policies. CUP utilizes the critic, a common component in actor-critic methods, to evaluate and choose source policies. At each state, CUP chooses the source policy that has the largest one-step improvement over the current target policy, and forms a guidance policy. The guidance policy is theoretically guaranteed to be a monotonic improvement over the current target policy. Then the target policy is regularized to imitate the guidance policy to perform efficient policy search. Empirical results demonstrate that CUP achieves efficient transfer and significantly outperforms baseline algorithms.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning",
        "paper_url": "https://openreview.net/pdf?id=NJr8GBsyTF0",
        "paper_authors": [
            "Joseph Early",
            "Tom Bewley",
            "Christine Evers",
            "SArvapali Ramchurn"
        ],
        "paper_abstract": "We generalise the problem of reward modelling (RM) for reinforcement learning (RL) to handle non-Markovian rewards. Existing work assumes that human evaluators observe each step in a trajectory independently when providing feedback on agent behaviour. In this work, we remove this assumption, extending RM to capture temporal dependencies in human assessment of trajectories. We show how RM can be approached as a multiple instance learning (MIL) problem, where trajectories are treated as bags with return labels, and steps within the trajectories are instances with unseen reward labels. We go on to develop new MIL models that are able to capture the time dependencies in labelled trajectories. We demonstrate on a range of RL tasks that our novel MIL models can reconstruct reward functions to a high level of accuracy, and can be used to train high-performing agent policies.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalization Bounds for Estimating Causal Effects of Continuous Treatments",
        "paper_url": "https://openreview.net/pdf?id=S0TR0W63NKl",
        "paper_authors": [
            "Xin Wang",
            "Shengfei Lyu",
            "Xingyu Wu",
            "Tianhao Wu",
            "Huanhuan Chen"
        ],
        "paper_abstract": "We focus on estimating causal effects of continuous treatments (e.g., dosage in medicine), also known as dose-response function. Existing methods in causal inference for continuous treatments using neural networks are effective and to some extent reduce selection bias, which is introduced by non-randomized treatments among individuals and might lead to covariate imbalance and thus unreliable inference. To theoretically support the alleviation of selection bias in the setting of continuous treatments, we exploit the re-weighting schema and the Integral Probability Metric (IPM) distance to derive an upper bound on the counterfactual loss of estimating the average dose-response function (ADRF), and herein the IPM distance builds a bridge from a source (factual) domain to an infinite number of target (counterfactual) domains. We provide a discretized approximation of the IPM distance with a theoretical guarantee in the practical implementation. Based on the theoretical analyses, we also propose a novel algorithm, called Average Dose- response estiMatIon via re-weighTing schema (ADMIT). ADMIT simultaneously learns a re-weighting network, which aims to alleviate the selection bias, and an inference network, which makes factual and counterfactual estimations. In addition, the effectiveness of ADMIT is empirically demonstrated in both synthetic and semi-synthetic experiments by outperforming the existing benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics",
        "paper_url": "https://openreview.net/pdf?id=bGo0A4bJBc",
        "paper_authors": [
            "Harsh Rangwani",
            "Shrinivas Ramasubramanian",
            "Sho Takemori",
            "Kato Takashi",
            "Yuhei Umeda",
            "Venkatesh Babu Radhakrishnan"
        ],
        "paper_abstract": "Self-training based semi-supervised learning algorithms have enabled the learning of highly accurate deep neural networks, using only a fraction of labeled data. However, the majority of work on self-training has focused on the objective of improving accuracy whereas practical machine learning systems can have complex goals (e.g. maximizing the minimum of recall across classes, etc.) that are non-decomposable in nature. In this work, we introduce the Cost-Sensitive Self-Training (CSST) framework which generalizes the self-training-based methods for optimizing non-decomposable metrics. We prove that our framework can better optimize the desired non-decomposable metric utilizing unlabeled data, under similar data distribution assumptions made for the analysis of self-training.  Using the proposed CSST framework, we obtain practical self-training methods (for both vision and NLP tasks) for optimizing different non-decomposable metrics using deep neural networks.  Our results demonstrate that CSST achieves an improvement over the state-of-the-art in majority of the cases across datasets and objectives.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SPD: Synergy Pattern Diversifying Oriented Unsupervised Multi-agent Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=jJwy2kcBYv",
        "paper_authors": [
            "Yuhang Jiang",
            "Jianzhun Shao",
            "Shuncheng He",
            "Hongchang Zhang",
            "Xiangyang Ji"
        ],
        "paper_abstract": "Reinforcement learning typically relies heavily on a well-designed reward signal, which gets more challenging in cooperative multi-agent reinforcement learning. Alternatively, unsupervised reinforcement learning (URL) has delivered on its promise in the recent past to learn useful skills and explore the environment without external supervised signals. These approaches mainly aimed for the single agent to reach distinguishable states, insufficient for multi-agent systems due to that each agent interacts with not only the environment, but also the other agents. We propose Synergy Pattern Diversifying Oriented Unsupervised Multi-agent Reinforcement Learning (SPD) to learn generic coordination policies for agents with no extrinsic reward. Specifically, we devise the Synergy Pattern Graph (SPG), a graph depicting the relationships of agents at each time step. Furthermore, we propose an episode-wise divergence measurement to approximate the discrepancy of synergy patterns. To overcome the challenge of sparse return, we decompose the discrepancy of synergy patterns to per-time-step pseudo-reward. Empirically, we show the capacity of SPD to acquire meaningful coordination policies, such as maintaining specific formations in Multi-Agent Particle Environment and pass-and-shoot in Google Research Football. Furthermore, we demonstrate that the same instructive pretrained policy's parameters can serve as a good initialization for a series of downstream tasks' policies, achieving higher data efficiency and outperforming state-of-the-art approaches in Google Research Football.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EpiGRAF: Rethinking training of 3D GANs",
        "paper_url": "https://openreview.net/pdf?id=TTM7iEFOTzJ",
        "paper_authors": [
            "Ivan Skorokhodov",
            "Sergey Tulyakov",
            "Yiqun Wang",
            "Peter Wonka"
        ],
        "paper_abstract": "A recent trend in generative modeling is building 3D-aware generators from 2D image collections. To induce the 3D bias, such models typically rely on volumetric rendering, which is expensive to employ at high resolutions. Over the past months, more than ten works have addressed this scaling issue by training a separate 2D decoder to upsample a low-resolution image (or a feature tensor) produced from a pure 3D generator.  But this solution comes at a cost: not only does it break multi-view consistency (i.e., shape and texture change when the camera moves), but it also learns geometry in low fidelity. In this work, we show that obtaining a high-resolution 3D generator with SotA image quality is possible by following a completely different route of simply training the model patch-wise. We revisit and improve this optimization scheme in two ways. First, we design a location- and scale-aware discriminator to work on patches of different proportions and spatial positions. Second, we modify the patch sampling strategy based on an annealed beta distribution to stabilize training and accelerate the convergence. The resulting model, named EpiGRAF, is an efficient, high-resolution, pure 3D generator, and we test it on four datasets (two introduced in this work) at \\(256^2\\) and \\(512^2\\) resolutions. It obtains state-of-the-art image quality, high-fidelity geometry and trains \\({\\approx}\\)2.5 faster than the upsampler-based counterparts. Code/data/visualizations: https://universome.github.io/epigraf.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coordinates Are NOT Lonely - Codebook Prior Helps Implicit Neural 3D representations",
        "paper_url": "https://openreview.net/pdf?id=oprTuM8F3dt",
        "paper_authors": [
            "Fukun Yin",
            "Wen Liu",
            "Zilong Huang",
            "Pei Cheng",
            "Tao Chen",
            "Gang YU"
        ],
        "paper_abstract": "Implicit neural 3D representation has achieved impressive results in surface or scene reconstruction and novel view synthesis, which typically uses the coordinate-based multi-layer perceptrons (MLPs) to learn a continuous scene representation. However, existing approaches, such as Neural Radiance Field (NeRF) and its variants, usually require dense input views (i.e. 50-150) to obtain decent results. To relive the over-dependence on massive calibrated images and enrich the coordinate-based feature representation, we explore injecting the prior information into the coordinate-based network and introduce a novel coordinate-based model, CoCo-INR, for implicit neural 3D representation. The cores of our method are two attention modules: codebook attention and coordinate attention. The former extracts the useful prototypes containing rich geometry and appearance information from the prior codebook, and the latter propagates such prior information into each coordinate and enriches its feature representation for a scene or object surface. With the help of the prior information, our method can render 3D views with more photo-realistic appearance and geometries than the current methods using fewer calibrated images available. Experiments on various scene reconstruction datasets, including DTU and BlendedMVS, and the full 3D head reconstruction dataset, H3DS, demonstrate the robustness under fewer input views and fine detail-preserving capability of our proposed method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Factored Adaptation for Non-Stationary Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=VQ9fogN1q6e",
        "paper_authors": [
            "Fan Feng",
            "Biwei Huang",
            "Kun Zhang",
            "Sara Magliacane"
        ],
        "paper_abstract": "Dealing with non-stationarity in environments (e.g., in the transition dynamics) and objectives (e.g., in the reward functions) is a challenging problem that is crucial in real-world applications of reinforcement learning (RL). While most current approaches model the changes as a single shared embedding vector, we leverage insights from the recent causality literature to model non-stationarity in terms of individual latent change factors, and causal graphs across different environments. In particular, we propose Factored Adaptation for Non-Stationary RL (FANS-RL), a factored adaption approach that learns jointly both the causal structure in terms of a factored MDP, and a factored representation of the individual time-varying change factors. We prove that under standard assumptions, we can completely recover the causal graph representing the factored transition and reward function, as well as a partial structure between the individual change factors and the state components. Through our general framework, we can consider general non-stationary scenarios with different function types and changing frequency, including changes across episodes and within episodes. Experimental results demonstrate that FANS-RL outperforms existing approaches in terms of return, compactness of the latent state representation, and robustness to varying degrees of non-stationarity.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bringing Image Scene Structure to Video via Frame-Clip Consistency of Object Tokens",
        "paper_url": "https://openreview.net/pdf?id=0JV4VVBsK6a",
        "paper_authors": [
            "Elad Ben Avraham",
            "Roei Herzig",
            "Karttikeya Mangalam",
            "Amir Bar",
            "Anna Rohrbach",
            "Leonid Karlinsky",
            "Trevor Darrell",
            "Amir Globerson"
        ],
        "paper_abstract": "Recent action recognition models have achieved impressive results by integrating objects, their locations and interactions. However, obtaining dense structured annotations for each frame is tedious and time-consuming, making these methods expensive to train and less scalable. At the same time, if a small set of annotated images is available, either within or outside the domain of interest, how could we leverage these for a video downstream task? We propose a learning framework StructureViT (SViT for short), which demonstrates how utilizing the structure of a small number of images only available during training can improve a video model. SViT relies on two key insights. First, as both images and videos contain structured information, we enrich a transformer model with a set of object tokens that can be used across images and videos. Second, the scene representations of individual frames in video should ``align'' with those of still images. This is achieved via a Frame-Clip Consistency loss, which ensures the flow of structured information between images and videos. We explore a particular instantiation of scene structure, namely a Hand-Object Graph, consisting of hands and objects with their locations as nodes, and physical relations of contact/no-contact as edges. SViT shows strong performance improvements on multiple video understanding tasks and datasets, including the first place in the Ego4D CVPR'22 Point of No Return Temporal Localization Challenge. For code and pretrained models, visit the project page at https://eladb3.github.io/SViT/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Increasing Confidence in Adversarial Robustness Evaluations",
        "paper_url": "https://openreview.net/pdf?id=NkK4i91VWp",
        "paper_authors": [
            "Roland S. Zimmermann",
            "Wieland Brendel",
            "Florian Tramer",
            "Nicholas Carlini"
        ],
        "paper_abstract": "Hundreds of defenses have been proposed to make deep neural networks robust against minimal (adversarial) input perturbations. However, only a handful of these defenses held up their claims because correctly evaluating robustness is extremely challenging: Weak attacks often fail to find adversarial examples even if they unknowingly exist, thereby making a vulnerable network look robust. In this paper, we propose a test to identify weak attacks and, thus, weak defense evaluations. Our test slightly modifies a neural network to guarantee the existence of an adversarial example for every sample. Consequentially, any correct attack must succeed in breaking this modified network. For eleven out of thirteen previously-published defenses, the original evaluation of the defense fails our test, while stronger attacks that break these defenses pass it. We hope that attack unit tests - such as ours - will be a major component in future robustness evaluations and increase confidence in an empirical field that is currently riddled with skepticism.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition",
        "paper_url": "https://openreview.net/pdf?id=zbuq101sCNV",
        "paper_authors": [
            "Yongwei Chen",
            "Rui Chen",
            "Jiabao Lei",
            "Yabin Zhang",
            "Kui Jia"
        ],
        "paper_abstract": "Creation of 3D content by stylization is a promising yet challenging problem in computer vision and graphics research. In this work, we focus on stylizing photorealistic appearance renderings of a given surface mesh of arbitrary topology. Motivated by the recent surge of cross-modal supervision of the Contrastive Language-Image Pre-training (CLIP) model, we propose TANGO, which transfers the appearance style of a given 3D shape according to a text prompt in a photorealistic manner. Technically, we propose to disentangle the appearance style as the spatially varying bidirectional reflectance distribution function, the local geometric variation, and the lighting condition, which are jointly optimized, via supervision of the CLIP loss, by a spherical Gaussians based differentiable renderer. As such, TANGO enables photorealistic 3D style transfer by automatically predicting reflectance effects even for bare, low-quality meshes, without training on a task-specific dataset. Extensive experiments show that TANGO outperforms existing methods of text-driven 3D style transfer in terms of photorealistic quality, consistency of 3D geometry, and robustness when stylizing low-quality meshes. Our codes and results are available at our project webpage https://cyw-3d.github.io/tango/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AutoMS: Automatic Model Selection for Novelty Detection with Error Rate Control",
        "paper_url": "https://openreview.net/pdf?id=HIslGib8XD",
        "paper_authors": [
            "Yifan Zhang",
            "Haiyan Jiang",
            "Haojie Ren",
            "Changliang Zou",
            "Dejing Dou"
        ],
        "paper_abstract": "Given an unsupervised novelty detection task on a new dataset, how can we automatically select a ''best'' detection model while simultaneously controlling the error rate of the best model? For novelty detection analysis, numerous detectors have been proposed to detect outliers on a new unseen dataset based on a score function trained on available clean data. However, due to the absence of labeled data for model evaluation and comparison, there is a lack of systematic approaches that are able to select a ''best'' model/detector (i.e., the algorithm as well as its hyperparameters) and achieve certain error rate control simultaneously. In this paper, we introduce a unified data-driven procedure to address this issue. The key idea is to maximize the number of detected outliers while controlling the false discovery rate (FDR) with the help of Jackknife prediction. We establish non-asymptotic bounds for the false discovery proportions and show that the proposed procedure yields valid FDR control under some mild conditions. Numerical experiments on both synthetic and real data validate the theoretical results and demonstrate the effectiveness of our proposed AutoMS method. The code is available at https://github.com/ZhangYifan1996/AutoMS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimal Algorithms for Decentralized Stochastic Variational Inequalities",
        "paper_url": "https://openreview.net/pdf?id=omI5hgwgrsa",
        "paper_authors": [
            "Dmitry Kovalev",
            "Aleksandr Beznosikov",
            "Abdurakhmon Sadiev",
            "Michael Igorevich Persiianov",
            "Peter Richt\u00e1rik",
            "Alexander Gasnikov"
        ],
        "paper_abstract": "Variational inequalities are a formalism that includes games, minimization, saddle point, and equilibrium problems as special cases. Methods for variational inequalities are therefore universal approaches for many applied tasks, including machine learning problems. This work concentrates on the decentralized setting, which is increasingly important but not well understood. In particular, we consider decentralized stochastic (sum-type) variational inequalities over fixed and time-varying networks. We present lower complexity bounds for both communication and local iterations and construct optimal algorithms that match these lower bounds. Our algorithms are the best among the available literature not only in the decentralized stochastic case, but also in the decentralized deterministic and non-distributed stochastic cases. Experimental results confirm the effectiveness of the presented algorithms.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Singular Value Fine-tuning: Few-shot Segmentation requires Few-parameters Fine-tuning",
        "paper_url": "https://openreview.net/pdf?id=LEqYZz7cZOI",
        "paper_authors": [
            "Yanpeng Sun",
            "Qiang Chen",
            "Xiangyu He",
            "Jian Wang",
            "Haocheng Feng",
            "Junyu Han",
            "Errui Ding",
            "Jian Cheng",
            "Zechao Li",
            "Jingdong Wang"
        ],
        "paper_abstract": "Freezing the pre-trained backbone has become a standard paradigm to avoid overfitting in few-shot segmentation. In this paper, we rethink the paradigm and explore a new regime: {\\em fine-tuning a small part of parameters in the backbone}. We present a solution to overcome the overfitting problem, leading to better model generalization on learning novel classes. Our method decomposes backbone parameters into three successive matrices via the Singular Value Decomposition (SVD), then {\\em only fine-tunes the singular values} and keeps others frozen. The above design allows the model to adjust feature representations on novel classes while maintaining semantic clues within the pre-trained backbone. We evaluate our {\\em Singular Value Fine-tuning (SVF)} approach on various few-shot segmentation methods with different backbones. We achieve state-of-the-art results on both Pascal-5$^i$ and COCO-20$^i$ across 1-shot and 5-shot settings. Hopefully, this simple baseline will encourage researchers to rethink the role of backbone fine-tuning in few-shot settings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Supported Policy Optimization for Offline Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=KCXQ5HoM-fy",
        "paper_authors": [
            "Jialong Wu",
            "Haixu Wu",
            "Zihan Qiu",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "paper_abstract": "Policy constraint methods to offline reinforcement learning (RL) typically utilize parameterization or regularization that constrains the policy to perform actions within the support set of the behavior policy. The elaborative designs of parameterization methods usually intrude into the policy networks, which may bring extra inference cost and cannot take full advantage of well-established online methods. Regularization methods reduce the divergence between the learned policy and the behavior policy, which may mismatch the inherent density-based definition of support set thereby failing to avoid the out-of-distribution actions effectively. This paper presents Supported Policy OpTimization (SPOT), which is directly derived from the theoretical formalization of the density-based support constraint. SPOT adopts a VAE-based density estimator to explicitly model the support set of behavior policy and presents a simple but effective density-based regularization term, which can be plugged non-intrusively into off-the-shelf off-policy RL algorithms. SPOT achieves the state-of-the-art performance on standard benchmarks for offline RL. Benefiting from the pluggable design, offline pretrained models from SPOT can also be applied to perform online fine-tuning seamlessly.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline",
        "paper_url": "https://openreview.net/pdf?id=DhmYYrH_M3m",
        "paper_authors": [
            "Penghao Wu",
            "Xiaosong Jia",
            "Li Chen",
            "Junchi Yan",
            "Hongyang Li",
            "Yu Qiao"
        ],
        "paper_abstract": "Current end-to-end autonomous driving methods either run a controller based on a planned trajectory or perform control prediction directly, which have spanned two separately studied lines of research. Seeing their potential mutual benefits to each other, this paper takes the initiative to explore the combination of these two well-developed worlds. Specifically, our integrated approach has two branches for trajectory planning and direct control, respectively. The trajectory branch predicts the future trajectory, while the control branch involves a novel multi-step prediction scheme such that the relationship between current actions and future states can be reasoned. The two branches are connected so that the control branch receives corresponding guidance from the trajectory branch at each time step. The outputs from two branches are then fused to achieve complementary advantages. Our results are evaluated in the closed-loop urban driving setting with challenging scenarios using the CARLA simulator. Even with a monocular camera input, the proposed approach ranks first on the official CARLA Leaderboard, outperforming other complex candidates with multiple sensors or fusion mechanisms by a large margin. The source\ncode is publicly available at https://github.com/OpenPerceptionX/TCP",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rotation-Equivariant Conditional Spherical Neural Fields for Learning a Natural Illumination Prior",
        "paper_url": "https://openreview.net/pdf?id=cj6K4IWVomU",
        "paper_authors": [
            "James A D Gardner",
            "Bernhard Egger",
            "William A P Smith"
        ],
        "paper_abstract": "Inverse rendering is an ill-posed problem. Previous work has sought to resolve this by focussing on priors for object or scene shape or appearance. In this work, we instead focus on a prior for natural illuminations. Current methods rely on spherical harmonic lighting or other generic representations and, at best, a simplistic prior on the parameters. We propose a conditional neural field representation based on a variational auto-decoder with a SIREN network and, extending Vector Neurons, build equivariance directly into the network. Using this, we develop a rotation-equivariant, high dynamic range (HDR) neural illumination model that is compact and able to express complex, high-frequency features of natural environment maps. Training our model on a curated dataset of 1.6K HDR environment maps of natural scenes, we compare it against traditional representations, demonstrate its applicability for an inverse rendering task and show environment map completion from partial observations.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "E-MAPP: Efficient Multi-Agent Reinforcement Learning with Parallel Program Guidance",
        "paper_url": "https://openreview.net/pdf?id=8LE06pFhqsW",
        "paper_authors": [
            "Can Chang",
            "Ni Mu",
            "Jiajun Wu",
            "Ling Pan",
            "Huazhe Xu"
        ],
        "paper_abstract": "A critical challenge in multi-agent reinforcement learning(MARL) is for multiple agents to efficiently accomplish complex, long-horizon tasks. The agents often have difficulties in cooperating on common goals, dividing complex tasks, and planning through several stages to make progress. We propose to address these challenges by guiding agents with programs designed for parallelization, since programs as a representation contain rich structural and semantic information, and are widely used as abstractions for long-horizon tasks. \nSpecifically, we introduce Efficient Multi-Agent Reinforcement Learning with Parallel Program Guidance(E-MAPP), a novel framework that leverages parallel programs to guide multiple agents to efficiently accomplish goals that require planning over $10+$ stages. \nE-MAPP integrates the structural information from a parallel program, promotes the cooperative behaviors grounded in program semantics, and improves the time efficiency via a task allocator. We conduct extensive experiments on a series of challenging, long-horizon cooperative tasks in the Overcooked environment. Results show that E-MAPP outperforms strong baselines in terms of the completion rate, time efficiency, and zero-shot generalization ability by a large margin.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Vision GNN: An Image is Worth Graph of Nodes",
        "paper_url": "https://openreview.net/pdf?id=htM1WJZVB2I",
        "paper_authors": [
            "Kai Han",
            "Yunhe Wang",
            "Jianyuan Guo",
            "Yehui Tang",
            "Enhua Wu"
        ],
        "paper_abstract": "Network architecture plays a key role in the deep learning-based computer vision system. The widely-used convolutional neural network and transformer treat the image as a grid or sequence structure, which is not flexible to capture irregular and complex objects. In this paper, we propose to represent the image as a graph structure and introduce a new \\emph{Vision GNN} (ViG) architecture to extract graph-level feature for visual tasks. We first split the image to a number of patches which are viewed as nodes, and construct a graph by connecting the nearest neighbors. Based on the graph representation of images, we build our ViG model to transform and exchange information among all the nodes. ViG consists of two basic modules: Grapher module with graph convolution for aggregating and updating graph information, and FFN module with two linear layers for node feature transformation. Both isotropic and pyramid architectures of ViG are built with different model sizes. Extensive experiments on image recognition and object detection tasks demonstrate the superiority of our ViG architecture. We hope this pioneering study of GNN on general visual tasks will provide useful inspiration and experience for future research.\n  \nThe PyTorch code is available at \\url{https://github.com/huawei-noah/Efficient-AI-Backbones} and the MindSpore code is available at \\url{https://gitee.com/mindspore/models}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-supervised Vision Transformers at Scale",
        "paper_url": "https://openreview.net/pdf?id=7a2IgJ7V4W",
        "paper_authors": [
            "Zhaowei Cai",
            "Avinash Ravichandran",
            "Paolo Favaro",
            "Manchen Wang",
            "Davide Modolo",
            "Rahul Bhotika",
            "Zhuowen Tu",
            "Stefano Soatto"
        ],
        "paper_abstract": "We study semi-supervised learning (SSL) for vision transformers (ViT), an under-explored topic despite the wide adoption of the ViT architectures to different tasks. To tackle this problem, we use a SSL pipeline, consisting of first un/self-supervised pre-training, followed by supervised fine-tuning, and finally semi-supervised fine-tuning. At the semi-supervised fine-tuning stage, we adopt an exponential moving average (EMA)-Teacher framework instead of the popular FixMatch, since the former is more stable and delivers higher accuracy for semi-supervised vision transformers. In addition, we propose a probabilistic pseudo mixup mechanism to interpolate unlabeled samples and their pseudo labels for improved regularization, which is important for training ViTs with weak inductive bias. Our proposed method, dubbed Semi-ViT, achieves comparable or better performance than the CNN counterparts in the semi-supervised classification setting. Semi-ViT also enjoys the scalability benefits of ViTs that can be readily scaled up to large-size models with increasing accuracy. For example, Semi-ViT-Huge achieves an impressive 80\\% top-1 accuracy on ImageNet using only 1\\% labels, which is comparable with Inception-v4 using 100\\% ImageNet labels. The code is available at https://github.com/amazon-science/semi-vit.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Model Reassembly",
        "paper_url": "https://openreview.net/pdf?id=gtCPWaY5bNh",
        "paper_authors": [
            "Xingyi Yang",
            "Zhou Daquan",
            "Songhua Liu",
            "Jingwen Ye",
            "Xinchao Wang"
        ],
        "paper_abstract": "In this paper, we explore a novel knowledge-transfer task, termed as Deep  Model Reassembly (DeRy), for general-purpose model reuse.\nGiven a collection of heterogeneous models pre-trained from distinct sources and with diverse architectures, the goal of DeRy, as its name implies, is to first dissect each model into distinctive building blocks, and then selectively reassemble the derived blocks to produce customized networks under both the hardware resource and performance constraints. Such ambitious nature of DeRy inevitably imposes significant challenges, including, in the first place, the feasibility of its solution. We strive to showcase that, through a dedicated paradigm proposed in this paper, DeRy can be made not only possibly but practically efficiently. Specifically, we conduct the partitions of all pre-trained networks jointly via a cover set optimization, and derive  a number of equivalence set, within each of which the network blocks are treated as functionally equivalent and hence interchangeable. The equivalence sets learned in this way, in turn, enable  picking and assembling blocks to customize networks subject to certain constraints, which is achieved via solving an integer program backed up with a training-free proxy to estimate the task performance. The reassembled models give rise to gratifying performances with the user-specified constraints satisfied. We demonstrate that on ImageNet, the best reassemble model achieves 78.6% top-1 accuracy without fine-tuning, which could be further elevated to 83.2% with end-to-end fine-tuning. Our code is available at https://github.com/Adamdad/DeRy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Are You Stealing My Model? Sample Correlation for Fingerprinting Deep Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=ebuR5LWzkk0",
        "paper_authors": [
            "Jiyang Guan",
            "Jian Liang",
            "Ran He"
        ],
        "paper_abstract": "An off-the-shelf model as a commercial service could be stolen by model stealing attacks, posing great threats to the rights of the model owner. Model fingerprinting aims to verify whether a suspect model is stolen from the victim model, which gains more and more attention nowadays. Previous methods always leverage the transferable adversarial examples as the model fingerprint, which is sensitive to adversarial defense or transfer learning scenarios. To address this issue, we consider the pairwise relationship between samples instead and propose a novel yet simple model stealing detection method based on SAmple Correlation (SAC). Specifically, we present SAC-w that selects wrongly classified normal samples as model inputs and calculates the mean correlation among their model outputs. To reduce the training time, we further develop SAC-m that selects CutMix Augmented samples as model inputs, without the need for training the surrogate models or generating adversarial examples. Extensive results validate that SAC successfully defends against various model stealing attacks, even including adversarial training or transfer learning, and detects the stolen models with the best performance in terms of AUC across different datasets and model architectures. The codes are available at https://github.com/guanjiyang/SAC.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Theoretically Inspired Neural Initialization Optimization",
        "paper_url": "https://openreview.net/pdf?id=xL8sFkkAkw",
        "paper_authors": [
            "Yibo Yang",
            "Hong Wang",
            "Haobo Yuan",
            "Zhouchen Lin"
        ],
        "paper_abstract": "Automated machine learning has been widely explored to reduce human efforts in designing neural architectures and looking for proper hyperparameters. In the domain of neural initialization, however, similar automated techniques have rarely been studied. Most existing initialization methods are handcrafted and highly dependent on specific architectures. In this paper, we propose a differentiable quantity, named GradCoisne, with theoretical insights to evaluate the initial state of a neural network. Specifically, GradCosine is the cosine similarity of sample-wise gradients with respect to the initialized parameters. By analyzing the sample-wise optimization landscape, we show that both the training and test performance of a network can be improved by maximizing GradCosine under gradient norm constraint. Based on this observation, we further propose the neural initialization optimization (NIO) algorithm. Generalized from the sample-wise analysis into the real batch setting, NIO is able to automatically look for a better initialization with negligible cost compared with the training time. With NIO, we improve the classification performance of a variety of neural architectures on CIFAR10, CIFAR-100, and ImageNet. Moreover, we find that our method can even help to train large vision Transformer architecture without warmup. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimal Gradient Sliding and its Application to Optimal Distributed Optimization Under Similarity",
        "paper_url": "https://openreview.net/pdf?id=QrK0WDLVHZt",
        "paper_authors": [
            "Dmitry Kovalev",
            "Aleksandr Beznosikov",
            "Ekaterina Dmitrievna Borodich",
            "Alexander Gasnikov",
            "Gesualdo Scutari"
        ],
        "paper_abstract": "We study structured convex  optimization problems, with additive objective   $r:=p + q$, where $r$ is ($\\mu$-strongly) convex, $q$ is $L_q$-smooth and convex, and $p$ is $L_p$-smooth, possibly nonconvex. For such a class of problems, we proposed an inexact accelerated gradient sliding method that can skip the gradient computation for one of these   components while still achieving optimal   complexity of gradient calls of $p$ and $q$, that is, $\\mathcal{O}(\\sqrt{L_p/\\mu})$ and $\\mathcal{O}(\\sqrt{L_q/\\mu})$, respectively. This result is much sharper than the classic black-box  complexity $\\mathcal{O}(\\sqrt{(L_p+L_q)/\\mu})$,   especially when  the difference between $L_p$ and $L_q$ is large. We then apply the proposed method to solve distributed optimization problems over master-worker architectures, under agents' function similarity, due to statistical data similarity or otherwise. The distributed algorithm achieves for the first time lower complexity bounds on both communication and local  gradient calls, with the former having being a long-standing open problem. Finally the method is extended to distributed saddle-problems (under function similarity) by means of solving a class of variational inequalities, achieving lower communication and computation complexity bounds.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decentralized Local Stochastic Extra-Gradient for Variational Inequalities",
        "paper_url": "https://openreview.net/pdf?id=Y4vT7m4e3d",
        "paper_authors": [
            "Aleksandr Beznosikov",
            "Pavel Dvurechensky",
            "Anastasia Koloskova",
            "Valentin Samokhin",
            "Sebastian U Stich",
            "Alexander Gasnikov"
        ],
        "paper_abstract": "We consider distributed stochastic variational inequalities (VIs) on unbounded domains with the problem data that is heterogeneous (non-IID) and distributed across many devices. We make a very general assumption on the computational network that, in particular, covers the settings of fully decentralized calculations with time-varying networks and centralized topologies commonly used in Federated Learning. Moreover, multiple local updates on the workers can be made for reducing the communication frequency between the workers.\nWe extend the stochastic extragradient method to this very general setting and theoretically analyze its convergence rate in the strongly-monotone, monotone, and non-monotone (when a Minty solution exists) settings. The provided rates explicitly exhibit the dependence on network characteristics (e.g., mixing time), iteration counter, data heterogeneity, variance, number of devices, and other standard parameters. As a special case, our method and analysis apply to distributed stochastic saddle-point problems (SPP), e.g., to the training of Deep Generative Adversarial Networks (GANs) for which decentralized training has been reported to be extremely challenging. In experiments for the decentralized training of GANs we demonstrate the effectiveness of our proposed approach.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "P2P: Tuning Pre-trained Image Models for Point Cloud Analysis with Point-to-Pixel Prompting",
        "paper_url": "https://openreview.net/pdf?id=CZNFw38dDDS",
        "paper_authors": [
            "Ziyi Wang",
            "Xumin Yu",
            "Yongming Rao",
            "Jie Zhou",
            "Jiwen Lu"
        ],
        "paper_abstract": "Nowadays, pre-training big models on large-scale datasets has become a crucial topic in deep learning. The pre-trained models with high representation ability and transferability achieve a great success and dominate many downstream tasks in natural language processing and 2D vision. However, it is non-trivial to promote such a pretraining-tuning paradigm to the 3D vision, given the limited training data that are relatively inconvenient to collect. In this paper, we provide a new perspective of leveraging pre-trained 2D knowledge in 3D domain to tackle this problem, tuning pre-trained image models with the novel Point-to-Pixel prompting for point cloud analysis at a minor parameter cost. Following the principle of prompting engineering, we transform point clouds into colorful images with geometry-preserved projection and geometry-aware coloring to adapt to pre-trained image models, whose weights are kept frozen during the end-to-end optimization of point cloud analysis tasks. We conduct extensive experiments to demonstrate that cooperating with our proposed Point-to-Pixel Prompting, better pre-trained image model will lead to consistently better performance in 3D vision. Enjoying prosperous development from image pre-training field, our method attains 89.3% accuracy on the hardest setting of ScanObjectNN, surpassing conventional point cloud models with much fewer trainable parameters. Our framework also exhibits very competitive performance on ModelNet classification and ShapeNet Part Segmentation. Code is available at https://github.com/wangzy22/P2P.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Your Transformer May Not be as Powerful as You Expect",
        "paper_url": "https://openreview.net/pdf?id=NQFFNdsOGD",
        "paper_authors": [
            "Shengjie Luo",
            "Shanda Li",
            "Shuxin Zheng",
            "Tie-Yan Liu",
            "Liwei Wang",
            "Di He"
        ],
        "paper_abstract": "Relative Positional Encoding (RPE), which encodes the relative distance between any pair of tokens, is one of the most successful modifications to the original Transformer. As far as we know, theoretical understanding of the RPE-based Transformers is largely unexplored. In this work, we mathematically analyze the power of RPE-based Transformers regarding whether the model is capable of approximating any continuous sequence-to-sequence functions. One may naturally assume the answer is in the affirmative---RPE-based Transformers are universal function approximators. However, we present a negative result by showing there exist continuous sequence-to-sequence functions that RPE-based Transformers cannot approximate no matter how deep and wide the neural network is. One key reason lies in that most RPEs are placed in the softmax attention that always generates a right stochastic matrix. This restricts the network from capturing positional information in the RPEs and limits its capacity. To overcome the problem and make the model more powerful, we first present sufficient conditions for RPE-based Transformers to achieve universal function approximation. With the theoretical guidance, we develop a novel attention module, called Universal RPE-based (URPE) Attention, which satisfies the conditions. Therefore, the corresponding URPE-based Transformers become universal function approximators. Extensive experiments covering typical architectures and tasks demonstrate that our model is parameter-efficient and can achieve superior performance to strong baselines in a wide range of applications. The code will be made publicly available at https://github.com/lsj2408/URPE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-Instance Causal Representation Learning for Instance Label Prediction and Out-of-Distribution Generalization",
        "paper_url": "https://openreview.net/pdf?id=2ktj0977QGO",
        "paper_authors": [
            "Weijia Zhang",
            "Xuanhui Zhang",
            "Han-Wen Deng",
            "Min-Ling Zhang"
        ],
        "paper_abstract": "Multi-instance learning (MIL) deals with objects represented as bags of instances and can predict instance labels from bag-level supervision. However, significant performance gaps exist between instance-level MIL algorithms and supervised learners since the instance labels are unavailable in MIL. Most existing MIL algorithms tackle the problem by treating multi-instance bags as harmful ambiguities and predicting instance labels by reducing the supervision inexactness. This work studies MIL from a new perspective by considering bags as auxiliary information, and utilize it to identify instance-level causal representations from bag-level weak supervision. We propose the CausalMIL algorithm, which not only excels at instance label prediction but also provides robustness to distribution change by synergistically integrating MIL with identifiable variational autoencoder. Our approach is based on a practical and general assumption: the prior distribution over the instance latent representations belongs to the non-factorized exponential family conditioning on the multi-instance bags. Experiments on synthetic and real-world datasets demonstrate that our approach significantly outperforms various baselines on instance label prediction and out-of-distribution generalization tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Online Training Through Time for Spiking Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=Siv3nHYHheI",
        "paper_authors": [
            "Mingqing Xiao",
            "Qingyan Meng",
            "Zongpeng Zhang",
            "Di He",
            "Zhouchen Lin"
        ],
        "paper_abstract": "Spiking neural networks (SNNs) are promising brain-inspired energy-efficient models. Recent progress in training methods has enabled successful deep SNNs on large-scale tasks with low latency. Particularly, backpropagation through time (BPTT) with surrogate gradients (SG) is popularly used to enable models to achieve high performance in a very small number of time steps. However, it is at the cost of large memory consumption for training, lack of theoretical clarity for optimization, and inconsistency with the online property of biological learning rules and rules on neuromorphic hardware. Other works connect the spike representations of SNNs with equivalent artificial neural network formulation and train SNNs by gradients from equivalent mappings to ensure descent directions. But they fail to achieve low latency and are also not online. In this work, we propose online training through time (OTTT) for SNNs, which is derived from BPTT to enable forward-in-time learning by tracking presynaptic activities and leveraging instantaneous loss and gradients. Meanwhile, we theoretically analyze and prove that the gradients of OTTT can provide a similar descent direction for optimization as gradients from equivalent mapping between spike representations under both feedforward and recurrent conditions. OTTT only requires constant training memory costs agnostic to time steps, avoiding the significant memory costs of BPTT for GPU training. Furthermore, the update rule of OTTT is in the form of three-factor Hebbian learning, which could pave a path for online on-chip learning. With OTTT, it is the first time that the two mainstream supervised SNN training methods, BPTT with SG and spike representation-based training, are connected, and meanwhile it is in a biologically plausible form. Experiments on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS demonstrate the superior performance of our method on large-scale static and neuromorphic datasets in a small number of time steps. Our code is available at https://github.com/pkuxmq/OTTT-SNN.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Asymptotic Properties for Bayesian Neural Network in Besov Space",
        "paper_url": "https://openreview.net/pdf?id=y5ziOXtKybL",
        "paper_authors": [
            "Kyeongwon Lee",
            "Jaeyong Lee"
        ],
        "paper_abstract": "Neural networks have shown great predictive power when applied to unstructured data such as images and natural languages. The Bayesian neural network captures the uncertainty of prediction by computing the posterior distribution of the model parameters. In this paper, we show that the Bayesian neural network with spikeand-slab prior has posterior consistency with a near minimax optimal convergence rate when the true regression function belongs to the Besov space. The spikeand-slab prior is adaptive to the smoothness of the regression function and the posterior convergence rate does not change even when the smoothness of the regression function is unknown. We also consider the shrinkage prior, which is computationally more feasible than the spike-and-slab prior, and show that it has the same posterior convergence rate as the spike-and-slab prior.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Planning for Sample Efficient Imitation Learning",
        "paper_url": "https://openreview.net/pdf?id=iKKfdIm81Jt",
        "paper_authors": [
            "Zhao-Heng Yin",
            "Weirui Ye",
            "Qifeng Chen",
            "Yang Gao"
        ],
        "paper_abstract": "Imitation learning is a class of promising policy learning algorithms that is free from many practical issues with reinforcement learning, such as the reward design issue and the exploration hardness. However, the current imitation algorithm struggles to achieve both high performance and high in-environment sample efficiency simultaneously. Behavioral Cloning (BC) does not need in-environment interactions, but it suffers from the covariate shift problem which harms its performance. Adversarial Imitation Learning (AIL) turns imitation learning into a distribution matching problem. It can achieve better performance on some tasks but it requires a large number of in-environment interactions. Inspired by the recent success of EfficientZero in RL, we propose EfficientImitate (EI), a planning-based imitation learning method that can achieve high in-environment sample efficiency and performance simultaneously. Our algorithmic contribution in this paper is two-fold. First, we extend AIL into the MCTS-based RL. Second, we show the seemingly incompatible two classes of imitation algorithms (BC and AIL) can be naturally unified under our framework, enjoying the benefits of both. We benchmark our method not only on the state-based DeepMind Control Suite but also on the image version which many previous works find highly challenging. Experimental results show that EI achieves state-of-the-art results in performance and sample efficiency. EI shows over 4x gain in performance in the limited sample setting on state-based and image-based tasks and can solve challenging problems like Humanoid, where previous methods fail with a small amount of interactions. Our code is available at https://github.com/zhaohengyin/EfficientImitate.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Peripheral Vision Transformer",
        "paper_url": "https://openreview.net/pdf?id=nE8IJLT7nW-",
        "paper_authors": [
            "Juhong Min",
            "Yucheng Zhao",
            "Chong Luo",
            "Minsu Cho"
        ],
        "paper_abstract": "Human vision possesses a special type of visual processing systems called peripheral vision. Partitioning the entire visual field into multiple contour regions based on the distance to the center of our gaze, the peripheral vision provides us the ability to perceive various visual features at different regions. In this work, we take a biologically inspired approach and explore to model peripheral vision in deep neural networks for visual recognition. We propose to incorporate peripheral position encoding to the multi-head self-attention layers to let the network learn to partition the visual field into diverse peripheral regions given training data. We evaluate the proposed network, dubbed PerViT, on ImageNet-1K and systematically investigate the inner workings of the model for machine perception, showing that the network learns to perceive visual data similarly to the way that human vision does. The performance improvements in image classification over the baselines across different model sizes demonstrate the efficacy of the proposed method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ZARTS: On Zero-order Optimization for Neural Architecture Search",
        "paper_url": "https://openreview.net/pdf?id=QzFJmwwBMd",
        "paper_authors": [
            "Xiaoxing Wang",
            "Wenxuan Guo",
            "Jianlin Su",
            "Xiaokang Yang",
            "Junchi Yan"
        ],
        "paper_abstract": "Differentiable architecture search (DARTS) has been a popular one-shot paradigm for NAS due to its high efficiency. It introduces trainable architecture parameters to represent the importance of candidate operations and proposes first/second-order approximation to estimate their gradients, making it possible to solve NAS by gradient descent algorithm. However, our in-depth empirical results show that the approximation often distorts the loss landscape, leading to the biased objective to optimize and, in turn, inaccurate gradient estimation for architecture parameters. This work turns to zero-order optimization and proposes a novel NAS scheme, called ZARTS, to search without enforcing the above approximation. Specifically, three representative zero-order optimization methods are introduced: RS, MGS, and GLD, among which MGS performs best by balancing the accuracy and speed. Moreover, we explore the connections between RS/MGS and gradient descent algorithm and show that our ZARTS can be seen as a robust gradient-free counterpart to DARTS. Extensive experiments on multiple datasets and search spaces show the remarkable performance of our method. In particular, results on 12 benchmarks verify the outstanding robustness of ZARTS, where the performance of DARTS collapses due to its known instability issue. Also, we search on the search space of DARTS to compare with peer methods, and our discovered architecture achieves 97.54\\% accuracy on CIFAR-10 and 75.7\\% top-1 accuracy on ImageNet. Finally, we combine our ZARTS with three orthogonal variants of DARTS for faster search speed and better performance.  Source code will be made publicly available at:  \\url{https://github.com/vicFigure/ZARTS}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Class-Dependent Label-Noise Learning with Cycle-Consistency Regularization",
        "paper_url": "https://openreview.net/pdf?id=IvnoGKQuXi",
        "paper_authors": [
            "De Cheng",
            "Yixiong Ning",
            "Nannan Wang",
            "Xinbo Gao",
            "Heng Yang",
            "Yuxuan Du",
            "Bo Han",
            "Tongliang Liu"
        ],
        "paper_abstract": "In label-noise learning, estimating the transition matrix plays an important role in building statistically consistent classifier. Current state-of-the-art consistent estimator for the transition matrix has been developed under the newly proposed sufficiently scattered assumption, through incorporating the minimum volume constraint of the transition matrix T into label-noise learning. To compute the volume of  T, it heavily relies on the estimated  noisy class posterior. However, the estimation error of the noisy class posterior could usually be large as deep learning methods tend to easily overfit the noisy labels. Then, directly minimizing the volume of such obtained T could lead the transition matrix to be poorly estimated.  Therefore, how to reduce the side-effects of the inaccurate noisy class posterior has become the bottleneck of such method. In this paper, we creatively propose to estimate the transition matrix under the forward-backward cycle-consistency regularization, of which we have greatly reduced the dependency of estimating the transition matrix T on the noisy class posterior. We show that the cycle-consistency regularization helps to minimize the volume of the transition matrix T indirectly without exploiting the estimated noisy class posterior, which could further encourage the estimated transition matrix T to converge to its optimal solution. Extensive experimental results consistently justify the effectiveness of the proposed method, on reducing the estimation error of the transition matrix and greatly boosting the classification performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "InsPro: Propagating Instance Query and Proposal for Online Video Instance Segmentation",
        "paper_url": "https://openreview.net/pdf?id=V3kqJWsKRu4",
        "paper_authors": [
            "Fei He",
            "Haoyang Zhang",
            "Naiyu Gao",
            "Jian Jia",
            "Yanhu Shan",
            "Xin Zhao",
            "Kaiqi Huang"
        ],
        "paper_abstract": "Video instance segmentation (VIS) aims at segmenting and tracking objects in videos. Prior methods typically generate frame-level or clip-level object instances first and then associate them by either additional tracking heads or complex instance matching algorithms. This explicit instance association approach increases system complexity and fails to fully exploit temporal cues in videos. In this paper, we design a simple, fast and yet effective query-based framework for online VIS. Relying on an instance query and proposal propagation mechanism with several specially developed components, this framework can perform accurate instance association implicitly. Specifically, we generate frame-level object instances based on a set of instance query-proposal pairs propagated from previous frames. This instance query-proposal pair is learned to bind with one specific object across frames through conscientiously developed strategies. When using such a pair to predict an object instance on the current frame, not only the generated instance is automatically associated with its precursors on previous frames, but the model gets a good prior for predicting the same object. In this way, we naturally achieve implicit instance association in parallel with segmentation and elegantly take advantage of temporal clues in videos. To show the effectiveness of our method InsPro, we evaluate it on two popular VIS benchmarks, i.e., YouTube-VIS 2019 and YouTube-VIS 2021. Without bells-and-whistles, our InsPro with ResNet-50 backbone achieves 43.2 AP and 37.6 AP on these two benchmarks respectively, outperforming all other online VIS methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-dataset Training of Transformers for Robust Action Recognition",
        "paper_url": "https://openreview.net/pdf?id=aGFQDrNb-KO",
        "paper_authors": [
            "Junwei Liang",
            "Enwei Zhang",
            "Jun Zhang",
            "Chunhua Shen"
        ],
        "paper_abstract": "We study the task of robust feature representations, aiming to generalize well on multiple datasets for action recognition. We build our method on Transformers for its efficacy. Although we have witnessed great progress for video action recognition in the past decade, it remains challenging yet valuable how to train a single model that can perform well across multiple datasets. Here, we propose a novel multi-dataset training paradigm, MultiTrain, with the design of two new loss terms, namely informative loss and projection loss, aiming to\nlearn robust representations for action recognition. In particular, the informative loss maximizes the expressiveness of the feature embedding while the projection loss for each dataset mines the intrinsic relations between classes across datasets. We verify the effectiveness of our method on five challenging datasets, Kinetics-\n400, Kinetics-700, Moments-in-Time, Activitynet and Something-something-v2 datasets. Extensive experimental results show that our method can consistently improve state-of-the-art performance. Code and models are released.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model",
        "paper_url": "https://openreview.net/pdf?id=a8qX5RG36jd",
        "paper_authors": [
            "Hao Fei",
            "Shengqiong Wu",
            "Jingye Li",
            "Bobo Li",
            "Fei Li",
            "Libo Qin",
            "Meishan Zhang",
            "Min Zhang",
            "Tat-Seng Chua"
        ],
        "paper_abstract": "Universally modeling all typical information extraction tasks (UIE) with one generative language model (GLM) has revealed great potential by the latest study, where various IE predictions are unified into a linearized hierarchical expression under a GLM. Syntactic structure information, a type of effective feature which has been extensively utilized in IE community, should also be beneficial to UIE. In this work, we propose a novel structure-aware GLM, fully unleashing the power of syntactic knowledge for UIE. A heterogeneous structure inductor is explored to unsupervisedly induce rich heterogeneous structural representations by post-training an existing GLM. In particular, a structural broadcaster is devised to compact various latent trees into explicit high-order forests, helping to guide a better generation during decoding. We finally introduce a task-oriented structure fine-tuning mechanism, further adjusting the learned structures to most coincide with the end-task's need. Over 12 IE benchmarks across 7 tasks our system shows significant improvements over the baseline UIE system. Further in-depth analyses show that our GLM learns rich task-adaptive structural bias that greatly resolves the UIE crux, the long-range dependence issue and boundary identifying.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Scalable Infomin Learning",
        "paper_url": "https://openreview.net/pdf?id=Ojakr9ofova",
        "paper_authors": [
            "Yanzhi Chen",
            "Weihao Sun",
            "Yingzhen Li",
            "Adrian Weller"
        ],
        "paper_abstract": "The task of infomin learning aims to learn a representation with high utility while being uninformative about a specified target, with the latter achieved by minimising the mutual information between the representation and the target. It has broad applications, ranging from training fair prediction models against protected attributes, to unsupervised learning with disentangled representations. Recent works on infomin learning mainly use adversarial training, which involves training a neural network to estimate mutual information or its proxy and thus is slow and difficult to optimise. Drawing on recent advances in slicing techniques, we propose a new infomin learning approach, which uses a novel proxy metric to mutual information. We further derive an accurate and analytically computable approximation to this proxy metric, thereby removing the need of constructing neural network-based mutual information estimators. Compared to baselines, experiments on algorithmic fairness, disentangled representation learning and domain adaptation verify that our method can more effectively remove unwanted information with limited time budget.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Linear tree shap",
        "paper_url": "https://openreview.net/pdf?id=OzbkiUo24g",
        "paper_authors": [
            "Peng Yu",
            "Albert Bifet",
            "Jesse Read",
            "Chao Xu"
        ],
        "paper_abstract": "Decision trees are well-known due to their ease of interpretability.\nTo improve accuracy, we need to grow deep trees or ensembles of trees.\nThese are hard to interpret, offsetting their original benefits. \nShapley values have recently become a popular way to explain the predictions of tree-based machine learning models. \nIt provides a linear weighting to features independent of the tree structure. \nThe rise in popularity is mainly due to TreeShap, which solves a general exponential complexity problem in polynomial time. \nFollowing extensive adoption in the industry, more efficient algorithms are required. \nThis paper presents a more efficient and straightforward algorithm: Linear TreeShap.\nLike TreeShap, Linear TreeShap is exact and requires the same amount of memory.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks",
        "paper_url": "https://openreview.net/pdf?id=L7P3IvsoUXY",
        "paper_authors": [
            "Xuanli He",
            "Qiongkai Xu",
            "Yi Zeng",
            "Lingjuan Lyu",
            "Fangzhao Wu",
            "Jiwei Li",
            "Ruoxi Jia"
        ],
        "paper_abstract": "Previous works have validated that text generation APIs can be stolen through imitation attacks, causing IP violations. In order to protect the IP of text generation APIs, recent work has introduced a watermarking algorithm and utilized the null-hypothesis test as a post-hoc ownership verification on the imitation models. However, we find that it is possible to detect those watermarks via sufficient statistics of the frequencies of candidate watermarking words. To address this drawback, in this paper, we propose a novel Conditional wATERmarking framework (CATER) for protecting the IP of text generation APIs. An optimization method is proposed to decide the watermarking rules that can minimize the distortion of overall word distributions while maximizing the change of conditional word selections. Theoretically, we prove that it is infeasible for even the savviest attacker (they know how CATER works) to reveal the used watermarks from a large pool of potential word pairs based on statistical inspection. Empirically, we observe that high-order conditions lead to an exponential growth of suspicious (unused) watermarks, making our crafted watermarks more stealthy. In addition, CATER can effectively identify IP infringement under architectural mismatch and cross-domain imitation attacks, with negligible impairments on the generation quality of victim APIs. We envision our work as a milestone for stealthily protecting the IP of text generation APIs.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GAPX: Generalized Autoregressive Paraphrase-Identification X",
        "paper_url": "https://openreview.net/pdf?id=r__gfIasEdN",
        "paper_authors": [
            "Yifei Zhou",
            "Renyu Li",
            "Hayden Housen",
            "Ser-Nam Lim"
        ],
        "paper_abstract": "Paraphrase Identification is a fundamental task in Natural Language Processing. While much progress has been made in the field, the performance of many state-of- the-art models often suffer from distribution shift during inference time. We verify that a major source of this performance drop comes from biases introduced by negative examples. To overcome these biases, we propose in this paper to train two separate models, one that only utilizes the positive pairs and the other the negative pairs. This enables us the option of deciding how much to utilize the negative model, for which we introduce a perplexity based out-of-distribution metric that we show can effectively and automatically determine how much weight it should be given during inference. We support our findings with strong empirical results.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Explaining Preferences with Shapley Values",
        "paper_url": "https://openreview.net/pdf?id=-me36V0os8P",
        "paper_authors": [
            "Robert Hu",
            "Siu Lun Chau",
            "Jaime Ferrando Huertas",
            "Dino Sejdinovic"
        ],
        "paper_abstract": "While preference modelling is becoming one of the pillars of machine learning, the problem of preference explanation remains challenging and underexplored. In this paper, we propose \\textsc{Pref-SHAP}, a Shapley value-based model explanation framework for pairwise comparison data. We derive the appropriate value functions for preference models and further extend the framework to model and explain \\emph{context specific} information, such as the surface type in a tennis game. To demonstrate the utility of \\textsc{Pref-SHAP}, we apply our method to a variety of synthetic and real-world datasets and show that richer and more insightful explanations can be obtained over the baseline.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "C-Mixup: Improving Generalization in Regression",
        "paper_url": "https://openreview.net/pdf?id=BgMz5LHc07R",
        "paper_authors": [
            "Huaxiu Yao",
            "Yiping Wang",
            "Linjun Zhang",
            "James Zou",
            "Chelsea Finn"
        ],
        "paper_abstract": "Improving the generalization of deep networks is an important open challenge, particularly in domains without plentiful data. The mixup algorithm improves generalization by linearly interpolating a pair of examples and their corresponding labels. These interpolated examples augment the original training set. Mixup has shown promising results in various classification tasks, but systematic analysis of mixup in regression remains underexplored. Using mixup directly on regression labels can result in arbitrarily incorrect labels. In this paper, we propose a simple yet powerful algorithm, C-Mixup, to improve generalization on regression tasks. In contrast with vanilla mixup, which picks training examples for mixing with uniform probability, C-Mixup adjusts the sampling probability based on the similarity of the labels. Our theoretical analysis confirms that C-Mixup with label similarity obtains a smaller mean square error in supervised regression and meta-regression than vanilla mixup and using feature similarity. Another benefit of C-Mixup is that it can improve out-of-distribution robustness, where the test distribution is different from the training distribution. By selectively interpolating examples with similar labels, it mitigates the effects of domain-associated information and yields domain-invariant representations. We evaluate C-Mixup on eleven datasets, ranging from tabular to video data. Compared to the best prior approach, C-Mixup achieves 6.56%, 4.76%, 5.82% improvements in in-distribution generalization, task generalization, and out-of-distribution robustness, respectively. Code is released at https://github.com/huaxiuyao/C-Mixup.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Infinite-Fidelity Coregionalization  for Physical Simulation",
        "paper_url": "https://openreview.net/pdf?id=dUYLikScE-",
        "paper_authors": [
            "Shibo Li",
            "Zheng Wang",
            "Robert Kirby",
            "Shandian Zhe"
        ],
        "paper_abstract": "Multi-fidelity modeling and learning is important in physical simulation related applications. It can leverage both low-fidelity and high-fidelity examples for training so as to reduce the cost of data generation yet still achieving good performance. While existing approaches only model finite, discrete fidelities, in practice, the feasible fidelity choice is often infinite, which can correspond to a continuous mesh spacing or finite element length. In this paper, we propose Infinite Fidelity Coregionalization (IFC). Given the data, our method can extract and exploit rich information within infinite, continuous fidelities to bolster the prediction accuracy. Our model can interpolate and/or extrapolate the predictions to novel fidelities that are not covered by the training data. Specifically, we introduce a low-dimensional latent output as a continuous function of the fidelity and input, and multiple it with a basis matrix to predict high-dimensional solution outputs. We model the latent output as a neural Ordinary Differential Equation (ODE) to capture the complex relationships within and integrate information throughout the continuous fidelities.  We then use Gaussian processes or another ODE to estimate the fidelity-varying bases. For efficient inference, we reorganize the bases as a tensor, and use a tensor-Gaussian variational posterior approximation to develop a scalable inference algorithm for massive outputs. We show the advantage of our method in several benchmark tasks in computational physics. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Giga-scale Kernel Matrix-Vector Multiplication on GPU",
        "paper_url": "https://openreview.net/pdf?id=fzvDZ0mraPP",
        "paper_authors": [
            "Robert Hu",
            "Siu Lun Chau",
            "Dino Sejdinovic",
            "Joan Alexis Glaun\u00e8s"
        ],
        "paper_abstract": "Kernel matrix-vector multiplication (KMVM) is a foundational operation in machine learning and scientific computing. However, as KMVM tends to scale quadratically in both memory and time, applications are often limited by these computational constraints. In this paper, we propose a novel approximation procedure coined \\textit{Faster-Fast and Free Memory Method} ($\\text{F}^3$M) to address these scaling issues of KMVM for tall~($10^8\\sim 10^9$) and skinny~($D\\leq7$) data. Extensive experiments demonstrate that $\\text{F}^3$M has empirical \\emph{linear time and memory} complexity with a relative error of order $10^{-3}$ and can compute a full KMVM for a billion points \\emph{in under a minute} on a high-end GPU, leading to a significant speed-up in comparison to existing CPU methods. We demonstrate the utility of our procedure by applying it as a drop-in for the state-of-the-art GPU-based linear solver FALKON, \\emph{improving speed 1.5-5.5 times} at the cost of $<1\\%$ drop in accuracy. We further demonstrate competitive results on \\emph{Gaussian Process regression} coupled with significant speedups on a variety of real-world datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Learning via Maximum Entropy Coding",
        "paper_url": "https://openreview.net/pdf?id=nJt27NQffr",
        "paper_authors": [
            "Xin Liu",
            "Zhongdao Wang",
            "Ya-Li Li",
            "Shengjin Wang"
        ],
        "paper_abstract": "A mainstream type of current self-supervised learning methods pursues a general-purpose representation that can be well transferred to downstream tasks, typically by optimizing on a given pretext task such as instance discrimination. In this work, we argue that existing pretext tasks inevitably introduce biases into the learned representation, which in turn leads to biased transfer performance on various downstream tasks. To cope with this issue, we propose Maximum Entropy Coding (MEC), a more principled objective that explicitly optimizes on the structure of the representation, so that the learned representation is less biased and thus generalizes better to unseen downstream tasks. Inspired by the principle of maximum entropy in information theory, we hypothesize that a generalizable representation should be the one that admits the maximum entropy among all plausible representations. To make the objective end-to-end trainable, we propose to leverage the minimal coding length in lossy data coding as a computationally tractable surrogate for the entropy, and further derive a scalable reformulation of the objective that allows fast computation. Extensive experiments demonstrate that MEC learns a more generalizable representation than previous methods based on specific pretext tasks. It achieves state-of-the-art performance consistently on various downstream tasks, including not only ImageNet linear probe, but also semi-supervised classification, object detection, instance segmentation, and object tracking. Interestingly, we show that existing batch-wise and feature-wise self-supervised objectives could be seen equivalent to low-order approximations of MEC. Code and pre-trained models are available at https://github.com/xinliu20/MEC.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Neural Transmitted Radiance Fields",
        "paper_url": "https://openreview.net/pdf?id=KglFYlTiASW",
        "paper_authors": [
            "Chengxuan Zhu",
            "Renjie Wan",
            "Boxin Shi"
        ],
        "paper_abstract": "Neural radiance fields (NeRF) have brought tremendous progress to novel view synthesis. Though NeRF enables the rendering of subtle details in a scene by learning from a dense set of images, it also reconstructs the undesired reflections when we capture images through glass. As a commonly observed interference, the reflection would undermine the visibility of the desired transmitted scene behind glass by occluding the transmitted light rays. In this paper, we aim at addressing the problem of rendering novel transmitted views given a set of reflection-corrupted images. By introducing the transmission encoder and recurring edge constraints as guidance, our neural transmitted radiance fields can resist such reflection interference during rendering and reconstruct high-fidelity results even under sparse views. The proposed method achieves superior performance from the experiments on a newly collected dataset compared with state-of-the-art methods. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sequencer: Deep LSTM for Image Classification",
        "paper_url": "https://openreview.net/pdf?id=wlrYnGZ37Wv",
        "paper_authors": [
            "Yuki Tatsunami",
            "Masato Taki"
        ],
        "paper_abstract": "In recent computer vision research, the advent of the Vision Transformer (ViT) has rapidly revolutionized various architectural design efforts: ViT achieved state-of-the-art image classification performance using self-attention found in natural language processing, and MLP-Mixer achieved competitive performance using simple multi-layer perceptrons. In contrast, several studies have also suggested that carefully redesigned convolutional neural networks (CNNs) can achieve advanced performance comparable to ViT without resorting to these new ideas. Against this background, there is growing interest in what inductive bias is suitable for computer vision. Here we propose Sequencer, a novel and competitive architecture alternative to ViT that provides a new perspective on these issues. Unlike ViTs, Sequencer models long-range dependencies using LSTMs rather than self-attention layers. We also propose a two-dimensional version of Sequencer module, where an LSTM is decomposed into vertical and horizontal LSTMs to enhance performance. Despite its simplicity, several experiments demonstrate that Sequencer performs impressively well: Sequencer2D-L, with 54M parameters, realizes 84.6% top-1 accuracy on only ImageNet-1K. Not only that, we show that it has good transferability and the robust resolution adaptability on double resolution-band. solution-band. Our source code is available at https://github.com/okojoalg/sequencer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Delving into Sequential Patches for Deepfake Detection",
        "paper_url": "https://openreview.net/pdf?id=osPA8Bs4MJB",
        "paper_authors": [
            "Jiazhi Guan",
            "Hang Zhou",
            "Zhibin Hong",
            "Errui Ding",
            "Jingdong Wang",
            "Chengbin Quan",
            "Youjian Zhao"
        ],
        "paper_abstract": "Recent advances in face forgery techniques produce nearly visually untraceable deepfake videos, which could be leveraged with malicious intentions. As a result, researchers have been devoted to deepfake detection. Previous studies have identified the importance of local low-level cues and temporal information in pursuit to generalize well across deepfake methods, however, they still suffer from robustness problem against post-processings. In this work, we  propose the Local- & Temporal-aware Transformer-based Deepfake Detection (LTTD) framework, which adopts a local-to-global learning protocol with a particular focus on the valuable temporal information within local sequences. Specifically, we propose a Local Sequence Transformer (LST), which models the temporal consistency on sequences of restricted spatial regions, where low-level information is hierarchically enhanced with shallow layers of learned 3D filters. Based on the local temporal embeddings, we then achieve the final classification in a global contrastive way. Extensive experiments on popular datasets validate that our approach effectively spots local forgery cues and achieves state-of-the-art performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Maximum Class Separation as Inductive Bias in One Matrix",
        "paper_url": "https://openreview.net/pdf?id=MbVS6BuJ3ql",
        "paper_authors": [
            "Tejaswi Kasarla",
            "Gertjan J. Burghouts",
            "Max van Spengler",
            "Elise van der Pol",
            "Rita Cucchiara",
            "Pascal Mettes"
        ],
        "paper_abstract": "Maximizing the separation between classes constitutes a well-known inductive bias in machine learning and a pillar of many traditional algorithms. By default, deep networks are not equipped with this inductive bias and therefore many alternative solutions have been proposed through differential optimization. Current approaches tend to optimize classification and separation jointly: aligning inputs with class vectors and separating class vectors angularly. This paper proposes a simple alternative: encoding maximum separation as an inductive bias in the network by adding one fixed matrix multiplication before computing the softmax activations. The main observation behind our approach is that separation does not require optimization but can be solved in closed-form prior to training and plugged into a network. We outline a recursive approach to obtain the matrix consisting of maximally separable vectors for any number of classes, which can be added with negligible engineering effort and computational overhead. Despite its simple nature, this one matrix multiplication provides real impact. We show that our proposal directly boosts classification, long-tailed recognition, out-of-distribution detection, and open-set recognition, from CIFAR to ImageNet. We find empirically that maximum separation works best as a fixed bias; making the matrix learnable adds nothing to the performance. The closed-form implementation and code to reproduce the experiments are available on github.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection",
        "paper_url": "https://openreview.net/pdf?id=kcQiIrvA_nz",
        "paper_authors": [
            "Yiming Li",
            "Yang Bai",
            "Yong Jiang",
            "Yong Yang",
            "Shu-Tao Xia",
            "Bo Li"
        ],
        "paper_abstract": "Deep neural networks (DNNs) have demonstrated their superiority in practice. Arguably, the rapid development of DNNs is largely benefited from high-quality (open-sourced) datasets, based on which researchers and developers can easily evaluate and improve their learning methods. Since the data collection is usually time-consuming or even expensive, how to protect their copyrights is of great significance and worth further exploration. In this paper, we revisit dataset ownership verification. We find that existing verification methods introduced new security risks in DNNs trained on the protected dataset, due to the targeted nature of poison-only backdoor watermarks. To alleviate this problem, in this work, we explore the untargeted backdoor watermarking scheme, where the abnormal model behaviors are not deterministic. Specifically, we introduce two dispersibilities and prove their correlation, based on which we design the untargeted backdoor watermark under both poisoned-label and clean-label settings. We also discuss how to use the proposed untargeted backdoor watermark for dataset ownership verification. Experiments on benchmark datasets verify the effectiveness of our methods and their resistance to existing backdoor defenses.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ClimbQ: Class Imbalanced Quantization Enabling Robustness on Efficient Inferences",
        "paper_url": "https://openreview.net/pdf?id=F7NQzsl334D",
        "paper_authors": [
            "Ting-An Chen",
            "De-Nian Yang",
            "Ming-syan Chen"
        ],
        "paper_abstract": "Quantization compresses models to low bits for efficient inferences which has received increasing attentions. However, existing approaches focused on balanced datasets, while imbalanced data is pervasive in the real world. Therefore, in this study, we investigate the realistic problem, quantization on class-imbalanced data. We observe from the analytical results that quantizing imbalanced data tends to obtain a large error due to the differences between separate class distributions, which leads to a significant accuracy loss. To address this issue, we propose a novel quantization framework, Class Imbalanced Quantization (ClimbQ) that focuses on diminishing the inter-class heterogeneity for quantization error reduction. ClimbQ first scales the variance of each class distribution and then projects data through the new distributions to the same space for quantization. To guarantee the homogeneity of class variances after the ClimbQ process, we examine the quantized features and derive that the homogeneity satisfies when data size for each class is restricted (bounded). Accordingly, we design a Homogeneous Variance Loss (HomoVar Loss) which reweights the data losses of each class based on the bounded data sizes to satisfy the homogeneity of class variances. Extensive experiments on class-imbalanced and benchmark balanced datasets reveal that ClimbQ outperforms the state-of-the-art quantization techniques, especially on highly imbalanced data. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Error Correction Code Transformer",
        "paper_url": "https://openreview.net/pdf?id=4F0Pd2Wjl0",
        "paper_authors": [
            "Yoni Choukroun",
            "Lior Wolf"
        ],
        "paper_abstract": "Error correction code is a major part of the physical communication layer, ensuring the reliable transfer of data over noisy channels.\nRecently, neural decoders were shown to outperform classical decoding techniques.\nHowever, the existing neural approaches present strong overfitting, due to the exponential training complexity, or a restrictive inductive bias, due to reliance on Belief Propagation.\nRecently, Transformers have become methods of choice in many applications, thanks to their ability to represent complex interactions between elements.\nIn this work, we propose to extend for the first time the Transformer architecture to the soft decoding of linear codes at arbitrary block lengths.\nWe encode each channel's output dimension to a high dimension for a better representation of the bits' information to be processed separately.\nThe element-wise processing allows the analysis of channel output reliability, while the algebraic code and the interaction between the bits are inserted into the model via an adapted masked self-attention module.\nThe proposed approach demonstrates the power and flexibility of Transformers and outperforms existing state-of-the-art neural decoders by large margins, at a fraction of their time complexity.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DISCO: Adversarial Defense with Local Implicit Functions",
        "paper_url": "https://openreview.net/pdf?id=vgIz0emVTAd",
        "paper_authors": [
            "Chih-Hui Ho",
            "Nuno Vasconcelos"
        ],
        "paper_abstract": "The problem of adversarial defenses for image classification, where the goal is to robustify a classifier against adversarial examples, is considered. Inspired by the hypothesis that these examples lie beyond the natural image manifold, a novel aDversarIal defenSe with local impliCit functiOns (DISCO) is proposed to remove adversarial perturbations by localized manifold projections. DISCO consumes an adversarial image and a query pixel location and outputs a clean RGB value at the location. It is implemented with an encoder and a local implicit module, where the former produces per-pixel deep features and the latter uses the features in the neighborhood of query pixel for predicting the clean RGB value. Extensive experiments demonstrate that both DISCO and its cascade version outperform prior defenses, regardless of whether the defense is known to the attacker. DISCO is also shown to be data and parameter efficient and to mount defenses that transfers across datasets, classifiers and attacks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Watermarking for Out-of-distribution Detection",
        "paper_url": "https://openreview.net/pdf?id=6rhl2k1SUGs",
        "paper_authors": [
            "Qizhou Wang",
            "Feng Liu",
            "Yonggang Zhang",
            "Jing Zhang",
            "Chen Gong",
            "Tongliang Liu",
            "Bo Han"
        ],
        "paper_abstract": "Out-of-distribution (OOD) detection aims to identify OOD data based on representations extracted from well-trained deep models. However, existing methods largely ignore the reprogramming property of deep models and thus may not fully unleash their intrinsic strength: without modifying parameters of a well-trained deep model, we can reprogram this model for a new purpose via data-level manipulation (e.g., adding a specific feature perturbation). This property motivates us to reprogram a classification model to excel at OOD detection (a new task), and thus we propose a general methodology named watermarking in this paper. Specifically, we learn a unified pattern that is superimposed onto features of original data, and the model's detection capability is largely boosted after watermarking. Extensive experiments verify the effectiveness of watermarking, demonstrating the significance of the reprogramming property of deep models in OOD detection.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Reinforcement Learning with a Terminator",
        "paper_url": "https://openreview.net/pdf?id=bIlUqzwObX",
        "paper_authors": [
            "Guy Tennenholtz",
            "Nadav Merlis",
            "Lior Shani",
            "Shie Mannor",
            "Uri Shalit",
            "Gal Chechik",
            "Assaf Hallak",
            "Gal Dalal"
        ],
        "paper_abstract": "We present the problem of reinforcement learning with exogenous termination. We define the Termination Markov Decision Process (TerMDP), an extension of the MDP framework, in which episodes may be interrupted by an external non-Markovian observer. This formulation accounts for numerous real-world situations, such as a human interrupting an autonomous driving agent for reasons of discomfort. We learn the parameters of the TerMDP and leverage the structure of the estimation problem to provide state-wise confidence bounds. We use these to construct a provably-efficient algorithm, which accounts for termination, and bound its regret. Motivated by our theoretical analysis, we design and implement a scalable approach, which combines optimism (w.r.t. termination) and a dynamic discount factor, incorporating the termination probability. We deploy our method on high-dimensional driving and MinAtar benchmarks. Additionally, we test our approach on human data in a driving setting. Our results demonstrate fast convergence and significant improvement over various baseline approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking Generalization in Few-Shot Classification",
        "paper_url": "https://openreview.net/pdf?id=p_g2nHlMus",
        "paper_authors": [
            "Markus Hiller",
            "Rongkai Ma",
            "Mehrtash Harandi",
            "Tom Drummond"
        ],
        "paper_abstract": "Single image-level annotations only correctly describe an often small subset of an image\u2019s content, particularly when complex real-world scenes are depicted. While this might be acceptable in many classification scenarios, it poses a significant challenge for applications where the set of classes differs significantly between training and test time. In this paper, we take a closer look at the implications in the context of few-shot learning. Splitting the input samples into patches and encoding these via the help of Vision Transformers allows us to establish semantic correspondences between local regions across images and independent of their respective class. The most informative patch embeddings for the task at hand are then determined as a function of the support set via online optimization at inference time, additionally providing visual interpretability of \u2018what matters most\u2019 in the image. We build on recent advances in unsupervised training of networks via masked image modelling to overcome the lack of fine-grained labels and learn the more general statistical structure of the data while avoiding negative image-level annotation influence, aka supervision collapse. Experimental results show the competitiveness of our approach, achieving new state-of-the-art results on four popular few-shot classification benchmarks for 5-shot and 1-shot scenarios.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Misspecified Phase Retrieval with Generative Priors",
        "paper_url": "https://openreview.net/pdf?id=--aQNMdJc9x",
        "paper_authors": [
            "Zhaoqiang Liu",
            "Xinshao Wang",
            "Jiulong Liu"
        ],
        "paper_abstract": "In this paper, we study phase retrieval under model misspecification and generative priors. In particular, we aim to estimate an $n$-dimensional signal $\\mathbf{x}$ from $m$ i.i.d.~realizations of the single index model $y = f(\\mathbf{a}^T\\mathbf{x})$, where $f$ is an unknown and possibly random nonlinear link function and $\\mathbf{a} \\in \\mathbb{R}^n$ is a standard Gaussian vector. We make the assumption $\\mathrm{Cov}[y,(\\mathbf{a}^T\\mathbf{x})^2] \\ne 0$, which corresponds to the misspecified phase retrieval problem. In addition, the underlying signal $\\mathbf{x}$ is assumed to lie in the range of an $L$-Lipschitz continuous generative model with bounded $k$-dimensional inputs. We propose a two-step approach, for which the first step plays the role of spectral initialization and the second step refines the estimated vector produced by the first step iteratively. We show that both steps enjoy a statistical rate of order $\\sqrt{(k\\log L)\\cdot (\\log m)/m}$ under suitable conditions. Experiments on image datasets are performed to demonstrate that our approach performs on par with or even significantly outperforms several competing methods. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Positively Weighted Kernel Quadrature via Subsampling",
        "paper_url": "https://openreview.net/pdf?id=V_4BQGbcwFB",
        "paper_authors": [
            "Satoshi Hayakawa",
            "Harald Oberhauser",
            "Terry Lyons"
        ],
        "paper_abstract": "We study kernel quadrature rules with convex weights. Our approach combines the spectral properties of the kernel with recombination results about point measures. This results in effective algorithms that construct convex quadrature rules using only access to i.i.d. samples from the underlying measure and evaluation of the kernel and that result in a small worst-case error. In addition to our theoretical results and the benefits resulting from convex weights, our experiments indicate that this construction can compete with the optimal bounds in well-known examples.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SHINE: SubHypergraph Inductive Neural nEtwork",
        "paper_url": "https://openreview.net/pdf?id=IsHRUzXPqhI",
        "paper_authors": [
            "Yuan Luo"
        ],
        "paper_abstract": "Hypergraph neural networks can model multi-way connections among nodes of the graphs, which are common in real-world applications such as genetic medicine. In particular, genetic pathways or gene sets encode molecular functions driven by multiple genes, naturally represented as hyperedges. Thus, hypergraph-guided embedding can capture functional relations in learned representations. Existing hypergraph neural network models often focus on node-level or graph-level inference. There is an unmet need in learning powerful representations of subgraphs of hypergraphs in real-world applications. For example, a cancer patient can be viewed as a subgraph of genes harboring mutations in the patient, while all the genes are connected by hyperedges that correspond to pathways representing specific molecular functions. For accurate inductive subgraph prediction, we propose SubHypergraph Inductive Neural nEtwork (SHINE). SHINE uses informative genetic pathways that encode molecular functions as hyperedges to connect genes as nodes. SHINE jointly optimizes the objectives of end-to-end subgraph classification and hypergraph nodes' similarity regularization. SHINE simultaneously learns representations for both genes and pathways using strongly dual attention message passing. The learned representations are aggregated via a subgraph attention layer and used to train a multilayer perceptron for subgraph inferencing. We evaluated SHINE against a wide array of state-of-the-art (hyper)graph neural networks, XGBoost, NMF and polygenic risk score models, using large scale NGS and curated datasets. SHINE outperformed all comparison models significantly, and yielded interpretable disease models with functional insights.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LASSIE: Learning Articulated Shapes from Sparse Image Ensemble via 3D Part Discovery",
        "paper_url": "https://openreview.net/pdf?id=0TDki1mlcwz",
        "paper_authors": [
            "Chun-Han Yao",
            "Wei-Chih Hung",
            "Yuanzhen Li",
            "Michael Rubinstein",
            "Ming-Hsuan Yang",
            "Varun Jampani"
        ],
        "paper_abstract": "Creating high-quality articulated 3D models of animals is challenging either via manual creation or using 3D scanning tools. \nTherefore, techniques to reconstruct articulated 3D objects from 2D images are crucial and highly useful. In this work, we propose a practical problem setting to estimate 3D pose and shape of animals given only a few (10-30) in-the-wild images of a particular animal species (say, horse). Contrary to existing works that rely on pre-defined template shapes, we do not assume any form of 2D or 3D ground-truth annotations, nor do we leverage any multi-view or temporal information. Moreover, each input image ensemble can contain animal instances with varying poses, backgrounds, illuminations, and textures. Our key insight is that 3D parts have much simpler shape compared to the overall animal and that they are robust w.r.t. animal pose articulations. Following these insights, we propose LASSIE, a novel optimization framework which discovers 3D parts in a self-supervised manner with minimal user intervention. A key driving force behind LASSIE is the enforcing of 2D-3D part consistency using self-supervisory deep features. Experiments on Pascal-Part and self-collected in-the-wild animal datasets demonstrate considerably better 3D reconstructions as well as both 2D and 3D part discovery compared to prior arts. Project page: https://chhankyao.github.io/lassie/",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bayesian Risk Markov Decision Processes",
        "paper_url": "https://openreview.net/pdf?id=PO6cKxILdi",
        "paper_authors": [
            "Yifan Lin",
            "Yuxuan Ren",
            "Enlu Zhou"
        ],
        "paper_abstract": "We consider finite-horizon Markov Decision Processes where parameters, such as transition probabilities, are unknown and estimated from data. The popular distributionally robust approach to addressing the parameter uncertainty can sometimes be overly conservative. In this paper, we propose a new formulation, Bayesian risk Markov decision process (BR-MDP), to address parameter uncertainty in MDPs, where a risk functional is applied in nested form to the expected total cost with respect to the Bayesian posterior distributions of the unknown parameters. The proposed formulation provides more flexible risk attitudes towards parameter uncertainty and takes into account the availability of data in future time stages. To solve the proposed formulation with the conditional value-at-risk (CVaR) risk functional, we propose an efficient approximation algorithm by deriving an analytical approximation of the value function and utilizing the convexity of CVaR. We demonstrate the empirical performance of the BR-MDP formulation and proposed algorithms on a gambler\u2019s betting problem and an inventory control problem.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-block-Single-probe Variance Reduced Estimator for Coupled Compositional Optimization",
        "paper_url": "https://openreview.net/pdf?id=16nVkS8Twxo",
        "paper_authors": [
            "Wei Jiang",
            "Gang Li",
            "Yibo Wang",
            "Lijun Zhang",
            "Tianbao Yang"
        ],
        "paper_abstract": "Variance reduction techniques such as SPIDER/SARAH/STORM have been extensively studied to improve the convergence rates of stochastic non-convex optimization, which usually maintain and update a sequence of estimators for a single function across iterations.  What if we need to track multiple functional mappings across iterations but only with access to stochastic samples of $\\mathcal{O}(1)$ functional mappings at each iteration? There is an important application in solving an emerging family of coupled compositional optimization problems in the form of $\\sum_{i=1}^m f_i(g_i(\\mathbf{w}))$, where $g_i$ is accessible through a stochastic oracle. The key issue is to track and estimate a sequence of $\\mathbf g(\\mathbf{w})=(g_1(\\mathbf{w}), \\ldots, g_m(\\mathbf{w}))$ across iterations, where $\\mathbf g(\\mathbf{w})$ has $m$ blocks and it is only allowed to probe $\\mathcal{O}(1)$ blocks to attain their stochastic values and Jacobians.  To improve the complexity for solving these problems, we propose a novel stochastic method named Multi-block-Single-probe Variance Reduced (MSVR) estimator to track the sequence of $\\mathbf g(\\mathbf{w})$. It is inspired by STORM but introduces a customized error correction term to alleviate the noise not only in stochastic samples for the selected blocks but also in those blocks that are not sampled. With the help of the MSVR estimator, we develop several algorithms for solving the aforementioned compositional problems with improved complexities across a spectrum of settings with non-convex/convex/strongly convex/Polyak-Lojasiewicz (PL) objectives. Our results improve upon prior ones in several aspects, including the order of sample complexities and dependence on the  strong convexity parameter. Empirical studies on multi-task deep AUC maximization demonstrate the better performance of using the new estimator. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Synergy-of-Experts: Collaborate to Improve Adversarial Robustness",
        "paper_url": "https://openreview.net/pdf?id=tuC6teLFZD",
        "paper_authors": [
            "Sen Cui",
            "Jingfeng Zhang",
            "Jian Liang",
            "Bo Han",
            "Masashi Sugiyama",
            "Changshui Zhang"
        ],
        "paper_abstract": "Learning adversarially robust models require invariant predictions to a small neighborhood of its natural inputs, often encountering insufficient model capacity. There is research showing that learning multiple sub-models in an ensemble could mitigate this insufficiency, further improving the generalization and the robustness. However, the ensemble's voting-based strategy excludes the possibility that the true predictions remain with the minority. Therefore, this paper further improves the ensemble through a collaboration scheme---Synergy-of-Experts (SoE). Compared with the voting-based strategy, the SoE enables the possibility of correct predictions even if there exists a single correct sub-model. In SoE, every sub-model fits its specific vulnerability area and reserves the rest of the sub-models to fit other vulnerability areas, which effectively optimizes the utilization of the model capacity. Empirical experiments verify that SoE outperforms various ensemble methods against white-box and transfer-based adversarial attacks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning",
        "paper_url": "https://openreview.net/pdf?id=Q8GnGqT-GTJ",
        "paper_authors": [
            "Xiang Chen",
            "Lei Li",
            "Ningyu Zhang",
            "Xiaozhuan Liang",
            "Shumin Deng",
            "Chuanqi Tan",
            "Fei Huang",
            "Luo Si",
            "Huajun Chen"
        ],
        "paper_abstract": "Prompt learning approaches have made waves in natural language processing by inducing better few-shot performance while they still follow a parametric-based learning paradigm; the oblivion and rote memorization problems in learning may encounter unstable generalization issues. Specifically, vanilla prompt learning may struggle to utilize atypical instances by rote during fully-supervised training or overfit shallow patterns with low-shot data. To alleviate such limitations, we develop RetroPrompt with the motivation of decoupling knowledge from memorization to help the model strike a balance between generalization and memorization. In contrast with vanilla prompt learning, RetroPrompt constructs an open-book knowledge-store from training instances and implements a retrieval mechanism during the process of input, training and inference, thus equipping the model with the ability to retrieve related contexts from the training corpus as cues for enhancement. Extensive experiments demonstrate that RetroPrompt can obtain better performance in both few-shot and zero-shot settings. Besides, we further illustrate that our proposed RetroPrompt can yield better generalization abilities with new datasets. Detailed analysis of memorization indeed reveals RetroPrompt can reduce the reliance of language models on memorization; thus, improving generalization for downstream tasks. Code is available in https://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HSDF: Hybrid Sign and Distance Field for Modeling Surfaces with Arbitrary Topologies",
        "paper_url": "https://openreview.net/pdf?id=Soadfc-JMeX",
        "paper_authors": [
            "Li Wang",
            "Jie Yang",
            "Weikai Chen",
            "Xiaoxu Meng",
            "Bo Yang",
            "Jintao Li",
            "Lin Gao"
        ],
        "paper_abstract": "Neural implicit function based on signed distance field (SDF) has achieved impressive progress in reconstructing 3D models with high fidelity. However, such approaches can only represent closed shapes. \nRecent works based on unsigned distance function (UDF) are proposed to handle both watertight and open surfaces. \nNonetheless, as UDF is signless, its direct output is limited to point cloud, which imposes an additional challenge on extracting high-quality meshes from discrete points.\nTo address this issue, we present a new learnable implicit representation, coded HSDF, that connects the good ends of SDF and UDF. In particular, HSDF is able to represent arbitrary topologies containing both closed and open surfaces while being compatible with existing iso-surface extraction techniques for easy field-to-mesh conversion. In addition to predicting a UDF, we propose to learn an additional sign field via a simple classifier. Unlike traditional SDF, HSDF is able to locate the surface of interest before level surface extraction by generating surface points following NDF~\\cite{chibane2020ndf}. We are then able to obtain open surfaces via an adaptive meshing approach that only instantiates regions containing surface into a polygon mesh. We also propose HSDF-Net, a dedicated learning framework that factorizes the learning of HSDF into two easier problems. \nExperiments on multiple datasets show that HSDF outperforms state-of-the-art techniques both qualitatively and quantitatively.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Obj2Seq: Formatting Objects as Sequences with Class Prompt for Visual Tasks",
        "paper_url": "https://openreview.net/pdf?id=cRNl08YWRKq",
        "paper_authors": [
            "Zhiyang Chen",
            "Yousong Zhu",
            "Zhaowen Li",
            "Fan Yang",
            "Wei Li",
            "Haixin Wang",
            "Chaoyang Zhao",
            "Liwei Wu",
            "Rui Zhao",
            "Jinqiao Wang",
            "Ming Tang"
        ],
        "paper_abstract": "Visual tasks vary a lot in their output formats and concerned contents, therefore it is hard to process them with an identical structure. One main obstacle lies in the high-dimensional outputs in object-level visual tasks. In this paper, we propose an object-centric vision framework, Obj2Seq. Obj2Seq takes objects as basic units, and regards most object-level visual tasks as sequence generation problems of objects. Therefore, these visual tasks can be decoupled into two steps. First recognize objects of given categories, and then generate a sequence for each of these objects. The definition of the output sequences varies for different tasks, and the model is supervised by matching these sequences with ground-truth targets. Obj2Seq is able to flexibly determine input categories to satisfy customized requirements, and be easily extended to different visual tasks. When experimenting on MS COCO, Obj2Seq achieves 45.7% AP on object detection, 89.0% AP on multi-label classification and 65.0% AP on human pose estimation. These results demonstrate its potential to be generally applied to different visual tasks. Code has been made available at: https://github.com/CASIA-IVA-Lab/Obj2Seq.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Riemannian Neural SDE: Learning Stochastic Representations on Manifolds",
        "paper_url": "https://openreview.net/pdf?id=1ryTomA0iKa",
        "paper_authors": [
            "Sung Woo Park",
            "Hyomin Kim",
            "Kyungjae Lee",
            "Junseok Kwon"
        ],
        "paper_abstract": "In recent years, the neural stochastic differential equation (NSDE) has gained attention for modeling stochastic representations with great success in various types of applications. However, it typically loses expressivity when the data representation is manifold-valued. To address this issue, we suggest a principled method for expressing the stochastic representation with the Riemannian neural SDE (RNSDE), which extends the conventional Euclidean NSDE. Empirical results for various tasks demonstrate that the proposed method significantly outperforms baseline methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Latent Seasonal-Trend Representations for Time Series Forecasting",
        "paper_url": "https://openreview.net/pdf?id=C9yUwd72yy",
        "paper_authors": [
            "Zhiyuan Wang",
            "Xovee Xu",
            "Weifeng Zhang",
            "Goce Trajcevski",
            "Ting Zhong",
            "Fan Zhou"
        ],
        "paper_abstract": "Forecasting complex time series is ubiquitous and vital in a range of applications but challenging. Recent advances endeavor to achieve progress by incorporating various deep learning techniques (e.g., RNN and Transformer) into sequential models. However, clear patterns are still hard to extract since time series are often composed of several intricately entangled components. Motivated by the success of disentangled variational autoencoder in computer vision and classical time series decomposition, we plan to infer a couple of representations that depict seasonal and trend components of time series. To achieve this goal, we propose LaST, which, based on variational inference, aims to disentangle the seasonal-trend representations in the latent space. Furthermore, LaST supervises and disassociates representations from the perspectives of themselves and input reconstruction, and introduces a series of auxiliary objectives. Extensive experiments prove that LaST achieves state-of-the-art performance on time series forecasting task against the most advanced representation learning and end-to-end forecasting models. For reproducibility, our implementation is publicly available on Github.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "QueryPose: Sparse Multi-Person Pose Regression via Spatial-Aware Part-Level Query",
        "paper_url": "https://openreview.net/pdf?id=tbId-oAOZo",
        "paper_authors": [
            "Yabo Xiao",
            "Kai Su",
            "Xiaojuan Wang",
            "Dongdong Yu",
            "Lei Jin",
            "Mingshu He",
            "Zehuan Yuan"
        ],
        "paper_abstract": "We propose a sparse end-to-end multi-person pose regression framework, termed QueryPose, which can directly predict multi-person keypoint sequences from the input image. The existing end-to-end methods rely on dense representations to preserve the spatial detail and structure for precise keypoint localization. However, the dense paradigm introduces complex and redundant post-processes during inference. In our framework, each human instance is encoded by several learnable spatial-aware part-level queries associated with an instance-level query. First, we propose the Spatial Part Embedding Generation Module (SPEGM) that considers the local spatial attention mechanism to generate several spatial-sensitive part embeddings, which contain spatial details and structural information for enhancing the part-level queries. Second, we introduce the Selective Iteration Module (SIM) to adaptively update the sparse part-level queries via the generated spatial-sensitive part embeddings stage-by-stage. Based on the two proposed modules, the part-level queries are able to fully encode the spatial details and structural information for precise keypoint regression. With the bipartite matching, QueryPose avoids the hand-designed post-processes. Without bells and whistles, QueryPose surpasses the existing dense end-to-end methods with 73.6 AP on MS COCO mini-val set and 72.7 AP on CrowdPose test set. Code is available at https://github.com/buptxyb666/QueryPose.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Mixture Of Surprises for Unsupervised Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=OHkq7qNr72-",
        "paper_authors": [
            "Andrew Zhao",
            "Matthieu Gaetan Lin",
            "Yangguang Li",
            "Yong-jin Liu",
            "Gao Huang"
        ],
        "paper_abstract": "Unsupervised reinforcement learning aims at learning a generalist policy in a reward-free manner for fast adaptation to downstream tasks. Most of the existing methods propose to provide an intrinsic reward based on surprise. Maximizing or minimizing surprise drives the agent to either explore or gain control over its environment. However, both strategies rely on a strong assumption: the entropy of the environment's dynamics is either high or low. This assumption may not always hold in real-world scenarios, where the entropy of the environment's dynamics may be unknown. Hence, choosing between the two objectives is a dilemma. We propose a novel yet simple mixture of policies to address this concern, allowing us to optimize an objective that simultaneously maximizes and minimizes the surprise. Concretely, we train one mixture component whose objective is to maximize the surprise and another whose objective is to minimize the surprise. Hence, our method does not make assumptions about the entropy of the environment's dynamics. We call our method a $\\textbf{M}\\text{ixture }\\textbf{O}\\text{f }\\textbf{S}\\text{urprise}\\textbf{S}$ (MOSS) for unsupervised reinforcement learning. Experimental results show that our simple method achieves state-of-the-art performance on the URLB benchmark, outperforming previous pure surprise maximization-based objectives. Our code is available at: https://github.com/LeapLabTHU/MOSS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Monocular Dynamic View Synthesis: A Reality Check",
        "paper_url": "https://openreview.net/pdf?id=pCrB8orUkSq",
        "paper_authors": [
            "Hang Gao",
            "Ruilong Li",
            "Shubham Tulsiani",
            "Bryan Russell",
            "Angjoo Kanazawa"
        ],
        "paper_abstract": "We study the recent progress on dynamic view synthesis (DVS) from monocular video. Though existing approaches have demonstrated impressive results, we show a discrepancy between the practical capture process and the existing experimental protocols, which effectively leaks in multi-view signals during training. We define effective multi-view factors (EMFs) to quantify the amount of multi-view signal present in the input capture sequence based on the relative camera-scene motion. We introduce two new metrics: co-visibility masked image metrics and correspondence accuracy, which overcome the issue in existing protocols. We also propose a new iPhone dataset that includes more diverse real-life deformation sequences. Using our proposed experimental protocol, we show that the state-of-the-art approaches observe a 1-2 dB drop in masked PSNR in the absence of multi-view cues and 4-5 dB drop when modeling complex motion. Code and data can be found at http://hangg7.com/dycheck.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Antigen-Specific Antibody Design and Optimization with Diffusion-Based Generative Models for Protein Structures",
        "paper_url": "https://openreview.net/pdf?id=jSorGn2Tjg",
        "paper_authors": [
            "Shitong Luo",
            "Yufeng Su",
            "Xingang Peng",
            "Sheng Wang",
            "Jian Peng",
            "Jianzhu Ma"
        ],
        "paper_abstract": "Antibodies are immune system proteins that protect the host by binding to specific antigens such as viruses and bacteria. The binding between antibodies and antigens is mainly determined by the complementarity-determining regions (CDR) of the antibodies. In this work, we develop a deep generative model that jointly models sequences and structures of CDRs based on diffusion probabilistic models and equivariant neural networks. Our method is the first deep learning-based method that generates antibodies explicitly targeting specific antigen structures and is one of the earliest diffusion probabilistic models for protein structures. The model is a \"Swiss Army Knife\" capable of sequence-structure co-design, sequence design for given backbone structures, and antibody optimization. We conduct extensive experiments to evaluate the quality of both sequences and structures of designed antibodies. We find that our model could yield competitive results in binding affinity measured by biophysical energy functions and other protein design metrics.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DropCov: A Simple yet Effective Method for Improving Deep Architectures",
        "paper_url": "https://openreview.net/pdf?id=QLGuUwDx4S",
        "paper_authors": [
            "Qilong Wang",
            "Mingze Gao",
            "Zhaolin Zhang",
            "Jiangtao Xie",
            "Peihua Li",
            "Qinghua Hu"
        ],
        "paper_abstract": "Previous works show global covariance pooling (GCP) has great potential to improve deep architectures especially on visual recognition tasks, where post-normalization of GCP plays a very important role in final performance. Although several post-normalization strategies have been studied, these methods pay more close attention to effect of normalization on covariance representations rather than the whole GCP networks, and their effectiveness requires further understanding. Meanwhile, existing effective post-normalization strategies (e.g., matrix power normalization) usually suffer from high computational complexity (e.g., $O(d^{3})$ for $d$-dimensional inputs). To handle above issues, this work first analyzes the effect of post-normalization from the perspective of training GCP networks. Particularly, we for the first time show that \\textit{effective post-normalization can make a good trade-off between representation decorrelation and information preservation for GCP, which are crucial to alleviate over-fitting and increase representation ability of deep GCP networks, respectively}. Based on this finding, we can improve existing post-normalization methods with some small modifications, providing further support to our observation. Furthermore, this finding encourages us to propose a novel pre-normalization method for GCP (namely DropCov), which develops an adaptive channel dropout on features right before GCP, aiming to reach trade-off between representation decorrelation and information preservation in a more efficient way. Our DropCov only has a linear complexity of $O(d)$, while being free for inference. Extensive experiments on various benchmarks (i.e., ImageNet-1K, ImageNet-C, ImageNet-A, Stylized-ImageNet, and iNat2017) show our DropCov is superior to the counterparts in terms of efficiency and effectiveness, and provides a simple yet effective method to improve performance of deep architectures involving both deep convolutional neural networks (CNNs) and vision transformers (ViTs).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Approximate Secular Equations for the Cubic Regularization Subproblem",
        "paper_url": "https://openreview.net/pdf?id=XrECTbqRCfX",
        "paper_authors": [
            "Yihang Gao",
            "Man-Chung Yue",
            "Michael Ng"
        ],
        "paper_abstract": "The cubic regularization method (CR) is a popular algorithm for unconstrained non-convex optimization. At each iteration, CR solves a cubically regularized quadratic problem, called the cubic regularization subproblem (CRS). One way to solve the CRS relies on solving the secular equation, whose computational bottleneck lies in the computation of all eigenvalues of the Hessian matrix. In this paper, we propose and analyze a novel CRS solver based on an approximate secular equation, which requires only some of the Hessian eigenvalues and is therefore much more efficient. Two approximate secular equations (ASEs) are developed. For both ASEs, we first study the existence and uniqueness of their roots and then establish an upper bound on the gap between the root and that of the standard secular equation. Such an upper bound can in turn be used to bound the distance from the approximate CRS solution based ASEs to the true CRS solution, thus offering a theoretical guarantee for our CRS solver. A desirable feature of our CRS solver is that it requires only matrix-vector multiplication but not matrix inversion, which makes it particularly suitable for high-dimensional applications of unconstrained non-convex optimization, such as low-rank recovery and deep learning. Numerical experiments with synthetic and real data-sets are conducted to investigate the practical performance of the proposed CRS solver. Experimental results show that the proposed solver outperforms two state-of-the-art methods. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Spatial Pruned Sparse Convolution for Efficient 3D Object Detection",
        "paper_url": "https://openreview.net/pdf?id=QqWqFLbllZh",
        "paper_authors": [
            "Jianhui Liu",
            "Yukang Chen",
            "Xiaoqing Ye",
            "Zhuotao Tian",
            "Xiao Tan",
            "XIAOJUAN QI"
        ],
        "paper_abstract": "3D scenes are dominated by a large number of background points, which is redundant for the detection task that mainly needs to focus on foreground objects. In this paper, we analyze major components of existing sparse 3D CNNs and find that 3D CNNs ignores the redundancy of data and further amplifies it in the down-sampling process, which brings a huge amount of extra and unnecessary computational overhead. Inspired by this, we propose a new convolution operator named spatial pruned sparse convolution (SPS-Conv), which includes two variants, spatial pruned submanifold sparse convolution (SPSS-Conv) and spatial pruned regular sparse convolution (SPRS-Conv), both of which are based on the idea of dynamically determine crucial areas for performing computations to reduce redundancy. We empirically find that magnitude of features can serve as an important cues to determine crucial areas which get rid of the heavy computations of learning-based methods. The proposed modules can easily be incorporated into existing sparse  3D CNNs without extra architectural modifications. Extensive experiments on the KITTI and nuScenes datasets demonstrate that our method can achieve more than 50% reduction in GFLOPs without compromising the performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "BMU-MoCo: Bidirectional Momentum Update for Continual Video-Language Modeling",
        "paper_url": "https://openreview.net/pdf?id=H5z5Q--YdYd",
        "paper_authors": [
            "Yizhao Gao",
            "Nanyi Fei",
            "Haoyu Lu",
            "Zhiwu Lu",
            "Hao Jiang",
            "Yijie Li",
            "Zhao Cao"
        ],
        "paper_abstract": "Video-language models suffer from forgetting old/learned knowledge when trained with streaming data. In this work, we thus propose a continual video-language modeling (CVLM) setting, where models are supposed to be sequentially trained on five widely-used video-text datasets with different data distributions. Although most of existing continual learning methods have achieved great success by exploiting extra information (e.g., memory data of past tasks) or dynamically extended networks, they cause enormous resource consumption when transferred to our CVLM setting. To overcome the challenges (i.e., catastrophic forgetting and heavy resource consumption) in CVLM, we propose a novel cross-modal MoCo-based model with bidirectional momentum update (BMU), termed BMU-MoCo. Concretely, our BMU-MoCo has two core designs: (1) Different from the conventional MoCo, we apply the momentum update to not only momentum encoders but also encoders (i.e., bidirectional) at each training step, which enables the model to review the learned knowledge retained in the momentum encoders. (2) To further enhance our BMU-MoCo by utilizing earlier knowledge, we additionally maintain a pair of global momentum encoders (only initialized at the very beginning) with the same BMU strategy. Extensive results show that our BMU-MoCo remarkably outperforms recent competitors w.r.t. video-text retrieval performance and forgetting rate, even without using any extra data or dynamic networks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images",
        "paper_url": "https://openreview.net/pdf?id=GAUwreODU5L",
        "paper_authors": [
            "Jun Gao",
            "Tianchang Shen",
            "Zian Wang",
            "Wenzheng Chen",
            "Kangxue Yin",
            "Daiqing Li",
            "Or Litany",
            "Zan Gojcic",
            "Sanja Fidler"
        ],
        "paper_abstract": "As several industries are moving towards modeling massive 3D virtual worlds, the need for content creation tools that can scale in terms of the quantity, quality, and diversity of 3D content is becoming evident. In our work, we aim to train performant 3D generative models that synthesize textured meshes which can be directly consumed by 3D rendering engines, thus immediately usable in downstream applications. Prior works on 3D generative modeling either lack geometric details, are limited in the mesh topology they can produce, typically do not support textures, or utilize neural renderers in the synthesis process, which makes their use in common 3D software non-trivial. In this work, we introduce GET3D, a Generative model that directly generates Explicit Textured 3D meshes with complex topology, rich geometric details, and high fidelity textures. We bridge recent success in the differentiable surface modeling, differentiable rendering as well as 2D Generative Adversarial Networks to train our model from 2D image collections. GET3D is able to generate high-quality 3D textured meshes, ranging from cars, chairs, animals, motorbikes and human characters to buildings, achieving significant improvements over previous methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Optical Flow from Continuous Spike Streams",
        "paper_url": "https://openreview.net/pdf?id=3vYkhJIty7E",
        "paper_authors": [
            "Rui Zhao",
            "Ruiqin Xiong",
            "Jing Zhao",
            "Zhaofei Yu",
            "Xiaopeng Fan",
            "Tiejun Huang"
        ],
        "paper_abstract": "Spike camera is an emerging bio-inspired vision sensor with ultra-high temporal resolution. It records scenes by accumulating photons and outputting continuous binary spike streams. Optical flow is a key task for spike cameras and their applications. A previous attempt has been made for spike-based optical flow. However, the previous work only focuses on motion between two moments, and it uses graphics-based data for training, whose generalization is limited. In this paper, we propose a tailored network,  Spike2Flow that extracts information from binary spikes with temporal-spatial representation based on the differential of spike firing time and spatial information aggregation. The network utilizes continuous motion clues through joint correlation decoding. Besides, a new dataset with real-world scenes is proposed for better generalization. Experimental results show that our approach achieves state-of-the-art performance on existing synthetic datasets and real data captured by spike cameras. The source code and dataset are available at \\url{https://github.com/ruizhao26/Spike2Flow}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "INRAS: Implicit Neural Representation for Audio Scenes",
        "paper_url": "https://openreview.net/pdf?id=7KBzV5IL7W",
        "paper_authors": [
            "Kun Su",
            "Mingfei Chen",
            "Eli Shlizerman"
        ],
        "paper_abstract": "The spatial acoustic information of a scene, i.e., how sounds emitted from a particular location in the scene are perceived in another location, is key for immersive scene modeling. Robust representation of scene's acoustics can be formulated through a continuous field formulation along with impulse responses varied by emitter-listener locations. The impulse responses are then used to render sounds perceived by the listener. While such representation is advantageous, parameterization of impulse responses for generic scenes presents itself as a challenge. Indeed, traditional pre-computation methods have only implemented parameterization at discrete probe points and require large storage, while other existing methods such as geometry-based sound simulations still suffer from inability to simulate all wave-based sound effects. In this work, we introduce a novel neural network for light-weight Implicit Neural Representation for Audio Scenes (INRAS), which can render a high fidelity time-domain impulse responses at any arbitrary emitter-listener positions by learning a continuous implicit function. INRAS disentangles scene\u2019s geometry features with three modules to generate independent features for the emitter, the geometry of the scene, and the listener respectively. These lead to an efficient reuse of scene-dependent features and support effective multi-condition training for multiple scenes.  Our experimental results show that INRAS outperforms existing approaches for representation and rendering of sounds for varying emitter-listener locations in all aspects, including the impulse response quality, inference speed, and storage requirements. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Posterior and Computational Uncertainty in Gaussian Processes",
        "paper_url": "https://openreview.net/pdf?id=Zzi8Od19DSU",
        "paper_authors": [
            "Jonathan Wenger",
            "Geoff Pleiss",
            "Marvin Pf\u00f6rtner",
            "Philipp Hennig",
            "John Patrick Cunningham"
        ],
        "paper_abstract": "Gaussian processes scale prohibitively with the size of the dataset. In response, many approximation methods have been developed, which inevitably introduce approximation error. This additional source of uncertainty, due to limited computation, is entirely ignored when using the approximate posterior. Therefore in practice, GP models are often as much about the approximation method as they are about the data. Here, we develop a new class of methods that provides consistent estimation of the combined uncertainty arising from both the finite number of data observed and the finite amount of computation expended. The most common GP approximations map to an instance in this class, such as methods based on the Cholesky factorization, conjugate gradients, and inducing points. For any method in this class, we prove (i) convergence of its posterior mean in the associated RKHS, (ii) decomposability of its combined posterior covariance into mathematical and computational covariances, and (iii) that the combined variance is a tight worst-case bound for the squared error between the method's posterior mean and the latent function. Finally, we empirically demonstrate the consequences of ignoring computational uncertainty and show how implicitly modeling it improves generalization performance on benchmark datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm",
        "paper_url": "https://openreview.net/pdf?id=9s3CbJh4vRP",
        "paper_authors": [
            "Changlong Wu",
            "Mohsen Heidari",
            "Ananth Grama",
            "Wojciech Szpankowski"
        ],
        "paper_abstract": "We study sequential general online regression, known also as sequential probability assignments, under logarithmic loss when compared against a broad class of experts. We obtain tight, often matching, lower and upper bounds for sequential minimax regret, which is defined as the excess loss incurred by the predictor over the best expert in the class. After proving a general upper bound we consider some specific classes of experts from Lipschitz class to bounded Hessian class and derive matching lower and upper bounds with provably optimal constants. Our bounds work for a wide range of values of the data dimension and the number of rounds. To derive lower bounds, we use tools from information theory (e.g., Shtarkov sum) and for upper bounds, we resort to new \"smooth truncated covering\" of the class of experts. This allows us to find constructive proofs by applying a simple and novel truncated Bayesian algorithm. Our proofs are substantially simpler than the existing ones and yet provide tighter (and often optimal) bounds.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Robust Testing in High-Dimensional Sparse Models",
        "paper_url": "https://openreview.net/pdf?id=UVF3yybAjF",
        "paper_authors": [
            "Anand Jerry George",
            "Clement Louis Canonne"
        ],
        "paper_abstract": "We consider the problem of robustly testing the norm of a high-dimensional sparse signal vector under two different observation models. In the first model, we are given $n$ i.i.d. samples from the distribution $\\mathcal{N}\\left(\\theta,I_d\\right)$ (with unknown $\\theta$), of which a small fraction has been arbitrarily corrupted. Under the promise that $\\|\\theta\\|_0\\le s$, we want to correctly distinguish whether $\\|\\theta\\|_2=0$ or $\\|\\theta\\|_2>\\gamma$, for some input parameter $\\gamma>0$. We show that any algorithm for this task requires $n=\\Omega\\left(s\\log\\frac{ed}{s}\\right)$ samples, which is tight up to logarithmic factors. We also extend our results to other common notions of sparsity, namely, $\\|\\theta\\|_q\\le s$ for any $0 < q < 2$. In the second observation model that we consider, the data is generated according to a sparse linear regression model, where the covariates are i.i.d. Gaussian and the regression coefficient (signal) is known to be $s$-sparse. Here too we assume that an $\\epsilon$-fraction of the data is arbitrarily corrupted. We show that any algorithm that reliably tests the norm of the regression coefficient requires at least $n=\\Omega\\left(\\min(s\\log d,{1}/{\\gamma^4})\\right)$ samples. Our results show that the complexity of testing in these two settings significantly increases under robustness constraints. This is in line with the recent observations made in robust mean testing and robust covariance testing.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VER: Scaling On-Policy RL Leads to the Emergence of Navigation in Embodied Rearrangement",
        "paper_url": "https://openreview.net/pdf?id=VrJWseIN98",
        "paper_authors": [
            "Erik Wijmans",
            "Irfan Essa",
            "Dhruv Batra"
        ],
        "paper_abstract": "We present Variable Experience Rollout (VER), a technique for efficiently scaling batched on-policy reinforcement learning in heterogenous environments (where different environments take vastly different times to generate rollouts) to many GPUs residing on, potentially, many machines. VER combines the strengths of and blurs the line between synchronous and asynchronous on-policy RL methods (SyncOnRL and AsyncOnRL, respectively). Specifically, it learns from on-policy experience (like SyncOnRL) and has no synchronization points (like AsyncOnRL) enabling high throughput.\n\nWe find that VER leads to significant and consistent speed-ups across a broad range of embodied navigation and mobile manipulation tasks in photorealistic 3D simulation environments. Specifically, for PointGoal navigation and ObjectGoal navigation in Habitat 1.0, VER is 60-100% faster (1.6-2x speedup) than DD-PPO, the current state of art for distributed SyncOnRL, with similar sample efficiency. For mobile manipulation tasks (open fridge/cabinet, pick/place objects) in Habitat 2.0 VER is 150% faster (2.5x speedup) on 1 GPU and 170% faster (2.7x speedup) on 8 GPUs than DD-PPO. Compared to SampleFactory (the current state-of-the-art AsyncOnRL), VER matches its speed on 1 GPU, and is 70% faster (1.7x speedup) on 8 GPUs with better sample efficiency.\n\nWe leverage these speed-ups to train chained skills for GeometricGoal rearrangement tasks in the Home Assistant Benchmark (HAB). We find a surprising emergence of navigation in skills that do not ostensible require any navigation. Specifically, the Pick skill involves a robot picking an object from a table. During training the robot was always spawned close to the table and never needed to navigate. However, we find that if base movement is part of the action space, the robot learns to navigate then pick an object in new environments with 50% success, demonstrating surprisingly high out-of-distribution generalization.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Identifiability and generalizability from multiple experts in Inverse Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=KFxIsdIvUj",
        "paper_authors": [
            "Paul Rolland",
            "Luca Viano",
            "Norman Schuerhoff",
            "Boris Nikolov",
            "Volkan Cevher"
        ],
        "paper_abstract": "While Reinforcement Learning (RL) aims to train an agent from a reward function in a given environment, Inverse Reinforcement Learning (IRL) seeks to recover the reward function from observing an expert's behavior. It is well known that, in general, various reward functions can lead to the same optimal policy, and hence, IRL is ill-defined. However, \\cite{cao2021identifiability} showed that, if we observe two or more experts with different discount factors or acting in different environments, the reward function can under certain conditions be identified up to a constant. This work starts by showing an equivalent identifiability statement from multiple experts in tabular MDPs based on a rank condition, which is easily verifiable and is shown to be also necessary. We then extend our result to various different scenarios, i.e., we characterize reward identifiability in the case where the reward function can be represented as a linear combination of given features, making it more interpretable, or when we have access to approximate transition matrices. Even when the reward is not identifiable, we provide conditions characterizing when data on multiple experts in a given environment allows to generalize and train an optimal agent in a new environment. Our theoretical results on reward identifiability and generalizability are validated in various numerical experiments.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos",
        "paper_url": "https://openreview.net/pdf?id=4kjQZTNz-NH",
        "paper_authors": [
            "Yanze Wu",
            "Xintao Wang",
            "Gen Li",
            "Ying Shan"
        ],
        "paper_abstract": "This paper studies the problem of real-world video super-resolution (VSR) for animation videos, and reveals three key improvements for practical animation VSR. First, recent real-world super-resolution approaches typically rely on degradation simulation using basic operators without any learning capability, such as blur, noise, and compression. In this work, we propose to learn such basic operators from real low-quality animation videos, and incorporate the learned ones into the degradation generation pipeline. Such neural-network-based basic operators could help to better capture the distribution of real degradations. Second, a large-scale high-quality animation video dataset, AVC, is built to facilitate comprehensive training and evaluations for animation VSR. Third, we further investigate an efficient multi-scale network structure. It takes advantage of the efficiency of unidirectional recurrent networks and the effectiveness of sliding-window-based methods. Thanks to the above delicate designs, our method, AnimeSR, is capable of restoring real-world low-quality animation videos effectively and efficiently, achieving superior performance to previous state-of-the-art methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking Alignment in Video Super-Resolution Transformers",
        "paper_url": "https://openreview.net/pdf?id=NgIf3FpcHie",
        "paper_authors": [
            "Shuwei Shi",
            "Jinjin Gu",
            "Liangbin Xie",
            "Xintao Wang",
            "Yujiu Yang",
            "Chao Dong"
        ],
        "paper_abstract": "The alignment of adjacent frames is considered an essential operation in video super-resolution (VSR). Advanced VSR models, including the latest VSR Transformers, are generally equipped with well-designed alignment modules. However, the progress of the self-attention mechanism may violate this common sense. In this paper, we rethink the role of alignment in VSR Transformers and make several counter-intuitive observations. Our experiments show that: (i) VSR Transformers can directly utilize multi-frame information from unaligned videos, and (ii) existing alignment methods are sometimes harmful to VSR Transformers. These observations indicate that we can further improve the performance of VSR Transformers simply by removing the alignment module and adopting a larger attention window. Nevertheless, such designs will dramatically increase the computational burden, and cannot deal with large motions. Therefore, we propose a new and efficient alignment method called patch alignment, which aligns image patches instead of pixels. VSR Transformers equipped with patch alignment could demonstrate state-of-the-art performance on multiple benchmarks. Our work provides valuable insights on how multi-frame information is used in VSR and how to select alignment methods for different networks/datasets. Codes and models will be released at https://github.com/XPixelGroup/RethinkVSRAlignment.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Censored Quantile Regression Neural Networks for Distribution-Free Survival Analysis",
        "paper_url": "https://openreview.net/pdf?id=pGcTocvaZkJ",
        "paper_authors": [
            "Tim Pearce",
            "Jong-Hyeon Jeong",
            "yichen jia",
            "Jun Zhu"
        ],
        "paper_abstract": "This paper considers doing quantile regression on censored data using neural networks (NNs). This adds to the survival analysis toolkit by allowing direct prediction of the target variable, along with a distribution-free characterisation of uncertainty, using a flexible function approximator. We begin by showing how an algorithm popular in linear models can be applied to NNs. However, the resulting procedure is inefficient, requiring sequential optimisation of an individual NN at each desired quantile. Our major contribution is a novel algorithm that simultaneously optimises a grid of quantiles output by a single NN. To offer theoretical insight into our algorithm, we show firstly that it can be interpreted as a form of expectation-maximisation, and secondly that it exhibits a desirable `self-correcting' property. Experimentally, the algorithm produces quantiles that are better calibrated than existing methods on 10 out of 12 real datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Effective Backdoor Defense by Exploiting Sensitivity of Poisoned Samples",
        "paper_url": "https://openreview.net/pdf?id=AsH-Tx2U0Ug",
        "paper_authors": [
            "Weixin Chen",
            "Baoyuan Wu",
            "Haoqian Wang"
        ],
        "paper_abstract": "Poisoning-based backdoor attacks are serious threat for training deep models on data from untrustworthy sources. Given a backdoored model, we observe that the feature representations of poisoned samples with trigger are more sensitive to transformations than those of clean samples. It inspires us to design a simple sensitivity metric, called feature consistency towards transformations (FCT), to distinguish poisoned samples from clean samples in the untrustworthy training set. Moreover, we propose two effective backdoor defense methods. Built upon a sample-distinguishment module utilizing the FCT metric, the first method trains a secure model from scratch using a two-stage secure training module. And the second method removes backdoor from a backdoored model with a backdoor removal module which alternatively unlearns the distinguished poisoned samples and relearns the distinguished clean samples. Extensive results on three benchmark datasets demonstrate the superior defense performance against eight types of backdoor attacks, to state-of-the-art backdoor defenses. Codes are available at: https://github.com/SCLBD/Effective_backdoor_defense.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Asymptotically Unbiased Instance-wise Regularized Partial AUC Optimization: Theory and Algorithm",
        "paper_url": "https://openreview.net/pdf?id=er4GR0wHWQO",
        "paper_authors": [
            "HuiYang Shao",
            "Qianqian Xu",
            "Zhiyong Yang",
            "Shilong Bao",
            "Qingming Huang"
        ],
        "paper_abstract": "    The Partial Area Under the ROC Curve (PAUC), typically including One-way Partial AUC (OPAUC) and Two-way Partial AUC (TPAUC), measures the average performance of a binary classifier within a specific false positive rate and/or true positive rate interval, which is a widely adopted measure when decision constraints must be considered. Consequently, PAUC optimization has naturally attracted increasing attention in the machine learning community within the last few years. Nonetheless, most of the existing methods could only optimize PAUC approximately, leading to inevitable biases that are not controllable. Fortunately, a recent work presents an unbiased formulation of the PAUC optimization problem via distributional robust optimization. However, it is based on the pair-wise formulation of AUC, which suffers from the limited scalability w.r.t. sample size and a slow convergence rate, especially for TPAUC. To address this issue, we present a simpler reformulation of the problem in an asymptotically unbiased and instance-wise manner. For both OPAUC and TPAUC, we come to a nonconvex strongly concave min-max regularized problem of instance-wise functions. On top of this, we employ an efficient solver that enjoys a linear per-iteration computational complexity w.r.t. the sample size and a time-complexity of $O(\\epsilon^{-1/3})$ to reach a $\\epsilon$ stationary point. Furthermore, we find that the min-max reformulation also facilitates the theoretical analysis of generalization error as a byproduct. Compared with the existing results, we present new error bounds that are much easier to prove and could deal with hypotheses with real-valued outputs. Finally, extensive experiments on several benchmark datasets demonstrate the effectiveness of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Constants of motion network",
        "paper_url": "https://openreview.net/pdf?id=Lpla1jmJkW",
        "paper_authors": [
            "Muhammad Firmansyah Kasim",
            "Yi Heng Lim"
        ],
        "paper_abstract": "The beauty of physics is that there is usually a conserved quantity in an always-changing system, known as the constant of motion. Finding the constant of motion is important in understanding the dynamics of the system, but typically requires mathematical proficiency and manual analytical work. In this paper, we present a neural network that can simultaneously learn the dynamics of the system and the constants of motion from data. By exploiting the discovered constants of motion, it can produce better predictions on dynamics and can work on a wider range of systems than Hamiltonian-based neural networks. In addition, the training progresses of our method can be used as an indication of the number of constants of motion in a system which could be useful in studying a novel physical system.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OTKGE: Multi-modal Knowledge Graph Embeddings via Optimal Transport",
        "paper_url": "https://openreview.net/pdf?id=gbXqMdxsZIP",
        "paper_authors": [
            "Zongsheng Cao",
            "Qianqian Xu",
            "Zhiyong Yang",
            "Yuan He",
            "Xiaochun Cao",
            "Qingming Huang"
        ],
        "paper_abstract": "Multi-modal knowledge graph embeddings (KGE) have caught more and more attention in learning representations of entities and relations for link prediction tasks. Different from previous uni-modal KGE approaches, multi-modal KGE can leverage expressive knowledge from a wealth of modalities (image, text, etc.), leading to more comprehensive representations of real-world entities. However, the critical challenge along this course lies in that the multi-modal embedding spaces are usually heterogeneous. In this sense, direct fusion will destroy the inherent spatial structure of different modal embeddings. To overcome this challenge, we revisit multi-modal KGE from a distributional alignment perspective and propose optimal transport knowledge graph embeddings (OTKGE). Specifically, we model the multi-modal fusion procedure as a transport plan moving different modal embeddings to a unified space by minimizing the Wasserstein distance between multi-modal distributions. Theoretically, we show that by minimizing the Wasserstein distance between the individual modalities and the unified embedding space, the final results are guaranteed to maintain consistency and comprehensiveness. Moreover, experimental results on well-established multi-modal knowledge graph completion benchmarks show that our OTKGE achieves state-of-the-art performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Keypoint-Guided Optimal Transport with Applications in Heterogeneous Domain Adaptation",
        "paper_url": "https://openreview.net/pdf?id=m6DJxSuKuqF",
        "paper_authors": [
            "Xiang Gu",
            "Yucheng Yang",
            "Wei Zeng",
            "Jian Sun",
            "Zongben Xu"
        ],
        "paper_abstract": "Existing Optimal Transport (OT) methods mainly derive the optimal transport plan/matching under the criterion of transport cost/distance minimization, which may cause incorrect matching in some cases. In many applications, annotating a few matched keypoints across domains is reasonable or even effortless in annotation burden. It is valuable to investigate how to leverage the annotated keypoints to guide the correct matching in OT. In this paper, we propose a novel KeyPoint-Guided model by ReLation preservation (KPG-RL) that searches for the matching guided by the keypoints in OT. To impose the keypoints in OT, first, we propose a mask-based constraint of the transport plan that preserves the matching of keypoint pairs. Second, we propose to preserve the relation of each data point to the keypoints to guide the matching. The proposed KPG-RL model can be solved by the Sinkhorn's algorithm and is applicable even when distributions are supported in different spaces. We further utilize the relation preservation constraint in the Kantorovich Problem and Gromov-Wasserstein model to impose the guidance of keypoints in them. Meanwhile, the proposed KPG-RL model is extended to partial OT setting. As an application, we apply the proposed KPG-RL model to the heterogeneous domain adaptation. Experiments verified the effectiveness of the KPG-RL model.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weak-shot Semantic Segmentation via Dual Similarity Transfer",
        "paper_url": "https://openreview.net/pdf?id=qSYVigfakqS",
        "paper_authors": [
            "Junjie Chen",
            "Li Niu",
            "Siyuan Zhou",
            "Jianlou Si",
            "Chen Qian",
            "Liqing Zhang"
        ],
        "paper_abstract": "Semantic segmentation is a practical and active task, but severely suffers from the expensive cost of pixel-level labels when extending to more classes in wider applications. To this end, we focus on the problem named weak-shot semantic segmentation, where the novel classes are learnt from cheaper image-level labels with the support of base classes having off-the-shelf pixel-level labels. To tackle this problem, we propose a dual similarity transfer framework, which is built upon MaskFormer to disentangle the semantic segmentation task into single-label classification and binary segmentation for each proposal. Specifically, the binary segmentation sub-task allows proposal-pixel similarity transfer from base classes to novel classes, which enables the mask learning of novel classes. We also learn pixel-pixel similarity from base classes and distill such class-agnostic semantic similarity to the semantic masks of novel classes, which regularizes the segmentation model with pixel-level semantic relationship across images. In addition, we propose a complementary loss to facilitate the learning of novel classes. Comprehensive experiments on the challenging COCO-Stuff-10K and ADE20K datasets demonstrate the effectiveness of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Generalizable Part-based Feature Representation for 3D Point Clouds",
        "paper_url": "https://openreview.net/pdf?id=V03mpOjCwtg",
        "paper_authors": [
            "Xin Wei",
            "Xiang Gu",
            "Jian Sun"
        ],
        "paper_abstract": "Deep networks on 3D point clouds have achieved remarkable success in 3D classification, while they are vulnerable to geometry variations caused by inconsistent data acquisition procedures. This results in a challenging 3D domain generalization (3DDG) problem, that is to generalize a model trained on source domain to an unseen target domain. Based on the observation that local geometric structures are more generalizable than the whole shape, we propose to reduce the geometry shift by a generalizable part-based feature representation and design a novel part-based domain generalization network (PDG) for 3D point cloud classification. Specifically, we build a part-template feature space shared by source and target domains. Shapes from distinct domains are first organized to part-level features and then represented by part-template features. The transformed part-level features, dubbed aligned part-based representations, are then aggregated by a part-based feature aggregation module. To improve the robustness of the part-based representations, we further propose a contrastive learning framework upon part-based shape representation. Experiments and ablation studies on 3DDA and 3DDG benchmarks justify the efficacy of the proposed approach for domain generalization, compared with the previous state-of-the-art methods. Our code will be available on http://github.com/weixmath/PDG.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Posterior Refinement Improves Sample Efficiency in Bayesian Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=Bv8GV6d76Sy",
        "paper_authors": [
            "Agustinus Kristiadi",
            "Runa Eschenhagen",
            "Philipp Hennig"
        ],
        "paper_abstract": "Monte Carlo (MC) integration is the _de facto_ method for approximating the predictive distribution of Bayesian neural networks (BNNs). But, even with many MC samples, Gaussian-based BNNs could still yield bad predictive performance due to the posterior approximation's error. Meanwhile, alternatives to MC integration are expensive. In this work, we experimentally show that the key to good MC-approximated predictive distributions is the quality of the approximate posterior itself. However, previous methods for obtaining accurate posterior approximations are expensive and non-trivial to implement. We, therefore, propose to refine Gaussian approximate posteriors with normalizing flows. When applied to last-layer BNNs, it yields a simple, cost-efficient, _post hoc_ method for improving pre-existing parametric approximations. We show that the resulting posterior approximation is competitive with even the gold-standard full-batch Hamiltonian Monte Carlo.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Training and Inference on Any-Order Autoregressive Models the Right Way",
        "paper_url": "https://openreview.net/pdf?id=VMU-hMsonit",
        "paper_authors": [
            "Andy Shih",
            "Dorsa Sadigh",
            "Stefano Ermon"
        ],
        "paper_abstract": "Conditional inference on arbitrary subsets of variables is a core problem in probabilistic inference with important applications such as masked language modeling and image inpainting. In recent years, the family of Any-Order Autoregressive Models (AO-ARMs) -- closely related to popular models such as BERT and XLNet -- has shown breakthrough performance in arbitrary conditional tasks across a sweeping range of domains. But, in spite of their success, in this paper we identify significant improvements to be made to previous formulations of AO-ARMs. First, we show that AO-ARMs suffer from redundancy in their probabilistic model, i.e., they define the same distribution in multiple different ways. We alleviate this redundancy by training on a smaller set of univariate conditionals that still maintains support for efficient arbitrary conditional inference. Second, we upweight the training loss for univariate conditionals that are evaluated more frequently during inference. Our method leads to improved performance with no compromises on tractability, giving state-of-the-art likelihoods in arbitrary conditional modeling on text (Text8), image (CIFAR10, ImageNet32), and continuous tabular data domains.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Versatile Multi-stage Graph Neural Network for Circuit Representation",
        "paper_url": "https://openreview.net/pdf?id=nax3ATLrovW",
        "paper_authors": [
            "Shuwen Yang",
            "Zhihao Yang",
            "Dong Li",
            "Yingxue Zhang",
            "Zhanguang Zhang",
            "Guojie Song",
            "Jianye HAO"
        ],
        "paper_abstract": "Due to the rapid growth in the scale of circuits and the desire for knowledge transfer from old designs to new ones, deep learning technologies have been widely exploited in Electronic Design Automation (EDA) to assist circuit design. In chip design cycles, we might encounter heterogeneous and diverse information sources, including the two most informative ones: the netlist and the design layout. However, handling each information source independently is sub-optimal. In this paper, we propose a novel way to integrate the multiple information sources under a unified heterogeneous graph named Circuit Graph, where topological and geometrical information is well integrated. Then, we propose Circuit GNN to fully utilize the features of vertices, edges as well as heterogeneous information during the message passing process. It is the first attempt to design a versatile circuit representation that is compatible across multiple EDA tasks and stages. Experiments on the two most representative prediction tasks in EDA show that our solution reaches state-of-the-art performance in both logic synthesis and global placement chip design stages. Besides, it achieves a 10x speed-up on congestion prediction compared to the state-of-the-art model.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "S$^3$-NeRF: Neural Reflectance Field from Shading and Shadow under a Single Viewpoint",
        "paper_url": "https://openreview.net/pdf?id=tvwkeAIcRP8",
        "paper_authors": [
            "Wenqi Yang",
            "Guanying Chen",
            "Chaofeng Chen",
            "Zhenfang Chen",
            "Kwan-Yee K. Wong"
        ],
        "paper_abstract": "In this paper, we address the \"dual problem\" of multi-view scene reconstruction in which we utilize single-view images captured under different point lights to learn a neural scene representation. Different from existing single-view methods which can only recover a 2.5D scene representation (i.e., a normal / depth map for the visible surface), our method learns a neural reflectance field to represent the 3D geometry and BRDFs of a scene. Instead of relying on multi-view photo-consistency, our method exploits two information-rich monocular cues, namely shading and shadow, to infer scene geometry. Experiments on multiple challenging datasets show that our method is capable of recovering 3D geometry, including both visible and invisible parts, of a scene from single-view images. Thanks to the neural reflectance field representation, our method is robust to depth discontinuities. It supports applications like novel-view synthesis and relighting. Our code and model can be found at https://ywq.github.io/s3nerf.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "High-dimensional Additive Gaussian Processes under Monotonicity Constraints",
        "paper_url": "https://openreview.net/pdf?id=YCPmfirAcc",
        "paper_authors": [
            "Andr\u00e9s F L\u00f3pez-Lopera",
            "Francois Bachoc",
            "Olivier Roustant"
        ],
        "paper_abstract": "We introduce an additive Gaussian process (GP) framework accounting for monotonicity constraints and scalable to high dimensions. Our contributions are threefold. First, we show that our framework enables to satisfy the constraints everywhere in the input space. We also show that more general componentwise linear inequality constraints can be handled similarly, such as componentwise convexity. Second, we propose the additive MaxMod algorithm for sequential dimension reduction. By sequentially maximizing a squared-norm criterion, MaxMod identifies the active input dimensions and refines the most important ones. This criterion can be computed explicitly at a linear cost. Finally, we provide open-source codes for our full framework. We demonstrate the performance and scalability of the methodology in several synthetic examples with hundreds of dimensions under monotonicity constraints as well as on a real-world flood application.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Enhanced Latent Space Blind Model for Real Image Denoising via Alternative Optimization",
        "paper_url": "https://openreview.net/pdf?id=Qt4rKNYzcO",
        "paper_authors": [
            "Chao Ren",
            "Yizhong Pan",
            "Jie Huang"
        ],
        "paper_abstract": "Motivated by the achievements in model-based methods and the advances in deep networks, we propose a novel enhanced latent space blind model based deep unfolding network, namely ScaoedNet, for complex real image denoising. It is derived by introducing latent space, noise information, and guidance constraint into the denoising cost function. A self-correction alternative optimization algorithm is proposed to split the novel cost function into three alternative subproblems, i.e., guidance representation (GR), degradation estimation (DE) and reconstruction (RE) subproblems. Finally, we implement the optimization process by a deep unfolding network consisting of GR, DE and RE networks. For higher performance of the DE network, a novel parameter-free noise feature adaptive enhancement (NFAE) layer is proposed. To synchronously and dynamically realize internal-external feature information mining in the RE network, a novel feature multi-modulation attention (FM2A) module is proposed. Our approach thereby leverages the advantages of deep learning, while also benefiting from the principled denoising provided by the classical model-based formulation. To the best of our knowledge, our enhanced latent space blind model, optimization scheme, NFAE and FM2A have not been reported in the previous literature. Experimental results show the promising performance of ScaoedNet on real image denoising. Code is available at https://github.com/chaoren88/ScaoedNet.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Equivariant Segmentation with Instance-Unique Querying",
        "paper_url": "https://openreview.net/pdf?id=q0XxMcbaZH9",
        "paper_authors": [
            "Wenguan Wang",
            "James Chenhao Liang",
            "Dongfang Liu"
        ],
        "paper_abstract": "Prevalent state-of-the-art instance segmentation methods fall into a query-based scheme, in which instance masks are derived by querying the image feature using a set of instance-aware embeddings. In this work, we devise a new training framework that boosts query-based models through discriminative query embedding learning. It explores two essential properties, namely dataset-level uniqueness and transformation equivariance, of the relation between queries and instances. First, our algorithm uses the queries to retrieve the corresponding instances from the whole training dataset, instead of only searching within individual scenes. As querying instances across scenes is more challenging, the segmenters are forced to learn more discriminative queries for effective instance separation. Second, our algorithm encourages both image (instance) representations and queries to be equivariant against geometric transformations, leading to more robust, instance-query matching. On top of four famous, query-based models (i.e., CondInst, SOLOv2, SOTR, and Mask2Former), our training algorithm provides significant performance gains (e.g., +1.6 \u2013 3.2 AP) on COCO dataset. In addition, our algorithm promotes the performance of SOLOv2 by 2.7 AP, on LVISv1 dataset.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Video-based Human-Object Interaction Detection from Tubelet Tokens",
        "paper_url": "https://openreview.net/pdf?id=kADW_LsENM",
        "paper_authors": [
            "Danyang Tu",
            "Wei Sun",
            "xiongkuo min",
            "Guangtao Zhai",
            "Wei Shen"
        ],
        "paper_abstract": "We present a novel vision Transformer, named TUTOR, which is able to learn tubelet tokens, served as highly-abstracted spatial-temporal representations, for video-based human-object interaction (V-HOI) detection. The tubelet tokens structurize videos by agglomerating and linking semantically-related patch tokens along spatial and temporal domains, which enjoy two benefits: 1) Compactness: each token is learned by a selective attention mechanism to reduce redundant dependencies from others; 2) Expressiveness: each token is enabled to align with a semantic instance, i.e., an object or a human, thanks to agglomeration and linking. The effectiveness and efficiency of TUTOR are verified by extensive experiments. Results show our method outperforms existing works by large margins, with a relative mAP gain of $16.14\\%$ on VidHOI and a 2 points gain on CAD-120 as well as a $4 \\times$ speedup.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Supervised Semantic Segmentation via Gentle Teaching Assistant",
        "paper_url": "https://openreview.net/pdf?id=r70ZpWKiCW",
        "paper_authors": [
            "Ying Jin",
            "Jiaqi Wang",
            "Dahua Lin"
        ],
        "paper_abstract": "Semi-Supervised Semantic Segmentation aims at training the segmentation model with limited labeled data and a large amount of unlabeled data. To effectively leverage the unlabeled data, pseudo labeling, along with the teacher-student framework, is widely adopted in semi-supervised semantic segmentation. Though proved to be effective, this paradigm suffers from incorrect pseudo labels which inevitably exist and are taken as auxiliary training data. To alleviate the negative impact of incorrect pseudo labels, we delve into the current Semi-Supervised Semantic Segmentation frameworks. We argue that the unlabeled data with pseudo labels can facilitate the learning of representative features in the feature extractor, but it is unreliable to supervise the mask predictor. Motivated by this consideration, we propose a novel framework, Gentle Teaching Assistant (GTA-Seg) to disentangle the effects of pseudo labels on feature extractor and mask predictor of the student model. Specifically, in addition to the original teacher-student framework, our method introduces a teaching assistant network which directly learns from pseudo labels generated by the teacher network. The gentle teaching assistant (GTA) is coined gentle since it only transfers the beneficial feature representation knowledge in the feature extractor to the student model in an Exponential Moving Average (EMA) manner, protecting the student model from the negative influences caused by unreliable pseudo labels in the mask predictor. The student model is also supervised by reliable labeled data to train an accurate mask predictor, further facilitating feature representation. Extensive experiment results on benchmark datasets validate that our method shows competitive performance against previous methods. We promise to release our code towards reproducibility. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Faster Stochastic Algorithms for Minimax Optimization under Polyak-{\\L}ojasiewicz Condition",
        "paper_url": "https://openreview.net/pdf?id=JSha3zfdmSo",
        "paper_authors": [
            "Lesi Chen",
            "Boyuan Yao",
            "Luo Luo"
        ],
        "paper_abstract": "This paper considers stochastic first-order algorithms for minimax optimization under Polyak-{\\L}ojasiewicz (PL) conditions. \nWe propose SPIDER-GDA for solving the finite-sum problem of the form $\\min_x \\max_y f(x,y)\\triangleq \\frac{1}{n} \\sum_{i=1}^n f_i(x,y)$, where the objective function $f(x,y)$ is $\\mu_x$-PL in $x$ and $\\mu_y$-PL in $y$; and each $f_i(x,y)$ is $L$-smooth. We prove SPIDER-GDA could find an $\\epsilon$-approximate solution within ${\\mathcal O}\\left((n + \\sqrt{n}\\,\\kappa_x\\kappa_y^2)\\log (1/\\epsilon)\\right)$ stochastic first-order oracle (SFO) complexity, which is better than the state-of-the-art method whose SFO upper bound is ${\\mathcal O}\\big((n + n^{2/3}\\kappa_x\\kappa_y^2)\\log (1/\\epsilon)\\big)$, where $\\kappa_x\\triangleq L/\\mu_x$ and $\\kappa_y\\triangleq L/\\mu_y$.\nFor the ill-conditioned case, we provide an accelerated algorithm to reduce the computational cost further. It achieves $\\tilde{{\\mathcal O}}\\big((n+\\sqrt{n}\\,\\kappa_x\\kappa_y)\\log^2 (1/\\epsilon)\\big)$ SFO upper bound when $\\kappa_x\\geq\\sqrt{n}$. Our ideas also can be applied to the more general setting that the objective function only satisfies PL condition for one variable. Numerical experiments validate the superiority of proposed methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Back Razor: Memory-Efficient Transfer Learning by Self-Sparsified Backpropagation",
        "paper_url": "https://openreview.net/pdf?id=mTXQIpXPDbh",
        "paper_authors": [
            "Ziyu Jiang",
            "Xuxi Chen",
            "Xueqin Huang",
            "Xianzhi Du",
            "Denny Zhou",
            "Zhangyang Wang"
        ],
        "paper_abstract": "Transfer learning from the model trained on large datasets to customized downstream tasks has been widely used as the pre-trained model can greatly boost the generalizability. However, the increasing sizes of pre-trained models also lead to a prohibitively large memory footprints for downstream transferring, making them unaffordable for personal devices. Previous work recognizes the bottleneck of the footprint to be the activation, and hence proposes various solutions such as injecting specific lite modules. In this work, we present a novel memory-efficient transfer framework called Back Razor, that can be plug-and-play applied to any pre-trained network without changing its architecture. The key idea of Back Razor is asymmetric sparsifying: pruning the activation stored for back-propagation, while keeping the forward activation dense. It is based on the observation that the stored activation, that dominates the memory footprint, is only needed for backpropagation. Such asymmetric pruning avoids affecting the precision of forward computation, thus making more aggressive pruning possible. Furthermore, we conduct the theoretical analysis for the convergence rate of Back Razor, showing that under mild conditions, our method retains the similar convergence rate as vanilla SGD. Extensive transfer learning experiments on both Convolutional Neural Networks and Vision Transformers with classification, dense prediction, and language modeling tasks show that Back Razor could yield up to 97% sparsity, saving 9.2x memory usage, without losing accuracy. The code is available at: https://github.com/VITA-Group/BackRazor_Neurips22.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DreamShard: Generalizable Embedding Table Placement for Recommender Systems",
        "paper_url": "https://openreview.net/pdf?id=_atSgd9Np52",
        "paper_authors": [
            "Daochen Zha",
            "Louis Feng",
            "Qiaoyu Tan",
            "Zirui Liu",
            "Kwei-Herng Lai",
            "Bhargav Bhushanam",
            "Yuandong Tian",
            "Arun Kejariwal",
            "Xia Hu"
        ],
        "paper_abstract": "We study embedding table placement for distributed recommender systems, which aims to partition and place the tables on multiple hardware devices (e.g., GPUs) to balance the computation and communication costs. Although prior work has explored learning-based approaches for the device placement of computational graphs, embedding table placement remains to be a challenging problem because of 1) the operation fusion of embedding tables, and 2) the generalizability requirement on unseen placement tasks with different numbers of tables and/or devices. To this end, we present DreamShard, a reinforcement learning (RL) approach for embedding table placement. DreamShard achieves the reasoning of operation fusion and generalizability with 1) a cost network to directly predict the costs of the fused operation, and 2) a policy network that is efficiently trained on an estimated Markov decision process (MDP) without real GPU execution, where the states and the rewards are estimated with the cost network. Equipped with sum and max representation reductions, the two networks can directly generalize to any unseen tasks with different numbers of tables and/or devices without fine-tuning. Extensive experiments show that DreamShard substantially outperforms the existing human expert and RNN-based strategies with up to 19% speedup over the strongest baseline on large-scale synthetic tables and our production tables. The code is available.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens in 3D Space",
        "paper_url": "https://openreview.net/pdf?id=YBsLfudKlBu",
        "paper_authors": [
            "Jinghuan Shang",
            "Srijan Das",
            "Michael S Ryoo"
        ],
        "paper_abstract": "Humans are remarkably flexible in understanding viewpoint changes due to visual cortex supporting the perception of 3D structure. In contrast, most of the computer vision models that learn visual representation from a pool of 2D images often fail to generalize over novel camera viewpoints. Recently, the vision architectures have shifted towards convolution-free architectures, visual Transformers, which operate on tokens derived from image patches. However, these Transformers do not perform explicit operations to learn viewpoint-agnostic representation for visual understanding. To this end, we propose a 3D Token Representation Layer (3DTRL) that estimates the 3D positional information of the visual tokens and leverages it for learning viewpoint-agnostic representations. The key elements of 3DTRL include a pseudo-depth estimator and a learned camera matrix to impose geometric transformations on the tokens, trained in an unsupervised fashion. These enable 3DTRL to recover the 3D positional information of the tokens from 2D patches. In practice, 3DTRL is easily plugged-in into a Transformer. Our experiments demonstrate the effectiveness of 3DTRL in many vision tasks including image classification, multi-view video alignment, and action recognition. The models with 3DTRL outperform their backbone Transformers in all the tasks with minimal added computation. Our code is available at https://github.com/elicassion/3DTRL.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?",
        "paper_url": "https://openreview.net/pdf?id=fVslVNBfjd8",
        "paper_authors": [
            "Xiang Li",
            "Jinghuan Shang",
            "Srijan Das",
            "Michael S Ryoo"
        ],
        "paper_abstract": "We investigate whether self-supervised learning (SSL) can improve online reinforcement learning (RL) from pixels. We extend the contrastive reinforcement learning framework (e.g., CURL) that jointly optimizes SSL and RL losses and conduct an extensive amount of experiments with various self-supervised losses. Our observations suggest that the existing SSL framework for RL fails to bring meaningful improvement over the baselines only taking advantage of image augmentation when the same amount of data and augmentation is used. We further perform evolutionary searches to find the optimal combination of multiple self-supervised losses for RL, but find that even such a loss combination fails to meaningfully outperform the methods that only utilize carefully designed image augmentations. After evaluating these approaches together in multiple different environments including a real-world robot environment, we confirm that no single self-supervised loss or image augmentation method can dominate all environments and that the current framework for joint optimization of SSL and RL is limited. Finally, we conduct the ablation study on multiple factors and demonstrate the properties of representations learned with different approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Masked Autoencoders that Listen",
        "paper_url": "https://openreview.net/pdf?id=MAMOi89bOL",
        "paper_authors": [
            "Po-Yao Huang",
            "Hu Xu",
            "Juncheng B Li",
            "Alexei Baevski",
            "Michael Auli",
            "Wojciech Galuba",
            "Florian Metze",
            "Christoph Feichtenhofer"
        ],
        "paper_abstract": "This paper studies a simple extension of image-based Masked Autoencoders (MAE) to self-supervised representation learning from audio spectrograms. Following the Transformer encoder-decoder design in MAE, our Audio-MAE first encodes audio spectrogram patches with a high masking ratio, feeding only the non-masked tokens through encoder layers. The decoder then re-orders and decodes the encoded context padded with mask tokens, in order to reconstruct the input spectrogram. We find it beneficial to incorporate local window attention in the decoder, as audio spectrograms are highly correlated in local time and frequency bands. We then fine-tune the encoder with a lower masking ratio on target datasets. Empirically, Audio-MAE sets new state-of-the-art performance on six audio and speech classification tasks, outperforming other recent models that use external supervised pre-training. Our code and models is available at https://github.com/facebookresearch/AudioMAE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MinVIS: A Minimal Video Instance Segmentation Framework without Video-based Training",
        "paper_url": "https://openreview.net/pdf?id=Ho_zIH4LA90",
        "paper_authors": [
            "De-An Huang",
            "Zhiding Yu",
            "Anima Anandkumar"
        ],
        "paper_abstract": "We propose MinVIS, a minimal video instance segmentation (VIS) framework that achieves state-of-the-art VIS performance with neither video-based architectures nor training procedures. By only training a query-based image instance segmentation model, MinVIS outperforms the previous best result on the challenging Occluded VIS dataset by over 10% AP. Since MinVIS treats frames in training videos as independent images, we can drastically sub-sample the annotated frames in training videos without any modifications. With only 1% of labeled frames, MinVIS outperforms or is comparable to fully-supervised state-of-the-art approaches on YouTube-VIS 2019/2021. Our key observation is that queries trained to be discriminative between intra-frame object instances are temporally consistent and can be used to track instances without any manually designed heuristics. MinVIS thus has the following inference pipeline: we first apply the trained query-based image instance segmentation to video frames independently. The segmented instances are then tracked by bipartite matching of the corresponding queries. This inference is done in an online fashion and does not need to process the whole video at once. MinVIS thus has the practical advantages of reducing both the labeling costs and the memory requirements, while not sacrificing the VIS performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Learning of Equivariant Structure from Sequences",
        "paper_url": "https://openreview.net/pdf?id=7b7iGkuVqlZ",
        "paper_authors": [
            "Takeru Miyato",
            "Masanori Koyama",
            "Kenji Fukumizu"
        ],
        "paper_abstract": "In this study, we present \\textit{meta-sequential prediction} (MSP), an unsupervised framework to learn the symmetry from the time sequence of length at least three. \nOur method leverages the stationary property~(e.g. constant velocity, constant acceleration) of the time sequence to learn the underlying equivariant structure of the dataset by simply training the encoder-decoder model to be able to predict the future observations. \nWe will demonstrate that, with our framework, the hidden disentangled structure of the dataset naturally emerges as a by-product by applying \\textit{simultaneous block-diagonalization} to the transition operators in the latent space, the procedure which is commonly used in representation theory to decompose the feature-space based on the type of response to group actions.\nWe will showcase our method from both empirical and theoretical perspectives.\nOur result suggests that finding a simple structured relation and learning a model with extrapolation capability are two sides of the same coin. The code is available at https://github.com/takerum/meta_sequential_prediction.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Conditional Randomization Test for Sparse Logistic Regression in High-Dimension",
        "paper_url": "https://openreview.net/pdf?id=HxZpawUrv9Q",
        "paper_authors": [
            "Binh Nguyen",
            "Bertrand Thirion",
            "Sylvain Arlot"
        ],
        "paper_abstract": "Identifying the relevant variables for a classification model with correct confidence levels is a central but difficult task in high-dimension. Despite the core role of sparse logistic regression in statistics and machine learning, it still lacks a good solution for accurate inference in the regime where the number of features $p$ is as large as or larger than the number of samples $n$. Here we tackle this problem by improving the Conditional Randomization Test (CRT). The original CRT algorithm shows promise as a way to output p-values while making few assumptions on the distribution of the test statistics. As it comes with a prohibitive computational cost even in mildly high-dimensional problems, faster solutions based on distillation have been proposed. Yet, they rely on unrealistic hypotheses and result in low-power solutions. To improve this, we propose \\emph{CRT-logit}, an algorithm that combines a variable-distillation step and a decorrelation step that takes into account the geometry of $\\ell_1$-penalized logistic regression problem. We provide a theoretical analysis of this procedure, and demonstrate its effectiveness on simulations, along with experiments on large-scale brain-imaging and genomics datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Inducing Neural Collapse in Imbalanced Learning: Do We Really Need a Learnable Classifier at the End of Deep Neural Network?",
        "paper_url": "https://openreview.net/pdf?id=A6EmxI3_Xc",
        "paper_authors": [
            "Yibo Yang",
            "Shixiang Chen",
            "Xiangtai Li",
            "Liang Xie",
            "Zhouchen Lin",
            "Dacheng Tao"
        ],
        "paper_abstract": "Modern deep neural networks for classification usually jointly learn a backbone for representation and a linear classifier to output the logit of each class. A recent study has shown a phenomenon called neural collapse that the within-class means of features and the classifier vectors converge to the vertices of a simplex equiangular tight frame (ETF) at the terminal phase of training on a balanced dataset. Since the ETF geometric structure maximally separates the pair-wise angles of all classes in the classifier, it is natural to raise the question, why do we spend an effort to learn a classifier when we know its optimal geometric structure? In this paper, we study the potential of learning a neural network for classification with the classifier randomly initialized as an ETF and fixed during training. Our analytical work based on the layer-peeled model indicates that the feature learning with a fixed ETF classifier naturally leads to the neural collapse state even when the dataset is imbalanced among classes. We further show that in this case the cross entropy (CE) loss is not necessary and can be replaced by a simple squared loss that shares the same global optimality but enjoys a better convergence property. Our experimental results show that our method is able to bring significant improvements with faster convergence on multiple imbalanced datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SegViT: Semantic Segmentation with Plain Vision Transformers",
        "paper_url": "https://openreview.net/pdf?id=4R7YrAGhnve",
        "paper_authors": [
            "Bowen Zhang",
            "Zhi Tian",
            "Quan Tang",
            "Xiangxiang Chu",
            "Xiaolin Wei",
            "Chunhua Shen",
            "Yifan liu"
        ],
        "paper_abstract": "We explore the capability of plain Vision Transformers (ViTs) for semantic segmentation and propose the SegViT. Previous ViT-based segmentation networks usually learn a pixel-level representation from the output of the ViT. Differently, we make use of the fundamental component\u2014attention mechanism, to generate masks for semantic segmentation. Specifically, we propose the Attention-to-Mask (ATM) module, in which the similarity maps between a set of learnable class tokens and the spatial feature maps are transferred to the segmentation masks. Experiments show that our proposed SegViT using the ATM module outperforms its counterparts using the plain ViT backbone on the ADE20K dataset and achieves new state-of-the-art performance on COCO-Stuff-10K and PASCAL-Context datasets. Furthermore, to reduce the computational cost of the ViT backbone, we propose query-based down-sampling (QD) and query-based up-sampling (QU) to build a Shrunk structure. With our Shrunk structure, the model can save up to 40% computations while maintaining competitive performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Making Sense of Dependence: Efficient Black-box Explanations Using Dependence Measure",
        "paper_url": "https://openreview.net/pdf?id=Vt3_mJNrjt",
        "paper_authors": [
            "Paul Novello",
            "Thomas FEL",
            "David Vigouroux"
        ],
        "paper_abstract": "This paper presents a new efficient black-box attribution method built on Hilbert-Schmidt Independence Criterion (HSIC). Based on Reproducing Kernel Hilbert Spaces (RKHS), HSIC measures the dependence between regions of an input image and the output of a model using the kernel embedding of their distributions. It thus provides explanations enriched by RKHS representation capabilities. HSIC can be estimated very efficiently, significantly reducing the computational cost compared to other black-box attribution methods.\nOur experiments show that HSIC is up to 8 times faster than the previous best black-box attribution methods while being as faithful.\nIndeed, we improve or match the state-of-the-art of both black-box and white-box attribution methods for several fidelity metrics on Imagenet with various recent model architectures.\nImportantly, we show that these advances can be transposed to efficiently and faithfully explain object detection models such as YOLOv4. \nFinally, we extend the traditional attribution methods by proposing a new kernel enabling an ANOVA-like orthogonal decomposition of importance scores based on HSIC, allowing us to evaluate not only the importance of each image patch but also the importance of their pairwise interactions. Our implementation is available at \\url{https://github.com/paulnovello/HSIC-Attribution-Method}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Causally motivated multi-shortcut identification and removal",
        "paper_url": "https://openreview.net/pdf?id=-ZQOx6yaVa-",
        "paper_authors": [
            "Jiayun Zheng",
            "Maggie Makar"
        ],
        "paper_abstract": "For predictive models to provide reliable guidance in decision making processes, they are often required to be accurate and robust to distribution shifts. Shortcut learning--where a model relies on spurious correlations or shortcuts to predict the target label--undermines the robustness property, leading to models with poor out-of-distribution accuracy despite good in-distribution performance. Existing work on shortcut learning either assumes that the set of possible shortcuts is known a priori or is discoverable using interpretability methods such as saliency maps, which might not always be true. Instead, we propose a two step approach to (1) efficiently identify relevant shortcuts, and (2) leverage the identified shortcuts to build models that are robust to distribution shifts. Our approach relies on having access to a (possibly) high dimensional set of auxiliary labels at training time, some of which correspond to possible shortcuts. We show both theoretically and empirically that our approach is able to identify a sufficient set of shortcuts leading to more efficient predictors in finite samples.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Geometry-aware Two-scale PIFu Representation for Human Reconstruction",
        "paper_url": "https://openreview.net/pdf?id=jtq4KwZ9_n9",
        "paper_authors": [
            "Zheng Dong",
            "Ke Xu",
            "Ziheng Duan",
            "Hujun Bao",
            "Weiwei Xu",
            "Rynson W. H. Lau"
        ],
        "paper_abstract": "Although PIFu-based 3D human reconstruction methods are popular, the quality of recovered details is still unsatisfactory. In a sparse (e.g., 3 RGBD sensors) capture setting, the depth noise is typically amplified in the PIFu representation, resulting in flat facial surfaces and geometry-fallible bodies. In this paper, we propose a novel geometry-aware two-scale PIFu for 3D human reconstruction from sparse, noisy inputs. Our key idea is to exploit the complementary properties of depth denoising and 3D reconstruction, for learning a two-scale PIFu representation to reconstruct high-frequency facial details and consistent bodies separately. To this end, we first formulate depth denoising and 3D reconstruction as a multi-task learning problem. The depth denoising process enriches the local geometry information of the reconstruction features, while the reconstruction process enhances depth denoising with global topology information. We then propose to learn the two-scale PIFu representation using two MLPs based on the denoised depth and geometry-aware features. Extensive experiments demonstrate the effectiveness of our approach in reconstructing facial details and bodies of different poses and its superiority over state-of-the-art methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Unified Analysis of Mixed Sample Data Augmentation: A Loss Function Perspective",
        "paper_url": "https://openreview.net/pdf?id=SLdfxFdIFeN",
        "paper_authors": [
            "Chanwoo Park",
            "Sangdoo Yun",
            "Sanghyuk Chun"
        ],
        "paper_abstract": "We propose the first unified theoretical analysis of mixed sample data augmentation (MSDA), such as Mixup and CutMix. Our theoretical results show that regardless of the choice of the mixing strategy, MSDA behaves as a pixel-level regularization of the underlying training loss and a regularization of the first layer parameters. Similarly, our theoretical results support that the MSDA training strategy can improve adversarial robustness and generalization compared to the vanilla training strategy. Using the theoretical results, we provide a high-level understanding of how different design choices of MSDA work differently. For example, we show that the most popular MSDA methods, Mixup and CutMix, behave differently, e.g., CutMix regularizes the input gradients by pixel distances, while Mixup regularizes the input gradients regardless of pixel distances. Our theoretical results also show that the optimal MSDA strategy depends on tasks, datasets, or model parameters. From these observations, we propose generalized MSDAs, a Hybrid version of Mixup and CutMix  (HMix) and Gaussian Mixup (GMix), simple extensions of Mixup and CutMix. Our implementation can leverage the advantages of Mixup and CutMix, while our implementation is very efficient, and the computation cost is almost neglectable as Mixup and CutMix. Our empirical study shows that our HMix and GMix outperform the previous state-of-the-art MSDA methods in CIFAR-100 and ImageNet classification tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Inception Transformer",
        "paper_url": "https://openreview.net/pdf?id=qf12cWVSksq",
        "paper_authors": [
            "Chenyang Si",
            "Weihao Yu",
            "Pan Zhou",
            "Yichen Zhou",
            "Xinchao Wang",
            "Shuicheng YAN"
        ],
        "paper_abstract": "Recent studies show that transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose $\\textit{Inception Transformer}$, or $\\textit{iFormer}$ for short, that effectively learns comprehensive features with both high- and low-frequency information in visual data. Specifically,  we design an Inception mixer to explicitly graft the advantages of convolution and max-pooling for capturing the high-frequency information to transformers. Different from recent hybrid frameworks, the Inception mixer brings greater efficiency through a channel splitting mechanism to adopt parallel convolution/max-pooling path and self-attention path as high- and low-frequency mixers, while having the flexibility to model discriminative information scattered within a wide frequency range. Considering that bottom layers play more roles in capturing high-frequency details while top layers more in modeling low-frequency global information, we further introduce a frequency ramp structure, i.e., gradually decreasing the dimensions fed to the high-frequency mixer and increasing those to the low-frequency mixer, which can effectively trade-off high- and low-frequency components across different layers. We benchmark the iFormer on a series of vision tasks, and showcase that it achieves impressive performance on  image classification, COCO detection and ADE20K segmentation. For example, our iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than DeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%) with only 1/4 parameters and 1/3 FLOPs. Code and models are released at https://github.com/sail-sg/iFormer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dataset Distillation via Factorization",
        "paper_url": "https://openreview.net/pdf?id=luGXvawYWJ",
        "paper_authors": [
            "Songhua Liu",
            "Kai Wang",
            "Xingyi Yang",
            "Jingwen Ye",
            "Xinchao Wang"
        ],
        "paper_abstract": "In this paper, we study dataset distillation (DD), from a novel perspective and introduce a \\emph{dataset factorization} approach, termed \\emph{HaBa}, which is a plug-and-play strategy portable to any existing DD baseline. Unlike conventional DD approaches that aim to produce distilled and representative samples, \\emph{HaBa} explores decomposing a dataset into two components: data \\emph{Ha}llucination networks and \\emph{Ba}ses, where the latter is fed into the former to reconstruct image samples. The flexible combinations between bases and hallucination networks, therefore, equip the distilled data with exponential informativeness gain, which largely increase the representation capability of distilled datasets. To furthermore increase the data efficiency of compression results, we further introduce a pair of adversarial contrastive \\xw{constraints} on the resultant hallucination networks and bases, which increase the diversity of generated images and inject more discriminant information into the factorization. Extensive comparisons and experiments demonstrate that our method can yield significant improvement on downstream classification tasks compared with previous state of the arts, while reducing the total number of compressed parameters by up to 65\\%. Moreover, distilled datasets by our approach also achieve \\textasciitilde10\\% higher accuracy than baseline methods in cross-architecture generalization. Our code is available \\href{https://github.com/Huage001/DatasetFactorization}{here}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Teach Less, Learn More: On the Undistillable Classes in Knowledge Distillation",
        "paper_url": "https://openreview.net/pdf?id=q6bZruC3dWJ",
        "paper_authors": [
            "Yichen Zhu",
            "Ning Liu",
            "Zhiyuan Xu",
            "Xin Liu",
            "Weibin Meng",
            "Louis Wang",
            "Zhicai Ou",
            "Jian Tang"
        ],
        "paper_abstract": "Knowledge distillation (KD) can effectively compress neural networks by training a smaller network (student) to simulate the behavior of a larger one (teacher). A counter-intuitive observation is that a more expansive teacher does not make a better student, but the reasons for this phenomenon remain unclear. In this paper, we demonstrate that this is directly attributed to the presence of  \\textit{undistillable classes}: when trained with distillation, the teacher's knowledge of some classes is incomprehensible to the student model. We observe that while KD improves the overall accuracy, it is at the cost of the model becoming inaccurate in these undistillable classes. After establishing their widespread existence in state-of-the-art distillation methods, we illustrate their correlation with the capacity gap between teacher and student models. Finally, we present a simple Teach Less Learn More (TLLM) framework to identify and discard the undistillable classes during training. We validate the effectiveness of our approach on multiple datasets with varying network architectures. In all settings, our proposed method is able to exceed the performance of competitive state-of-the-art techniques. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VITA: Video Instance Segmentation via Object Token Association",
        "paper_url": "https://openreview.net/pdf?id=xnuN2vGmZA0",
        "paper_authors": [
            "Miran Heo",
            "Sukjun Hwang",
            "Seoung Wug Oh",
            "Joon-Young Lee",
            "Seon Joo Kim"
        ],
        "paper_abstract": "We introduce a novel paradigm for offline Video Instance Segmentation (VIS), based on the hypothesis that explicit object-oriented information can be a strong clue for understanding the context of the entire sequence. To this end, we propose VITA, a simple structure built on top of an off-the-shelf Transformer-based image instance segmentation model. Specifically, we use an image object detector as a means of distilling object-specific contexts into object tokens. VITA accomplishes video-level understanding by associating frame-level object tokens without using spatio-temporal backbone features. By effectively building relationships between objects using the condensed information, VITA achieves the state-of-the-art on VIS benchmarks with a ResNet-50 backbone: 49.8 AP, 45.7 AP on YouTube-VIS 2019 & 2021, and 19.6 AP on OVIS. Moreover, thanks to its object token-based structure that is disjoint from the backbone features, VITA shows several practical advantages that previous offline VIS methods have not explored - handling long and high-resolution videos with a common GPU, and freezing a frame-level detector trained on image domain. Code is available at the link.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hilbert Distillation for Cross-Dimensionality Networks",
        "paper_url": "https://openreview.net/pdf?id=kZnGYt-3f_X",
        "paper_authors": [
            "Dian Qin",
            "Haishuai Wang",
            "Zhe Liu",
            "HONGJIA XU",
            "Sheng Zhou",
            "Jiajun Bu"
        ],
        "paper_abstract": "3D convolutional neural networks have revealed superior performance in processing volumetric data such as video and medical imaging. However, the competitive performance by leveraging 3D networks results in huge computational costs, which are far beyond that of 2D networks. In this paper, we propose a novel Hilbert curve-based cross-dimensionality distillation approach that facilitates the knowledge of 3D networks to improve the performance of 2D networks. The proposed Hilbert Distillation (HD) method preserves the structural information via the Hilbert curve, which maps high-dimensional (>=2) representations to one-dimensional continuous space-filling curves. Since the distilled 2D networks are supervised by the curves converted from dimensionally heterogeneous 3D features, the 2D networks are given an informative view in terms of learning structural information embedded in well-trained high-dimensional representations. We further propose a Variable-length Hilbert Distillation (VHD) method to dynamically shorten the walking stride of the Hilbert curve in activation feature areas and lengthen the stride in context feature areas, forcing the 2D networks to pay more attention to learning from activation features. The proposed algorithm outperforms the current state-of-the-art distillation techniques adapted to cross-dimensionality distillation on two classification tasks. Moreover, the distilled 2D networks by the proposed method achieve competitive performance with the original 3D networks, indicating the lightweight distilled 2D networks could potentially be the substitution of cumbersome 3D networks in the real-world scenario.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting",
        "paper_url": "https://openreview.net/pdf?id=ucNDIDRNjjv",
        "paper_authors": [
            "Yong Liu",
            "Haixu Wu",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "paper_abstract": "Transformers have shown great power in time series forecasting due to their global-range modeling ability. However, their performance can degenerate terribly on non-stationary real-world data in which the joint distribution changes over time. Previous studies primarily adopt stationarization to attenuate the non-stationarity of original series for better predictability. But the stationarized series deprived of inherent non-stationarity can be less instructive for real-world bursty events forecasting. This problem, termed over-stationarization in this paper, leads Transformers to generate indistinguishable temporal attentions for different series and impedes the predictive capability of deep models. To tackle the dilemma between series predictability and model capability, we propose Non-stationary Transformers as a generic framework with two interdependent modules: Series Stationarization and De-stationary Attention. Concretely, Series Stationarization unifies the statistics of each input and converts the output with restored statistics for better predictability. To address the over-stationarization problem, De-stationary Attention is devised to recover the intrinsic non-stationary information into temporal dependencies by approximating distinguishable attentions learned from raw series. Our Non-stationary Transformers framework consistently boosts mainstream Transformers by a large margin, which reduces MSE by 49.43% on Transformer, 47.34% on Informer, and 46.89% on Reformer, making them the state-of-the-art in time series forecasting. Code is available at this repository: https://github.com/thuml/Nonstationary_Transformers.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VCT: A Video Compression Transformer",
        "paper_url": "https://openreview.net/pdf?id=lme1MKnSMb",
        "paper_authors": [
            "Fabian Mentzer",
            "George Toderici",
            "David Minnen",
            "Sergi Caelles",
            "Sung Jin Hwang",
            "Mario Lucic",
            "Eirikur Agustsson"
        ],
        "paper_abstract": "We show how transformers can be used to vastly simplify neural video compression. Previous methods have been relying on an increasing number of architectural biases and priors, including motion prediction and warping operations, resulting in complex models. Instead, we independently map input frames to representations and use a transformer to model their dependencies, letting it predict the distribution of future representations given the past. The resulting video compression transformer outperforms previous methods on standard video compression data sets. Experiments on synthetic data show that our model learns to handle complex motion patterns such as panning, blurring and fading purely from data. Our approach is easy to implement, and we release code to facilitate future research.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pragmatically Learning from Pedagogical Demonstrations in Multi-Goal Environments",
        "paper_url": "https://openreview.net/pdf?id=sGugMYr3Hdy",
        "paper_authors": [
            "Hugo Caselles-Dupr\u00e9",
            "Olivier Sigaud",
            "Mohamed CHETOUANI"
        ],
        "paper_abstract": "Learning from demonstration methods usually leverage close to optimal demonstrations to accelerate training. By contrast, when demonstrating a task, human teachers deviate from optimal demonstrations and pedagogically modify their behavior by giving demonstrations that best disambiguate the goal they want to demonstrate. Analogously, human learners excel at pragmatically inferring the intent of the teacher, facilitating communication between the two agents. These mechanisms are critical in the few demonstrations regime, where inferring the goal is more difficult. In this paper, we implement pedagogy and pragmatism mechanisms by leveraging a Bayesian model of Goal Inference from demonstrations. We highlight the benefits of this model in multi-goal teacher-learner setups with two artificial agents that learn with goal-conditioned Reinforcement Learning. We show that combining BGI-agents (a pedagogical teacher and a pragmatic learner) results in faster learning and reduced goal ambiguity over standard learning from demonstrations, especially in the few demonstrations regime.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HUMANISE: Language-conditioned Human Motion Generation in 3D Scenes",
        "paper_url": "https://openreview.net/pdf?id=bntkx18xEb4",
        "paper_authors": [
            "Zan Wang",
            "Yixin Chen",
            "Tengyu Liu",
            "Yixin Zhu",
            "Wei Liang",
            "Siyuan Huang"
        ],
        "paper_abstract": "Learning to generate diverse scene-aware and goal-oriented human motions in 3D scenes remains challenging due to the mediocre characters of the existing datasets on Human-Scene Interaction (HSI); they only have limited scale/quality and lack semantics. To fill in the gap, we propose a large-scale and semantic-rich synthetic HSI dataset, denoted as HUMANISE, by aligning the captured human motion sequences with various 3D indoor scenes. We automatically annotate the aligned motions with language descriptions that depict the action and the individual interacting objects; e.g., sit on the armchair near the desk. HUMANIZE thus enables a new generation task, language-conditioned human motion generation in 3D scenes. The proposed task is challenging as it requires joint modeling of the 3D scene, human motion, and natural language. To tackle this task, we present a novel scene-and-language conditioned generative model that can produce 3D human motions of the desirable action interacting with the specified objects. Our experiments demonstrate that our model generates diverse and semantically consistent human motions in 3D scenes. \n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fully Convolutional One-Stage 3D Object Detection on LiDAR Range Images",
        "paper_url": "https://openreview.net/pdf?id=2-REuflJDT",
        "paper_authors": [
            "Zhi Tian",
            "Xiangxiang Chu",
            "Xiaoming Wang",
            "Xiaolin Wei",
            "Chunhua Shen"
        ],
        "paper_abstract": "We present a simple yet effective fully convolutional one-stage 3D object detector for LiDAR point clouds of autonomous driving scenes, termed FCOS-LiDAR. Unlike the dominant methods that use the bird-eye view (BEV), our proposed detector detects objects from the range view (RV, a.k.a. range image) of the LiDAR points. Due to the range view's compactness and compatibility with the LiDAR sensors' sampling process on self-driving cars, the range view-based object detector can be realized by solely exploiting the vanilla 2D convolutions, departing from the BEV-based methods which often involve complicated voxelization operations and sparse convolutions.\n  \nFor the first time, we show that an RV-based 3D detector with standard 2D convolutions alone can achieve comparable performance to state-of-the-art BEV-based detectors while being significantly faster and simpler. More importantly, almost all previous range view-based detectors only focus on single-frame point clouds since it is challenging to fuse multi-frame point clouds into a single range view. In this work, we tackle this challenging issue with a novel range view projection mechanism, and for the first time demonstrate the benefits of fusing multi-frame point clouds for a range-view based detector. Extensive experiments on nuScenes show the superiority of our proposed method and we believe that our work can be strong evidence that an RV-based 3D detector can compare favourably with the current mainstream BEV-based detectors. Code will be made publicly available.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GMMSeg: Gaussian Mixture based Generative Semantic Segmentation Models",
        "paper_url": "https://openreview.net/pdf?id=mMuVRbsvPyw",
        "paper_authors": [
            "Chen Liang",
            "Wenguan Wang",
            "Jiaxu Miao",
            "Yi Yang"
        ],
        "paper_abstract": "Prevalent semantic segmentation solutions are, in essence, a dense discriminative classifier of p(class|pixel feature). Though straightforward, this de facto paradigm neglects the underlying data distribution p(pixel feature|class), and struggles to identify out-of-distribution data. Going beyond this, we propose GMMSeg, a new family of segmentation models that rely on a dense generative classifier for the joint distribution p(pixel feature,class). For each class, GMMSeg builds Gaussian Mixture Models (GMMs) via Expectation-Maximization (EM), so as to capture class-conditional densities. Meanwhile, the deep dense representation is end-to-end trained in a discriminative manner, i.e., maximizing p(class|pixel feature). This endows GMMSeg with the strengths of both generative and discriminative models. With a variety of segmentation architectures and backbones, GMMSeg outperforms the discriminative counterparts on three closed-set datasets. More impressively, without any modification, GMMSeg even performs well on open-world datasets. We believe this work brings fundamental insights into the related fields.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Counterfactual Fairness with Partially Known Causal Graph",
        "paper_url": "https://openreview.net/pdf?id=9aLbntHz1Uq",
        "paper_authors": [
            "Aoqi Zuo",
            "Susan Wei",
            "Tongliang Liu",
            "Bo Han",
            "Kun Zhang",
            "Mingming Gong"
        ],
        "paper_abstract": "Fair machine learning aims to avoid treating individuals or sub-populations unfavourably based on \\textit{sensitive attributes}, such as gender and race. Those methods in fair machine learning that are built on causal inference ascertain discrimination and bias through causal effects. Though causality-based fair learning is attracting increasing attention, current methods assume the true causal graph is fully known. This paper proposes a general method to achieve the notion of counterfactual fairness when the true causal graph is unknown. To select features that lead to counterfactual fairness, we derive the conditions and algorithms to identify ancestral relations between variables on a \\textit{Partially Directed Acyclic Graph (PDAG)}, specifically, a class of causal DAGs that can be learned from observational data combined with domain knowledge. Interestingly, we find that counterfactual fairness can be achieved as if the true causal graph were fully known, when specific background knowledge is provided: the sensitive attributes do not have ancestors in the causal graph. Results on both simulated and real-world datasets demonstrate the effectiveness of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Distinct and Representative Modes for Image Captioning",
        "paper_url": "https://openreview.net/pdf?id=LMuh9bS4tqF",
        "paper_authors": [
            "Qi Chen",
            "Chaorui Deng",
            "Qi Wu"
        ],
        "paper_abstract": "Over the years, state-of-the-art (SoTA) image captioning methods have achieved promising results on some evaluation metrics (e.g., CIDEr). However, recent findings show that the captions generated by these methods tend to be biased toward the \"average\" caption that only captures the most general mode (a.k.a, language pattern) in the training corpus, i.e., the so-called mode collapse problem. Affected by it, the generated captions are limited in diversity and usually less informative than natural image descriptions made by humans. In this paper, we seek to avoid this problem by proposing a Discrete Mode Learning (DML) paradigm for image captioning. Our innovative idea is to explore the rich modes in the training caption corpus to learn a set of \"mode embeddings\", and further use them to control the mode of the generated captions for existing image captioning models. Specifically, the proposed DML optimizes a dual architecture that consists of an image-conditioned discrete variational autoencoder (CdVAE) branch and a mode-conditioned image captioning (MIC) branch. The CdVAE branch maps each image caption to one of the mode embeddings stored in a learned codebook, and is trained with a pure non-autoregressive generation objective to make the modes distinct and representative. The MIC branch can be simply modified from an existing image captioning model, where the mode embedding is added to the original word embeddings as the control signal. In the experiments, we apply the proposed DML to two widely used image captioning models, Transformer and AoANet. The results show that the learned mode embedding successfully facilitates these models to generate high-quality image captions with different modes, further leading to better performance for both diversity and quality on the MS COCO dataset.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Parameter-Efficient Masking Networks",
        "paper_url": "https://openreview.net/pdf?id=7rcuQ_V2GFg",
        "paper_authors": [
            "Yue Bai",
            "Huan Wang",
            "Xu Ma",
            "Yitian Zhang",
            "ZHIQIANG TAO",
            "Yun Fu"
        ],
        "paper_abstract": "A deeper network structure generally handles more complicated non-linearity and performs more competitively. Nowadays, advanced network designs often contain a large number of repetitive structures (e.g., Transformer). They empower the network capacity to a new level but also increase the model size inevitably, which is unfriendly to either model restoring or transferring. In this study, we are the first to investigate the representative potential of fixed random weights with limited unique values by learning diverse masks and introduce the Parameter-Efficient Masking Networks (PEMN). It also naturally leads to a new paradigm for model compression to diminish the model size. Concretely, motivated by the repetitive structures in modern neural networks, we utilize one random initialized layer, accompanied with different masks, to convey different feature mappings and represent repetitive network modules. Therefore, the model can be expressed as \\textit{one-layer} with a bunch of masks, which significantly reduce the model storage cost. Furthermore, we enhance our strategy by learning masks for a model filled by padding a given random weights vector. In this way, our method can further lower the space complexity, especially for models without many repetitive architectures. We validate the potential of PEMN learning masks on random weights with limited unique values and test its effectiveness for a new compression paradigm based on different network architectures.\nCode is available at \\href{https://github.com/yueb17/PEMN}{\\textcolor{magenta}{https://github.com/yueb17/PEMN}}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Look More but Care Less in Video Recognition",
        "paper_url": "https://openreview.net/pdf?id=owZdBnUiw2",
        "paper_authors": [
            "Yitian Zhang",
            "Yue Bai",
            "Huan Wang",
            "Yi Xu",
            "Yun Fu"
        ],
        "paper_abstract": "Existing action recognition methods typically sample a few frames to represent each video to avoid the enormous computation, which often limits the recognition performance. To tackle this problem, we propose Ample and Focal Network (AFNet), which is composed of two branches to utilize more frames but with less computation. Specifically, the Ample Branch takes all input frames to obtain abundant information with condensed computation and provides the guidance for Focal Branch by the proposed Navigation Module; the Focal Branch squeezes the temporal size to only focus on the salient frames at each convolution block; in the end, the results of two branches are adaptively fused to prevent the loss of information. With this design, we can introduce more frames to the network but cost less computation. Besides, we demonstrate AFNet can utilize less frames while achieving higher accuracy as the dynamic selection in intermediate features enforces implicit temporal modeling. Further, we show that our method can be extended to reduce spatial redundancy with even less cost. Extensive experiments on five datasets demonstrate the effectiveness and efficiency of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimistic Mirror Descent Either Converges to Nash or to Strong Coarse Correlated Equilibria in Bimatrix Games",
        "paper_url": "https://openreview.net/pdf?id=evRyKOjOx20",
        "paper_authors": [
            "Ioannis Anagnostides",
            "Gabriele Farina",
            "Ioannis Panageas",
            "Tuomas Sandholm"
        ],
        "paper_abstract": "We show that, for any sufficiently small fixed $\\epsilon > 0$, when both players in a general-sum two-player (bimatrix) game employ optimistic mirror descent (OMD) with smooth regularization, learning rate $\\eta = O(\\epsilon^2)$ and $T = \\Omega(poly(1/\\epsilon))$ repetitions, either the dynamics reach an $\\epsilon$-approximate Nash equilibrium (NE), or the average correlated distribution of play is an $\\Omega(poly(\\epsilon))$-strong coarse correlated equilibrium (CCE): any possible unilateral deviation does not only leave the player worse, but will decrease its utility by $\\Omega(poly(\\epsilon))$. As an immediate consequence, when the iterates of OMD are bounded away from being Nash equilibria in a bimatrix game, we guarantee convergence to an \\emph{exact} CCE after only $O(1)$ iterations. Our results reveal that uncoupled no-regret learning algorithms can converge to CCE in general-sum games remarkably faster than to NE in, for example, zero-sum games. To establish this, we show that when OMD does not reach arbitrarily close to a NE, the (cumulative) regret of both players is not only negative, but decays linearly with time. Given that regret is the canonical measure of performance in online learning, our results suggest that cycling behavior of no-regret learning algorithms in games can be justified in terms of efficiency.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deterministic Langevin Monte Carlo with Normalizing Flows for Bayesian Inference",
        "paper_url": "https://openreview.net/pdf?id=kEPAmGivMD",
        "paper_authors": [
            "Richard D.P. Grumitt",
            "Biwei Dai",
            "Uros Seljak"
        ],
        "paper_abstract": "We propose a general purpose Bayesian inference algorithm for expensive likelihoods, replacing the stochastic term in the Langevin equation with a deterministic density gradient term. The particle density is evaluated from the current particle positions using a Normalizing Flow (NF), which is differentiable and has good generalization properties in high dimensions. We take advantage of NF preconditioning and NF based Metropolis-Hastings updates for a faster convergence. We show on various examples that the method is competitive against state of the art sampling methods. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Uncoupled Learning Dynamics with $O(\\log T)$ Swap Regret in Multiplayer Games",
        "paper_url": "https://openreview.net/pdf?id=CZwh1XdAhNv",
        "paper_authors": [
            "Ioannis Anagnostides",
            "Gabriele Farina",
            "Christian Kroer",
            "Chung-Wei Lee",
            "Haipeng Luo",
            "Tuomas Sandholm"
        ],
        "paper_abstract": "In this paper we establish efficient and \\emph{uncoupled} learning dynamics so that, when employed by all players in a general-sum multiplayer game, the \\emph{swap regret} of each player after $T$ repetitions of the game is bounded by $O(\\log T)$, improving over the prior best bounds of $O(\\log^4 (T))$. At the same time, we guarantee optimal $O(\\sqrt{T})$ swap regret in the adversarial regime as well. To obtain these results, our primary contribution is to show that when all players follow our dynamics with a \\emph{time-invariant} learning rate, the \\emph{second-order path lengths} of the dynamics up to time $T$ are bounded by $O(\\log T)$, a fundamental property which could have further implications beyond near-optimally bounding the (swap) regret. Our proposed learning dynamics combine in a novel way \\emph{optimistic} regularized learning with the use of \\emph{self-concordant barriers}. Further, our analysis is remarkably simple, bypassing the cumbersome framework of higher-order smoothness recently developed by Daskalakis, Fishelson, and Golowich (NeurIPS'21).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos",
        "paper_url": "https://openreview.net/pdf?id=fT9W53lLxNS",
        "paper_authors": [
            "Gamaleldin Fathy Elsayed",
            "Aravindh Mahendran",
            "Sjoerd van Steenkiste",
            "Klaus Greff",
            "Michael Curtis Mozer",
            "Thomas Kipf"
        ],
        "paper_abstract": "The visual world can be parsimoniously characterized in terms of distinct entities with sparse interactions. Discovering this compositional structure in dynamic visual scenes has proven challenging for end-to-end computer vision approaches unless explicit instance-level supervision is provided. Slot-based models leveraging motion cues have recently shown great promise in learning to represent, segment, and track objects without direct supervision, but they still fail to scale to complex real-world multi-object videos. In an effort to bridge this gap, we take inspiration from human development and hypothesize that information about scene geometry in the form of depth signals can facilitate object-centric learning. We introduce SAVi++, an object-centric video model which is trained to predict depth signals from a slot-based video representation. By further leveraging best practices for model scaling, we are able to train SAVi++ to segment complex dynamic scenes recorded with moving cameras, containing both static and moving objects of diverse appearance on naturalistic backgrounds, without the need for segmentation supervision. Finally, we demonstrate that by using sparse depth signals obtained from LiDAR, SAVi++ is able to learn emergent object segmentation and tracking from videos in the real-world Waymo Open dataset.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "AutoLink: Self-supervised Learning of Human Skeletons and Object Outlines by Linking Keypoints",
        "paper_url": "https://openreview.net/pdf?id=mXP-qQcYCBN",
        "paper_authors": [
            "Xingzhe He",
            "Bastian Wandt",
            "Helge Rhodin"
        ],
        "paper_abstract": "Structured representations such as keypoints are widely used in pose transfer, conditional image generation, animation, and 3D reconstruction. However, their supervised learning requires expensive annotation for each target domain. We propose a self-supervised method that learns to disentangle object structure from the appearance with a graph of 2D keypoints linked by straight edges. Both the keypoint location and their pairwise edge weights are learned, given only a collection of images depicting the same object class. The resulting graph is interpretable, for example, AutoLink recovers the human skeleton topology when applied to images showing people. Our key ingredients are i) an encoder that predicts keypoint locations in an input image, ii) a shared graph as a latent variable that links the same pairs of keypoints in every image, iii) an intermediate edge map that combines the latent graph edge weights and keypoint locations in a soft, differentiable manner, and iv) an inpainting objective on randomly masked images. Although simpler, AutoLink outperforms existing self-supervised methods on the established keypoint and pose estimation benchmarks and paves the way for structure-conditioned generative models on more diverse datasets.  Project website: https://xingzhehe.github.io/autolink/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Video Diffusion Models",
        "paper_url": "https://openreview.net/pdf?id=f3zNgKga_ep",
        "paper_authors": [
            "Jonathan Ho",
            "Tim Salimans",
            "Alexey A. Gritsenko",
            "William Chan",
            "Mohammad Norouzi",
            "David J. Fleet"
        ],
        "paper_abstract": "Generating temporally coherent high fidelity video is an important milestone in generative modeling research. We make progress towards this milestone by proposing a diffusion model for video generation that shows very promising initial results. Our model is a natural extension of the standard image diffusion architecture, and it enables jointly training from image and video data, which we find to reduce the variance of minibatch gradients and speed up optimization. To generate long and higher resolution videos we introduce a new conditional sampling technique for spatial and temporal video extension that performs better than previously proposed methods. We present the first results on a large text-conditioned video generation task, as well as state-of-the-art results on established benchmarks for video prediction and unconditional video generation. Supplementary material is available at https://video-diffusion.github.io/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UDC: Unified DNAS for Compressible TinyML Models for Neural Processing Units",
        "paper_url": "https://openreview.net/pdf?id=ZJe-XahpyBf",
        "paper_authors": [
            "Igor Fedorov",
            "Ramon Matas",
            "Hokchhay Tann",
            "Chuteng Zhou",
            "Matthew Mattina",
            "Paul Whatmough"
        ],
        "paper_abstract": "Deploying TinyML models on low-cost IoT hardware is very challenging, due to limited device memory capacity. Neural processing unit (NPU) hardware address the memory challenge by using model compression to exploit weight quantization and sparsity to fit more parameters in the same footprint. However, designing compressible neural networks (NNs) is challenging, as it expands the design space across which we must make balanced trade-offs. This paper demonstrates Unified DNAS for Compressible (UDC) NNs, which explores a large search space to generate state-of-the-art compressible NNs for NPU. ImageNet results show UDC networks are up to 3.35x smaller (iso-accuracy) or 6.25% more accurate (iso-model size) than previous work.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Reasonable Budget Allocation in Untargeted Graph Structure Attacks via Gradient Debias",
        "paper_url": "https://openreview.net/pdf?id=vkGk2HI8oOP",
        "paper_authors": [
            "Zihan Liu",
            "Yun Luo",
            "Lirong Wu",
            "Zicheng Liu",
            "Stan Z. Li"
        ],
        "paper_abstract": "It has become cognitive inertia to employ cross-entropy loss function in classification related tasks. In the untargeted attacks on graph structure, the gradients derived from the attack objective are the attacker's basis for evaluating a perturbation scheme. Previous methods use negative cross-entropy loss as the attack objective in attacking node-level classification models. However, the suitability of the cross-entropy function for constructing the untargeted attack objective has yet been discussed in previous works. This paper argues about the previous unreasonable attack objective from the perspective of budget allocation. We demonstrate theoretically and empirically that negative cross-entropy tends to produce more significant gradients from nodes with lower confidence in the labeled classes, even if the predicted classes of these nodes have been misled. To free up these inefficient attack budgets, we propose a simple attack model for untargeted attacks on graph structure based on a novel attack objective which generates unweighted gradients on graph structures that are not affected by the node confidence. By conducting experiments in gray-box poisoning attack scenarios, we demonstrate that a reasonable budget allocation can significantly improve the effectiveness of gradient-based edge perturbations without any extra hyper-parameter.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Signal Recovery with Non-Expansive Generative Network Priors",
        "paper_url": "https://openreview.net/pdf?id=319xcX5qIcO",
        "paper_authors": [
            "Jorio Cocola"
        ],
        "paper_abstract": "We study compressive sensing with a deep generative network prior. Initial theoretical guarantees for efficient recovery from compressed linear measurements have been developed for signals in the range of a ReLU network with Gaussian weights and logarithmic expansivity: that is when each layer is larger than the previous one by a logarithmic factor. It was later shown that constant expansivity is sufficient for recovery. It has remained open whether the expansivity can be relaxed, allowing for networks with contractive layers (as often the case of real generators). In this work we answer this question, proving that a signal in the range of a Gaussian generative network can be recovered from few linear measurements provided that the width of the layers is proportional to the input layer size (up to log factors). This condition allows the generative network to have contractive layers. Our result is based on showing that Gaussian matrices satisfy a matrix concentration inequality which we term Range Restricted Weight Distribution Condition (R2WDC) and which weakens the Weight Distribution Condition (WDC) upon which previous theoretical guarantees were based. The WDC has also been used to analyze other signal recovery problems with generative network priors. By replacing the WDC with the R2WDC, we are able to extend previous results for signal recovery with expansive generative network priors to non-expansive ones. We discuss these extensions for phase retrieval, denoising, and spiked matrix recovery.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Spectral Approach to Item Response Theory",
        "paper_url": "https://openreview.net/pdf?id=1ItkxrZP0rg",
        "paper_authors": [
            "Duc Nguyen",
            "Anderson Ye Zhang"
        ],
        "paper_abstract": "The Rasch model is one of the most fundamental models in item response theory and has wide-ranging applications from education testing to recommendation systems. In a universe with $n$ users and $m$ items, the Rasch model assumes that the binary response $X_{li} \\in \\{0,1\\}$ of a user $l$ with parameter $\\theta^*_l$ to an item $i$ with parameter $\\beta^*_i$ (e.g., a user likes a movie, a student correctly solves a problem) is distributed as $\\mathbb{P}(X_{li}=1) = 1/(1 + \\exp(-(\\theta^*_l - \\beta^*_i)))$. In this paper, we propose a new item estimation algorithm for this celebrated model (i.e., to estimate $\\beta^*$). The core of our algorithm is the computation of the stationary distribution of a Markov chain defined on an item-item graph. We complement our algorithmic contributions with finite-sample error guarantees, the first of their kind in the literature, showing that our algorithm is consistent and enjoys favorable optimality properties. We discuss practical modifications to accelerate and robustify the algorithm that practitioners can adopt. Experiments on synthetic and real-life datasets, ranging from small education testing datasets to large recommendation systems datasets show that our algorithm is scalable, accurate, and competitive with the most commonly used methods in the literature.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Regret Bounds for Information-Directed Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=1pHC-yZfaTK",
        "paper_authors": [
            "Botao Hao",
            "Tor Lattimore"
        ],
        "paper_abstract": "Information-directed sampling (IDS) has revealed its potential as a data-efficient algorithm for reinforcement learning (RL). However, theoretical understanding of IDS for Markov Decision Processes (MDPs) is still limited. We develop novel information-theoretic tools to bound the information ratio and cumulative information gain about the learning target. Our theoretical results shed light on the importance of choosing the learning target such that the practitioners can balance the computation and regret bounds. As a consequence, we derive prior-free Bayesian regret bounds for vanilla-IDS which learns the whole environment under tabular finite-horizon MDPs. In addition, we propose a computationally-efficient regularized-IDS that maximizes an additive form rather than the ratio form and show that it enjoys the same regret bound as vanilla-IDS. With the aid of rate-distortion theory, we improve the regret bound by learning a surrogate, less informative environment. Furthermore, we extend our analysis to linear MDPs and prove similar regret bounds for Thompson sampling as a by-product.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TUSK: Task-Agnostic Unsupervised Keypoints",
        "paper_url": "https://openreview.net/pdf?id=VOPiHQUevh5",
        "paper_authors": [
            "Yuhe Jin",
            "Weiwei Sun",
            "Jan Hosang",
            "Eduard Trulls",
            "Kwang Moo Yi"
        ],
        "paper_abstract": "Existing unsupervised methods for keypoint learning rely heavily on the assumption that a specific keypoint type (e.g. elbow, digit, abstract geometric shape) appears only once in an image. This greatly limits their applicability, as each instance must be isolated before applying the method\u2014an issue that is never discussed or evaluated. We thus propose a novel method to learn Task-agnostic, UnSupervised Keypoints (TUSK) which can deal with multiple instances. To achieve this, instead of the commonly-used strategy of detecting multiple heatmaps, each dedicated to a specific keypoint type, we use a single heatmap for detection, and enable unsupervised learning of keypoint types through clustering. Specifically, we encode semantics into the keypoints by teaching them to reconstruct images from a sparse set of keypoints and their descriptors, where the descriptors are forced to form distinct clusters in feature space around learned prototypes. This makes our approach amenable to a wider range of tasks than any previous unsupervised keypoint method: we show experiments on multiple-instance detection and classification, object discovery, and landmark detection\u2014all unsupervised\u2014with performance on par with the state of the art, while also being able to deal with multiple instances.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semantic Diffusion Network for Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=mmzkqUKNVm",
        "paper_authors": [
            "Haoru Tan",
            "Sitong Wu",
            "Jimin Pi"
        ],
        "paper_abstract": "Precise and accurate predictions over boundary areas are essential for semantic segmentation. However, the commonly used convolutional operators tend to smooth and blur local detail cues, making it difficult for deep models to generate accurate boundary predictions. In this paper, we introduce an operator-level approach to enhance semantic boundary awareness, so as to improve the prediction of the deep semantic segmentation model. Specifically, we formulate the boundary feature enhancement process as an anisotropic diffusion process. \nWe propose a novel learnable approach called semantic diffusion network (SDN) for approximating the diffusion process, which contains a parameterized semantic difference convolution operator followed by a feature fusion module and constructs a differentiable mapping from original backbone features to advanced boundary-aware features. The proposed SDN is an efficient and flexible module that can be plugged into existing encoder-decoder segmentation models. Extensive experiments show that our approach can achieve consistent improvements over several typical state-of-the-art segmentation baseline models on challenging public benchmarks. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Social-Inverse: Inverse Decision-making of Social Contagion Management with Task Migrations",
        "paper_url": "https://openreview.net/pdf?id=q__FmUtPZd9",
        "paper_authors": [
            "Guangmo Tong"
        ],
        "paper_abstract": "Considering two decision-making tasks $A$ and $B$, each of which wishes to compute an effective decision $Y$ for a given query $X$, can we solve task $B$ by using query-decision pairs $(X, Y)$ of $A$ without knowing the latent decision-making model? Such problems, called inverse decision-making with task migrations, are of interest in that the complex and stochastic nature of real-world applications often prevents the agent from completely knowing the underlying system. In this paper, we introduce such a new problem with formal formulations and present a generic framework for addressing decision-making tasks in social contagion management. On the theory side, we present a generalization analysis for justifying the learning performance of our framework. In empirical studies, we perform a sanity check and compare the presented method with other possible learning-based and graph-based methods. We have acquired promising experimental results, confirming for the first time that it is possible to solve one decision-making task by using the solutions associated with another one.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fair and Optimal Decision Trees: A Dynamic Programming Approach",
        "paper_url": "https://openreview.net/pdf?id=LCIZmSw1DuE",
        "paper_authors": [
            "Jacobus G.M. van der Linden",
            "Mathijs Weerdt",
            "Emir Demirovi\u0107"
        ],
        "paper_abstract": "Interpretable and fair machine learning models are required for many applications, such as credit assessment and in criminal justice. Decision trees offer this interpretability, especially when they are small. Optimal decision trees are of particular interest because they offer the best performance possible for a given size. However, state-of-the-art algorithms for fair and optimal decision trees have scalability issues, often requiring several hours to find such trees even for small datasets. Previous research has shown that dynamic programming (DP) performs well for optimizing decision trees because it can exploit the tree structure. However, adding a global fairness constraint to a DP approach is not straightforward, because the global constraint violates the condition that subproblems should be independent. We show how such a constraint can be incorporated by introducing upper and lower bounds on final fairness values for partial solutions of subproblems, which enables early comparison and pruning. Our results show that our model can find fair and optimal trees several orders of magnitude faster than previous methods, and now also for larger datasets that were previously beyond reach. Moreover, we show that with this substantial improvement our method can find the full Pareto front in the trade-off between accuracy and fairness.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Instance-Based Uncertainty Estimation for Gradient-Boosted Regression Trees",
        "paper_url": "https://openreview.net/pdf?id=v6CqBssIwYw",
        "paper_authors": [
            "Jonathan Brophy",
            "Daniel Lowd"
        ],
        "paper_abstract": "Gradient-boosted regression trees (GBRTs) are hugely popular for solving tabular regression problems, but provide no estimate of uncertainty. We propose Instance-Based Uncertainty estimation for Gradient-boosted regression trees (IBUG), a simple method for extending any GBRT point predictor to produce probabilistic predictions. IBUG computes a non-parametric distribution around a prediction using the $k$-nearest training instances, where distance is measured with a tree-ensemble kernel. The runtime of IBUG depends on the number of training examples at each leaf in the ensemble, and can be improved by sampling trees or training instances. Empirically, we find that IBUG achieves similar or better performance than the previous state-of-the-art across 22 benchmark regression datasets. We also find that IBUG can achieve improved probabilistic performance by using different base GBRT models, and can more flexibly model the posterior distribution of a prediction than competing methods. We also find that previous methods suffer from poor probabilistic calibration on some datasets, which can be mitigated using a scalar factor tuned on the validation data. Source code is available at https://github.com/jjbrophy47/ibug.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Counterfactual harm",
        "paper_url": "https://openreview.net/pdf?id=zkQho-Jxky9",
        "paper_authors": [
            "Jonathan Richens",
            "Rory Beard",
            "Daniel H. Thompson"
        ],
        "paper_abstract": "To act safely and ethically in the real world, agents must be able to reason about harm and avoid harmful actions. However, to date there is no statistical method for measuring harm and factoring it into algorithmic decisions. In this paper we propose the first formal definition of harm and benefit using causal models. We show that any factual definition of harm is incapable of identifying harmful actions in certain scenarios, and show that standard machine learning algorithms that cannot perform counterfactual reasoning are guaranteed to pursue harmful policies following distributional shifts. We use our definition of harm to devise a framework for harm-averse decision making using counterfactual objective functions. We demonstrate this framework on the problem of identifying optimal drug doses using a dose-response model learned from randomised control trial data. We find that the standard method of selecting doses using treatment effects results in unnecessarily harmful doses, while our counterfactual approach identifies doses that are significantly less harmful without sacrificing efficacy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hand-Object Interaction Image Generation",
        "paper_url": "https://openreview.net/pdf?id=DDEwoD608_l",
        "paper_authors": [
            "Hezhen Hu",
            "Weilun Wang",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "paper_abstract": "In this work, we are dedicated to a new task, i.e., hand-object interaction image generation, which aims to conditionally generate the hand-object image under the given hand, object and their interaction status. This task is challenging and research-worthy in many potential application scenarios, such as AR/VR games and online shopping, etc. To address this problem, we propose a novel HOGAN framework, which utilizes the expressive model-aware hand-object representation and leverages its inherent topology to build the unified surface space. In this space, we explicitly consider the complex self- and mutual occlusion during interaction. During final image synthesis, we consider different characteristics of hand and object and generate the target image in a split-and-combine manner. For evaluation, we build a comprehensive protocol to access both the fidelity and structure preservation of the generated image. Extensive experiments on two large-scale datasets, i.e., HO3Dv3 and DexYCB, demonstrate the effectiveness and superiority of our framework both quantitatively and qualitatively. The code will be available at https://github.com/play-with-HOI-generation/HOIG.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Predicting Label Distribution from Multi-label Ranking",
        "paper_url": "https://openreview.net/pdf?id=8wtaJ9dE9Y2",
        "paper_authors": [
            "Yunan Lu",
            "Xiuyi Jia"
        ],
        "paper_abstract": "Label distribution can provide richer information about label polysemy than logical labels in multi-label learning. There are currently two strategies including LDL (label distribution learning) and LE (label enhancement) to predict label distributions. LDL requires experts to annotate instances with label distributions and learn a predictive mapping on such a training set. LE requires experts to annotate instances with logical labels and generates label distributions from them. However, LDL requires costly annotation, and the performance of the LE is unstable. In this paper, we study the problem of predicting label distribution from multi-label ranking which is a compromise w.r.t. annotation cost but has good guarantees for performance. On the one hand, we theoretically investigate the relation between multi-label ranking and label distribution. We define the notion of EAE (expected approximation error) to quantify the quality of an annotation, give the bounds of EAE for multi-label ranking, and derive the optimal range of label distribution corresponding to a particular multi-label ranking. On the other hand, we propose a framework of label distribution predicting from multi-label ranking via conditional Dirichlet mixtures. This framework integrates the processes of recovering and learning label distributions end-to-end and allows us to easily encode our knowledge about current tasks by a scoring function. Finally, we implement extensive experiments to validate our proposal.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Best Combination for Efficient N:M Sparsity",
        "paper_url": "https://openreview.net/pdf?id=tbdk6XLYmZj",
        "paper_authors": [
            "Yuxin Zhang",
            "Mingbao Lin",
            "ZhiHang Lin",
            "Yiting Luo",
            "Ke Li",
            "Fei Chao",
            "YONGJIAN WU",
            "Rongrong Ji"
        ],
        "paper_abstract": "By forcing N out of M consecutive weights to be non-zero, the recent N:M fine-grained network sparsity has received increasing attention with its two attractive advantages over traditional irregular network sparsity methods: 1) Promising performance at a high sparsity. 2) Significant speedups when performed on NVIDIA A100 GPUs. Current implementation on N:M sparsity requires a tedious pre-training phase or computationally heavy from-scratch training. To circumvent these problems, this paper presents an efficient solution for achieving N:M fine-grained sparsity from scratch. Specifically, we first make a re-formulation to convert the N:M fine-grained sparsity into a combinatorial problem, in which, the object falls into choosing the best weight combination among $C_M^N$ candidates. Then, we equip each combination with a learnable importance score, which can be jointly optimized along with its associated weights. Through rigorous proof, we demonstrate that the magnitude of the optimized score well reflects the importance of its corresponding weights combination to the training loss. Therefore, by gradually removing combinations with smaller scores till the best one is left, N:M fine-grained sparsity can be efficiently optimized during the normal training phase without any extra expenditure. Comprehensive experimental results have demonstrated that our proposed method for learning best combination, dubbed as LBC, consistently increases the efficacy of the off-the-shelf N:M methods across varying networks and datasets. Our project is released at https://github.com/zyxxmu/LBC.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation",
        "paper_url": "https://openreview.net/pdf?id=6H2pBoPtm0s",
        "paper_authors": [
            "Yufei Xu",
            "Jing Zhang",
            "Qiming Zhang",
            "Dacheng Tao"
        ],
        "paper_abstract": "Although no specific domain knowledge is considered in the design, plain vision transformers have shown excellent performance in visual recognition tasks. However, little effort has been made to reveal the potential of such simple structures for pose estimation tasks. In this paper, we show the surprisingly good capabilities of plain vision transformers for pose estimation from various aspects, namely simplicity in model structure, scalability in model size, flexibility in training paradigm, and transferability of knowledge between models, through a simple baseline model called ViTPose. Specifically, ViTPose employs plain and non-hierarchical vision transformers as backbones to extract features for a given person instance and a lightweight decoder for pose estimation. It can be scaled up from 100M to 1B parameters by taking the advantages of the scalable model capacity and high parallelism of transformers, setting a new Pareto front between throughput and performance. Besides, ViTPose is very flexible regarding the attention type, input resolution, pre-training and finetuning strategy, as well as dealing with multiple pose tasks. We also empirically demonstrate that the knowledge of large ViTPose models can be easily transferred to small ones via a simple knowledge token. Experimental results show that our basic ViTPose model outperforms representative methods on the challenging MS COCO Keypoint Detection benchmark, while the largest model sets a new state-of-the-art. The code and models are available at https://github.com/ViTAE-Transformer/ViTPose.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Saliency-Aware Neural Architecture Search",
        "paper_url": "https://openreview.net/pdf?id=Ho6oWAslz5L",
        "paper_authors": [
            "Ramtin Hosseini",
            "Pengtao Xie"
        ],
        "paper_abstract": "Recently a wide variety of NAS methods have been proposed and achieved considerable success in automatically identifying highly-performing architectures of neural networks for the sake of reducing the reliance on human experts. Existing NAS methods ignore the fact that different input data elements (e.g., image pixels) have different importance (or saliency) in determining the prediction outcome. They treat all data elements as being equally important and therefore lead to suboptimal performance. To address this problem, we propose an end-to-end framework which dynamically detects saliency of input data, reweights data using saliency maps, and searches  architectures on saliency-reweighted data. Our framework is based on four-level optimization, which performs four learning stages in a unified way. At the first stage, a model is trained with its architecture tentatively fixed. At the second stage, saliency maps are generated using the trained model. At the third stage, the model is retrained on saliency-reweighted data. At the fourth stage, the model is evaluated on a validation set and the architecture is updated by minimizing the validation loss. Experiments on several datasets demonstrate the effectiveness of our framework.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NeurOLight: A Physics-Agnostic Neural Operator Enabling Parametric Photonic Device Simulation",
        "paper_url": "https://openreview.net/pdf?id=Il0ymeSnKyL",
        "paper_authors": [
            "Jiaqi Gu",
            "Zhengqi Gao",
            "Chenghao Feng",
            "Hanqing Zhu",
            "Ray Chen",
            "Duane S Boning",
            "David Z. Pan"
        ],
        "paper_abstract": "Optical computing has become emerging technology in next-generation efficient artificial intelligence (AI) due to its ultra-high speed and efficiency. Electromagnetic field simulation is critical to the design, optimization, and validation of photonic devices and circuits.\nHowever, costly numerical simulation significantly hinders the scalability and turn-around time in the photonic circuit design loop. Recently, physics-informed neural networks were proposed to predict the optical field solution of a single instance of a partial differential equation (PDE) with predefined parameters. Their complicated PDE formulation and lack of efficient parametrization mechanism limit their flexibility and generalization in practical simulation scenarios. In this work, for the first time, a physics-agnostic neural operator-based framework, dubbed NeurOLight, is proposed to learn a family of frequency-domain Maxwell PDEs for ultra-fast parametric photonic device simulation. Specifically, we discretize different devices into a unified domain, represent parametric PDEs with a compact wave prior, and encode the incident light via masked source modeling. We design our model to have parameter-efficient cross-shaped NeurOLight blocks and adopt superposition-based augmentation for data-efficient learning. With those synergistic approaches, NeurOLight demonstrates 2-orders-of-magnitude faster simulation speed than numerical solvers and outperforms prior NN-based models by ~54% lower prediction error using ~44% fewer parameters.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields",
        "paper_url": "https://openreview.net/pdf?id=Qq-ge2k8uml",
        "paper_authors": [
            "Keqiang Sun",
            "Shangzhe Wu",
            "Zhaoyang Huang",
            "Ning Zhang",
            "Quan Wang",
            "Hongsheng Li"
        ],
        "paper_abstract": "Capitalizing on the recent advances in image generation models, existing controllable face image synthesis methods are able to generate high-fidelity images with some levels of controllability, e.g., controlling the shapes, expressions, textures, and poses of the generated face images. However, these methods focus on 2D image generative models, which are prone to producing inconsistent face images under large expression and pose changes. In this paper, we propose a new NeRF-based conditional 3D face synthesis framework, which enables 3D controllability over the generated face images by imposing explicit 3D conditions from 3D face priors. At its core is a conditional Generative Occupancy Field (cGOF) that effectively enforces the shape of the generated face to commit to a given 3D Morphable Model (3DMM) mesh. To achieve accurate control over fine-grained 3D face shapes of the synthesized image, we additionally incorporate a 3D landmark loss as well as a volume warping loss into our synthesis algorithm. Experiments validate the effectiveness of the proposed method, which is able to generate high-fidelity face images and shows more precise 3D controllability than state-of-the-art 2D-based controllable face synthesis methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Robustness of Deep Clustering Models: Adversarial Attacks and Defenses",
        "paper_url": "https://openreview.net/pdf?id=p62j5eqi_g2",
        "paper_authors": [
            "Anshuman Chhabra",
            "Ashwin Sekhari",
            "Prasant Mohapatra"
        ],
        "paper_abstract": "Clustering models constitute a class of unsupervised machine learning methods which are used in a number of application pipelines, and play a vital role in modern data science. With recent advancements in deep learning-- deep clustering models have emerged as the current state-of-the-art over traditional clustering approaches, especially for high-dimensional image datasets. While traditional clustering approaches have been analyzed from a robustness perspective, no prior work has investigated adversarial attacks and robustness for deep clustering models in a principled manner. To bridge this gap, we propose a blackbox attack using Generative Adversarial Networks (GANs) where the adversary does not know which deep clustering model is being used, but can query it for outputs. We analyze our attack against multiple state-of-the-art deep clustering models and real-world datasets, and find that it is highly successful. We then employ some natural unsupervised defense approaches, but find that these are unable to mitigate our attack. Finally, we attack Face++, a production-level face clustering API service, and find that we can significantly reduce its performance as well. Through this work, we thus aim to motivate the need for truly robust deep clustering models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Blackbox Attacks via Surrogate Ensemble Search",
        "paper_url": "https://openreview.net/pdf?id=lSfrwyww-FR",
        "paper_authors": [
            "Zikui Cai",
            "Chengyu Song",
            "Srikanth Krishnamurthy",
            "Amit Roy-Chowdhury",
            "M. Salman Asif"
        ],
        "paper_abstract": "Blackbox adversarial attacks can be categorized into  transfer- and query-based attacks. Transfer methods do not require any feedback from the victim model, but provide lower success rates compared to query-based methods. Query attacks often require a large number of queries for success. To achieve the best of both approaches, recent efforts have  tried to combine them, but still require hundreds of queries to achieve high success rates (especially for targeted attacks). In this paper, we propose a novel method for Blackbox Attacks via Surrogate Ensemble Search (BASES) that can generate highly successful blackbox attacks using an extremely small number of queries. We first define a perturbation machine that generates a perturbed image by minimizing a weighted loss function over a fixed set of surrogate models. To generate an attack for a given victim model, we search over the weights in the loss function using queries generated by the perturbation machine. Since the dimension of the search space is small (same as the number of surrogate models), the search requires a small number of queries. We demonstrate that our proposed method achieves better success rate with at least $30\\times$ fewer queries compared to state-of-the-art methods on different image classifiers trained with  ImageNet (including VGG-19, DenseNet-121, and ResNext-50). In particular, our method requires as few as 3 queries per image (on average) to achieve more than a $90\\%$ success rate for targeted attacks and 1--2 queries per image for over a $99\\%$ success rate for untargeted attacks. Our method is also effective on Google Cloud Vision API and achieved a $91\\%$ untargeted attack success rate with 2.9 queries per image. We also show that the perturbations generated by our proposed method are highly transferable and can be adopted for hard-label blackbox attacks. Furthermore, we argue that BASES can be used to create attacks for a variety of tasks and show its effectiveness for attacks on object detection models. Our code is available at https://github.com/CSIPlab/BASES.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Inverse Game Theory for Stackelberg Games: the Blessing of Bounded Rationality",
        "paper_url": "https://openreview.net/pdf?id=ymAsTHhrnGm",
        "paper_authors": [
            "Jibang Wu",
            "Weiran Shen",
            "Fei Fang",
            "Haifeng Xu"
        ],
        "paper_abstract": "Optimizing strategic decisions (a.k.a. computing equilibrium) is key to the success of many non-cooperative multi-agent applications. However, in many real-world situations, we may face the exact opposite of this game-theoretic problem --- instead of prescribing equilibrium of a given game, we may directly observe the agents' equilibrium behaviors but want to infer the underlying parameters of an unknown game. This research question, also known as inverse game theory, has been studied in multiple recent works in the context of Stackelberg games. Unfortunately, existing works exhibit quite negative results, showing statistical hardness and computational hardness, assuming follower's perfectly rational behaviors. Our work relaxes the perfect rationality agent assumption to the classic quantal response model, a more realistic behavior model of bounded rationality. Interestingly, we show that the smooth property brought by such bounded rationality model actually leads to provably more efficient learning of the follower utility parameters in general Stackelberg games. Systematic empirical experiments on synthesized games confirm our theoretical results and further suggest its robustness beyond the strict quantal response model.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Semi-Discrete Normalizing Flows through Differentiable Tessellation",
        "paper_url": "https://openreview.net/pdf?id=NMTSIY6ykw7",
        "paper_authors": [
            "Ricky T. Q. Chen",
            "Brandon Amos",
            "Maximilian Nickel"
        ],
        "paper_abstract": "Mapping between discrete and continuous distributions is a difficult task and many have had to resort to heuristical approaches. We propose a tessellation-based approach that directly learns quantization boundaries in a continuous space, complete with exact likelihood evaluations. This is done through constructing normalizing flows on convex polytopes parameterized using a simple homeomorphism with an efficient log determinant Jacobian. We explore this approach in two application settings, mapping from discrete to continuous and vice versa. Firstly, a Voronoi dequantization allows automatically learning quantization boundaries in a multidimensional space. The location of boundaries and distances between regions can encode useful structural relations between the quantized discrete values. Secondly, a Voronoi mixture model has near-constant computation cost for likelihood evaluation regardless of the number of mixture components. Empirically, we show improvements over existing methods across a range of structured data modalities.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trajectory of Mini-Batch Momentum: Batch Size Saturation and Convergence in High Dimensions",
        "paper_url": "https://openreview.net/pdf?id=z9poo2GhOh6",
        "paper_authors": [
            "Kiwon Lee",
            "Andrew Nicholas Cheng",
            "Elliot Paquette",
            "Courtney Paquette"
        ],
        "paper_abstract": "We analyze the dynamics of large batch stochastic gradient descent with momentum (SGD+M) on the least squares problem when both the number of samples and dimensions are large. In this setting, we show that the dynamics of SGD+M converge to a deterministic discrete Volterra equation as dimension increases, which we analyze.  We identify a stability measurement, the implicit conditioning ratio (ICR), which regulates the ability of SGD+M to accelerate the algorithm.  When the batch size exceeds this ICR, SGD+M converges linearly at a rate of $\\mathcal{O}(1/\\sqrt{\\kappa})$, matching optimal full-batch momentum (in particular performing as well as a full-batch but with a fraction of the size).  For batch sizes smaller than the ICR, in contrast, SGD+M has rates that scale like a multiple of the single batch SGD rate. We give explicit choices for the learning rate and momentum parameter in terms of the Hessian spectra that achieve this performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Closer Look at Weakly-Supervised Audio-Visual Source Localization",
        "paper_url": "https://openreview.net/pdf?id=pn5trhFskOt",
        "paper_authors": [
            "Shentong Mo",
            "Pedro Morgado"
        ],
        "paper_abstract": "Audio-visual source localization is a challenging task that aims to predict the location of visual sound sources in a video. Since collecting ground-truth annotations of sounding objects can be costly, a plethora of weakly-supervised localization methods that can learn from datasets with no bounding-box annotations have been proposed in recent years, by leveraging the natural co-occurrence of audio and visual signals. Despite significant interest, popular evaluation protocols have two major flaws. First, they allow for the use of a fully annotated dataset to perform early stopping, thus significantly increasing the annotation effort required for training. Second, current evaluation metrics assume the presence of sound sources at all times. This is of course an unrealistic assumption, and thus better metrics are necessary to capture the model's performance on (negative) samples with no visible sound sources. To accomplish this, we extend the test set of popular benchmarks, Flickr SoundNet and VGG-Sound Sources, in order to include negative samples, and measure performance using metrics that balance localization accuracy and recall. Using the new protocol, we conducted an extensive evaluation of prior methods, and found that most prior works are not capable of identifying negatives and suffer from significant overfitting problems (rely heavily on early stopping for best results). We also propose a new approach for visual sound source localization that addresses both these problems. In particular, we found that, through extreme visual dropout and the use of momentum encoders, the proposed approach combats overfitting effectively, and establishes a new state-of-the-art performance on both Flickr SoundNet and VGG-Sound Source. Code and pre-trained models are available at https://github.com/stoneMo/SLAVC.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Policy-Guided Imitation Approach for Offline Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=CKbqDtZnSc",
        "paper_authors": [
            "Haoran Xu",
            "Li Jiang",
            "Jianxiong Li",
            "Xianyuan Zhan"
        ],
        "paper_abstract": "Offline reinforcement learning (RL) methods can generally be categorized into two types: RL-based and Imitation-based. RL-based methods could in principle enjoy out-of-distribution generalization but suffer from erroneous off-policy evaluation. Imitation-based methods avoid off-policy evaluation but are too conservative to surpass the dataset. In this study, we propose an alternative approach, inheriting the training stability of imitation-style methods while still allowing logical out-of-distribution generalization. We decompose the conventional reward-maximizing policy in offline RL into a guide-policy and an execute-policy. During training, the guide-poicy and execute-policy are learned using only data from the dataset, in a supervised and decoupled manner. During evaluation, the guide-policy guides the execute-policy by telling where it should go so that the reward can be maximized, serving as the \\textit{Prophet}. By doing so, our algorithm allows \\textit{state-compositionality} from the dataset, rather than \\textit{action-compositionality} conducted in prior imitation-style methods. We dumb this new approach Policy-guided Offline RL (\\texttt{POR}). \\texttt{POR} demonstrates the state-of-the-art performance on D4RL, a standard benchmark for offline RL. We also highlight the benefits of \\texttt{POR} in terms of improving with supplementary suboptimal data and easily adapting to new tasks by only changing the guide-poicy.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Posterior Collapse of a Linear Latent Variable Model",
        "paper_url": "https://openreview.net/pdf?id=zAc2a6_0aHb",
        "paper_authors": [
            "Zihao Wang",
            "Liu Ziyin"
        ],
        "paper_abstract": "This work identifies the existence and cause of a type of posterior collapse that frequently occurs in the Bayesian deep learning practice. For a general linear latent variable model that includes linear variational autoencoders as a special case, we precisely identify the nature of posterior collapse to be the competition between the likelihood and the regularization of the mean due to the prior. Our result also suggests that posterior collapse may be a general problem of learning for deeper architectures and deepens our understanding of Bayesian deep learning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Weakly-Supervised Multi-Granularity Map Learning for Vision-and-Language Navigation",
        "paper_url": "https://openreview.net/pdf?id=gyZMZBiI9Cw",
        "paper_authors": [
            "Peihao Chen",
            "Dongyu Ji",
            "Kunyang Lin",
            "Runhao Zeng",
            "Thomas H. Li",
            "Mingkui Tan",
            "Chuang Gan"
        ],
        "paper_abstract": "We address a practical yet challenging problem of training robot agents to navigate in an environment following a path described by some language instructions. The instructions often contain descriptions of objects in the environment. To achieve accurate and efficient navigation, it is critical to build a map that accurately represents both spatial location and the semantic information of the environment objects. However, enabling a robot to build a map that well represents the environment is extremely challenging as the environment often involves diverse objects with various attributes. In this paper, we propose a multi-granularity map, which contains both object fine-grained details (\\eg, color, texture) and semantic classes, to represent objects more comprehensively. Moreover, we propose a weakly-supervised auxiliary task, which requires the agent to localize instruction-relevant objects on the map. Through this task, the agent not only learns to localize the instruction-relevant objects for navigation but also is encouraged to learn a better map representation that reveals object information. We then feed the learned map and instruction to a waypoint predictor to determine the next navigation goal. Experimental results show our method outperforms the state-of-the-art by 4.0% and 4.6% w.r.t. success rate both in seen and unseen environments, respectively on VLN-CE dataset. The code is available at https://github.com/PeihaoChen/WS-MGMap.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Active Camera  for Multi-Object Navigation",
        "paper_url": "https://openreview.net/pdf?id=iH4eyI5A7o",
        "paper_authors": [
            "Peihao Chen",
            "Dongyu Ji",
            "Kunyang Lin",
            "Weiwen Hu",
            "Wenbing Huang",
            "Thomas H. Li",
            "Mingkui Tan",
            "Chuang Gan"
        ],
        "paper_abstract": "Getting robots to navigate to multiple objects autonomously is essential yet difficult in robot applications. One of the key challenges is how to explore environments efficiently with camera sensors only. Existing navigation methods mainly focus on fixed cameras and few attempts have been made to navigate with active cameras. As a result, the agent may take a very long time to perceive the environment due to limited camera scope. In contrast, humans typically gain a larger field of view by looking around for a better perception of the environment. How to make robots perceive the environment as efficiently as humans is a fundamental problem in robotics. In this paper, we consider navigating to multiple objects more efficiently with active cameras. Specifically, we cast moving camera to a Markov Decision Process and reformulate the active camera problem as a reinforcement learning problem. However, we have to address two new challenges: 1) how to learn a good camera policy in complex environments and 2) how to coordinate it with the navigation policy. To address these, we carefully design a reward function to encourage the agent to explore more areas by moving camera actively. Moreover, we exploit human experience to infer a rule-based camera action to guide the learning process. Last, to better coordinate two kinds of policies, the camera policy takes navigation actions into account when making camera moving decisions. Experimental results show our camera policy consistently improves the performance of multi-object navigation over four baselines on two datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Signal Processing for Implicit Neural Representations",
        "paper_url": "https://openreview.net/pdf?id=qqIrESv4f_L",
        "paper_authors": [
            "Dejia Xu",
            "Peihao Wang",
            "Yifan Jiang",
            "Zhiwen Fan",
            "Zhangyang Wang"
        ],
        "paper_abstract": "Implicit Neural Representations (INRs) encoding continuous multi-media data via multi-layer perceptrons has shown undebatable promise in various computer vision tasks. Despite many successful applications, editing and processing an INR remains intractable as signals are represented by latent parameters of a neural network. Existing works manipulate such continuous representations via processing on their discretized instance, which breaks down the compactness and continuous nature of INR. In this work, we present a pilot study on the question: how to directly modify an INR without explicit decoding? We answer this question by proposing an implicit neural signal processing network, dubbed INSP-Net, via differential operators on INR. Our key insight is that spatial gradients of neural networks can be computed analytically and are invariant to translation, while mathematically we show that any continuous convolution filter can be uniformly approximated by a linear combination of high-order differential operators. With these two knobs, INSP-Net instantiates the signal processing operator as a weighted composition of computational graphs corresponding to the high-order derivatives of INRs, where the weighting parameters can be data-driven learned. Based on our proposed INSP-Net, we further build the first Convolutional Neural Network (CNN) that implicitly runs on INRs, named INSP-ConvNet. Our experiments validate the expressiveness of INSP-Net and INSP-ConvNet in fitting low-level image and geometry processing kernels (e.g. blurring, deblurring, denoising, inpainting, and smoothening) as well as for high-level tasks on implicit fields such as image classification.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Window Transformer for Image Restoration",
        "paper_url": "https://openreview.net/pdf?id=0ucMtEKCihU",
        "paper_authors": [
            "Jie Xiao",
            "Xueyang Fu",
            "Feng Wu",
            "Zheng-Jun Zha"
        ],
        "paper_abstract": "Thanks to the powerful representation capabilities, transformers have made impressive progress in image restoration. However, existing transformers-based methods do not carefully consider the particularities of image restoration. In general, image restoration requires that an ideal approach should be translation-invariant to the degradation, i.e., the undesirable degradation should be removed irrespective of its position within the image. Furthermore, the local relationships also play a vital role, which should be faithfully exploited for recovering clean images. Nevertheless, most transformers either adopt local attention with the fixed local window strategy or global attention, which unfortunately breaks the translation invariance and causes huge loss of local relationships. To address these issues, we propose an elegant stochastic window strategy for transformers. Specifically, we first introduce the window partition with stochastic shift to replace the original fixed window partition for training. Then, we design a new layer expectation propagation algorithm to efficiently approximate the expectation of the induced stochastic transformer for testing. Our stochastic window transformer not only enjoys powerful representation but also maintains the desired property of translation invariance and locality. Experiments validate the stochastic window strategy consistently improves performance on various image restoration tasks (deraining, denoising and deblurring) by significant margins. The code is available at https://github.com/jiexiaou/Stoformer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "An Empirical Study on Disentanglement of Negative-free Contrastive Learning",
        "paper_url": "https://openreview.net/pdf?id=fJguu0okUY1",
        "paper_authors": [
            "Jinkun Cao",
            "Ruiqian Nai",
            "Qing Yang",
            "Jialei Huang",
            "Yang Gao"
        ],
        "paper_abstract": "Negative-free contrastive learning methods have attracted a lot of attention with simplicity and impressive performances for large-scale pretraining. However, its disentanglement property remains unexplored. In this paper, we examine negative-free contrastive learning methods to study the disentanglement property empirically. We find that existing disentanglement metrics fail to make meaningful measurements for high-dimensional representation models, so we propose a new disentanglement metric based on Mutual Information between latent representations and data factors. With this proposed metric, we benchmark the disentanglement property of negative-free contrastive learning on both popular synthetic datasets and a real-world dataset CelebA. Our study shows that the investigated methods can learn a well-disentangled subset of representation. As far as we know, we are the first to extend the study of disentangled representation learning to high-dimensional representation space and introduce negative-free contrastive learning methods into this area. The source code of this paper is available at https://github.com/noahcao/disentanglement_lib_med.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods",
        "paper_url": "https://openreview.net/pdf?id=59pMU2xFxG",
        "paper_authors": [
            "Julien Colin",
            "Thomas FEL",
            "Remi Cadene",
            "Thomas Serre"
        ],
        "paper_abstract": "A multitude of explainability methods has been described to try to help users better understand how modern AI systems make decisions. However, most performance metrics developed to evaluate these methods have remained largely theoretical -- without much consideration for the human end-user. In particular, it is not yet clear (1) how useful current explainability methods are in real-world scenarios; and (2) whether current performance metrics accurately reflect the usefulness of explanation methods for the end user. To fill this gap, we conducted psychophysics experiments at scale ($n=1,150$) to evaluate the usefulness of representative attribution methods in three real-world scenarios. Our results demonstrate that the degree to which individual attribution methods help human participants better understand an AI system varies widely across these scenarios. This suggests the need to move beyond quantitative improvements of current attribution methods, towards the development of complementary approaches that provide qualitatively different sources of information to human end-users.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Theseus: A Library for Differentiable Nonlinear Optimization",
        "paper_url": "https://openreview.net/pdf?id=K48UYo0glaJ",
        "paper_authors": [
            "Luis Pineda",
            "Taosha Fan",
            "Maurizio Monge",
            "Shobha Venkataraman",
            "Paloma Sodhi",
            "Ricky T. Q. Chen",
            "Joseph Ortiz",
            "Daniel DeTone",
            "Austin S Wang",
            "Stuart Anderson",
            "Jing Dong",
            "Brandon Amos",
            "Mustafa Mukadam"
        ],
        "paper_abstract": "We present Theseus, an efficient application-agnostic open source library for differentiable nonlinear least squares (DNLS) optimization built on PyTorch, providing a common framework for end-to-end structured learning in robotics and vision. Existing DNLS implementations are application specific and do not always incorporate many ingredients important for efficiency. Theseus is application-agnostic, as we illustrate with several example applications that are built using the same underlying differentiable components, such as second-order optimizers, standard costs functions, and Lie groups. For efficiency, Theseus incorporates support for sparse solvers, automatic vectorization, batching, GPU acceleration, and gradient computation with implicit differentiation and direct loss minimization. We do extensive performance evaluation in a set of applications, demonstrating significant efficiency gains and better scalability when these features are incorporated. Project page: https://sites.google.com/view/theseus-ai/",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Representation Learning from Pre-trained Diffusion Probabilistic Models",
        "paper_url": "https://openreview.net/pdf?id=IiCsx9KNVa0",
        "paper_authors": [
            "Zijian Zhang",
            "Zhou Zhao",
            "Zhijie Lin"
        ],
        "paper_abstract": "Diffusion Probabilistic Models (DPMs) have shown a powerful capacity of generating high-quality image samples. Recently, diffusion autoencoders (Diff-AE) have been proposed to explore DPMs for representation learning via autoencoding. Their key idea is to jointly train an encoder for discovering meaningful representations from images and a conditional DPM as the decoder for reconstructing images. Considering that training DPMs from scratch will take a long time and there have existed numerous pre-trained DPMs, we propose \\textbf{P}re-trained \\textbf{D}PM \\textbf{A}uto\\textbf{E}ncoding (\\textbf{PDAE}), a general method to adapt existing pre-trained DPMs to the decoders for image reconstruction, with better training efficiency and performance than Diff-AE. Specifically, we find that the reason that pre-trained DPMs fail to reconstruct an image from its latent variables is due to the information loss of forward process, which causes a gap between their predicted posterior mean and the true one. From this perspective, the classifier-guided sampling method can be explained as computing an extra mean shift to fill the gap, reconstructing the lost class information in samples. These imply that the gap corresponds to the lost information of the image, and we can reconstruct the image by filling the gap. Drawing inspiration from this, we employ a trainable model to predict a mean shift according to encoded representation and train it to fill as much gap as possible, in this way, the encoder is forced to learn as much information as possible from images to help the filling. By reusing a part of network of pre-trained DPMs and redesigning the weighting scheme of diffusion loss, PDAE can learn meaningful representations from images efficiently. Extensive experiments demonstrate the effectiveness, efficiency and flexibility of PDAE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SPoVT: Semantic-Prototype Variational Transformer for Dense Point Cloud Semantic Completion",
        "paper_url": "https://openreview.net/pdf?id=JVoKzM_-lhz",
        "paper_authors": [
            "Sheng Yu Huang",
            "Hao-Yu Hsu",
            "Yu-Chiang Frank Wang"
        ],
        "paper_abstract": "Point cloud completion is an active research topic for 3D vision and has been widely\nstudied in recent years. Instead of directly predicting missing point cloud from\nthe partial input, we introduce a Semantic-Prototype Variational Transformer\n(SPoVT) in this work, which takes both partial point cloud and their semantic\nlabels as the inputs for semantic point cloud object completion. By observing\nand attending at geometry and semantic information as input features, our SPoVT\nwould derive point cloud features and their semantic prototypes for completion\npurposes. As a result, our SPoVT not only performs point cloud completion with\nvarying resolution, it also allows manipulation of different semantic parts of an\nobject. Experiments on benchmark datasets would quantitatively and qualitatively\nverify the effectiveness and practicality of our proposed model.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "End-to-end Symbolic Regression with Transformers",
        "paper_url": "https://openreview.net/pdf?id=GoOuIrDHG_Y",
        "paper_authors": [
            "Pierre-Alexandre Kamienny",
            "St\u00e9phane d'Ascoli",
            "Guillaume Lample",
            "Francois Charton"
        ],
        "paper_abstract": "Symbolic regression, the task of predicting the mathematical expression of a function from the observation of its values, is a difficult task which usually involves a two-step procedure: predicting the \"skeleton\" of the expression up to the choice of numerical constants, then fitting the constants by optimizing a non-convex loss function. The dominant approach is genetic programming, which evolves candidates by iterating this subroutine a large number of times. Neural networks have recently been tasked to predict the correct skeleton in a single try, but remain much less powerful.\n\nIn this paper, we challenge this two-step procedure, and task a Transformer to directly predict the full mathematical expression, constants included. One can subsequently refine the predicted constants by feeding them to the non-convex optimizer as an informed initialization. We present ablations to show that this end-to-end approach yields better results, sometimes even without the refinement step. We evaluate our model on problems from the SRBench benchmark and show that our model approaches the performance of state-of-the-art genetic programming with several orders of magnitude faster inference. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Pay attention to your loss : understanding misconceptions about Lipschitz neural networks",
        "paper_url": "https://openreview.net/pdf?id=BRIL0EFvTgc",
        "paper_authors": [
            "Louis B\u00e9thune",
            "Thibaut Boissin",
            "Mathieu Serrurier",
            "Franck Mamalet",
            "Corentin Friedrich",
            "Alberto Gonzalez Sanz"
        ],
        "paper_abstract": "Lipschitz constrained networks have gathered considerable attention in the deep learning community, with usages ranging from Wasserstein distance estimation to the training of certifiably robust classifiers. However they remain commonly considered as less accurate, and their properties in learning are still not fully understood. In this paper we clarify the matter: when it comes to classification 1-Lipschitz neural networks enjoy several advantages over their unconstrained counterpart. First, we show that these networks are as accurate as classical ones, and can fit arbitrarily difficult boundaries. Then, relying on a robustness metric that reflects operational needs we characterize the most robust classifier: the WGAN discriminator. Next, we show that 1-Lipschitz neural networks generalize well under milder assumptions. Finally, we show that hyper-parameters of the loss are crucial for controlling the accuracy-robustness trade-off. We conclude that they exhibit appealing properties to pave the way toward provably accurate, and provably robust neural networks.    ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Panchromatic and Multispectral Image Fusion via Alternating Reverse Filtering Network",
        "paper_url": "https://openreview.net/pdf?id=hH9ohGbhyv",
        "paper_authors": [
            "Keyu Yan",
            "Man Zhou",
            "Jie Huang",
            "Feng Zhao",
            "Chengjun Xie",
            "Chongyi Li",
            "Danfeng Hong"
        ],
        "paper_abstract": "Panchromatic (PAN) and multi-spectral (MS) image fusion, named Pan-sharpening, refers to super-resolve the low-resolution (LR) multi-spectral (MS) images in the spatial domain to generate the expected high-resolution (HR) MS images, conditioning on the corresponding high-resolution PAN images. In this paper, we present a simple yet effective alternating reverse filtering network for pan-sharpening. Inspired by the classical reverse filtering that reverses images to the status before filtering, we formulate pan-sharpening as an alternately iterative reverse filtering process, which fuses LR MS and HR MS in an interpretable manner. Different from existing model-driven methods that require well-designed priors and degradation assumptions, the reverse filtering process avoids the dependency on pre-defined exact priors. To guarantee the stability and convergence of the iterative process via contraction mapping on a metric space, we develop the learnable multi-scale Gaussian kernel module, instead of using specific filters. We demonstrate the theoretical feasibility of such formulations. Extensive experiments on diverse scenes to thoroughly verify the performance of our method, significantly outperforming the state of the arts.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Joint Entropy Search for Multi-Objective Bayesian Optimization",
        "paper_url": "https://openreview.net/pdf?id=ZChgD8OoGds",
        "paper_authors": [
            "Ben Tu",
            "Axel Gandy",
            "Nikolas Kantas",
            "Behrang Shafei"
        ],
        "paper_abstract": "Many real-world problems can be phrased as a multi-objective optimization problem, where the goal is to identify the best set of compromises between the competing objectives. Multi-objective Bayesian optimization (BO) is a sample efficient strategy that can be deployed to solve these vector-valued optimization problems where access is limited to a number of noisy objective function evaluations. In this paper, we propose a novel information-theoretic acquisition function for BO called Joint Entropy Search (JES), which considers the joint information gain for the optimal set of inputs and outputs. We present several analytical approximations to the JES acquisition function and also introduce an extension to the batch setting. We showcase the effectiveness of this new approach on a range of synthetic and real-world problems in terms of the hypervolume and its weighted variants.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mining Unseen Classes via Regional Objectness: A Simple Baseline for Incremental Segmentation",
        "paper_url": "https://openreview.net/pdf?id=G1vrYk9uX-_",
        "paper_authors": [
            "Zekang Zhang",
            "Guangyu Gao",
            "Zhiyuan Fang",
            "Jianbo Jiao",
            "Yunchao Wei"
        ],
        "paper_abstract": "Incremental or continual learning has been extensively studied for image classification tasks to alleviate catastrophic forgetting, a phenomenon in which earlier learned knowledge is forgotten when learning new concepts. For class incremental semantic segmentation, such a phenomenon often becomes much worse due to the semantic shift of the background class, \\ie, some concepts learned at previous stages are assigned to the background class at the current training stage, therefore, significantly reducing the performance of these old concepts. To address this issue, we propose a simple yet effective method in this paper, named Mining unseen Classes via Regional Objectness (MicroSeg). Our MicroSeg is based on the assumption that \\emph{background regions with strong objectness possibly belong to those concepts in the historical or future stages}. Therefore, to avoid forgetting old knowledge at the current training stage, our MicroSeg first splits the given image into hundreds of segment proposals with a proposal generator. Those segment proposals with strong objectness from the background are then clustered and assigned new defined labels during the optimization. In this way, the distribution characterizes of old concepts in the feature space could be better perceived, relieving the catastrophic forgetting caused by the semantic shift of the background class accordingly.  We conduct extensive experiments on Pascal VOC and ADE20K, and competitive results well demonstrate the effectiveness of our MicroSeg. Code is available at \\href{https://github.com/zkzhang98/MicroSeg}{\\textcolor{orange}{\\texttt{https://github.com/zkzhang98/MicroSeg}}}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing",
        "paper_url": "https://openreview.net/pdf?id=zfo2LqFEVY",
        "paper_authors": [
            "Shentong Mo",
            "Yapeng Tian"
        ],
        "paper_abstract": "The audio-visual video parsing task aims to parse a video into modality- and category-aware temporal segments. Previous work mainly focuses on weakly-supervised approaches, which learn from video-level event labels. During training, they do not know which modality perceives and meanwhile which temporal segment contains the video event. Since there is no explicit grouping in the existing frameworks, the modality and temporal uncertainties make these methods suffer from false predictions. For instance, segments in the same category could be predicted in different event classes. Learning compact and discriminative multi-modal subspaces is essential for mitigating the issue. To this end, in this paper, we propose a novel Multi-modal Grouping Network, namely MGN, for explicitly semantic-aware grouping. Specifically, MGN aggregates event-aware unimodal features through unimodal grouping in terms of learnable categorical embedding tokens. Furthermore, it leverages the cross-modal grouping for modality-aware prediction to match the video-level target. Our simple framework achieves improving results against previous baselines on weakly-supervised audio-visual video parsing. In addition, our MGN is much more lightweight, using only 47.2% of the parameters of baselines (17 MB vs. 36 MB). Code is available at https://github.com/stoneMo/MGN.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Understanding Benign Overfitting in Gradient-Based Meta Learning",
        "paper_url": "https://openreview.net/pdf?id=oW4Zz0zlbFF",
        "paper_authors": [
            "Lisha Chen",
            "Songtao Lu",
            "Tianyi Chen"
        ],
        "paper_abstract": "Meta learning has demonstrated tremendous success in few-shot learning with  limited supervised data. In those settings, the meta model is usually overparameterized. While the conventional statistical learning theory suggests that overparameterized models tend to overfit, empirical evidence reveals that overparameterized meta learning methods still work well -- a phenomenon often called ``benign overfitting.'' To understand this phenomenon, we focus on the meta learning settings with a challenging bilevel structure that we term the gradient-based meta learning, and analyze its generalization performance under an overparameterized meta linear regression model. While our analysis uses the relatively tractable linear models, our theory contributes to understanding the delicate interplay among data heterogeneity, model adaptation and benign overfitting in gradient-based meta learning tasks. We corroborate our theoretical claims through numerical simulations. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Representing Spatial Trajectories as Distributions",
        "paper_url": "https://openreview.net/pdf?id=nJWcpq2fco3",
        "paper_authors": [
            "Didac Suris Coll-Vinent",
            "Carl Vondrick"
        ],
        "paper_abstract": "We introduce a representation learning framework for spatial trajectories. We represent partial observations of trajectories as probability distributions in a learned latent space, which characterize the uncertainty about unobserved parts of the trajectory. Our framework allows us to obtain samples from a trajectory for any continuous point in time\u2014both interpolating and extrapolating. Our flexible approach supports directly modifying specific attributes of a trajectory, such as its pace, as well as combining different partial observations into single representations. Experiments show our method's superiority over baselines in prediction tasks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Convergence Rate of Stochastic Gradient Langevin Dynamics with Variance Reduction and its Application to Optimization",
        "paper_url": "https://openreview.net/pdf?id=Sj2z__i1wX-",
        "paper_authors": [
            "Yuri Kinoshita",
            "Taiji Suzuki"
        ],
        "paper_abstract": "The stochastic gradient Langevin Dynamics is one of the most fundamental algorithms to solve sampling problems and non-convex optimization appearing in several machine learning applications. Especially, its variance reduced versions have nowadays gained particular attention. In this paper, we study two variants of this kind, namely, the Stochastic Variance Reduced Gradient Langevin Dynamics and the Stochastic Recursive Gradient Langevin Dynamics. We prove their convergence to the objective distribution in terms of KL-divergence under the sole assumptions of smoothness and Log-Sobolev inequality which are weaker conditions than those used in prior works for these algorithms. With the batch size and the inner loop length set to $\\sqrt{n}$, the gradient complexity to achieve an $\\epsilon$-precision is $\\tilde{O}((n+dn^{1/2}\\epsilon^{-1})\\gamma^2 L^2\\alpha^{-2})$, which is an improvement from any previous analyses. We also show some essential applications of our result to non-convex optimization.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decoupling Features in Hierarchical Propagation for Video Object Segmentation",
        "paper_url": "https://openreview.net/pdf?id=DgM7-7eMkq0",
        "paper_authors": [
            "Zongxin Yang",
            "Yi Yang"
        ],
        "paper_abstract": "This paper focuses on developing a more effective method of hierarchical propagation for semi-supervised Video Object Segmentation (VOS). Based on vision transformers, the recently-developed Associating Objects with Transformers (AOT) approach introduces hierarchical propagation into VOS and has shown promising results. The hierarchical propagation can gradually propagate information from past frames to the current frame and transfer the current frame feature from object-agnostic to object-specific. However, the increase of object-specific information will inevitably lead to the loss of object-agnostic visual information in deep propagation layers. To solve such a problem and further facilitate the learning of visual embeddings, this paper proposes a Decoupling Features in Hierarchical Propagation (DeAOT) approach. Firstly, DeAOT decouples the hierarchical propagation of object-agnostic and object-specific embeddings by handling them in two independent branches. Secondly, to compensate for the additional computation from dual-branch propagation, we propose an efficient module for constructing hierarchical propagation, i.e., Gated Propagation Module, which is carefully designed with single-head attention. Extensive experiments show that DeAOT significantly outperforms AOT in both accuracy and efficiency. On YouTube-VOS, DeAOT can achieve 86.0% at 22.4fps and 82.0% at 53.4fps. Without test-time augmentations, we achieve new state-of-the-art performance on four benchmarks, i.e., YouTube-VOS (86.2%), DAVIS 2017 (86.2%), DAVIS 2016 (92.9%), and VOT 2020 (0.622 EAO).  Project page: https://github.com/z-x-yang/AOT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Harmonizing the object recognition strategies of deep neural networks with humans",
        "paper_url": "https://openreview.net/pdf?id=ZYKWi6Ylfg",
        "paper_authors": [
            "Thomas FEL",
            "Ivan F Rodriguez Rodriguez",
            "Drew Linsley",
            "Thomas Serre"
        ],
        "paper_abstract": "The many successes of deep neural networks (DNNs) over the past decade have largely been driven by computational scale rather than insights from biological intelligence. Here, we explore if these trends have also carried concomitant improvements in explaining the visual strategies humans rely on for object recognition. We do this by comparing two related but distinct properties of visual strategies in humans and DNNs: where they believe important visual features are in images and how they use those features to categorize objects. Across 84 different DNNs trained on ImageNet and three independent datasets measuring the where and the how of human visual strategies for object recognition on those images, we find a systematic trade-off between DNN categorization accuracy and alignment with human visual strategies for object recognition. \\textit{State-of-the-art DNNs are progressively becoming less aligned with humans as their accuracy improves}. We rectify this growing issue with our neural harmonizer: a general-purpose training routine that both aligns DNN and human visual strategies and improves categorization accuracy. Our work represents the first demonstration that the scaling laws that are guiding the design of DNNs today have also produced worse models of human vision. We release our code and data at https://serre-lab.github.io/Harmonization to help the field build more human-like DNNs.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bi-directional Weakly Supervised Knowledge Distillation for Whole Slide Image Classification",
        "paper_url": "https://openreview.net/pdf?id=JoZyVgp1hm",
        "paper_authors": [
            "Linhao Qu",
            "xiaoyuan Luo",
            "Manning Wang",
            "Zhijian Song"
        ],
        "paper_abstract": "Computer-aided pathology diagnosis based on the classification of Whole Slide Image (WSI) plays an important role in clinical practice, and it is often formulated as a weakly-supervised Multiple Instance Learning (MIL) problem. Existing methods solve this problem from either a bag classification or an instance classification perspective. In this paper, we propose an end-to-end weakly supervised knowledge distillation framework (WENO) for WSI classification, which integrates a bag classifier and an instance classifier in a knowledge distillation framework to mutually improve the performance of both classifiers. Specifically, an attention-based bag classifier is used as the teacher network, which is trained with weak bag labels, and an instance classifier is used as the student network, which is trained using the normalized attention scores obtained from the teacher network as soft pseudo labels for the instances in positive bags. An instance feature extractor is shared between the teacher and the student to further enhance the knowledge exchange between them. In addition, we propose a hard positive instance mining strategy based on the output of the student network to force the teacher network to keep mining hard positive instances. WENO is a plug-and-play framework that can be easily applied to any existing attention-based bag classification methods. Extensive experiments on five datasets demonstrate the efficiency of WENO. Code is available at https://github.com/miccaiif/WENO.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection",
        "paper_url": "https://openreview.net/pdf?id=-deKNiSOXLG",
        "paper_authors": [
            "Yue Song",
            "Nicu Sebe",
            "Wei Wang"
        ],
        "paper_abstract": "The task of out-of-distribution (OOD) detection is crucial for deploying machine learning models in real-world settings. In this paper, we observe that the singular value distributions of the in-distribution (ID) and OOD features are quite different: the OOD feature matrix tends to have a larger dominant singular value than the ID feature, and the class predictions of OOD samples are largely determined by it. This observation motivates us to propose RankFeat, a simple yet effective post hoc approach for OOD detection by removing the rank-1 matrix composed of the largest singular value and the associated singular vectors from the high-level feature. RankFeat achieves state-of-the-art performance and reduces the average false positive rate (FPR95) by 17.90% compared with the previous best method. Extensive ablation studies and comprehensive theoretical analyses are presented to support the empirical results.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling",
        "paper_url": "https://openreview.net/pdf?id=ikXoMuy_H4",
        "paper_authors": [
            "Amir Feder",
            "Guy Horowitz",
            "Yoav Wald",
            "Roi Reichart",
            "Nir Rosenfeld"
        ],
        "paper_abstract": "Accurately predicting the relevance of items to users is crucial to the success of many social platforms. Conventional approaches train models on logged historical data; but recommendation systems, media services, and online marketplaces all exhibit a constant influx of new content---making relevancy a moving target, to which standard predictive models are not robust. In this paper, we propose a learning framework for relevance prediction that is robust to changes in the data distribution. Our key observation is that robustness can be obtained by accounting for \\emph{how users causally perceive the environment}. We model users as boundedly-rational decision makers whose causal beliefs are encoded by a causal graph, and show how minimal information regarding the graph can be used to contend with distributional changes. Experiments in multiple settings demonstrate the effectiveness of our approach.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ResT V2: Simpler, Faster and Stronger",
        "paper_url": "https://openreview.net/pdf?id=2OdAggzzF3z",
        "paper_authors": [
            "Qinglong Zhang",
            "Yu-Bin Yang"
        ],
        "paper_abstract": "This paper proposes ResTv2, a simpler, faster, and stronger multi-scale vision Transformer for visual recognition. ResTv2 simplifies the EMSA structure in ResTv1 (i.e., eliminating the multi-head interaction part) and employs an upsample operation to reconstruct the lost medium- and high-frequency information caused by the downsampling operation. In addition, we explore different techniques for better applying ResTv2 backbones to downstream tasks. We find that although combining EMSAv2 and window attention can greatly reduce the theoretical matrix multiply FLOPs, it may significantly decrease the computation density, thus causing lower actual speed. We comprehensively validate ResTv2 on ImageNet classification, COCO detection, and ADE20K semantic segmentation. Experimental results show that the proposed ResTv2 can outperform the recently state-of-the-art backbones by a large margin, demonstrating the potential of ResTv2 as solid backbones. The code and models will be made publicly available at \\url{https://github.com/wofmanaf/ResT}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dataset Inference for Self-Supervised Models",
        "paper_url": "https://openreview.net/pdf?id=CCBJf9xJo2X",
        "paper_authors": [
            "Adam Dziedzic",
            "Haonan Duan",
            "Muhammad Ahmad Kaleem",
            "Nikita Dhawan",
            "Jonas Guan",
            "Yannis Cattan",
            "Franziska Boenisch",
            "Nicolas Papernot"
        ],
        "paper_abstract": "Self-supervised models are increasingly prevalent in machine learning (ML) since they reduce the need for expensively labeled data. Because of their versatility in downstream applications, they are increasingly used as a service exposed via public APIs. At the same time, these encoder models are particularly vulnerable to model stealing attacks due to the high dimensionality of vector representations they output. Yet, encoders remain undefended: existing mitigation strategies for stealing attacks focus on supervised learning. We introduce a new dataset inference defense, which uses the private training set of the victim encoder model to attribute its ownership in the event of stealing. The intuition is that the log-likelihood of an encoder's output representations is higher on the victim's training data than on test data if it is stolen from the victim, but not if it is independently trained. We compute this log-likelihood using density estimation models. As part of our evaluation, we also propose measuring the fidelity of stolen encoders and quantifying the effectiveness of the theft detection without involving downstream tasks; instead, we leverage mutual information and distance measurements. Our extensive empirical results in the vision domain demonstrate that dataset inference is a promising direction for defending self-supervised models against model stealing.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=RYZyj_wwgfa",
        "paper_authors": [
            "Zhiwei Deng",
            "Olga Russakovsky"
        ],
        "paper_abstract": "We propose an algorithm that compresses the critical information of a large dataset into compact addressable memories. These memories can then be recalled to quickly re-train a neural network and recover the performance (instead of storing and re-training on the full original dataset). Building upon the dataset distillation framework, we make a key observation that a shared common representation allows for more efficient and effective distillation. Concretely, we learn a set of bases (aka ``memories'') which are shared between classes and combined through learned flexible addressing functions to generate a diverse set of training examples. This leads to several benefits: 1) the size of compressed data does not necessarily grow linearly with the number of classes; 2) an overall higher compression rate with more effective distillation is achieved; and 3) more generalized queries are allowed beyond recalling the original classes. We demonstrate state-of-the-art results on the dataset distillation task across five benchmarks, including up to 16.5% and 9.7% accuracy improvement when distilling CIFAR10 and CIFAR100 respectively. We then leverage our framework to perform continual learning, achieving state-of-the-art results on four benchmarks, with 23.2% accuracy improvement on MANY.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GenSDF: Two-Stage Learning of Generalizable Signed Distance Functions",
        "paper_url": "https://openreview.net/pdf?id=QK38rpF8RWL",
        "paper_authors": [
            "Gene Chou",
            "Ilya Chugunov",
            "Felix Heide"
        ],
        "paper_abstract": "We investigate the generalization capabilities of neural signed distance functions (SDFs) for learning 3D object representations for unseen and unlabeled point clouds. Existing methods can fit SDFs to a handful of object classes and boast fine detail or fast inference speeds, but do not generalize well to unseen shapes. We introduce a two-stage semi-supervised meta-learning approach that transfers shape priors from labeled to unlabeled data to reconstruct unseen object categories. The first stage uses an episodic training scheme to simulate training on unlabeled data and meta-learns initial shape priors. The second stage then introduces unlabeled data with disjoint classes in a semi-supervised scheme to diversify these priors and achieve generalization. We assess our method on both synthetic data and real collected point clouds. Experimental results and analysis validate that our approach outperforms existing neural SDF methods and is capable of robust zero-shot inference on 100+ unseen classes. Code can be found at https://github.com/princeton-computational-imaging/gensdf",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Product Ranking for Revenue Maximization with Multiple Purchases",
        "paper_url": "https://openreview.net/pdf?id=wxWTyJtiJZ",
        "paper_authors": [
            "Renzhe Xu",
            "Xingxuan Zhang",
            "Bo Li",
            "Yafeng Zhang",
            "xiaolong chen",
            "Peng Cui"
        ],
        "paper_abstract": "Product ranking is the core problem for revenue-maximizing online retailers. To design proper product ranking algorithms, various consumer choice models are proposed to characterize the consumers' behaviors when they are provided with a list of products. However, existing works assume that each consumer purchases at most one product or will keep viewing the product list after purchasing a product, which does not agree with the common practice in real scenarios. In this paper, we assume that each consumer can purchase multiple products at will. To model consumers' willingness to view and purchase, we set a random attention span and purchase budget, which determines the maximal amount of products that he/she views and purchases, respectively. Under this setting, we first design an optimal ranking policy when the online retailer can precisely model consumers' behaviors. Based on the policy, we further develop the Multiple-Purchase-with-Budget UCB (MPB-UCB) algorithms with $\\tilde{O}(\\sqrt{T})$ regret that estimate consumers' behaviors and maximize revenue simultaneously in online settings. Experiments on both synthetic and semi-synthetic datasets prove the effectiveness of the proposed algorithms.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Explainable Reinforcement Learning via Model Transforms",
        "paper_url": "https://openreview.net/pdf?id=32Ryt4pAHeD",
        "paper_authors": [
            "Mira Finkelstein",
            "Nitsan Schlotterbeck levy",
            "Lucy Liu",
            "Yoav Kolumbus",
            "David C. Parkes",
            "Jeffrey Rosenschein",
            "Sarah Keren"
        ],
        "paper_abstract": "Understanding emerging behaviors of reinforcement learning (RL) agents may be difficult since such agents are often trained in complex environments using highly complex decision making procedures. This has given rise to a variety of approaches to explainability in RL that aim to reconcile discrepancies that may arise between the behavior of an agent and the behavior that is anticipated by an observer. Most recent approaches have relied either on domain knowledge, that may not always be available, on an analysis of the agent\u2019s policy, or on an analysis of specific elements of the underlying environment, typically modeled as a Markov Decision Process (MDP). Our key claim is that even if the underlying model is not fully known (e.g., the transition probabilities have not been accurately learned) or is not maintained by the agent (i.e., when using model-free methods), the model can nevertheless be exploited to automatically generate explanations. For this purpose, we suggest using formal MDP abstractions and transforms, previously used in the literature for expediting the search for optimal policies, to automatically produce explanations. Since such transforms are typically based on a symbolic representation of the environment, they can provide meaningful explanations for gaps between the anticipated and actual agent behavior. We formally define the explainability problem, suggest a class of transforms that can be used for explaining emergent behaviors, and suggest methods that enable efficient search for an explanation. We demonstrate the approach on a set of standard benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "One Model to Edit Them All: Free-Form Text-Driven Image Manipulation with Semantic Modulations",
        "paper_url": "https://openreview.net/pdf?id=kb33f8J83c",
        "paper_authors": [
            "Yiming Zhu",
            "Hongyu Liu",
            "Yibing Song",
            "Ziyang Yuan",
            "Xintong Han",
            "Chun Yuan",
            "Qifeng Chen",
            "Jue Wang"
        ],
        "paper_abstract": "Free-form text prompts allow users to describe their intentions during image manipulation conveniently. Based on the visual latent space of StyleGAN[21] and text embedding space of CLIP[34], studies focus on how to map these two latent spaces for text-driven attribute manipulations. Currently, the latent mapping between these two spaces is empirically designed and confines that each manipulation model can only handle one fixed text prompt. In this paper, we propose a method named Free-Form CLIP (FFCLIP), aiming to  establish an automatic latent mapping so that one manipulation model handles free-form text prompts. Our FFCLIP has a cross-modality semantic modulation module containing semantic alignment and injection. The semantic alignment performs the automatic latent mapping via linear transformations with a cross attention mechanism. After alignment, we inject semantics from text prompt embeddings to the StyleGAN latent space. For one type of image (e.g., `human portrait'), one FFCLIP model can be learned to handle free-form text prompts. Meanwhile, we observe that although each training text prompt only contains a single semantic meaning, FFCLIP can leverage text prompts with multiple semantic meanings for image manipulation. In the experiments, we evaluate FFCLIP on three types of images (i.e., `human portraits', `cars', and `churches'). Both visual and numerical results show that FFCLIP effectively produces semantically accurate and visually realistic images. Project page:  https://github.com/KumapowerLIU/FFCLIP.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Practical Control of Singular Values of Convolutional Layers",
        "paper_url": "https://openreview.net/pdf?id=T5TtjbhlAZH",
        "paper_authors": [
            "Alexandra Senderovich",
            "Ekaterina Bulatova",
            "Anton Obukhov",
            "Maxim Rakhuba"
        ],
        "paper_abstract": "In general, convolutional neural networks (CNNs) are easy to train, but their essential properties, such as generalization error and adversarial robustness, are hard to control. Recent research demonstrated that singular values of convolutional layers significantly affect such elusive properties and offered several methods for controlling them. Nevertheless, these methods present an intractable computational challenge or resort to coarse approximations. In this paper, we offer a principled approach to alleviating constraints of the prior art at the expense of an insignificant reduction in layer expressivity. Our method is based on the tensor-train decomposition; it retains control over the actual singular values of convolutional mappings while providing structurally sparse and hardware-friendly representation. We demonstrate the improved properties of modern CNNs with our method and analyze its impact on the model performance, calibration, and adversarial robustness. The source code is available at: https://github.com/WhiteTeaDragon/practical_svd_conv",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Versatile Embodied Navigation",
        "paper_url": "https://openreview.net/pdf?id=ZMrZ5SC2G3_",
        "paper_authors": [
            "Hanqing Wang",
            "Wei Liang",
            "Luc Van Gool",
            "Wenguan Wang"
        ],
        "paper_abstract": "With the emergence of varied visual navigation tasks (e.g., image-/object-/audio-goal and vision-language navigation) that specify the target in different ways, the community has made appealing advances in training specialized agents capable of handling individual navigation tasks well. Given plenty of embodied navigation tasks and task-specific solutions, we address a more fundamental question: can we learn a single powerful agent that masters not one but multiple navigation tasks concurrently? First, we propose VXN, a large-scale 3D dataset that instantiates~four classic navigation tasks in standardized, continuous, and audiovisual-rich environments. Second, we propose Vienna, a versatile embodied navigation agent that simultaneously learns to perform the four navigation tasks with one model. Building upon a full-attentive architecture, Vienna formulates various navigation tasks as a unified, parse-and-query procedure: the target description, augmented with four task embeddings, is comprehensively interpreted into a set of diversified goal vectors, which are refined as the navigation progresses, and used as queries to retrieve supportive context from episodic history for decision making. This enables the reuse of knowledge across navigation tasks with varying input domains/modalities. We empirically demonstrate that, compared with learning each visual navigation task individually, our multitask agent achieves comparable or even better performance with reduced complexity.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Resource-Adaptive Federated Learning with All-In-One Neural Composition",
        "paper_url": "https://openreview.net/pdf?id=wfel7CjOYk",
        "paper_authors": [
            "Yiqun Mei",
            "Pengfei Guo",
            "Mo Zhou",
            "Vishal Patel"
        ],
        "paper_abstract": "Conventional Federated Learning (FL) systems inherently assume a uniform processing capacity among clients for deployed models.  However, diverse client hardware often leads to varying computation resources in practice. Such system heterogeneity results in an inevitable trade-off between model complexity and data accessibility as a bottleneck. To avoid such a dilemma and achieve resource-adaptive federated learning, we introduce a simple yet effective mechanism, termed All-In-One Neural Composition, to systematically support training complexity-adjustable models with flexible resource adaption. It is able to efficiently construct models at various complexities using one unified neural basis shared among clients, instead of pruning the global model into local ones. The proposed mechanism endows the system with unhindered access to the full range of knowledge scattered across clients and generalizes existing pruning-based solutions by allowing soft and learnable extraction of low footprint models. Extensive experiment results on popular FL benchmarks demonstrate the effectiveness of our approach. The resulting FL system empowered by our All-In-One Neural Composition, called FLANC, manifests consistent performance gains across diverse system/data heterogeneous setups while keeping high efficiency in computation and communication. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decision Trees with Short Explainable Rules",
        "paper_url": "https://openreview.net/pdf?id=Lp-QFq2QRXA",
        "paper_authors": [
            "Victor Feitosa Souza",
            "Ferdinando Cicalese",
            "Eduardo Sany Laber",
            "Marco Molinaro"
        ],
        "paper_abstract": "Decision trees are widely used in many settings where interpretable models are preferred or required. As confirmed by recent empirical studies,  the interpretability/explanability of a decision tree critically depends on some of its structural parameters, like size and the  average/maximum depth of its leaves. There is indeed a vast literature on the design and analysis of decision tree algorithms that aim at optimizing these parameters.\n\nThis paper contributes to this important line of research: we propose as a novel criterion of measuring the interpretability of a decision tree, the sparsity of the set of attributes that are (on average) required to explain the classification of the examples. We give a tight characterization of the best possible guarantees achievable by a decision tree built to optimize both our new\nmeasure (which we call the {\\em explanation size})  and the more classical measures of worst-case and average depth. In particular, we give an algorithm that guarantees $O(\\ln n )$-approximation (hence optimal if $P \\neq NP$) for the minimization of both the average/worst-case explanation size and the average/worst-case depth. In addition to our theoretical contributions, experiments with 20 real datasets show that our algorithm has accuracy competitive with CART while producing trees that allow for much simpler explanations.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MsSVT: Mixed-scale Sparse Voxel Transformer for 3D Object Detection on Point Clouds",
        "paper_url": "https://openreview.net/pdf?id=hOVEBHpHrMu",
        "paper_authors": [
            "Shaocong Dong",
            "Lihe Ding",
            "Haiyang Wang",
            "Tingfa Xu",
            "Xinli Xu",
            "Jie Wang",
            "Ziyang Bian",
            "Ying Wang",
            "Jianan Li"
        ],
        "paper_abstract": "3D object detection from the LiDAR point cloud is fundamental to autonomous driving. Large-scale outdoor scenes usually feature significant variance in instance scales, thus requiring features rich in long-range and fine-grained information to support accurate detection. Recent detectors leverage the power of window-based transformers to model long-range dependencies but tend to blur out fine-grained details. To mitigate this gap, we present a novel Mixed-scale Sparse Voxel Transformer, named MsSVT, which can well capture both types of information simultaneously by the divide-and-conquer philosophy. Specifically, MsSVT explicitly divides attention heads into multiple groups, each in charge of attending to information within a particular range. All groups' output is merged to obtain the final mixed-scale features. Moreover, we provide a novel chessboard sampling strategy to reduce the computational complexity of applying a window-based transformer in 3D voxel space. To improve efficiency, we also implement the voxel sampling and gathering operations sparsely with a hash map. Endowed by the powerful capability and high efficiency of modeling mixed-scale information, our single-stage detector built on top of MsSVT surprisingly outperforms state-of-the-art two-stage detectors on Waymo. Our project page: https://github.com/dscdyc/MsSVT. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generalized Delayed Feedback Model with Post-Click Information in Recommender Systems",
        "paper_url": "https://openreview.net/pdf?id=IvJj3CvjqHC",
        "paper_authors": [
            "Jia-Qi Yang",
            "De-Chuan Zhan"
        ],
        "paper_abstract": "Predicting conversion rate (e.g., the probability that a user will purchase an item) is a fundamental problem in machine learning based recommender systems. However, accurate conversion labels are revealed after a long delay, which harms the timeliness of recommender systems. Previous literature concentrates on utilizing early conversions to mitigate such a delayed feedback problem. In this paper, we show that post-click user behaviors are also informative to conversion rate prediction and can be used to improve timeliness. We propose a generalized delayed feedback model (GDFM) that unifies both post-click behaviors and early conversions as stochastic post-click information, which could be utilized to train GDFM in a streaming manner efficiently. Based on GDFM, we further establish a novel perspective that the performance gap introduced by delayed feedback can be attributed to a temporal gap and a sampling gap. Inspired by our analysis, we propose to measure the quality of post-click information with a combination of temporal distance and sample complexity. The training objective is re-weighted accordingly to highlight informative and timely signals. We validate our analysis on public datasets, and experimental performance confirms the effectiveness of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging",
        "paper_url": "https://openreview.net/pdf?id=r9b6T088_75",
        "paper_authors": [
            "Yuanhao Cai",
            "Jing Lin",
            "Haoqian Wang",
            "Xin Yuan",
            "Henghui Ding",
            "Yulun Zhang",
            "Radu Timofte",
            "Luc Van Gool"
        ],
        "paper_abstract": "In coded aperture snapshot spectral compressive imaging (CASSI) systems, hyperspectral image (HSI) reconstruction methods are employed to recover the spatial-spectral signal from a compressed measurement. Among these algorithms, deep unfolding methods demonstrate promising performance but suffer from two issues. Firstly, they do not estimate the degradation patterns and ill-posedness degree from CASSI to guide the iterative learning. Secondly, they are mainly CNN-based, showing limitations in capturing long-range dependencies. In this paper, we propose a principled Degradation-Aware Unfolding Framework (DAUF) that estimates parameters from the compressed image and physical mask, and then uses these parameters to control each iteration. Moreover, we customize a novel Half-Shuffle Transformer (HST) that simultaneously captures local contents and non-local dependencies. By plugging HST into DAUF, we establish the first Transformer-based deep unfolding method, Degradation-Aware Unfolding Half-Shuffle Transformer (DAUHST), for HSI reconstruction. Experiments show that DAUHST surpasses state-of-the-art methods while requiring cheaper computational and memory costs. Code and models are publicly available at https://github.com/caiyuanhao1998/MST",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PerfectDou: Dominating DouDizhu with Perfect Information Distillation",
        "paper_url": "https://openreview.net/pdf?id=Blbzv2ZjT7",
        "paper_authors": [
            "Guan Yang",
            "Minghuan Liu",
            "Weijun Hong",
            "Weinan Zhang",
            "Fei Fang",
            "Guangjun Zeng",
            "Yue Lin"
        ],
        "paper_abstract": "As a challenging multi-player card game, DouDizhu has recently drawn much attention for analyzing competition and collaboration in imperfect-information games. In this paper, we propose PerfectDou, a state-of-the-art Doudizhu AI system that summits the game, in an actor-critic framework with a proposed technique named perfect information distillation.\nIn detail, we adopt a perfect-training-imperfection-execution framework that allows the agents to utilize the global information to guide the training of the policies as if it is a perfect information game and the trained policies can be used to play the imperfect information game during the actual gameplay. Correspondingly, we characterize card and game features for DouDizhu to represent the perfect and imperfect information. To train our system, we adopt proximal policy optimization with generalized advantage estimation in a parallel training paradigm. In experiments we show how and why PerfectDou beats all existing programs, and achieves state-of-the-art performance.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NCP: Neural Correspondence Prior for Effective Unsupervised Shape Matching",
        "paper_url": "https://openreview.net/pdf?id=ouXTjiP0ffV",
        "paper_authors": [
            "Souhaib Attaiki",
            "Maks Ovsjanikov"
        ],
        "paper_abstract": "We present Neural Correspondence Prior (NCP), a new paradigm for computing correspondences between 3D shapes. Our approach is fully unsupervised and can lead to high quality correspondences even in challenging cases such as sparse point clouds or non-isometric meshes, where current methods fail. Our first key observation is that, in line with neural priors observed in other domains, recent network architectures on 3D data, even without training, tend to produce pointwise features that induce plausible maps between rigid or non-rigid shapes. Secondly, we show that given a noisy map as input, training a feature extraction network with the input map as supervision, tends to remove artifacts from the input and can act as a powerful correspondence denoising mechanism, both between individual pairs and within a collection. With  these observations in hand, we propose a two-stage unsupervised paradigm for shape matching, by (i) performing unsupervised training by adapting an existing approach to obtain an initial set of noisy matches, (ii) using these matches to train a network in a supervised manner. We demonstrate that this approach significantly improves the accuracy of the maps, especially when trained within a collection. We show that NCP is data-efficient, fast, and achieves state-of-the-art results on many tasks. Our code will be released after publication.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A2: Efficient Automated Attacker for Boosting Adversarial Training",
        "paper_url": "https://openreview.net/pdf?id=SsA-0BZa7B_",
        "paper_authors": [
            "Zhuoer Xu",
            "Guanghui Zhu",
            "Changhua Meng",
            "shiwen cui",
            "Zhenzhe Ying",
            "Weiqiang Wang",
            "Ming GU",
            "Yihua Huang"
        ],
        "paper_abstract": "Based on the significant improvement of model robustness by AT (Adversarial Training), various variants have been proposed to further boost the performance. Well-recognized methods have focused on different components of AT (e.g., designing loss functions and leveraging additional unlabeled data). It is generally accepted that stronger perturbations yield more robust models.\nHowever, how to generate stronger perturbations efficiently is still missed. In this paper, we propose an efficient automated attacker called A2 to boost AT by generating the optimal perturbations on-the-fly during training. A2 is a parameterized automated attacker to search in the attacker space for the best attacker against the defense model and examples. Extensive experiments across different datasets demonstrate that A2 generates stronger perturbations with low extra cost and reliably improves the robustness of various AT methods against different attacks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient learning of nonlinear prediction models with time-series privileged information",
        "paper_url": "https://openreview.net/pdf?id=V9ngeCMsZK3",
        "paper_authors": [
            "Bastian Jung",
            "Fredrik Daniel Johansson"
        ],
        "paper_abstract": "In domains where sample sizes are limited, efficient learning algorithms are critical. Learning using privileged information (LuPI) offers increased sample efficiency by allowing prediction models access to auxiliary information at training time which is unavailable when the models are used. In recent work, it was shown that for prediction in linear-Gaussian dynamical systems, a LuPI learner with access to intermediate time series data is never worse and often better in expectation than any unbiased classical learner. We provide new insights into this analysis and generalize it to nonlinear prediction tasks in latent dynamical systems, extending theoretical guarantees to the case where the map connecting latent variables and observations is known up to a linear transform. In addition, we propose algorithms based on random features and representation learning for the case when this map is unknown. A suite of empirical results confirm theoretical findings and show the potential of using privileged time-series information in nonlinear prediction.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ElasticMVS: Learning elastic part representation for self-supervised multi-view stereopsis",
        "paper_url": "https://openreview.net/pdf?id=lAN7mytwrIy",
        "paper_authors": [
            "Jinzhi Zhang",
            "Ruofan Tang",
            "Zheng Cao",
            "Jing Xiao",
            "Ruqi Huang",
            "LU FANG"
        ],
        "paper_abstract": "Self-supervised multi-view stereopsis (MVS) attracts increasing attention for learning dense surface predictions from only a set of images without onerous ground-truth 3D training data for supervision. However, existing methods highly rely on the local photometric consistency, which fails to identify accurately dense correspondence in broad textureless and reflectance areas.In this paper, we show that geometric proximity such as surface connectedness and occlusion boundaries implicitly inferred from images could serve as reliable guidance for pixel-wise multi-view correspondences. With this insight, we present a novel elastic part representation which encodes physically-connected part segmentations with elastically-varying scales, shapes and boundaries. Meanwhile, a self-supervised MVS framework namely ElasticMVS is proposed to learn the representation and estimate per-view depth following a part-aware propagation and evaluation scheme. Specifically, the pixel-wise part representation is trained by a contrastive learning-based strategy, which increases the representation compactness in geometrically concentrated areas and contrasts otherwise. ElasticMVS iteratively optimizes a part-level consistency loss and a surface smoothness loss, based on a set of depth hypotheses propagated from the geometrically concentrated parts. Extensive evaluations convey the superiority of ElasticMVS in the reconstruction completeness and accuracy, as well as the efficiency and scalability. Particularly, for the challenging large-scale reconstruction benchmark, ElasticMVS demonstrates significant performance gain over both the supervised and self-supervised approaches.  ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Interaction Modeling with Multiplex Attention",
        "paper_url": "https://openreview.net/pdf?id=SeHslYhFx5-",
        "paper_authors": [
            "Fan-Yun Sun",
            "Isaac Kauvar",
            "Ruohan Zhang",
            "Jiachen Li",
            "Mykel Kochenderfer",
            "Jiajun Wu",
            "Nick Haber"
        ],
        "paper_abstract": "Modeling multi-agent systems requires understanding how agents interact. Such systems are often difficult to model because they can involve a variety of types of interactions that layer together to drive rich social behavioral dynamics. Here we introduce a method for accurately modeling multi-agent systems. We present Interaction Modeling with Multiplex Attention (IMMA), a forward prediction model that uses a multiplex latent graph to represent multiple independent types of interactions and attention to account for relations of different strengths. We also introduce Progressive Layer Training, a training strategy for this architecture. We show that our approach outperforms state-of-the-art models in trajectory forecasting and relation inference, spanning three multi-agent scenarios: social navigation, cooperative task achievement, and team sports. We further demonstrate that our approach can improve zero-shot generalization and allows us to probe how different interactions impact agent behavior.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment",
        "paper_url": "https://openreview.net/pdf?id=uP9RiC4uVcR",
        "paper_authors": [
            "Zhijing Jin",
            "Sydney Levine",
            "Fernando Gonzalez Adauto",
            "Ojasv Kamal",
            "Maarten Sap",
            "Mrinmaya Sachan",
            "Rada Mihalcea",
            "Joshua B. Tenenbaum",
            "Bernhard Sch\u00f6lkopf"
        ],
        "paper_abstract": "AI systems are becoming increasingly intertwined with human life. In order to effectively collaborate with humans and ensure safety, AI systems need to be able to understand, interpret and predict human moral judgments and decisions. Human moral judgments are often guided by rules, but not always. A central challenge for AI safety is capturing the flexibility of the human moral mind \u2014 the ability to determine when a rule should be broken, especially in novel or unusual situations. In this paper, we present a novel challenge set consisting of moral exception question answering (MoralExceptQA) of cases that involve potentially permissible moral exceptions \u2013 inspired by recent moral psychology studies. Using a state-of-the-art large language model (LLM) as a basis, we propose a novel moral chain of thought (MoralCoT) prompting strategy that combines the strengths of LLMs with theories of moral reasoning developed in cognitive science to predict human moral judgments. MoralCoT outperforms seven existing LLMs by 6.2% F1, suggesting that modeling human reasoning might be necessary to capture the flexibility of the human moral mind. We also conduct a detailed error analysis to suggest directions for future work to improve AI safety using MoralExceptQA. Our data is open-sourced at https://huggingface.co/datasets/feradauto/MoralExceptQA and code at https://github.com/feradauto/MoralCoT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Matryoshka Representation Learning",
        "paper_url": "https://openreview.net/pdf?id=9njZa1fm35",
        "paper_authors": [
            "Aditya Kusupati",
            "Gantavya Bhatt",
            "Aniket Rege",
            "Matthew Wallingford",
            "Aditya Sinha",
            "Vivek Ramanujan",
            "William Howard-Snyder",
            "Kaifeng Chen",
            "Sham M. Kakade",
            "Prateek Jain",
            "Ali Farhadi"
        ],
        "paper_abstract": "Learned representations are a central component in modern ML systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context rigid, fixed capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying computational resources? Our main contribution is Matryoshka Representation Learning (MRL) which encodes information at different granularities and allows a single embedding to adapt to the computational constraints of downstream tasks. MRL minimally modifies existing representation learning pipelines and imposes no additional cost during inference and deployment. MRL learns coarse-to-fine representations that are at least as accurate and rich as independently trained low-dimensional representations. The flexibility within the learned Matryoshka Representations offer: (a) up to $\\mathbf{14}\\times$ smaller embedding size for ImageNet-1K classification at the same level of accuracy; (b) up to $\\mathbf{14}\\times$ real-world speed-ups for large-scale retrieval on ImageNet-1K and 4K; and (c) up to $\\mathbf{2}\\%$ accuracy improvements for long-tail few-shot classification, all while being as robust as the original representations. Finally, we show that MRL extends seamlessly to web-scale datasets (ImageNet, JFT) across various modalities -- vision (ViT, ResNet), vision + language (ALIGN) and language (BERT). MRL code and pretrained models are open-sourced at https://github.com/RAIVNLab/MRL.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deep Fourier Up-Sampling",
        "paper_url": "https://openreview.net/pdf?id=NIrbtCdxfBl",
        "paper_authors": [
            "man zhou",
            "Hu Yu",
            "Jie Huang",
            "Feng Zhao",
            "Jinwei Gu",
            "Chen Change Loy",
            "Deyu Meng",
            "Chongyi Li"
        ],
        "paper_abstract": "Existing convolutional neural networks widely adopt spatial down-/up-sampling for multi-scale modeling. However, spatial up-sampling operators (e.g., interpolation, transposed convolution, and un-pooling) heavily depend on local pixel attention, incapably exploring the global dependency. In contrast,  the Fourier domain is in accordance with the nature of global modeling according to the spectral convolution theorem. Unlike the spatial domain that easily performs  up-sampling with the property of local similarity, up-sampling in the Fourier domain is more challenging as it does not follow such a local property. In this study, we propose a theoretically feasible Deep Fourier Up-Sampling (FourierUp) to solve these issues. We revisit the relationships between spatial and Fourier domains and reveal the transform rules on the features of different resolutions in the Fourier domain, which provide key insights for FourierUp's designs. FourierUp as a generic operator consists of three key components: 2D discrete Fourier transform,  Fourier dimension increase rules, and 2D inverse Fourier transform, which can be directly integrated with existing networks. Extensive experiments across multiple computer vision tasks, including object detection, image segmentation, image de-raining, image dehazing, and guided image super-resolution, demonstrate the consistent performance gains obtained by introducing our FourierUp. Code will be publicly available.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trajectory Inference via Mean-field Langevin in Path Space",
        "paper_url": "https://openreview.net/pdf?id=Mftcm8i4sL",
        "paper_authors": [
            "L\u00e9na\u00efc Chizat",
            "Stephen Zhang",
            "Matthieu Heitz",
            "Geoffrey Schiebinger"
        ],
        "paper_abstract": "Trajectory inference aims at recovering the dynamics of a population from snapshots of its temporal marginals. To solve this task, a min-entropy estimator relative to the Wiener measure in path space was introduced in [Lavenant et al., 2021], and shown to consistently recover the dynamics of a large class of drift-diffusion processes from the solution of an infinite dimensional convex optimization problem. In this paper, we introduce a grid-free algorithm to compute this estimator. Our method consists in a family of point clouds (one per snapshot) coupled via Schr\u00f6dinger bridges which evolve with noisy gradient descent. We study the mean-field limit of the dynamics and prove its global convergence to the desired estimator. Overall, this leads to an inference method with end-to-end theoretical guarantees that solves an interpretable model for trajectory inference. We also present how to adapt the method to deal with mass variations, a useful extension when dealing with single cell RNA-sequencing data where cells can branch and die.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Divert More Attention to Vision-Language Tracking",
        "paper_url": "https://openreview.net/pdf?id=NhrbIME2Ljl",
        "paper_authors": [
            "Mingzhe Guo",
            "Zhipeng Zhang",
            "Heng Fan",
            "Liping Jing"
        ],
        "paper_abstract": "Relying on Transformer for complex visual feature learning, object tracking has witnessed the new standard for state-of-the-arts (SOTAs). However, this advancement accompanies by larger training data and longer training period, making tracking increasingly expensive. In this paper, we demonstrate that the Transformer-reliance is not necessary and the pure ConvNets are still competitive and even better yet more economical and friendly in achieving SOTA tracking. Our solution is to unleash the power of multimodal vision-language (VL) tracking, simply using ConvNets. The essence lies in learning novel unified-adaptive VL representations with our modality mixer (ModaMixer) and asymmetrical ConvNet search. We show that our unified-adaptive VL representation, learned purely with the ConvNets, is a simple yet strong alternative to Transformer visual features, by unbelievably improving a CNN-based Siamese tracker by 14.5% in SUC on challenging LaSOT (50.7%$\\rightarrow$65.2%), even outperforming several Transformer-based SOTA trackers. Besides empirical results, we theoretically analyze our approach to evidence its effectiveness. By revealing the potential of VL representation, we expect the community to divert more attention to VL tracking and hope to open more possibilities for future tracking beyond Transformer. Code and models are released at https://github.com/JudasDie/SOTS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Object Scene Representation Transformer",
        "paper_url": "https://openreview.net/pdf?id=znNmsN_O7Sh",
        "paper_authors": [
            "Mehdi S. M. Sajjadi",
            "Daniel Duckworth",
            "Aravindh Mahendran",
            "Sjoerd van Steenkiste",
            "Filip Pavetic",
            "Mario Lucic",
            "Leonidas Guibas",
            "Klaus Greff",
            "Thomas Kipf"
        ],
        "paper_abstract": "A compositional understanding of the world in terms of objects and their geometry in 3D space is considered a cornerstone of human cognition. Facilitating the learning of such a representation in neural networks holds promise for substantially improving labeled data efficiency. As a key step in this direction, we make progress on the problem of learning 3D-consistent decompositions of complex scenes into individual objects in an unsupervised fashion. We introduce Object Scene Representation Transformer (OSRT), a 3D-centric model in which individual object representations naturally emerge through novel view synthesis. OSRT scales to significantly more complex scenes with larger diversity of objects and backgrounds than existing methods. At the same time, it is multiple orders of magnitude faster at compositional rendering thanks to its light field parametrization and the novel Slot Mixer decoder. We believe this work will not only accelerate future architecture exploration and scaling efforts, but it will also serve as a useful tool for both object-centric as well as neural scene representation learning communities.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rethinking Individual Global Max in Cooperative Multi-Agent Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=xs9Sia9J_O",
        "paper_authors": [
            "Yitian Hong",
            "Yaochu Jin",
            "Yang Tang"
        ],
        "paper_abstract": "In cooperative multi-agent reinforcement learning, centralized training and decentralized execution (CTDE) has achieved remarkable success. Individual Global Max (IGM) decomposition, which is an important element of CTDE, measures the consistency between local and joint policies. The majority of IGM-based research focuses on how to establish this consistent relationship, but little attention has been paid to examining IGM's potential flaws. In this work, we reveal that the IGM condition is a lossy decomposition, and the error of lossy decomposition will accumulated in hypernetwork-based methods. To address the above issue, we propose to adopt an imitation learning strategy to separate the lossy decomposition from Bellman iterations, thereby avoiding error accumulation. The proposed strategy is theoretically proved and empirically verified on the StarCraft Multi-Agent Challenge benchmark problem with zero sight view. The results also confirm that the proposed method outperforms state-of-the-art IGM-based approaches.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Discrete-Convex-Analysis-Based Framework for Warm-Starting Algorithms with Predictions",
        "paper_url": "https://openreview.net/pdf?id=-GgDBzwZ-e7",
        "paper_authors": [
            "Shinsaku Sakaue",
            "Taihei Oki"
        ],
        "paper_abstract": "Augmenting algorithms with learned predictions is a promising approach for going beyond worst-case bounds. Dinitz, Im, Lavastida, Moseley, and Vassilvitskii~(2021) have demonstrated that warm-starts with learned dual solutions can improve the time complexity of the Hungarian method for weighted perfect bipartite matching. We extend and improve their framework in a principled manner via \\textit{discrete convex analysis} (DCA), a discrete analog of convex analysis. We show the usefulness of our DCA-based framework by applying it to weighted perfect bipartite matching, weighted matroid intersection, and discrete energy minimization for computer vision. Our DCA-based framework yields time complexity bounds that depend on the $\\ell_\\infty$-distance from a predicted solution to an optimal solution, which has two advantages relative to the previous $\\ell_1$-distance-dependent bounds: time complexity bounds are smaller, and learning of predictions is more sample efficient. We also discuss whether to learn primal or dual solutions from the DCA perspective.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring Example Influence in Continual Learning",
        "paper_url": "https://openreview.net/pdf?id=u4dXcUEsN7B",
        "paper_authors": [
            "Qing Sun",
            "Fan Lyu",
            "Fanhua Shang",
            "Wei Feng",
            "Liang Wan"
        ],
        "paper_abstract": "Continual Learning (CL) sequentially learns new tasks like human beings, with the goal to achieve better Stability (S, remembering past tasks) and Plasticity (P, adapting to new tasks). Due to the fact that past training data is not available, it is valuable to explore the influence difference on S and P among training examples, which may improve the learning pattern towards better SP. Inspired by Influence Function (IF), we first study example influence via adding perturbation to example weight and computing the influence derivation. To avoid the storage and calculation burden of Hessian inverse in neural networks, we propose a simple yet effective MetaSP algorithm to simulate the two key steps in the computation of IF and obtain the S- and P-aware example influence. Moreover, we propose to fuse two kinds of example influence by solving a dual-objective optimization problem, and obtain a fused influence towards SP Pareto optimality. The fused influence can be used to control the update of model and optimize the storage of rehearsal. Empirical results show that our algorithm significantly outperforms state-of-the-art methods on both task- and class-incremental benchmark CL datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Motion Transformer with Global Intention Localization and Local Movement Refinement",
        "paper_url": "https://openreview.net/pdf?id=9t-j3xDm7_Q",
        "paper_authors": [
            "Shaoshuai Shi",
            "Li Jiang",
            "Dengxin Dai",
            "Bernt Schiele"
        ],
        "paper_abstract": "Predicting multimodal future behavior of traffic participants is essential for robotic vehicles to make safe decisions. Existing works explore to directly predict future trajectories based on latent features or utilize dense goal candidates to identify agent's destinations, where the former strategy converges slowly since all motion modes are derived from the same feature while the latter strategy has efficiency issue since its performance highly relies on the density of goal candidates. In this paper, we propose the Motion TRansformer (MTR) framework that models motion prediction as the joint optimization of global intention localization and local movement refinement. Instead of using goal candidates, MTR incorporates spatial intention priors by adopting a small set of learnable motion query pairs. Each motion query pair takes charge of trajectory prediction and refinement for a specific motion mode, which stabilizes the training process and facilitates better multimodal predictions. Experiments show that MTR achieves state-of-the-art performance on both the marginal and joint motion prediction challenges, ranking 1st on the leaderbaords of Waymo Open Motion Dataset. Code will be available at https://github.com/sshaoshuai/MTR.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection",
        "paper_url": "https://openreview.net/pdf?id=aKXBrj0DHm",
        "paper_authors": [
            "Hanoona Abdul Rasheed",
            "Muhammad Maaz",
            "Muhammd Uzair Khattak",
            "Salman Khan",
            "Fahad Khan"
        ],
        "paper_abstract": "Existing open-vocabulary object detectors typically enlarge their vocabulary sizes by leveraging different forms of weak supervision. This helps generalize to novel objects at inference. Two popular forms of weak-supervision used in open-vocabulary detection (OVD) include pretrained CLIP model and image-level supervision. We note that both these modes of supervision are not optimally aligned for the detection task: CLIP is trained with image-text pairs and lacks precise localization of objects while the image-level supervision has been used with heuristics that do not accurately specify local object regions. In this work, we propose to address this problem by performing object-centric alignment  of the language embeddings from the CLIP model. Furthermore, we visually ground the objects with only image-level supervision using a pseudo-labeling process that provides high-quality object proposals and helps expand the vocabulary during training. We establish a bridge between the above two object-alignment strategies via a novel weight transfer function that aggregates their complimentary strengths. In essence, the proposed model seeks to minimize the gap between object and image-centric representations in the OVD setting. On the COCO benchmark, our proposed approach achieves 36.6 AP50 on novel classes, an absolute 8.2 gain over the previous best performance. For LVIS, we surpass the state-of-the-art ViLD model by 5.0 mask AP for rare categories and 3.4 overall. Code: https://github.com/hanoonaR/object-centric-ovd.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "What Makes a \"Good\" Data Augmentation in Knowledge Distillation - A Statistical Perspective",
        "paper_url": "https://openreview.net/pdf?id=6avZnPpk7m9",
        "paper_authors": [
            "Huan Wang",
            "Suhas Lohit",
            "Michael Jeffrey Jones",
            "Yun Fu"
        ],
        "paper_abstract": "Knowledge distillation (KD) is a general neural network training approach that uses a teacher model to guide the student model. Existing works mainly study KD from the network output side (e.g., trying to design a better KD loss function), while few have attempted to understand it from the input side. Especially, its interplay with data augmentation (DA) has not been well understood. In this paper, we ask: Why do some DA schemes (e.g., CutMix) inherently perform much better than others in KD? What makes a \"good\" DA in KD? Our investigation from a statistical perspective suggests that a good DA scheme should reduce the covariance of the teacher-student cross-entropy. A practical metric, the stddev of teacher\u2019s mean probability (T. stddev), is further presented and well justified empirically. Besides the theoretical understanding, we also introduce a new entropy-based data-mixing DA scheme, CutMixPick, to further enhance CutMix. Extensive empirical studies support our claims and demonstrate how we can harvest considerable performance gains simply by using a better DA scheme in knowledge distillation. Code: https://github.com/MingSun-Tse/Good-DA-in-KD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Behavior Transformers: Cloning $k$ modes with one stone",
        "paper_url": "https://openreview.net/pdf?id=agTr-vRQsa",
        "paper_authors": [
            "Nur Muhammad Mahi Shafiullah",
            "Zichen Jeff Cui",
            "Ariuntuya Altanzaya",
            "Lerrel Pinto"
        ],
        "paper_abstract": "While behavior learning has made impressive progress in recent times, it lags behind computer vision and natural language processing due to its inability to leverage large, human-generated datasets. Human behavior has a wide variance, multiple modes, and human demonstrations naturally do not come with reward labels. These properties limit the applicability of current methods in Offline RL and Behavioral Cloning to learn from large, pre-collected datasets. In this work, we present Behavior Transformer (BeT), a new technique to model unlabeled demonstration data with multiple modes. BeT retrofits standard transformer architectures with action discretization coupled with a multi-task action correction inspired by offset prediction in object detection. This allows us to leverage the multi-modal modeling ability of modern transformers to predict multi-modal continuous actions. We experimentally evaluate BeT on a variety of robotic manipulation and self-driving behavior datasets. We show that BeT significantly improves over prior state-of-the-art work on solving demonstrated tasks while capturing the major modes present in the pre-collected datasets. Finally, through an extensive ablation study, we further analyze the importance of every crucial component in BeT. Videos of behavior generated by BeT are available here: https://mahis.life/bet",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Deliberated Domain Bridging for Domain Adaptive Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=ievxJqXwPCm",
        "paper_authors": [
            "Lin Chen",
            "Zhixiang Wei",
            "Xin Jin",
            "Huaian Chen",
            "Miao Zheng",
            "Kai Chen",
            "Yi Jin"
        ],
        "paper_abstract": "In unsupervised domain adaptation (UDA), directly adapting from the source to the target domain usually suffers significant discrepancies and leads to insufficient alignment. Thus, many UDA works attempt to vanish the domain gap gradually and softly via various intermediate spaces, dubbed domain bridging (DB). However, for dense prediction tasks such as domain adaptive semantic segmentation (DASS), existing solutions have mostly relied on rough style transfer and how to elegantly bridge domains is still under-explored. In this work, we resort to data mixing to establish a deliberated domain bridging (DDB) for DASS, through which the joint distributions of source and target domains are aligned and interacted with each in the intermediate space. At the heart of DDB lies a dual-path domain bridging step for generating two intermediate domains using the coarse-wise and the fine-wise data mixing techniques, alongside a cross-path knowledge distillation step for taking two complementary models trained on generated intermediate samples as \u2018teachers\u2019 to develop a superior \u2018student\u2019 in a multi-teacher distillation manner. These two optimization steps work in an alternating way and reinforce each other to give rise to DDB with strong adaptation power. Extensive experiments on adaptive segmentation tasks with different settings demonstrate that our DDB significantly outperforms state-of-the-art methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids",
        "paper_url": "https://openreview.net/pdf?id=b90lKL1IqcF",
        "paper_authors": [
            "Katja Schwarz",
            "Axel Sauer",
            "Michael Niemeyer",
            "Yiyi Liao",
            "Andreas Geiger"
        ],
        "paper_abstract": "State-of-the-art 3D-aware generative models rely on coordinate-based MLPs to parameterize 3D radiance fields. While demonstrating impressive results, querying an MLP for every sample along each ray leads to slow rendering.\nTherefore, existing approaches often render low-resolution feature maps and process them with an upsampling network to obtain the final image. \nAlbeit efficient, neural rendering often entangles viewpoint and content such that changing the camera pose results in unwanted changes of geometry or appearance.\nMotivated by recent results in voxel-based novel view synthesis, we investigate the utility of sparse voxel grid representations for fast and 3D-consistent generative modeling in this paper.\nOur results demonstrate that monolithic MLPs can indeed be replaced by 3D convolutions when combining sparse voxel grids with progressive growing, free space pruning and appropriate regularization.\nTo obtain a compact representation of the scene and allow for scaling to higher voxel resolutions, our model disentangles the foreground object (modeled in 3D) from the background (modeled in 2D).\nIn contrast to existing approaches, our method requires only a single forward pass to generate a full 3D scene. It hence allows for efficient rendering from arbitrary viewpoints while yielding 3D consistent results with high visual fidelity. Code and models are available at https://github.com/autonomousvision/voxgraf.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross Aggregation Transformer for Image Restoration",
        "paper_url": "https://openreview.net/pdf?id=wQ2QNNP8GtM",
        "paper_authors": [
            "Zheng Chen",
            "Yulun Zhang",
            "Jinjin Gu",
            "Yongbing Zhang",
            "Linghe Kong",
            "Xin Yuan"
        ],
        "paper_abstract": "Recently, Transformer architecture has been introduced into image restoration to replace convolution neural network (CNN) with surprising results. Considering the high computational complexity of Transformer with global attention, some methods use the local square window to limit the scope of self-attention. However, these methods lack direct interaction among different windows, which limits the establishment of long-range dependencies. To address the above issue, we propose a new image restoration model, Cross Aggregation Transformer (CAT). The core of our CAT is the Rectangle-Window Self-Attention (Rwin-SA), which utilizes horizontal and vertical rectangle window attention in different heads parallelly to expand the attention area and aggregate the features cross different windows. We also introduce the Axial-Shift operation for different window interactions. Furthermore, we propose the Locality Complementary Module to complement the self-attention mechanism, which incorporates the inductive bias of CNN (e.g., translation invariance and locality) into Transformer, enabling global-local coupling. Extensive experiments demonstrate that our CAT outperforms recent state-of-the-art methods on several image restoration applications. The code and models are available at https://github.com/zhengchen1999/CAT.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploit Reward Shifting in Value-Based Deep-RL: Optimistic Curiosity-Based Exploration and Conservative Exploitation via Linear Reward Shaping",
        "paper_url": "https://openreview.net/pdf?id=iCxRsZcVVAH",
        "paper_authors": [
            "Hao Sun",
            "Lei Han",
            "Rui Yang",
            "Xiaoteng Ma",
            "Jian Guo",
            "Bolei Zhou"
        ],
        "paper_abstract": "In this work, we study the simple yet universally applicable case of reward shaping in value-based Deep Reinforcement Learning (DRL). We show that reward shifting in the form of a linear transformation is equivalent to changing the initialization of the $Q$-function in function approximation. Based on such an equivalence, we bring the key insight that a positive reward shifting leads to conservative exploitation, while a negative reward shifting leads to curiosity-driven exploration. Accordingly, conservative exploitation improves offline RL value estimation, and optimistic value estimation improves exploration for online RL. We validate our insight on a range of RL tasks and show its improvement over baselines: (1) In offline RL, the conservative exploitation leads to improved performance based on off-the-shelf algorithms; (2) In online continuous control, multiple value functions with different shifting constants can be used to tackle the exploration-exploitation dilemma for better sample efficiency; (3) In discrete control tasks, a negative reward shifting yields an improvement over the curiosity-based exploration method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TotalSelfScan: Learning Full-body Avatars from Self-Portrait Videos of Faces, Hands, and Bodies",
        "paper_url": "https://openreview.net/pdf?id=lgj33-O1Ely",
        "paper_authors": [
            "Junting Dong",
            "Qi Fang",
            "Yudong Guo",
            "Sida Peng",
            "Qing Shuai",
            "Xiaowei Zhou",
            "Hujun Bao"
        ],
        "paper_abstract": "Recent advances in implicit neural representations make it possible to reconstruct a human-body model from a monocular self-rotation video. While previous works present impressive results of human body reconstruction, the quality of  reconstructed face and hands are relatively low. The main reason is that the image region occupied by these parts is very small compared to the body. To solve this problem, we propose a new approach named TotalSelfScan, which reconstructs the full-body model from several monocular self-rotation videos that focus on the face, hands, and body, respectively. Compared to recording a single video, this setting has almost no additional cost but provides more details of essential parts. To learn the full-body model, instead of encoding the whole body in a single network, we propose a multi-part representation to model separate parts and then fuse the part-specific observations into a single unified human model. Once learned, the full-body model enables rendering photorealistic free-viewpoint videos under novel human poses. Experiments show that TotalSelfScan can significantly improve the reconstruction and rendering quality on the face and hands compared to the existing methods. The code is available at \\url{https://zju3dv.github.io/TotalSelfScan}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies",
        "paper_url": "https://openreview.net/pdf?id=EAcWgk7JM58",
        "paper_authors": [
            "Guocheng Qian",
            "Yuchen Li",
            "Houwen Peng",
            "Jinjie Mai",
            "Hasan Abed Al Kader Hammoud",
            "Mohamed Elhoseiny",
            "Bernard Ghanem"
        ],
        "paper_abstract": "PointNet++ is one of the most influential neural architectures for point cloud understanding. Although the accuracy of PointNet++ has been largely surpassed by recent networks such as PointMLP and Point Transformer, we find that a large portion of the performance gain is due to improved training strategies, i.e. data augmentation and optimization techniques, and increased model sizes rather than architectural innovations. Thus, the full potential of PointNet++ has yet to be explored. In this work, we revisit the classical PointNet++ through a systematic study of model training and scaling strategies, and offer two major contributions. First, we propose a set of improved training strategies that significantly improve PointNet++ performance. For example, we show that, without any change in architecture, the overall accuracy (OA) of PointNet++ on ScanObjectNN object classification can be raised from 77.9% to 86.1%, even outperforming state-of-the-art PointMLP. Second, we introduce an inverted residual bottleneck design and separable MLPs into PointNet++ to enable efficient and effective model scaling and propose PointNeXt, the next version of PointNets. PointNeXt can be flexibly scaled up and outperforms state-of-the-art methods on both 3D classification and segmentation tasks. For classification, PointNeXt reaches an overall accuracy of 87.7 on ScanObjectNN, surpassing PointMLP by 2.3%, while being 10x faster in inference. For semantic segmentation, PointNeXt establishes a new state-of-the-art performance with 74.9% mean IoU on S3DIS (6-fold cross-validation), being superior to the recent Point Transformer. The code and models are available at https://github.com/guochengqian/pointnext.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stochastic Adaptive Activation Function",
        "paper_url": "https://openreview.net/pdf?id=wtuYr8_KhyM",
        "paper_authors": [
            "Kyungsu Lee",
            "Jaeseung Yang",
            "Haeyun Lee",
            "Jae Youn Hwang"
        ],
        "paper_abstract": "The simulation of human neurons and neurotransmission mechanisms has been realized in deep neural networks based on the theoretical implementations of activation functions. However, recent studies have reported that the threshold potential of neurons exhibits different values according to the locations and types of individual neurons, and that the activation functions have limitations in terms of representing this variability. Therefore, this study proposes a simple yet effective activation function that facilitates different thresholds and adaptive activations according to the positions of units and the contexts of inputs. Furthermore, the proposed activation function mathematically exhibits a more generalized form of Swish activation function, and thus we denoted it as Adaptive SwisH (ASH). ASH highlights informative features that exhibit large values in the top percentiles in an input, whereas it rectifies low values. Most importantly, ASH exhibits trainable, adaptive, and context-aware properties compared to other activation functions. Furthermore, ASH represents general formula of the previously studied activation function and provides a reasonable mathematical background for the superior performance. To validate the effectiveness and robustness of ASH, we implemented ASH into many deep learning models for various tasks, including classification, detection, segmentation, and image generation. Experimental analysis demonstrates that our activation function can provide the benefits of more accurate prediction and earlier convergence in many deep learning applications.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Improved Fine-Tuning by Better Leveraging Pre-Training Data",
        "paper_url": "https://openreview.net/pdf?id=YTXIIc7cAQ",
        "paper_authors": [
            "Ziquan Liu",
            "Yi Xu",
            "Yuanhong Xu",
            "Qi Qian",
            "Hao Li",
            "Xiangyang Ji",
            "Antoni B. Chan",
            "Rong Jin"
        ],
        "paper_abstract": "As a dominant paradigm, fine-tuning a pre-trained model on the target data is widely used in many deep learning applications, especially for small data sets. However, recent studies have empirically shown that training from scratch has the final performance that is no worse than this pre-training strategy once the number of training samples is increased in some vision tasks. In this work, we revisit this phenomenon from the perspective of generalization analysis by using excess risk bound which is popular in learning theory. The result reveals that the excess risk bound may have a weak dependency on the pre-trained model. The observation inspires us to leverage pre-training data for fine-tuning, since this data is also available for fine-tuning. The generalization result of using pre-training data shows that the excess risk bound on a target task can be improved when the appropriate pre-training data is included in fine-tuning. With the theoretical motivation, we propose a novel selection strategy to select a subset from pre-training data to help improve the generalization on the target task. Extensive experimental results for image classification tasks on 8 benchmark data sets verify the effectiveness of the proposed data selection based fine-tuning pipeline. Our code is available at https://github.com/ziquanliu/NeurIPS2022_UOT_fine_tuning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RainNet: A Large-Scale Imagery Dataset and Benchmark for Spatial Precipitation Downscaling",
        "paper_url": "https://openreview.net/pdf?id=0cn6LSqwjUv",
        "paper_authors": [
            "Xuanhong Chen",
            "Kairui Feng",
            "Naiyuan Liu",
            "Bingbing Ni",
            "Yifan Lu",
            "Zhengyan Tong",
            "Ziang Liu"
        ],
        "paper_abstract": "AI-for-science approaches have been applied to solve scientific problems (e.g., nuclear fusion, ecology, genomics, meteorology) and have achieved highly promising results. Spatial precipitation downscaling is one of the most important meteorological problem and urgently requires the participation of AI. However, the lack of a well-organized and annotated large-scale dataset hinders the training and verification of more effective and advancing deep-learning models for precipitation downscaling. To alleviate these obstacles, we present the first large-scale spatial precipitation downscaling dataset named RainNet, which contains more than 62,400 pairs of high-quality low/high-resolution precipitation maps for over 17 years, ready to help the evolution of deep learning models in precipitation downscaling. Specifically, the precipitation maps carefully collected in RainNet cover various meteorological phenomena (e.g., hurricane, squall), which is of great help to improve the model generalization ability. In addition, the map pairs in RainNet are organized in the form of image sequences (720 maps per month or 1 map/hour), showing complex physical properties, e.g., temporal misalignment, temporal sparse, and fluid properties. Furthermore, two deep-learning-oriented metrics are specifically introduced to evaluate or verify the comprehensive performance of the trained model (e.g., prediction maps reconstruction accuracy). To illustrate the applications of RainNet, 14 state-of-the-art models, including deep models and traditional approaches, are evaluated. To fully explore potential downscaling solutions, we propose an implicit physical estimation benchmark framework to learn the above characteristics. Extensive experiments demonstrate the value of RainNet in training and evaluating downscaling models. Our dataset is available at https://neuralchen.github.io/RainNet/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Robust Blind Face Restoration with Codebook Lookup Transformer",
        "paper_url": "https://openreview.net/pdf?id=XdDl3bFUNn5",
        "paper_authors": [
            "Shangchen Zhou",
            "Kelvin C.K. Chan",
            "Chongyi Li",
            "Chen Change Loy"
        ],
        "paper_abstract": "Blind face restoration is a highly ill-posed problem that often requires auxiliary guidance to 1) improve the mapping from degraded inputs to desired outputs, or 2) complement high-quality details lost in the inputs. In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting \\textit{blind face restoration} as a \\textit{code prediction} task, while providing rich visual atoms for generating high-quality faces. Under this paradigm, we propose a Transformer-based prediction network, named \\textit{CodeFormer}, to model the global composition and context of the low-quality faces for code prediction, enabling the discovery of natural faces that closely approximate the target faces even when the inputs are severely degraded. To enhance the adaptiveness for different degradation, we also propose a controllable feature transformation module that allows a flexible trade-off between fidelity and quality. Thanks to the expressive codebook prior and global modeling, \\textit{CodeFormer} outperforms the state of the arts in both quality and fidelity, showing superior robustness to degradation. Extensive experimental results on synthetic and real-world datasets verify the effectiveness of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Coupled Design of Exploiting Record Similarity for Practical Vertical Federated Learning",
        "paper_url": "https://openreview.net/pdf?id=fiBnhdazkyx",
        "paper_authors": [
            "Zhaomin Wu",
            "Qinbin Li",
            "Bingsheng He"
        ],
        "paper_abstract": "Federated learning is a learning paradigm to enable collaborative learning across different parties without revealing raw data. Notably, vertical federated learning (VFL), where parties share the same set of samples but only hold partial features, has a wide range of real-world applications. However, most existing studies in VFL disregard the \"record linkage'' process. They design algorithms either assuming the data from different parties can be exactly linked or simply linking each record with its most similar neighboring record. These approaches may fail to capture the key features from other less similar records. Moreover, such improper linkage cannot be corrected by training since existing approaches provide no feedback on linkage during training. In this paper, we design a novel coupled training paradigm, FedSim, that integrates one-to-many linkage into the training process. Besides enabling VFL in many real-world applications with fuzzy identifiers, FedSim also achieves better performance in traditional VFL tasks. Moreover, we theoretically analyze the additional privacy risk incurred by sharing similarities. Our experiments on eight datasets with various similarity metrics show that FedSim outperforms other state-of-the-art baselines. The codes of FedSim are available at https://github.com/Xtra-Computing/FedSim.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Memorization and Optimization in Deep Neural Networks with Minimum Over-parameterization",
        "paper_url": "https://openreview.net/pdf?id=x8DNliTBSYY",
        "paper_authors": [
            "Simone Bombari",
            "Mohammad Hossein Amani",
            "Marco Mondelli"
        ],
        "paper_abstract": "The Neural Tangent Kernel (NTK) has emerged as a powerful tool to provide memorization, optimization and generalization guarantees in deep neural networks. A line of work has studied the NTK spectrum for two-layer and deep networks with at least a layer with $\\Omega(N)$ neurons, $N$ being the number of training samples. Furthermore, there is increasing evidence suggesting that deep networks with sub-linear layer widths are powerful memorizers and optimizers, as long as the number of parameters exceeds the number of samples. Thus, a natural open question is whether the NTK is well conditioned in such a challenging sub-linear setup. In this paper, we answer this question in the affirmative. Our key technical contribution is a lower bound on the smallest NTK eigenvalue for deep networks with the minimum possible over-parameterization: up to logarithmic factors, the number of parameters is $\\Omega(N)$ and, hence, the number of neurons is as little as $\\Omega(\\sqrt{N})$. To showcase the applicability of our NTK bounds, we provide two results concerning memorization capacity and optimization guarantees for gradient descent training.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Multivariate Time-Series Forecasting with Temporal Polynomial Graph Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=pMumil2EJh",
        "paper_authors": [
            "Yijing Liu",
            "Qinxian Liu",
            "Jian-Wei Zhang",
            "Haozhe Feng",
            "Zhongwei Wang",
            "Zihan Zhou",
            "Wei Chen"
        ],
        "paper_abstract": "Modeling multivariate time series (MTS) is critical in modern intelligent systems. The accurate forecast of MTS data is still challenging due to the complicated latent variable correlation. Recent works apply the Graph Neural Networks (GNNs) to the task, with the basic idea of representing the correlation as a static graph. However, predicting with a static graph causes significant bias because the correlation is time-varying in the real-world MTS data. Besides, there is no gap analysis between the actual correlation and the learned one in their works to validate the effectiveness. This paper proposes a temporal polynomial graph neural network (TPGNN) for accurate MTS forecasting, which represents the dynamic variable correlation as a temporal matrix polynomial in two steps. First, we capture the overall correlation with a static matrix basis. Then, we use a set of time-varying coefficients and the matrix basis to construct a matrix polynomial for each time step. The constructed result empirically captures the precise dynamic correlation of six synthetic MTS datasets generated by a non-repeating random walk model. Moreover, the theoretical analysis shows that TPGNN can achieve perfect approximation under a commutative condition. We conduct extensive experiments on two traffic datasets with prior structure and four benchmark datasets. The results indicate that TPGNN achieves the state-of-the-art on both short-term and long-term MTS forecastings.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Model-Based Imitation Learning for Urban Driving",
        "paper_url": "https://openreview.net/pdf?id=Zk1SbbdZwS",
        "paper_authors": [
            "Anthony Hu",
            "Gianluca Corrado",
            "Nicolas Griffiths",
            "Zachary Murez",
            "Corina Gurau",
            "Hudson Yeo",
            "Alex Kendall",
            "Roberto Cipolla",
            "Jamie Shotton"
        ],
        "paper_abstract": "An accurate model of the environment and the dynamic agents acting in it offers great potential for improving motion planning. We present MILE: a Model-based Imitation LEarning approach to jointly learn a model of the world and a policy for autonomous driving. Our method leverages 3D geometry as an inductive bias and learns a highly compact latent space directly from high-resolution videos of expert demonstrations. Our model is trained on an offline corpus of urban driving data, without any online interaction with the environment. MILE improves upon prior state-of-the-art by 31% in driving score on the CARLA simulator when deployed in a completely new town and new weather conditions. Our model can predict diverse and plausible states and actions, that can be interpretably decoded to bird's-eye view semantic segmentation. Further, we demonstrate that it can execute complex driving manoeuvres from plans entirely predicted in imagination. Our approach is the first camera-only method that models static scene, dynamic scene, and ego-behaviour in an urban driving environment. The code and model weights are available at https://github.com/wayveai/mile.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Multi-resolution Functional Maps with Spectral Attention for Robust Shape Matching",
        "paper_url": "https://openreview.net/pdf?id=2EwEWrNADpT",
        "paper_authors": [
            "Lei Li",
            "Nicolas Donati",
            "Maks Ovsjanikov"
        ],
        "paper_abstract": "In this work, we present a novel non-rigid shape matching framework based on multi-resolution functional maps with spectral attention. Existing functional map learning methods all rely on the critical choice of the spectral resolution hyperparameter, which can severely affect the overall accuracy or lead to overfitting, if not chosen carefully. In this paper, we show that spectral resolution tuning can be alleviated by introducing spectral attention. Our framework is applicable in both supervised and unsupervised settings, and we show that it is possible to train the network so that it can adapt the spectral resolution, depending on the given shape input. More specifically, we propose to compute multi-resolution functional maps that characterize correspondence across a range of spectral resolutions, and introduce a spectral attention network that helps to combine this representation into a single coherent final correspondence. Our approach is not only accurate with near-isometric input, for which a high spectral resolution is typically preferred, but also robust and able to produce reasonable matching even in the presence of significant non-isometric distortion, which poses great challenges to existing methods. We demonstrate the superior performance of our approach through experiments on a suite of challenging near-isometric and non-isometric shape matching benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fully Sparse 3D Object Detection",
        "paper_url": "https://openreview.net/pdf?id=evWx_rWWJuG",
        "paper_authors": [
            "Lue Fan",
            "Feng Wang",
            "Naiyan Wang",
            "Zhaoxiang Zhang"
        ],
        "paper_abstract": "As the perception range of LiDAR increases, LiDAR-based 3D object detection becomes a dominant task in the long-range perception task of autonomous driving. The mainstream 3D object detectors usually build dense feature maps in the network backbone and prediction head. However, the computational and spatial costs on the dense feature map are quadratic to the perception range, which makes them hardly scale up to the long-range setting. To enable efficient long-range LiDAR-based object detection, we build a fully sparse 3D object detector (FSD). The computational and spatial cost of FSD is roughly linear to the number of points and independent of the perception range. FSD is built upon the general sparse voxel encoder and a novel sparse instance recognition (SIR) module.  SIR first groups the points into instances and then applies instance-wise feature extraction and prediction. In this way, SIR resolves the issue of center feature missing, which hinders the design of the fully sparse architecture for all center-based or anchor-based detectors. Moreover, SIR avoids the time-consuming neighbor queries in previous point-based methods by grouping points into instances. We conduct extensive experiments on the large-scale Waymo Open Dataset to reveal the working mechanism of FSD, and state-of-the-art performance is reported. To demonstrate the superiority of FSD in long-range detection, we also conduct experiments on Argoverse 2 Dataset, which has a much larger perception range ($200m$) than Waymo Open Dataset ($75m$).  On such a large perception range, FSD achieves state-of-the-art performance and is 2.4$\\times$ faster than the dense counterpart. Codes will be released.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer",
        "paper_url": "https://openreview.net/pdf?id=fU-m9kQe0ke",
        "paper_authors": [
            "Yanjing Li",
            "Sheng Xu",
            "Baochang Zhang",
            "Xianbin Cao",
            "Peng Gao",
            "Guodong Guo"
        ],
        "paper_abstract": "The large pre-trained vision transformers (ViTs) have demonstrated remarkable performance on various visual tasks, but suffer from expensive computational and memory cost problems when deployed on resource-constrained devices. Among the powerful compression approaches, quantization extremely reduces the computation and memory consumption by low-bit parameters and bit-wise operations. However, low-bit ViTs remain largely unexplored and usually suffer from a significant performance drop compared with the real-valued counterparts. In this work, through extensive empirical analysis, we first identify the bottleneck  for  severe performance drop comes from  the information distortion of the low-bit quantized self-attention map. We then develop an information rectification module (IRM) and a distribution guided distillation (DGD) scheme for fully quantized vision transformers (Q-ViT) to effectively eliminate such distortion, leading to a fully quantized ViTs. We evaluate our methods on popular DeiT and Swin backbones. Extensive experimental results show that our method achieves a much better performance than the prior arts. For example, our Q-ViT can theoretically accelerates the ViT-S by 6.14x and achieves about 80.9% Top-1 accuracy, even surpassing the full-precision counterpart by 1.0% on ImageNet dataset. Our codes and models are attached on https://github.com/YanjingLi0202/Q-ViT",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Stability and Generalization of Kernel Clustering: from Single Kernel to Multiple Kernel",
        "paper_url": "https://openreview.net/pdf?id=QYD9bDWR3R_",
        "paper_authors": [
            "Weixuan Liang",
            "Xinwang Liu",
            "Yong Liu",
            "sihang zhou",
            "Jun-Jie Huang",
            "Siwei Wang",
            "Jiyuan Liu",
            "Yi Zhang",
            "En Zhu"
        ],
        "paper_abstract": "Multiple kernel clustering (MKC) is an important research topic that has been widely studied for decades. However, current methods still face two problems: inefficient when handling out-of-sample data points and lack of theoretical study of the stability and generalization of clustering. In this paper, we propose a novel method that can efficiently compute the embedding of out-of-sample data with a solid generalization guarantee. Specifically, we approximate the eigen functions of the integral operator associated with the linear combination of base kernel functions to construct low-dimensional embeddings of out-of-sample points for efficient multiple kernel clustering. In addition, we, for the first time, theoretically study the stability of clustering algorithms and prove that the single-view version of the proposed method has uniform stability as $\\mathcal{O}\\left(Kn^{-3/2}\\right)$ and establish an upper bound of excess risk as $\\widetilde{\\mathcal{O}}\\left(Kn^{-3/2}+n^{-1/2}\\right)$, where $K$ is the cluster number and $n$ is the number of samples. We then extend the theoretical results to multiple kernel scenarios and find that the stability of MKC depends on kernel weights. As an example, we apply our method to a novel MKC algorithm termed SimpleMKKM and derive the upper bound of its excess clustering risk, which is tighter than the current results. Extensive experimental results validate the effectiveness and efficiency of the proposed method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "UMIX: Improving Importance Weighting for Subpopulation Shift via Uncertainty-Aware Mixup",
        "paper_url": "https://openreview.net/pdf?id=IzpgGB5pC_s",
        "paper_authors": [
            "Zongbo Han",
            "Zhipeng Liang",
            "Fan Yang",
            "Liu Liu",
            "Lanqing Li",
            "Yatao Bian",
            "Peilin Zhao",
            "Bingzhe Wu",
            "Changqing Zhang",
            "Jianhua Yao"
        ],
        "paper_abstract": "Subpopulation shift widely exists in many real-world machine learning applications, referring to the training and test distributions containing the same subpopulation groups but varying in subpopulation frequencies. Importance reweighting is a normal way to handle the subpopulation shift issue by imposing constant or adaptive sampling weights on each sample in the training dataset.  However, some recent studies have recognized that most of these approaches fail to improve the performance over empirical risk minimization especially when applied to over-parameterized neural networks. In this work, we propose a simple yet practical framework, called uncertainty-aware mixup (UMIX), to mitigate the overfitting issue in over-parameterized models by reweighting the ''mixed'' samples according to the sample uncertainty. The training-trajectories-based uncertainty estimation is equipped in the proposed UMIX for each sample to flexibly characterize the subpopulation distribution. We also provide insightful theoretical analysis to verify that UMIX achieves better generalization bounds over prior works. Further, we conduct extensive empirical studies across a wide range of tasks to  validate the effectiveness of our method both qualitatively and quantitatively. Code is available at https://github.com/TencentAILabHealthcare/UMIX.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On the Strong Correlation Between Model Invariance and Generalization",
        "paper_url": "https://openreview.net/pdf?id=QRKmc0dRP75",
        "paper_authors": [
            "Weijian Deng",
            "Stephen Gould",
            "Liang Zheng"
        ],
        "paper_abstract": "Generalization and invariance are two essential properties of  machine learning models. Generalization captures a model's ability to classify unseen data while invariance measures consistency of model predictions on transformations of the data. Existing research suggests a positive relationship: a model generalizing well should be invariant to certain visual factors. Building on this qualitative implication we make two contributions. First, we introduce effective invariance (EI), a simple and reasonable measure of model invariance which does not rely on image labels. Given predictions on a test image and its transformed version, EI measures how well the predictions agree and with what level of confidence. Second, using invariance scores computed by EI, we perform large-scale quantitative correlation studies between generalization and invariance, focusing on rotation and grayscale transformations. From a model-centric view, we observe generalization and invariance of different models exhibit a strong linear relationship, on both in-distribution and out-of-distribution datasets. From a dataset-centric view, we find a certain model's accuracy and invariance linearly correlated on different test sets. Apart from these major findings, other minor but interesting insights are also discussed.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Multi-Object Segmentation by Predicting Probable Motion Patterns",
        "paper_url": "https://openreview.net/pdf?id=_w2-1nXNjvv",
        "paper_authors": [
            "Laurynas Karazija",
            "Subhabrata Choudhury",
            "Iro Laina",
            "Christian Rupprecht",
            "Andrea Vedaldi"
        ],
        "paper_abstract": "We propose a new approach to learn to segment multiple image objects without manual supervision. The method can extract objects form still images, but uses videos for supervision. While prior works have considered motion for segmentation, a key insight is that, while motion can be used to identify objects, not all objects are necessarily in motion: the absence of motion does not imply the absence of objects. Hence, our model learns to predict image regions that are likely to contain motion patterns characteristic of objects moving rigidly. It does not predict specific motion, which cannot be done unambiguously from a still image, but a distribution of possible motions, which includes the possibility that an object does not move at all. We demonstrate the advantage of this approach over its deterministic counterpart and show state-of-the-art unsupervised object segmentation performance on simulated and real-world benchmarks, surpassing methods that use motion even at test time. As our approach is applicable to variety of network architectures that segment the scenes, we also apply it to existing image reconstruction-based models showing drastic improvement. Project page and code: https://www.robots.ox.ac.uk/~vgg/research/ppmp.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Roadblocks for Temporarily Disabling Shortcuts and Learning New Knowledge",
        "paper_url": "https://openreview.net/pdf?id=QjurhjyTAb",
        "paper_authors": [
            "Hongjing Niu",
            "Hanting Li",
            "Feng Zhao",
            "Bin Li"
        ],
        "paper_abstract": "Deep learning models have been found with a tendency of relying on shortcuts, i.e., decision rules that perform well on standard benchmarks but fail when transferred to more challenging testing conditions. Such reliance may hinder deep learning models from learning other task-related features and seriously affect their performance and robustness. Although recent studies have shown some characteristics of shortcuts, there are few investigations on how to help the deep learning models to solve shortcut problems. This paper proposes a framework to address this issue by setting up roadblocks on shortcuts. Specifically, roadblocks are placed when the model is urged to learn to complete a gently modified task to ensure that the learned knowledge, including shortcuts, is insufficient the complete the task. Therefore, the model trained on the modified task will no longer over-rely on shortcuts. Extensive experiments demonstrate that the proposed framework significantly improves the training of networks on both synthetic and real-world datasets in terms of both classification accuracy and feature diversity. Moreover, the visualization results show that the mechanism behind the proposed our method is consistent with our expectations. In summary, our approach can effectively disable the shortcuts and thus learn more robust features.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Synthetic Model Combination: An Instance-wise Approach to Unsupervised Ensemble Learning",
        "paper_url": "https://openreview.net/pdf?id=RgWjps_LdkJ",
        "paper_authors": [
            "Alex Chan",
            "Mihaela van der Schaar"
        ],
        "paper_abstract": "Consider making a prediction over new test data without any opportunity to learn from a training set of labelled data - instead given access to a set of expert models and their predictions alongside some limited information about the dataset used to train them. In scenarios from finance to the medical sciences, and even consumer practice, stakeholders have developed models on private data they either cannot, or do not want to, share. Given the value and legislation surrounding personal information, it is not surprising that only the models, and not the data, will be released - the pertinent question becoming: how best to use these models? Previous work has focused on global model selection or ensembling, with the result of a single final model across the feature space. Machine learning models perform notoriously poorly on data outside their training domain however, and so we argue that when ensembling models the weightings for individual instances must reflect their respective domains - in other words models that are more likely to have seen information on that instance should have more attention paid to them. We introduce a method for such an instance-wise ensembling of models, including a novel representation learning step for handling sparse high-dimensional domains. Finally, we demonstrate the need and generalisability of our method on classical machine learning tasks as well as highlighting a real world use case in the pharmacological setting of vancomycin precision dosing.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "4D Unsupervised Object Discovery",
        "paper_url": "https://openreview.net/pdf?id=eQfuHqEsUj",
        "paper_authors": [
            "Yuqi Wang",
            "Yuntao Chen",
            "Zhaoxiang Zhang"
        ],
        "paper_abstract": "Object discovery is a core task in computer vision. While fast progresses have been made in supervised object detection, its unsupervised counterpart remains largely unexplored. With the growth of data volume, the expensive cost of annotations is the major limitation hindering further study.  Therefore, discovering objects without annotations has great significance. However, this task seems impractical on still-image or point cloud alone due to the lack of discriminative information. Previous studies underlook the crucial temporal information and constraints naturally behind multi-modal inputs. In this paper, we propose 4D unsupervised object discovery, jointly discovering objects from 4D data -- 3D point clouds and 2D RGB images with temporal information. We present the first practical approach for this task by proposing a ClusterNet on 3D point clouds, which is jointly iteratively optimized with a 2D localization network. Extensive experiments on the large-scale Waymo Open Dataset suggest that the localization network and ClusterNet achieve competitive performance on both class-agnostic 2D object detection and 3D instance segmentation, bridging the gap between unsupervised methods and full supervised ones. Codes and models will be made available at https://github.com/Robertwyq/LSMOL.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Hierarchical  Normalization for Robust Monocular Depth Estimation",
        "paper_url": "https://openreview.net/pdf?id=BNqRpzwyOFU",
        "paper_authors": [
            "Chi Zhang",
            "Wei Yin",
            "Billzb Wang",
            "Gang YU",
            "BIN FU",
            "Chunhua Shen"
        ],
        "paper_abstract": "In this paper, we address monocular depth estimation with deep neural networks. To enable training of deep monocular estimation models with various sources of datasets, state-of-the-art methods adopt image-level normalization strategies to generate affine-invariant depth representations. However, learning with the image-level normalization mainly emphasizes the relations of pixel representations with the global statistic in the images, such as the structure of the scene, while the fine-grained depth difference may be overlooked. In this paper, we propose a novel multi-scale depth normalization method that hierarchically normalizes the depth representations based on \nspatial information and depth distributions. Compared with previous normalization strategies applied only at the holistic image level, the proposed hierarchical normalization can effectively preserve the fine-grained details and improve accuracy. We present two strategies that define the hierarchical normalization contexts in the depth domain and the spatial domain, respectively. Our extensive experiments show that the proposed normalization strategy remarkably outperforms previous normalization methods, and we set new state-of-the-art on five zero-shot transfer benchmark datasets. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Whitening Convergence Rate of Coupling-based Normalizing Flows",
        "paper_url": "https://openreview.net/pdf?id=TN4UpY_Qzo",
        "paper_authors": [
            "Felix Draxler",
            "Christoph Schnoerr",
            "Ullrich Koethe"
        ],
        "paper_abstract": "Coupling-based normalizing flows (e.g. RealNVP) are a popular family of normalizing flow architectures that work surprisingly well in practice. This calls for theoretical understanding. Existing work shows that such flows weakly converge to arbitrary data distributions. However, they make no statement about the stricter convergence criterion used in practice, the maximum likelihood loss. For the first time, we make a quantitative statement about this kind of convergence: We prove that all coupling-based normalizing flows perform whitening of the data distribution (i.e. diagonalize the covariance matrix) and derive corresponding convergence bounds that show a linear convergence rate in the depth of the flow. Numerical experiments demonstrate the implications of our theory and point at open questions.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Estimating Noise Transition Matrix with Label Correlations for Noisy Multi-Label Learning",
        "paper_url": "https://openreview.net/pdf?id=GwXrGy_vc8m",
        "paper_authors": [
            "Shikun Li",
            "Xiaobo Xia",
            "Hansong Zhang",
            "Yibing Zhan",
            "Shiming Ge",
            "Tongliang Liu"
        ],
        "paper_abstract": "In label-noise learning, the noise transition matrix, bridging the class posterior for noisy and clean data, has been widely exploited to learn statistically consistent classifiers. The effectiveness of these algorithms relies heavily on estimating the transition matrix. Recently, the problem of label-noise learning in multi-label classification has received increasing attention, and these consistent algorithms can be applied in multi-label cases. However, the estimation of transition matrices in noisy multi-label learning has not been studied and remains challenging, since most of the existing estimators in noisy multi-class learning depend on the existence of anchor points and the accurate fitting of noisy class posterior. To address this problem, in this paper, we first study the identifiability problem of the class-dependent transition matrix in noisy multi-label learning, and then inspired by the identifiability results, we propose a new estimator by exploiting label correlations without neither anchor points nor accurate fitting of noisy class posterior. Specifically, we estimate the occurrence probability of two noisy labels to get noisy label correlations. Then, we perform sample selection to further extract information that implies clean label correlations, which is used to estimate the occurrence probability of one noisy label when a certain clean label appears. By utilizing the mismatch of label correlations implied in these occurrence probabilities, the transition matrix is identifiable, and can then be acquired by solving a simple bilinear decomposition problem. Empirical results demonstrate the effectiveness of our estimator to estimate the transition matrix with label correlations, leading to better classification performance. Source codes are available at https://github.com/tmllab/Multi-Label-T.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Advancing Model Pruning via Bi-level Optimization",
        "paper_url": "https://openreview.net/pdf?id=t6O08FxvtBY",
        "paper_authors": [
            "Yihua Zhang",
            "Yuguang Yao",
            "Parikshit Ram",
            "Pu Zhao",
            "Tianlong Chen",
            "Mingyi Hong",
            "Yanzhi Wang",
            "Sijia Liu"
        ],
        "paper_abstract": "The deployment constraints in practical applications necessitate the pruning of large-scale deep learning models, i.e., promoting their weight sparsity. As illustrated by the Lottery Ticket Hypothesis (LTH), pruning also has the potential of improving their generalization ability. At the core of LTH, iterative magnitude pruning (IMP) is the predominant pruning method to successfully find \u2018winning tickets\u2019. Yet, the computation cost of IMP grows prohibitively as the targeted pruning ratio increases. To reduce the computation overhead, various efficient \u2018one-shot\u2019 pruning methods have been developed, but these schemes are usually unable to find winning tickets as good as IMP. This raises the question of how to close the gap between pruning accuracy and pruning efficiency? To tackle it, we pursue the algorithmic advancement of model pruning. Specifically, we formulate the pruning problem from a fresh and novel viewpoint, bi-level optimization (BLO). We show that the BLO interpretation provides a technically-grounded optimization base for an efficient implementation of the pruning-retraining learning paradigm used in IMP. We also show that the proposed bi-level optimization-oriented pruning method (termed BiP) is a special class of BLO problems with a bi-linear problem structure. By leveraging such bi-linearity, we theoretically show that BiP can be solved as easily as first-order optimization, thus inheriting the computation efficiency. Through extensive experiments on both structured and unstructured pruning with 5 model architectures and 4 data sets, we demonstrate that BiP can find better winning tickets than IMP in most cases, and is computationally as efficient as the one-shot pruning schemes, demonstrating $2-7\\times$ speedup over IMP for the same level of model accuracy and sparsity.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learn what matters: cross-domain imitation learning with task-relevant embeddings",
        "paper_url": "https://openreview.net/pdf?id=_w-ivKc1cj",
        "paper_authors": [
            "Tim Franzmeyer",
            "Philip Torr",
            "Joao F. Henriques"
        ],
        "paper_abstract": "We study how an autonomous agent learns to perform a task from demonstrations in a different domain, such as a different environment or different agent. Such cross-domain imitation learning is required to, for example, train an artificial agent from demonstrations of a human expert. We propose a scalable framework that enables cross-domain imitation learning without access to additional demonstrations or further domain knowledge. We jointly train the learner agent's policy and learn a mapping between the learner and expert domains with adversarial training. We effect this by using a mutual information criterion to find an embedding of the expert's state space that contains task-relevant information and is invariant to domain specifics. This step significantly simplifies estimating the mapping between the learner and expert domains and hence facilitates end-to-end learning. We demonstrate successful transfer of policies between considerably different domains, without extra supervision such as additional demonstrations, and in situations where other methods fail.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HumanLiker: A Human-like Object Detector to Model the Manual Labeling Process",
        "paper_url": "https://openreview.net/pdf?id=_VF5QKgXoqt",
        "paper_authors": [
            "Haoran Wei",
            "Ping Guo",
            "Yangguang Zhu",
            "Chenglong Liu",
            "Peng Wang"
        ],
        "paper_abstract": "Popular object detection models generate bounding boxes in a different way than we humans. As an example, modern detectors yield object box either upon the regression of its center and width/height (center-guided detector), or by grouping paired estimated corners (corner-guided detector). However, that is not the pattern we manually label an object due to high degrees of freedom in searching centers or low efficiency of grouping corners. Empirically, humans run two steps to locate an object bounding box manually: 1) click the mouse at the top-left corner of object, and then drag the mouse to the bottom-right corner; 2) refine the corner positions to make the bounding box more precisely, if necessary.  Inspired by this manual labeling process, we propose a novel human-like detector, termed as HumanLiker, which is devised as a two-stage end-to-end detector to simulate the two aforementioned. Like we humans in manual labeling, HumanLiker can effectively avert both the thorny center searching and heuristic corner grouping. Different from the mainstream detector branches, i.e., the center/corner-guided methods, the HumanLiker provides a new paradigm which integrates the advantages of both branches to balance the detection efficiency and bounding box quality. On MS-COCO test-dev set, HumanLiker can achieve 50.2%/51.6% and 53.8%/55.6% in term of AP with ResNeXt-101 and SwinTransformer backbones in single/multi-scale testing, outperforming current popular center/corner-guided baselines (e.g., DETR/CornerNet) by a large margin, with much less training epochs and higher inference FPS.  Code will be available soon.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Lightweight Black-Box Attack Against Deep Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=Gpqqm4p91Ez",
        "paper_authors": [
            "Chenghao Sun",
            "Yonggang Zhang",
            "Wan Chaoqun",
            "Qizhou Wang",
            "Ya Li",
            "Tongliang Liu",
            "Bo Han",
            "Xinmei Tian"
        ],
        "paper_abstract": "Black-box attacks can generate adversarial examples without accessing the parameters of target model, largely exacerbating the threats of deployed deep neural networks (DNNs). However, previous works state that black-box attacks fail to mislead target models when their training data and outputs are inaccessible. In this work, we argue that black-box attacks can pose practical attacks in this extremely restrictive scenario where only several test samples are available.  Specifically, we find that attacking the shallow layers of DNNs trained on a few test samples can generate powerful adversarial examples. As only a few samples are required, we refer to these attacks as lightweight black-box attacks. The main challenge to promoting lightweight attacks is to mitigate the adverse impact caused by the approximation error of shallow layers. As it is hard to mitigate the approximation error with few available samples, we propose Error TransFormer (ETF) for lightweight attacks. Namely, ETF transforms the approximation error in the parameter space into a perturbation in the feature space and alleviates the error by disturbing features. In experiments, lightweight black-box attacks with the proposed ETF achieve surprising results. For example, even if only 1 sample per category available, the attack success rate in lightweight black-box attacks is only about 3% lower than that of the black-box attacks with complete training data. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models",
        "paper_url": "https://openreview.net/pdf?id=BZ92dxDS3tO",
        "paper_authors": [
            "Xingyi He",
            "Jiaming Sun",
            "Yuang Wang",
            "Di Huang",
            "Hujun Bao",
            "Xiaowei Zhou"
        ],
        "paper_abstract": "We propose a new method for object pose estimation without CAD models. The previous feature-matching-based method OnePose has shown promising results under a one-shot setting which eliminates the need for CAD models or object-specific training. However, OnePose relies on detecting repeatable image keypoints and is thus prone to failure on low-textured objects. We propose a keypoint-free pose estimation pipeline to remove the need for repeatable keypoint detection. Built upon the detector-free feature matching method LoFTR, we devise a new keypoint-free SfM method to reconstruct a semi-dense point-cloud model for the object. Given a query image for object pose estimation, a 2D-3D matching network directly establishes 2D-3D correspondences between the query image and the reconstructed point-cloud model without first detecting keypoints in the image. Experiments show that the proposed pipeline outperforms existing one-shot CAD-model-free methods by a large margin and is comparable to CAD-model-based methods on LINEMOD even for low-textured objects. We also collect a new dataset composed of 80 sequences of 40 low-textured objects to facilitate future research on one-shot object pose estimation. The supplementary material, code and dataset are available on the project page: https://zju3dv.github.io/onepose_plus_plus/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DeepInteraction: 3D Object Detection via Modality Interaction",
        "paper_url": "https://openreview.net/pdf?id=rY2wXCSruO",
        "paper_authors": [
            "Zeyu Yang",
            "Jiaqi Chen",
            "Zhenwei Miao",
            "Wei Li",
            "Xiatian Zhu",
            "Li Zhang"
        ],
        "paper_abstract": "Existing top-performance 3D object detectors typically rely on the multi-modal fusion strategy. This design is however fundamentally restricted due to overlooking the modality-specific useful information and finally hampering the model performance. To address this limitation, in this work we introduce a novel modality interaction strategy where individual per-modality representations are learned and maintained throughout for enabling their unique characteristics to be exploited during object detection. To realize this proposed strategy, we design a DeepInteraction architecture characterized by a multi-modal representational interaction encoder and a multi-modal predictive interaction decoder. Experiments on the large-scale nuScenes dataset show that our proposed method surpasses all prior arts often by a large margin. Crucially, our method is ranked at the first position at the highly competitive nuScenes object detection leaderboard.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MoVQ: Modulating Quantized Vectors for High-Fidelity Image Generation",
        "paper_url": "https://openreview.net/pdf?id=Qb-AoSw4Jnm",
        "paper_authors": [
            "Chuanxia Zheng",
            "Long Tung Vuong",
            "Jianfei Cai",
            "Dinh Phung"
        ],
        "paper_abstract": "Although two-stage Vector Quantized (VQ) generative models allow for synthesizing high-fidelity and high-resolution images, their quantization operator encodes similar patches within an image into the same index, resulting in a repeated artifact for similar adjacent regions using existing decoder architectures. To address this issue, we propose to incorporate the spatially conditional normalization to modulate the quantized vectors so as to insert spatially variant information to the embedded index maps, encouraging the decoder to generate more photorealistic images. Moreover, we use multichannel quantization to increase the recombination capability of the discrete codes without increasing the cost of model and codebook. Additionally, to generate discrete tokens at the second stage, we adopt a Masked Generative Image Transformer (MaskGIT) to learn an underlying prior distribution in the compressed latent space, which is much faster than the conventional autoregressive model. Experiments on two benchmark datasets demonstrate that our proposed modulated VQGAN is able to greatly improve the reconstructed image quality as well as provide high-fidelity image generation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TransTab: Learning Transferable Tabular Transformers Across Tables",
        "paper_url": "https://openreview.net/pdf?id=A1yGs_SWiIi",
        "paper_authors": [
            "Zifeng Wang",
            "Jimeng Sun"
        ],
        "paper_abstract": "Tabular data (or tables) are the most widely used data format in machine learning (ML). However, ML models often assume the table structure keeps fixed in training and testing. Before ML modeling, heavy data cleaning is required to merge disparate tables with different columns. This preprocessing often incurs significant data waste (e.g., removing unmatched columns and samples). How to learn ML models from multiple tables with partially overlapping columns? How to incrementally update ML models as more columns become available over time? Can we leverage model pretraining on multiple distinct tables? How to train an ML model which can predict on an unseen table? \n\nTo answer all those questions, we propose to relax fixed table structures by introducing a Transferable Tabular Transformer (TransTab) for tables. The goal of TransTab is to convert each sample (a row in the table) to a generalizable embedding vector, and then apply stacked transformers for feature encoding. One methodology insight is combining column description and table cells as the raw input to a gated transformer model. The other insight is to introduce supervised and self-supervised pretraining to improve model performance. We compare TransTab with multiple baseline methods on diverse benchmark datasets and five oncology clinical trial datasets. Overall, TransTab ranks 1.00, 1.00, 1.78 out of 12 methods in supervised learning, incremental feature learning, and transfer learning scenarios, respectively; and the proposed pretraining leads to 2.3\\% AUC lift on average over the supervised learning.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Towards Efficient 3D Object Detection with Knowledge Distillation",
        "paper_url": "https://openreview.net/pdf?id=1tnVNogPUz9",
        "paper_authors": [
            "Jihan Yang",
            "Shaoshuai Shi",
            "Runyu Ding",
            "Zhe Wang",
            "XIAOJUAN QI"
        ],
        "paper_abstract": "Despite substantial progress in 3D object detection, advanced 3D detectors often suffer from heavy computation overheads. To this end, we explore the potential of knowledge distillation (KD) for developing efficient 3D object detectors, focusing on popular pillar- and voxel-based detectors. In the absence of well-developed teacher-student pairs, we first study how to obtain student models with good trade offs between accuracy and efficiency from the perspectives of model compression and input resolution reduction. Then, we build a benchmark to assess existing KD methods developed in the 2D domain for 3D object detection upon six well-constructed teacher-student pairs. Further, we propose an improved KD pipeline incorporating an enhanced logit KD method that performs KD on only a few pivotal positions determined by teacher classification response and a teacher-guided student model initialization to facilitate transferring teacher model's feature extraction ability to students through weight inheritance. Finally, we conduct extensive experiments on the Waymo dataset. Our best performing model achieves $65.75\\%$ LEVEL 2 mAPH surpassing its teacher model and requiring only $44\\%$ of teacher flops. Our most efficient model runs 51 FPS on an NVIDIA A100, which is $2.2\\times$ faster than PointPillar with even higher accuracy. Code will be available.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Tensor Wheel Decomposition and Its Tensor Completion Application",
        "paper_url": "https://openreview.net/pdf?id=Ag3ycrdh6n",
        "paper_authors": [
            "Zhong-Cheng Wu",
            "Ting-Zhu Huang",
            "Liang-Jian Deng",
            "Hong-Xia Dou",
            "Deyu Meng"
        ],
        "paper_abstract": "Recently, tensor network (TN) decompositions have gained prominence in computer vision and contributed promising results to high-order data recovery tasks. However, current TN models are rather being developed towards more intricate structures to pursue incremental improvements, which instead leads to a dramatic increase in rank numbers, thus encountering laborious hyper-parameter selection, especially for higher-order cases. In this paper, we propose a novel TN decomposition, dubbed tensor wheel (TW) decomposition, in which a high-order tensor is represented by a set of latent factors mapped into a specific wheel topology. Such decomposition is constructed starting from analyzing the graph structure, aiming to more accurately characterize the complex interactions inside objectives while maintaining a lower hyper-parameter scale, theoretically alleviating the above deficiencies. Furthermore, to investigate the potentiality of TW decomposition, we provide its one numerical application, i.e., tensor completion (TC), yet develop an efficient proximal alternating minimization-based solving algorithm with guaranteed convergence. Experimental results elaborate that the proposed method is significantly superior to other tensor decomposition-based state-of-the-art methods on synthetic and real-world data, implying the merits of TW decomposition. The code is available at: https://github.com/zhongchengwu/code_TWDec.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Optimistic Tree Searches for Combinatorial Black-Box Optimization",
        "paper_url": "https://openreview.net/pdf?id=JGLW4DvX11F",
        "paper_authors": [
            "Cedric Malherbe",
            "Antoine Grosnit",
            "Rasul Tutunov",
            "Haitham Bou Ammar",
            "Jun Wang"
        ],
        "paper_abstract": "The optimization of combinatorial black-box functions is pervasive in computer science and engineering. However, the combinatorial explosion of the search space and lack of natural ordering pose significant challenges for current techniques from a theoretical and practical perspective, and require new algorithmic ideas. In this paper, we propose to adapt the recent advances in tree searches and partitioning techniques to design and analyze novel black-box combinatorial solvers. A first contribution is the analysis of a first tree-search algorithm called Optimistic Lipschitz Tree Search (OLTS) which assumes the Lipschitz constant of the function to be known. Linear convergence rates are provided for this algorithm under specific conditions, improving upon the logarithmic rates of baselines. An adaptive version, called Optimistic Combinatorial Tree Search (OCTS), is then introduced for the more realistic setup where we do not have any information on the Lipschitz constant of the function. Similar theoretical guarantees are shown to hold for OCTS and a numerical assessment is provided to illustrate the potential of tree searches with respect to state-of-the-art methods over typical benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Recurrent Video Restoration Transformer with Guided Deformable Attention",
        "paper_url": "https://openreview.net/pdf?id=GKfNB4BegL",
        "paper_authors": [
            "Jingyun Liang",
            "Yuchen Fan",
            "Xiaoyu Xiang",
            "Rakesh Ranjan",
            "Eddy Ilg",
            "Simon Green",
            "Jiezhang Cao",
            "Kai Zhang",
            "Radu Timofte",
            "Luc Van Gool"
        ],
        "paper_abstract": "Video restoration aims at restoring multiple high-quality frames from multiple low-quality frames. Existing video restoration methods generally fall into two extreme cases, i.e., they either restore all frames in parallel or restore the video frame by frame in a recurrent way, which would result in different merits and drawbacks. Typically, the former has the advantage of temporal information fusion. However, it suffers from large model size and intensive memory consumption; the latter has a relatively small model size as it shares parameters across frames; however, it lacks long-range dependency modeling ability and parallelizability. In this paper, we attempt to integrate the advantages of the two cases by proposing a recurrent video restoration transformer, namely RVRT. RVRT processes local neighboring frames in parallel within a globally recurrent framework which can achieve a good trade-off between model size, effectiveness, and efficiency. Specifically, RVRT divides the video into multiple clips and uses the previously inferred clip feature to estimate the subsequent clip feature. Within each clip, different frame features are jointly updated with implicit feature aggregation. Across different clips, the guided deformable attention is designed for clip-to-clip alignment, which predicts multiple relevant locations from the whole inferred clip and aggregates their features by the attention mechanism. Extensive experiments on video super-resolution, deblurring, and denoising show that the proposed RVRT achieves state-of-the-art performance on benchmark datasets with balanced model size, testing memory and runtime.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection",
        "paper_url": "https://openreview.net/pdf?id=kCTZt0b9DQz",
        "paper_authors": [
            "Shizhen Zhao",
            "XIAOJUAN QI"
        ],
        "paper_abstract": "Most existing 3D point cloud object detection approaches heavily rely on large amounts of labeled training data. However, the labeling process is costly and time-consuming. This paper considers few-shot 3D point cloud object detection, where only a few annotated samples of novel classes are needed with abundant samples of base classes. To this end, we propose Prototypical VoteNet to recognize and localize novel instances, which incorporates two new modules: Prototypical Vote Module (PVM) and Prototypical Head Module (PHM). Specifically, as the 3D basic geometric structures can be shared among categories, PVM is designed to leverage class-agnostic geometric prototypes, which are learned from base classes, to refine local features of novel categories. Then PHM is proposed to utilize class prototypes to enhance the global feature of each object, facilitating subsequent object localization and classification, which is trained by the episodic training strategy. To evaluate the model in this new setting, we contribute two new benchmark datasets, FS-ScanNet and FS-SUNRGBD. We conduct extensive experiments to demonstrate the effectiveness of Prototypical VoteNet, and our proposed method shows significant and consistent improvements compared to baselines on two benchmark datasets. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation",
        "paper_url": "https://openreview.net/pdf?id=dVXO3Orjmxk",
        "paper_authors": [
            "Bin-Bin Gao",
            "Xiaochen Chen",
            "Zhongyi Huang",
            "Congchong Nie",
            "Jun Liu",
            "Jinxiang Lai",
            "GUANNAN JIANG",
            "Xi Wang",
            "Chengjie Wang"
        ],
        "paper_abstract": "This paper focus on few-shot object detection~(FSOD) and instance segmentation~(FSIS), which requires a model to quickly adapt to novel classes with a few labeled instances. The existing methods severely suffer from bias classification because of the missing label issue which naturally exists in an instance-level few-shot scenario and is first formally proposed by us. Our analysis suggests that the standard classification head of most FSOD or FSIS models needs to be decoupled to mitigate the bias classification. Therefore, we propose an embarrassingly simple but effective method that decouples the standard classifier into two heads. Then, these two individual heads are capable of independently addressing clear positive samples and noisy negative samples which are caused by the missing label. In this way, the model can effectively learn novel classes while mitigating the effects of noisy negative samples. Without bells and whistles, our model without any additional computation cost and parameters consistently outperforms its baseline and state-of-the-art by a large margin on PASCAL VOC and MS-COCO benchmarks for FSOD and FSIS tasks.\\footnote{\\url{https://csgaobb.github.io/Projects/DCFS}.}",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Knowledge Distillation from Model Checkpoints",
        "paper_url": "https://openreview.net/pdf?id=0ltDq6SjrfW",
        "paper_authors": [
            "Chaofei Wang",
            "Qisen Yang",
            "Rui Huang",
            "Shiji Song",
            "Gao Huang"
        ],
        "paper_abstract": "Knowledge distillation is an effective approach to learn compact models (students) with the supervision of large and strong models (teachers). As empirically there exists a strong correlation between the performance of teacher and student models, it is commonly believed that a high performing teacher is preferred. Consequently, practitioners tend to use a well trained network or an ensemble of them as the teacher. In this paper, we observe that an intermediate model, i.e., a checkpoint in the middle of the training procedure, often serves as a better teacher compared to the fully converged model, although the former has much lower accuracy. More surprisingly, a weak snapshot ensemble of several intermediate models from a same training trajectory can outperform a strong ensemble of independently trained and fully converged models, when they are used as teachers. We show that this phenomenon can be partially explained by the information bottleneck principle: the feature representations of intermediate models can have higher mutual information regarding the input, and thus contain more ``dark knowledge'' for effective distillation. We further propose an optimal intermediate teacher selection algorithm based on maximizing the total task-related mutual information. Experiments verify its effectiveness and applicability. Our code is available at https://github.com/LeapLabTHU/CheckpointKD.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds",
        "paper_url": "https://openreview.net/pdf?id=wS23xAeKwSN",
        "paper_authors": [
            "Aoran Xiao",
            "Jiaxing Huang",
            "Dayan Guan",
            "Kaiwen Cui",
            "Shijian Lu",
            "Ling Shao"
        ],
        "paper_abstract": "LiDAR point clouds, which are usually scanned by rotating LiDAR sensors continuously, capture precise geometry of the surrounding environment and are crucial to many autonomous detection and navigation tasks. Though many 3D deep architectures have been developed, efficient collection and annotation of large amounts of point clouds remain one major challenge in the analytics and understanding of point cloud data. This paper presents PolarMix, a point cloud augmentation technique that is simple and generic but can mitigate the data constraint effectively across various perception tasks and scenarios. PolarMix enriches point cloud distributions and preserves point cloud fidelity via two cross-scan augmentation strategies that cut, edit, and mix point clouds along the scanning direction. The first is scene-level swapping which exchanges point cloud sectors of two LiDAR scans that are cut along the LiDAR scanning direction. The second is instance-level rotation and paste which crops point instances from one LiDAR scan, rotates them by multiple angles (to create multiple copies), and paste the rotated point instances into other scans. Extensive experiments show that PolarMix achieves superior performance consistently across different perception tasks and scenarios. In addition, it can work as a plug-and-play for various 3D deep architectures and also performs well for unsupervised domain adaptation. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Is Out-of-Distribution Detection Learnable?",
        "paper_url": "https://openreview.net/pdf?id=sde_7ZzGXOE",
        "paper_authors": [
            "Zhen Fang",
            "Yixuan Li",
            "Jie Lu",
            "Jiahua Dong",
            "Bo Han",
            "Feng Liu"
        ],
        "paper_abstract": "Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms. To study the generalization of OOD detection, in this paper, we investigate the probably approximately correct (PAC) learning theory of OOD detection, which is proposed by researchers as an open problem. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we also offer theoretical supports for several representative OOD detection works based on our OOD theory.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Let Images Give You More: Point Cloud Cross-Modal Training for Shape Analysis",
        "paper_url": "https://openreview.net/pdf?id=1qXIyIxLbEu",
        "paper_authors": [
            "Xu Yan",
            "Heshen Zhan",
            "Chaoda Zheng",
            "Jiantao Gao",
            "Ruimao Zhang",
            "Shuguang Cui",
            "Zhen Li"
        ],
        "paper_abstract": "Although recent point cloud analysis achieves impressive progress, the paradigm of representation learning from single modality gradually meets its bottleneck. In this work, we take a step towards more discriminative 3D point cloud representation using 2D images, which inherently contain richer appearance information, e.g., texture, color, and shade. Specifically, this paper introduces a simple but effective point cloud cross-modality training (PointCMT) strategy, which utilizes view-images, i.e., rendered or projected 2D images of the 3D object, to boost point cloud classification. In practice, to effectively acquire auxiliary knowledge from view-images, we develop a teacher-student framework and formulate the cross-modal learning as a knowledge distillation problem. Through novel feature and classifier enhancement criteria, PointCMT eliminates the distribution discrepancy between different modalities and avoid potential negative transfer effectively. Note that PointCMT efficiently improves the point-only representation without any architecture modification. Sufficient experiments verify significant gains on various datasets based on several backbones, i.e., equipped with PointCMT, PointNet++ and PointMLP achieve state-of-the-art performance on two benchmarks, i.e., 94.4% and 86.7% accuracy on ModelNet40 and ScanObjectNN, respectively.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork",
        "paper_url": "https://openreview.net/pdf?id=h10xdBrOxNI",
        "paper_authors": [
            "Haotao Wang",
            "Junyuan Hong",
            "Aston Zhang",
            "Jiayu Zhou",
            "Zhangyang Wang"
        ],
        "paper_abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks. Previous works have shown it extremely challenging to unlearn the undesired backdoor behavior from the network, since the entire network can be affected by the backdoor samples. In this paper, we propose a brand-new backdoor defense strategy, which makes it much easier to remove the harmful influence of backdoor samples from the model. Our defense strategy, \\emph{Trap and Replace}, consists of two stages. In the first stage, we bait and trap the backdoors in a small and easy-to-replace subnetwork. Specifically, we add an auxiliary image reconstruction head on top of the stem network shared with a light-weighted classification head. The intuition is that the auxiliary image reconstruction task encourages the stem network to keep sufficient low-level visual features that are hard to learn but semantically correct, instead of overfitting to the easy-to-learn but semantically incorrect backdoor correlations.  As a result, when trained on backdoored datasets, the backdoors are easily baited towards the unprotected classification head, since it is much more vulnerable than the shared stem, leaving the stem network hardly poisoned. In the second stage, we replace the poisoned light-weighted classification head with an untainted one, by re-training it from scratch only on a small holdout dataset with clean samples, while fixing the stem network. As a result, both the stem and the classification head in the final network are hardly affected by backdoor training samples. We evaluate our method against ten different backdoor attacks. Our method outperforms previous state-of-the-art methods by up to $20.57\\%$, $9.80\\%$, and $13.72\\%$ attack success rate and on-average $3.14\\%$, $1.80\\%$, and $1.21\\%$ clean classification accuracy on CIFAR10, GTSRB, and ImageNet-12, respectively. Code is available at https://github.com/VITA-Group/Trap-and-Replace-Backdoor-Defense.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Masked Autoencoders As Spatiotemporal Learners",
        "paper_url": "https://openreview.net/pdf?id=UaXD4Al3mdb",
        "paper_authors": [
            "Christoph Feichtenhofer",
            "Haoqi Fan",
            "Yanghao Li",
            "Kaiming He"
        ],
        "paper_abstract": "This paper studies a conceptually simple extension of Masked Autoencoders (MAE) to spatiotemporal representation learning from videos. We randomly mask out spacetime patches in videos and learn an autoencoder to reconstruct them in pixels. Interestingly, we show that our MAE method can learn strong representations with almost no inductive bias on spacetime (only except for patch and positional embeddings), and spacetime-agnostic random masking performs the best. We observe that the optimal masking ratio is as high as 90% (vs. 75% on images), supporting the hypothesis that this ratio is related to information redundancy of the data. A high masking ratio leads to a large speedup, e.g., > 4x in wall-clock time or even more. We report competitive results on several challenging video datasets using vanilla Vision Transformers. We observe that MAE can outperform supervised pre-training by large margins. We further report encouraging results of training on real-world, uncurated Instagram data. Our study suggests that the general framework of masked autoencoding (BERT, MAE, etc.) can be a unified methodology for representation learning with minimal domain knowledge.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "TOIST: Task Oriented Instance Segmentation Transformer with Noun-Pronoun Distillation",
        "paper_url": "https://openreview.net/pdf?id=V91cZ9i_sV3",
        "paper_authors": [
            "Pengfei Li",
            "Beiwen Tian",
            "Yongliang Shi",
            "Xiaoxue Chen",
            "Hao Zhao",
            "Guyue Zhou",
            "Ya-Qin Zhang"
        ],
        "paper_abstract": "Current referring expression comprehension algorithms can effectively detect or segment objects indicated by nouns, but how to understand verb reference is still under-explored. As such, we study the challenging problem of task oriented detection, which aims to find objects that best afford an action indicated by verbs like sit comfortably on. Towards a finer localization that better serves downstream applications like robot interaction, we extend the problem into task oriented instance segmentation. A unique requirement of this task is to select preferred candidates among possible alternatives. Thus we resort to the transformer architecture which naturally models pair-wise query relationships with attention, leading to the TOIST method. In order to leverage pre-trained noun referring expression comprehension models and the fact that we can access privileged noun ground truth during training, a novel noun-pronoun distillation framework is proposed. Noun prototypes are generated in an unsupervised manner and contextual pronoun features are trained to select prototypes. As such, the network remains noun-agnostic during inference. We evaluate TOIST on the large-scale task oriented dataset COCO-Tasks and achieve +10.7% higher $\\rm{mAP^{box}}$ than the best-reported results. The proposed noun-pronoun distillation can boost $\\rm{mAP^{box}}$ and $\\rm{mAP^{mask}}$ by +2.6% and +3.6%. Codes and models are publicly available.\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Cross-Image Context for Single Image Inpainting",
        "paper_url": "https://openreview.net/pdf?id=QfI_usBXNCM",
        "paper_authors": [
            "Tingliang Feng",
            "Wei Feng",
            "Weiqi Li",
            "Di Lin"
        ],
        "paper_abstract": "Visual context is of crucial importance for image inpainting. The contextual information captures the appearance and semantic correlation between the image regions, helping to propagate the information of the complete regions for reasoning the content of the corrupted regions. Many inpainting methods compute the visual context based on the regions within the single image. In this paper, we propose the Cross-Image Context Memory (CICM) for learning and using the cross-image context to recover the corrupted regions. CICM consists of multiple sets of the cross-image representations learned from the image regions with different visual patterns. The regional representations are learned across different images, thus providing richer context that benefit the inpainting task. The experimental results demonstrate the effectiveness and generalization of CICM, which achieves state-of-the-art performances on various datasets for single image inpainting.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Natural Color Fool: Towards Boosting Black-box Unrestricted Attacks",
        "paper_url": "https://openreview.net/pdf?id=-T5seeOMnM5",
        "paper_authors": [
            "Shengming Yuan",
            "Qilong Zhang",
            "Lianli Gao",
            "Yaya Cheng",
            "Jingkuan Song"
        ],
        "paper_abstract": "Unrestricted color attacks, which manipulate semantically meaningful color of an image, have shown their stealthiness and success in fooling both human eyes and deep neural networks. However, current works usually sacrifice the flexibility of the uncontrolled setting to ensure the naturalness of adversarial examples. As a result, the black-box attack performance of these methods is limited. To boost transferability of adversarial examples without damaging image quality, we propose a novel Natural Color Fool (NCF) which is guided by realistic color distributions sampled from a publicly available dataset and optimized by our neighborhood search and initialization reset. By conducting extensive experiments and visualizations, we convincingly demonstrate the effectiveness of our proposed method. Notably, on average, results show that our NCF can outperform state-of-the-art approaches by 15.0%$\\sim$32.9% for fooling normally trained models and 10.0%$\\sim$25.3% for evading defense methods. Our code is available at https://github.com/VL-Group/Natural-Color-Fool.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adversarial Style Augmentation for Domain Generalized Urban-Scene Segmentation",
        "paper_url": "https://openreview.net/pdf?id=lXUp6skJ7r",
        "paper_authors": [
            "Zhun Zhong",
            "Yuyang Zhao",
            "Gim Hee Lee",
            "Nicu Sebe"
        ],
        "paper_abstract": "In this paper, we consider the problem of domain generalization in semantic segmentation, which aims to learn a robust model using only labeled synthetic (source) data. The model is expected to perform well on unseen real (target) domains. Our study finds that the image style variation can largely influence the model's performance and the style features can be well represented by the channel-wise mean and standard deviation of images. Inspired by this, we propose a novel adversarial style augmentation (AdvStyle) approach, which can dynamically generate hard stylized images during training and thus can effectively prevent the model from overfitting on the source domain. Specifically, AdvStyle regards the style feature as a learnable parameter and updates it by adversarial training. The learned adversarial style feature is used to construct an adversarial image for robust model training. AdvStyle is easy to implement and can be readily applied to different models. Experiments on two synthetic-to-real semantic segmentation benchmarks demonstrate that AdvStyle can significantly improve the model performance on unseen real domains and show that we can achieve the state of the art. Moreover, AdvStyle can be employed to domain generalized image classification and produces a clear improvement on the considered datasets.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "HSurf-Net: Normal Estimation for 3D Point Clouds by Learning Hyper Surfaces",
        "paper_url": "https://openreview.net/pdf?id=_yEcbgIT68e",
        "paper_authors": [
            "Qing Li",
            "Yu-Shen Liu",
            "Jin-San Cheng",
            "Cheng Wang",
            "Yi Fang",
            "Zhizhong Han"
        ],
        "paper_abstract": "We propose a novel normal estimation method called HSurf-Net, which can accurately predict normals from point clouds with noise and density variations. Previous methods focus on learning point weights to fit neighborhoods into a geometric surface approximated by a polynomial function with a predefined order, based on which normals are estimated. However, fitting surfaces explicitly from raw point clouds suffers from overfitting or underfitting issues caused by inappropriate polynomial orders and outliers, which significantly limits the performance of existing methods. To address these issues, we introduce hyper surface fitting to implicitly learn hyper surfaces, which are represented by multi-layer perceptron (MLP) layers that take point features as input and output surface patterns in a high dimensional feature space. We introduce a novel space transformation module, which consists of a sequence of local aggregation layers and global shift layers, to learn an optimal feature space, and a relative position encoding module to effectively convert point clouds into the learned feature space. Our model learns hyper surfaces from the noise-less features and directly predicts normal vectors. We jointly optimize the MLP weights and module parameters in a data-driven manner to make the model adaptively find the most suitable surface pattern for various points. Experimental results show that our HSurf-Net achieves the state-of-the-art performance on the synthetic shape dataset, the real-world indoor and outdoor scene datasets. The code, data and pretrained models are publicly available.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning",
        "paper_url": "https://openreview.net/pdf?id=gkQkZy-pRik",
        "paper_authors": [
            "Jiangmeng Li",
            "Wenwen Qiang",
            "Yanan Zhang",
            "Wenyi Mo",
            "Changwen Zheng",
            "Bing Su",
            "Hui Xiong"
        ],
        "paper_abstract": "As a successful approach to self-supervised learning, contrastive learning aims to learn invariant information shared among distortions of the input sample. While contrastive learning has yielded continuous advancements in sampling strategy and architecture design, it still remains two persistent defects: the interference of task-irrelevant information and sample inefficiency, which are related to the recurring existence of trivial constant solutions. From the perspective of dimensional analysis, we find out that the dimensional redundancy and dimensional confounder are the intrinsic issues behind the phenomena, and provide experimental evidence to support our viewpoint. We further propose a simple yet effective approach MetaMask, short for the dimensional Mask learned by Meta-learning, to learn representations against dimensional redundancy and confounder. MetaMask adopts the redundancy-reduction technique to tackle the dimensional redundancy issue and innovatively introduces a dimensional mask to reduce the gradient effects of specific dimensions containing the confounder, which is trained by employing a meta-learning paradigm with the objective of improving the performance of masked representations on a typical self-supervised task. We provide solid theoretical analyses to prove MetaMask can obtain tighter risk bounds for downstream classification compared to typical contrastive methods. Empirically, our method achieves state-of-the-art performance on various benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Heterogeneous Skill Learning for Multi-agent Tasks",
        "paper_url": "https://openreview.net/pdf?id=5VCT-DptDTs",
        "paper_authors": [
            "Yuntao Liu",
            "Yuan Li",
            "Xinhai Xu",
            "Yong Dou",
            "Donghong Liu"
        ],
        "paper_abstract": "Heterogeneous behaviours are widespread in many multi-agent tasks, which have not been paid much attention in the community of multi-agent reinforcement learning. It would be a key factor for improving the learning performance to efficiently characterize and automatically find heterogeneous behaviours. In this paper, we introduce the concept of the skill to explore the ability of heterogeneous behaviours. We propose a novel skill-based multi-agent reinforcement learning framework to enable agents to master diverse skills. Specifically, our framework consists of the skill representation mechanism, the skill selector and the skill-based policy learning mechanism. We design an auto-encoder model to generate the latent variable as the skill representation by incorporating the environment information, which ensures the distinguishable of agents for skill selection and the discriminability for the skill learning. With the representation, a skill selection mechanism is invented to realize the assignment from agents to skills. Meanwhile, diverse skill-based policies are generated through a novel skill-based policy learning method. To promote efficient skill discovery, a mutual information based intrinsic reward function is constructed. Empirical results show that our framework obtains the best performance on three challenging benchmarks, i.e., StarCraft II micromanagement tasks, Google Research Football and GoBigger, over state-of-the-art MARL methods.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "ELIAS: End-to-End Learning to Index and Search in Large Output Spaces",
        "paper_url": "https://openreview.net/pdf?id=RF5Lb6NaZp",
        "paper_authors": [
            "Nilesh Gupta",
            "Patrick CHen",
            "Hsiang-Fu Yu",
            "Cho-Jui Hsieh",
            "Inderjit S Dhillon"
        ],
        "paper_abstract": "Extreme multi-label classification (XMC) is a popular framework for solving many real-world problems that require accurate prediction from a very large number of potential output choices. A popular approach for dealing with the large label space is to arrange the labels into a shallow tree-based index and then learn an ML model to efficiently search this index via beam search. Existing methods initialize the tree index by clustering the label space into a few mutually exclusive clusters based on pre-defined features and keep it fixed throughout the training procedure. This approach results in a sub-optimal indexing structure over the label space and limits the search performance to the quality of choices made during the initialization of the index. In this paper, we propose a novel method ELIAS which relaxes the tree-based index to a specialized weighted graph-based index which is learned end-to-end with the final task objective. More specifically, ELIAS models the discrete cluster-to-label assignments in the existing tree-based index as soft learnable parameters that are learned jointly with the rest of the ML model. ELIAS achieves state-of-the-art performance on several large-scale extreme classification benchmarks with millions of labels. In particular, ELIAS can be up to 2.5% better at precision@$1$ and up to 4% better at recall@$100$ than existing XMC methods. A PyTorch implementation of ELIAS along with other resources is available at https://github.com/nilesh2797/ELIAS.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SNAKE: Shape-aware Neural 3D Keypoint Field",
        "paper_url": "https://openreview.net/pdf?id=oWx_9VJgyV7",
        "paper_authors": [
            "Chengliang Zhong",
            "Peixing You",
            "Xiaoxue Chen",
            "Hao Zhao",
            "Fuchun Sun",
            "Guyue Zhou",
            "Xiaodong Mu",
            "Chuang Gan",
            "Wenbing Huang"
        ],
        "paper_abstract": "Detecting 3D keypoints from point clouds is important for shape reconstruction, while this work investigates the dual question: can shape reconstruction benefit 3D keypoint detection? Existing methods either seek salient features according to statistics of different orders or learn to predict keypoints that are invariant to transformation. Nevertheless, the idea of incorporating shape reconstruction into 3D keypoint detection is under-explored. We argue that this is restricted by former problem formulations. To this end, a novel unsupervised paradigm named SNAKE is proposed, which is short for shape-aware neural 3D keypoint field. Similar to recent coordinate-based radiance or distance field, our network takes 3D coordinates as inputs and predicts implicit shape indicators and keypoint saliency simultaneously, thus naturally entangling 3D keypoint detection and shape reconstruction. We achieve superior performance on various public benchmarks, including standalone object datasets ModelNet40, KeypointNet, SMPL meshes and scene-level datasets 3DMatch and Redwood. Intrinsic shape awareness brings several advantages as follows. (1) SNAKE generates 3D keypoints consistent with human semantic annotation, even without such supervision. (2) SNAKE outperforms counterparts in terms of repeatability, especially when the input point clouds are down-sampled. (3) the generated keypoints allow accurate geometric registration, notably in a zero-shot setting. Codes and models are available at https://github.com/zhongcl-thu/SNAKE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Aggregation of Diverse Experts for Test-Agnostic Long-Tailed Recognition",
        "paper_url": "https://openreview.net/pdf?id=m7CmxlpHTiu",
        "paper_authors": [
            "Yifan Zhang",
            "Bryan Hooi",
            "Lanqing HONG",
            "Jiashi Feng"
        ],
        "paper_abstract": "Existing long-tailed recognition methods, aiming to train class-balanced models from long-tailed data, generally assume the models would be evaluated on the uniform test class distribution. However, practical test class distributions often violate this assumption (e.g., being either long-tailed or even inversely long-tailed), which may lead existing methods to fail in real applications. In this paper, we study a more practical yet challenging task, called test-agnostic long-tailed recognition, where the training class distribution is long-tailed while the test class distribution is agnostic and not necessarily uniform. In addition to the issue of class imbalance, this task poses another challenge: the class distribution shift between the training and test data is unknown. To tackle this task, we propose a novel approach, called Self-supervised Aggregation of Diverse Experts, which consists of two strategies: (i) a new skill-diverse expert learning strategy that trains multiple experts from a single and stationary long-tailed dataset to separately handle different class distributions; (ii) a novel test-time expert aggregation strategy that leverages self-supervision to aggregate the learned multiple experts for handling unknown test class distributions. We theoretically show that our self-supervised strategy has a provable ability to simulate test-agnostic class distributions. Promising empirical results demonstrate the effectiveness of our method on both vanilla and test-agnostic long-tailed recognition. The source code is available at https://github.com/Vanint/SADE-AgnosticLT. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Phase Transition from Clean Training to Adversarial Training",
        "paper_url": "https://openreview.net/pdf?id=gwsnBjNcVEe",
        "paper_authors": [
            "Yue Xing",
            "Qifan Song",
            "Guang Cheng"
        ],
        "paper_abstract": "Adversarial training is one important algorithm to achieve robust machine learning models. However, numerous empirical results show a great performance degradation from clean training to adversarial training (e.g., 90+\\% vs 67\\% testing accuracy on CIFAR-10 dataset), which does not match the theoretical guarantee delivered by the existing studies. Such a gap inspires us to explore the existence of an (asymptotic) phase transition phenomenon with respect to the attack strength: adversarial training is as well behaved as clean training in the small-attack regime, but there is a sharp transition from clean training to adversarial training in the large-attack regime. We validate this conjecture in linear regression models, and conduct comprehensive experiments in deep neural networks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot Adaptation",
        "paper_url": "https://openreview.net/pdf?id=G6cJsOOx2R3",
        "paper_authors": [
            "Markus Hiller",
            "Mehrtash Harandi",
            "Tom Drummond"
        ],
        "paper_abstract": "Inspired by the concept of preconditioning, we propose a novel method to increase adaptation speed for gradient-based meta-learning methods without incurring extra parameters. We demonstrate that recasting the optimisation problem to a non-linear least-squares formulation provides a principled way to actively enforce a well-conditioned parameter space for meta-learning models based on the concepts of the condition number and local curvature. Our comprehensive evaluations show that the proposed method significantly outperforms its unconstrained counterpart especially during initial adaptation steps, while achieving comparable or better overall results on several few-shot classification tasks \u2013 creating the possibility of dynamically choosing the number of adaptation steps at inference time.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Audio-Driven Co-Speech Gesture Video Generation",
        "paper_url": "https://openreview.net/pdf?id=VhgC3SMTiy",
        "paper_authors": [
            "Xian Liu",
            "Qianyi Wu",
            "Hang Zhou",
            "Yuanqi Du",
            "Wayne Wu",
            "Dahua Lin",
            "Ziwei Liu"
        ],
        "paper_abstract": "Co-speech gesture is crucial for human-machine interaction and digital entertainment. While previous works mostly map speech audio to human skeletons (e.g., 2D keypoints), directly generating speakers' gestures in the image domain remains unsolved. In this work, we formally define and study this challenging problem of audio-driven co-speech gesture video generation, i.e., using a unified framework to generate speaker image sequence driven by speech audio. Our key insight is that the co-speech gestures can be decomposed into common motion patterns and subtle rhythmic dynamics. To this end, we propose a novel framework, Audio-driveN Gesture vIdeo gEneration (ANGIE), to effectively capture the reusable co-speech gesture patterns as well as fine-grained rhythmic movements. To achieve high-fidelity image sequence generation, we leverage an unsupervised motion representation instead of a structural human body prior (e.g., 2D skeletons). Specifically, 1) we propose a vector quantized motion extractor (VQ-Motion Extractor) to summarize common co-speech gesture patterns from implicit motion representation to codebooks. 2) Moreover, a co-speech gesture GPT with motion refinement (Co-Speech GPT) is devised to complement the subtle prosodic motion details. Extensive experiments demonstrate that our framework renders realistic and vivid co-speech gesture video. Demo video and more resources can be found in: https://alvinliu0.github.io/projects/ANGIE",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Visual Concepts Tokenization",
        "paper_url": "https://openreview.net/pdf?id=rWgfLdqVVl_",
        "paper_authors": [
            "Tao Yang",
            "Yuwang Wang",
            "Yan Lu",
            "Nanning Zheng"
        ],
        "paper_abstract": "Obtaining the human-like perception ability of abstracting visual concepts from concrete pixels has always been a fundamental and important target in machine learning research fields such as disentangled representation learning and scene decomposition. Towards this goal, we propose an unsupervised transformer-based Visual Concepts Tokenization framework, dubbed VCT, to perceive an image into a set of disentangled visual concept tokens, with each concept token responding to one type of independent visual concept. Particularly, to obtain these concept tokens, we only use cross-attention to extract visual information from the image tokens layer by layer without self-attention between concept tokens, preventing information leakage across concept tokens. We further propose a Concept Disentangling Loss to facilitate that different concept tokens represent independent visual concepts. The cross-attention and disentangling loss play the role of induction and mutual exclusion for the concept tokens, respectively. Extensive experiments on several popular datasets verify the effectiveness of VCT on the tasks of disentangled representation learning and scene decomposition. VCT achieves the state of the art results by a large margin.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Orthogonal Transformer: An Efficient Vision Transformer Backbone with Token Orthogonalization",
        "paper_url": "https://openreview.net/pdf?id=GGtH47T31ZC",
        "paper_authors": [
            "Huaibo Huang",
            "Xiaoqiang Zhou",
            "Ran He"
        ],
        "paper_abstract": "We present a general vision transformer backbone, called as Orthogonal Transformer, in pursuit of both efficiency and effectiveness. A major challenge for vision transformer is that self-attention, as the key element in capturing long-range dependency, is very computationally expensive for dense prediction tasks (e.g., object detection). Coarse global self-attention and local self-attention are then designed to reduce the cost, but they suffer from either neglecting local correlations or hurting global modeling. We present an orthogonal self-attention mechanism to alleviate these issues. Specifically, self-attention is computed in the orthogonal space that is reversible to the spatial domain but has much lower resolution. The capabilities of learning global dependency and exploring local correlations are maintained because every orthogonal token in self-attention can attend to the entire visual tokens. Remarkably, orthogonality is realized by constructing an endogenously orthogonal matrix that is friendly to neural networks and can be optimized as arbitrary orthogonal matrices. We also introduce Positional MLP to incorporate position information for arbitrary input resolutions as well as enhance the capacity of MLP. Finally, we develop a hierarchical architecture for Orthogonal Transformer. Extensive experiments demonstrate its strong performance on a broad range of vision tasks, including image classification, object detection, instance segmentation and semantic segmentation.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Finding Differences Between Transformers and ConvNets Using Counterfactual Simulation Testing",
        "paper_url": "https://openreview.net/pdf?id=Aisi2oEq1sc",
        "paper_authors": [
            "Nataniel Ruiz",
            "Sarah Adel Bargal",
            "Cihang Xie",
            "Kate Saenko",
            "Stan Sclaroff"
        ],
        "paper_abstract": "Modern deep neural networks tend to be evaluated on static test sets. One shortcoming of this is the fact that these deep neural networks cannot be easily evaluated for robustness issues with respect to specific scene variations. For example, it is hard to study the robustness of these networks to variations of object scale, object pose, scene lighting and 3D occlusions. The main reason is that collecting real datasets with fine-grained naturalistic variations of sufficient scale can be extremely time-consuming and expensive. In this work, we present Counterfactual Simulation Testing, a counterfactual framework that allows us to study the robustness of neural networks with respect to some of these naturalistic variations by building realistic synthetic scenes that allow us to ask counterfactual questions to the models, ultimately providing answers to questions such as \"Would your classification still be correct if the object were viewed from the top?\" or \"Would your classification still be correct if the object were partially occluded by another object?\". Our method allows for a fair comparison of the robustness of recently released, state-of-the-art Convolutional Neural Networks and Vision Transformers, with respect to these naturalistic variations. We find evidence that ConvNext is more robust to pose and scale variations than Swin, that ConvNext generalizes better to our simulated domain and that Swin handles partial occlusion better than ConvNext. We also find that robustness for all networks improves with network scale and with data scale and variety. We release the Naturalistic Variation Object Dataset (NVD), a large simulated dataset of 272k images of everyday objects with naturalistic variations such as object pose, scale, viewpoint, lighting and occlusions. Project page: https://counterfactualsimulation.github.io",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Polynomial Neural Fields for Subband Decomposition and Manipulation",
        "paper_url": "https://openreview.net/pdf?id=juE5ErmZB61",
        "paper_authors": [
            "Guandao Yang",
            "Sagie Benaim",
            "Varun Jampani",
            "Kyle Genova",
            "Jonathan T. Barron",
            "Thomas Funkhouser",
            "Bharath Hariharan",
            "Serge Belongie"
        ],
        "paper_abstract": "Neural fields have emerged as a new paradigm for representing signals, thanks to their ability to do it compactly while being easy to optimize. In most applications, however, neural fields are treated like a black box, which precludes many signal manipulation tasks. In this paper, we propose a new class of neural fields called basis-encoded polynomial neural fields (PNFs). The key advantage of a PNF is that it can represent a signal as a composition of a number of manipulable and interpretable components without losing the merits of neural fields representation. We develop a general theoretical framework to analyze and design PNFs. We use this framework to design Fourier PNFs, which match state-of-the-art performance in signal representation tasks that use neural fields. In addition, we empirically demonstrate that Fourier PNFs enable signal manipulation applications such as texture transfer and scale-space interpolation. Code is available at https://github.com/stevenygd/PNF.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Anticipating Performativity by Predicting from Predictions",
        "paper_url": "https://openreview.net/pdf?id=80RnitDehg_",
        "paper_authors": [
            "Celestine Mendler-D\u00fcnner",
            "Frances Ding",
            "Yixin Wang"
        ],
        "paper_abstract": "Predictions about people, such as their expected educational achievement or their credit risk, can be performative and shape the outcome that they are designed to predict. Understanding the causal effect of  predictions on the eventual outcomes is crucial for foreseeing the implications of future predictive models and selecting which models to deploy. However, this causal estimation task poses unique challenges: model predictions are usually deterministic functions of input features and highly correlated with outcomes, which can make the causal effects of predictions on outcomes impossible to disentangle from the direct effect of the covariates. We study this problem through the lens of causal identifiability. Despite the hardness of this problem in full generality, we highlight three natural scenarios where the causal effect of predictions can be identified from observational data: randomization in predictions, overparameterization of the predictive model deployed during data collection, and discrete prediction outputs. Empirically we show that given our identifiability conditions hold, standard variants of supervised learning that predict from predictions by treating the prediction as an input feature can find transferable functional relationships that allow for conclusions about newly deployed predictive models. These positive results fundamentally rely on model predictions being recorded during data collection, bringing forward the importance of rethinking standard data collection practices to enable progress towards a better understanding of social outcomes and performative feedback loops.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Invariant Graph Representations for Out-of-Distribution Generalization",
        "paper_url": "https://openreview.net/pdf?id=acKK8MQe2xc",
        "paper_authors": [
            "Haoyang Li",
            "Ziwei Zhang",
            "Xin Wang",
            "Wenwu Zhu"
        ],
        "paper_abstract": "Graph representation learning has shown effectiveness when testing and training graph data come from the same distribution, but most existing approaches fail to generalize under distribution shifts. Invariant learning, backed by the invariance principle from causality, can achieve guaranteed generalization under distribution shifts in theory and has shown great successes in practice. However, invariant learning for graphs under distribution shifts remains unexplored and challenging. To solve this problem, we propose Graph Invariant Learning (GIL) model capable of learning generalized graph representations under distribution shifts. Our proposed method can capture the invariant relationships between predictive graph structural information and labels in a mixture of latent environments through jointly optimizing three tailored modules. Specifically, we first design a GNN-based subgraph generator to identify invariant subgraphs. Then we use the variant subgraphs, i.e., complements of invariant subgraphs, to infer the latent environment labels. We further propose an invariant learning module to learn graph representations that can generalize to unknown test graphs. Theoretical justifications for our proposed method are also provided. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of our method against state-of-the-art baselines under distribution shifts for the graph classification task. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SegNeXt: Rethinking Convolutional Attention Design for Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=VgOw1pUPh97",
        "paper_authors": [
            "Meng-Hao Guo",
            "Cheng-Ze Lu",
            "Qibin Hou",
            "Zheng-Ning Liu",
            "Ming-Ming Cheng",
            "Shi-min Hu"
        ],
        "paper_abstract": "We present SegNeXt, a simple convolutional network architecture for semantic segmentation. Recent transformer-based models have dominated the field of se- mantic segmentation due to the efficiency of self-attention in encoding spatial information. In this paper, we show that convolutional attention is a more efficient and effective way to encode contextual information than the self-attention mech- anism in transformers. By re-examining the characteristics owned by successful segmentation models, we discover several key components leading to the perfor- mance improvement of segmentation models. This motivates us to design a novel convolutional attention network that uses cheap convolutional operations. Without bells and whistles, our SegNeXt significantly improves the performance of previous state-of-the-art methods on popular benchmarks, including ADE20K, Cityscapes, COCO-Stuff, Pascal VOC, Pascal Context, and iSAID. Notably, SegNeXt out- performs EfficientNet-L2 w/ NAS-FPN and achieves 90.6% mIoU on the Pascal VOC 2012 test leaderboard using only 1/10 parameters of it. On average, SegNeXt achieves about 2.0% mIoU improvements compared to the state-of-the-art methods on the ADE20K datasets with the same or fewer computations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Active Labeling: Streaming Stochastic Gradients",
        "paper_url": "https://openreview.net/pdf?id=Iqm6AiHPs_z",
        "paper_authors": [
            "Vivien Cabannes",
            "Francis Bach",
            "Vianney Perchet",
            "Alessandro Rudi"
        ],
        "paper_abstract": "The workhorse of machine learning is stochastic gradient descent.\nTo access stochastic gradients, it is common to consider iteratively input/output pairs of a training dataset.\nInterestingly, it appears that one does not need full supervision to access stochastic gradients, which is the main motivation of this paper.\nAfter formalizing the \"active labeling\" problem, which focuses on active learning with partial supervision, we provide a streaming technique that provably minimizes the ratio of generalization error over the number of samples.\nWe illustrate our technique in depth for robust regression.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Practical Adversarial Attacks on Spatiotemporal Traffic Forecasting Models",
        "paper_url": "https://openreview.net/pdf?id=lTKXh991Ayv",
        "paper_authors": [
            "Fan Liu",
            "Hao Liu",
            "Wenzhao Jiang"
        ],
        "paper_abstract": "Machine learning based traffic forecasting models leverage sophisticated spatiotemporal auto-correlations to provide accurate predictions of city-wide traffic states. However, existing methods assume a reliable and unbiased forecasting environment, which is not always available in the wild. In this work, we investigate the vulnerability of spatiotemporal traffic forecasting models and propose a practical adversarial spatiotemporal attack framework. Specifically, instead of simultaneously attacking all geo-distributed data sources, an iterative gradient guided node saliency method is proposed to identify the time-dependent set of victim nodes. Furthermore, we devise a spatiotemporal gradient descent based scheme to generate real-valued adversarial traffic states under a perturbation constraint.\nMeanwhile, we theoretically demonstrate the worst performance bound of adversarial traffic forecasting attacks. Extensive experiments on two real-world datasets show that the proposed two-step framework achieves up to 67.8% performance degradation on various advanced spatiotemporal forecasting models. Remarkably, we also show that adversarial training with our proposed attacks can significantly improve the robustness of spatiotemporal traffic forecasting models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fast Vision Transformers with HiLo Attention",
        "paper_url": "https://openreview.net/pdf?id=Pyd6Rh9r1OT",
        "paper_authors": [
            "Zizheng Pan",
            "Jianfei Cai",
            "Bohan Zhuang"
        ],
        "paper_abstract": "Vision Transformers (ViTs) have triggered the most recent and significant breakthroughs in computer vision. Their efficient designs are mostly guided by the indirect metric of computational complexity, i.e., FLOPs, which however has a clear gap with the direct metric such as throughput. Thus, we propose to use the direct speed evaluation on the target platform as the design principle for efficient ViTs. Particularly, we introduce LITv2, a simple and effective ViT which performs favourably against the existing state-of-the-art methods across a spectrum of different model sizes with faster speed. At the core of LITv2 is a novel self-attention mechanism, which we dub HiLo. HiLo is inspired by the insight that high frequencies in an image capture local fine details and low frequencies focus on global structures, whereas a multi-head self-attention layer neglects the characteristic of different frequencies. Therefore, we propose to disentangle the high/low frequency patterns in an attention layer by separating the heads into two groups, where one group encodes high frequencies via self-attention within each local window, and another group encodes low frequencies by performing global attention between the average-pooled low-frequency keys and values from each window and each query position in the input feature map. Benefiting from the efficient design for both groups, we show that HiLo is superior to the existing attention mechanisms by comprehensively benchmarking FLOPs, speed and memory consumption on GPUs and CPUs. For example, HiLo is 1.4\u00d7 faster than spatial reduction attention and 1.6\u00d7 faster than local window attention on CPUs. Powered by HiLo, LITv2 serves as a strong backbone for mainstream vision tasks including image classification, dense detection and segmentation. Code is available at https://github.com/ziplab/LITv2.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "LGDN: Language-Guided Denoising Network for Video-Language Modeling",
        "paper_url": "https://openreview.net/pdf?id=rA2tItoRUth",
        "paper_authors": [
            "Haoyu Lu",
            "Mingyu Ding",
            "Nanyi Fei",
            "Yuqi Huo",
            "Zhiwu Lu"
        ],
        "paper_abstract": "Video-language modeling has attracted much attention with the rapid growth of web videos. Most existing methods assume that the video frames and text description are semantically correlated, and focus on video-language modeling at video level. However, this hypothesis often fails for two reasons: (1) With the rich semantics of video contents, it is difficult to cover all frames with a single video-level description; (2) A raw video typically has noisy/meaningless information (e.g., scenery shot, transition or teaser). Although a number of recent works deploy attention mechanism to alleviate this problem, the irrelevant/noisy information still makes it very difficult to address. To overcome such challenge, we thus propose an efficient and effective model, termed Language-Guided Denoising Network (LGDN), for video-language modeling. Different from most existing methods that utilize all extracted video frames, LGDN dynamically filters out the misaligned or redundant frames under the language supervision and obtains only 2--4 salient frames per video for cross-modal token-level alignment. Extensive experiments on five public datasets show that our LGDN outperforms the state-of-the-arts by large margins. We also provide detailed ablation study to reveal the critical importance of solving the noise issue, in hope of inspiring future video-language work.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining",
        "paper_url": "https://openreview.net/pdf?id=7YTh6S8HIY",
        "paper_authors": [
            "Yuting Gao",
            "Jinfeng Liu",
            "Zihan Xu",
            "Jun Zhang",
            "Ke Li",
            "Rongrong Ji",
            "Chunhua Shen"
        ],
        "paper_abstract": "Large-scale vision-language pre-training has achieved promising results on downstream tasks. Existing methods highly rely on the assumption that the image-text pairs crawled from the Internet are in perfect one-to-one correspondence. However, in real scenarios, this assumption can be difficult to hold: the text description, obtained by crawling the affiliated metadata of the image, often suffers from the semantic mismatch and the mutual compatibility. To address these issues, we introduce PyramidCLIP, which constructs an input pyramid with different semantic levels for each modality, and aligns visual elements and linguistic elements in the form of hierarchy via peer-level semantics alignment and cross-level relation alignment. Furthermore, we soften the loss of negative samples (unpaired samples) so as to weaken the strict constraint during the pre-training stage, thus mitigating the risk of forcing the model to distinguish compatible negative pairs. Experiments on five downstream tasks demonstrate the effectiveness of the proposed PyramidCLIP. In particular, with the same amount of 15 million pre-training image-text pairs, PyramidCLIP exceeds CLIP on ImageNet zero-shot classification top-1 accuracy by 10.6%/13.2%/10.0% with ResNet50/ViT-B32/ViT-B16 based image encoder respectively. When scaling to larger datasets, PyramidCLIP achieves the state-of-the-art results on several downstream tasks. In particular, the results of PyramidCLIP-ResNet50 trained on 143M image-text pairs surpass that of CLIP using 400M data on ImageNet zero-shot classification task, significantly improving the data efficiency of CLIP.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Divide and Contrast: Source-free Domain Adaptation via Adaptive Contrastive Learning",
        "paper_url": "https://openreview.net/pdf?id=NjImFaBEHl",
        "paper_authors": [
            "Ziyi Zhang",
            "Weikai Chen",
            "Hui Cheng",
            "Zhen Li",
            "Siyuan Li",
            "Liang Lin",
            "Guanbin Li"
        ],
        "paper_abstract": "We investigate a practical domain adaptation task, called source-free domain adaptation (SFUDA), where the source pretrained model is adapted to the target domain without access to the source data. Existing techniques mainly leverage self-supervised pseudo-labeling to achieve class-wise global alignment [1] or rely on local structure extraction that encourages the feature consistency among neighborhoods [2]. While impressive progress has been made, both lines of methods have their own drawbacks \u2013 the \u201cglobal\u201d approach is sensitive to noisy labels while the \u201clocal\u201d counterpart suffers from the source bias. In this paper, we present Divide and Contrast (DaC), a new paradigm for SFUDA that strives to connect the good ends of both worlds while bypassing their limitations. Based on the prediction confidence of the source model, DaC divides the target data into source-like and target-specific samples, where either group of samples is treated with tailored goals under an adaptive contrastive learning framework. Specifically, the source-like samples are utilized for learning global class clustering thanks to their relatively clean labels. The more noisy target-specific data are harnessed at the instance level for learning the intrinsic local structures. We further align the source-like domain with the target-specific samples using a memory bank-based Maximum Mean Discrepancy (MMD) loss to reduce the distribution mismatch. Extensive experiments on VisDA, Office-Home, and the more challenging DomainNet have verified the superior performance of DaC over current state-of-the-art approaches. The code is available at https://github.com/ZyeZhang/DaC.git.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning",
        "paper_url": "https://openreview.net/pdf?id=S7Evzt9uit3",
        "paper_authors": [
            "Weixin Liang",
            "Yuhui Zhang",
            "Yongchan Kwon",
            "Serena Yeung",
            "James Zou"
        ],
        "paper_abstract": "We present modality gap, an intriguing geometric phenomenon of the representation space of multi-modal models. Specifically, we show that different data modalities (e.g. images and text) are embedded at arm's length in their shared representation in multi-modal models such as CLIP. Our systematic analysis demonstrates that this gap is caused by a combination of model initialization and contrastive learning optimization. In model initialization, we show empirically and theoretically that the representation of a common deep neural network is restricted to a narrow cone. As a consequence, in a multi-modal model with two encoders, the representations of the two modalities are clearly apart when the model is initialized. During optimization,  contrastive learning keeps the different modalities separate by a certain distance, which is influenced by the temperature parameter in the loss function. Our experiments further demonstrate that varying the modality gap distance has a significant impact in improving the model's downstream zero-shot classification performance and fairness.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency",
        "paper_url": "https://openreview.net/pdf?id=OjS3nkNATOw",
        "paper_authors": [
            "Viraj Uday Prabhu",
            "Sriram Yenamandra",
            "Aaditya Singh",
            "Judy Hoffman"
        ],
        "paper_abstract": "Visual domain adaptation (DA) seeks to transfer trained models to unseen, unlabeled domains across distribution shift, but approaches typically focus on adapting convolutional neural network architectures initialized with supervised ImageNet representations. In this work, we shift focus to adapting modern architectures for object recognition -- the increasingly popular Vision Transformer (ViT) -- initialized with modern pretraining based on self-supervised learning (SSL). Inspired by the design of recent SSL approaches based on learning from partial image inputs generated via masking or cropping -- either by learning to predict the missing pixels, or learning representational invariances to such augmentations -- we propose PACMAC, a two-stage adaptation algorithm for self-supervised ViTs. PACMAC first performs in-domain SSL on pooled source and target data to learn task-discriminative features, and then probes the model's predictive consistency across a set of partial target inputs generated via a novel attention-conditioned masking strategy, to identify reliable candidates for self-training. Our simple approach leads to consistent performance gains over competing methods that use ViTs and self-supervised initializations on standard object recognition benchmarks. Our code is available at https://github.com/virajprabhu/PACMAC.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dense Interspecies Face Embedding",
        "paper_url": "https://openreview.net/pdf?id=m67FNFdgLO9",
        "paper_authors": [
            "Sejong Yang",
            "Subin Jeon",
            "Seonghyeon Nam",
            "Seon Joo Kim"
        ],
        "paper_abstract": "Dense Interspecies Face Embedding (DIFE) is a new direction for understanding faces of various animals by extracting common features among animal faces including human face. There are three main obstacles for interspecies face understanding: (1) lack of animal data compared to human, (2) ambiguous connection between faces of various animals, and (3) extreme shape and style variance. To cope with the lack of data, we utilize multi-teacher knowledge distillation of CSE and StyleGAN2 requiring no additional data or label. Then we synthesize pseudo pair images through the latent space exploration of StyleGAN2 to find implicit associations between different animal faces. Finally, we introduce the semantic matching loss to overcome the problem of extreme shape differences between species. To quantitatively evaluate our method over possible previous methodologies like unsupervised keypoint detection, we perform interspecies facial keypoint transfer on MAFL and AP-10K. Furthermore, the results of other applications like interspecies face image manipulation and dense keypoint transfer are provided. The code is available at https://github.com/kingsj0405/dife.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Self-Supervised Visual Representation Learning with Semantic Grouping",
        "paper_url": "https://openreview.net/pdf?id=H3JObxjd8S",
        "paper_authors": [
            "Xin Wen",
            "Bingchen Zhao",
            "Anlin Zheng",
            "Xiangyu Zhang",
            "XIAOJUAN QI"
        ],
        "paper_abstract": "In this paper, we tackle the problem of learning visual representations from unlabeled scene-centric data. Existing works have demonstrated the potential of utilizing the underlying complex structure within scene-centric data; still, they commonly rely on hand-crafted objectness priors or specialized pretext tasks to build a learning framework, which may harm generalizability. Instead, we propose contrastive learning from data-driven semantic slots, namely SlotCon, for joint semantic grouping and representation learning. The semantic grouping is performed by assigning pixels to a set of learnable prototypes, which can adapt to each sample by attentive pooling over the feature and form new slots. Based on the learned data-dependent slots, a contrastive objective is employed for representation learning, which enhances the discriminability of features, and conversely facilitates grouping semantically coherent pixels together. Compared with previous efforts, by simultaneously optimizing the two coupled objectives of semantic grouping and contrastive learning, our approach bypasses the disadvantages of hand-crafted priors and is able to learn object/group-level representations from scene-centric images. Experiments show our approach effectively decomposes complex scenes into semantic groups for feature learning and significantly benefits downstream tasks, including object detection, instance segmentation, and semantic segmentation. Code is available at: https://github.com/CVMI-Lab/SlotCon.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Flexible Neural Image Compression via Code Editing",
        "paper_url": "https://openreview.net/pdf?id=uV_VYGB3FCi",
        "paper_authors": [
            "Chenjian Gao",
            "Tongda Xu",
            "Dailan He",
            "Yan Wang",
            "Hongwei Qin"
        ],
        "paper_abstract": "Neural image compression (NIC) has outperformed traditional image codecs in rate-distortion (R-D) performance. However, it usually requires a dedicated encoder-decoder pair for each point on R-D curve, which greatly hinders its practical deployment. While some recent works have enabled bitrate control via conditional coding, they impose strong prior during training and provide limited flexibility. In this paper we propose Code Editing, a highly flexible coding method for NIC based on semi-amortized inference and adaptive quantization. Our work is a new paradigm for variable bitrate NIC, and experimental results show that our method surpasses existing variable-rate methods. Furthermore, our approach is so flexible that it can also achieves ROI coding and multi-distortion trade-off with a single decoder. Our approach is compatible to all NIC methods with differentiable decoder NIC, and it can be even directly adopted on existing pre-trained models.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DAGMA: Learning DAGs via M-matrices and a Log-Determinant Acyclicity Characterization",
        "paper_url": "https://openreview.net/pdf?id=8rZYMpFUgK",
        "paper_authors": [
            "Kevin Bello",
            "Bryon Aragam",
            "Pradeep Kumar Ravikumar"
        ],
        "paper_abstract": "The combinatorial problem of learning directed acyclic graphs (DAGs) from data was recently framed as a purely continuous optimization problem by leveraging a differentiable acyclicity characterization of DAGs based on the trace of a matrix exponential function. Existing acyclicity characterizations are based on the idea that powers of an adjacency matrix contain information about walks and cycles. In this work, we propose a new acyclicity characterization based on the log-determinant (log-det) function, which leverages the nilpotency property of DAGs. To deal with the inherent asymmetries of a DAG, we relate the domain of our log-det characterization to the set of $\\textit{M-matrices}$, which is a key difference to the classical log-det function defined over the cone of positive definite matrices.\nSimilar to acyclicity functions previously proposed, our characterization is also exact and differentiable. However, when compared to existing characterizations, our log-det function: (1) Is better at detecting large cycles; (2) Has better-behaved gradients; and (3) Its runtime is in practice about an order of magnitude faster. From the optimization side, we drop the typically used augmented Lagrangian scheme and propose DAGMA ($\\textit{Directed Acyclic Graphs via M-matrices for Acyclicity}$), a method that resembles the central path for barrier methods. Each point in the central path of DAGMA is a solution to an unconstrained problem regularized by our log-det function, then we show that at the limit of the central path the solution is guaranteed to be a DAG. Finally, we provide extensive experiments for $\\textit{linear}$ and $\\textit{nonlinear}$ SEMs and show that our approach can reach large speed-ups and smaller structural Hamming distances against state-of-the-art methods. Code implementing the proposed method is open-source and publicly available at https://github.com/kevinsbello/dagma.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "The Minority Matters: A Diversity-Promoting Collaborative Metric Learning Algorithm",
        "paper_url": "https://openreview.net/pdf?id=xubxAVbOsw",
        "paper_authors": [
            "Shilong Bao",
            "Qianqian Xu",
            "Zhiyong Yang",
            "Yuan He",
            "Xiaochun Cao",
            "Qingming Huang"
        ],
        "paper_abstract": "Collaborative Metric Learning (CML) has recently emerged as a popular method in recommendation systems (RS), closing the gap between metric learning and Collaborative Filtering. Following the convention of RS, existing methods exploit unique user representation in their model design. This paper focuses on a challenging scenario where a user has multiple categories of interests. Under this setting, we argue that the unique user representation might induce preference bias, especially when the item category distribution is imbalanced. To address this issue, we propose a novel method called Diversity-Promoting Collaborative Metric Learning (DPCML), with the hope of considering the commonly ignored minority interest of the user. The key idea behind DPCML is to include a multiple set of representations for each user in the system. Based on this embedding paradigm, user preference toward an item is aggregated from different embeddings by taking the minimum item-user distance among the user embedding set. Furthermore, we observe that the diversity of the embeddings for the same user also plays an essential role in the model. To this end, we propose a diversity control regularization term to accommodate the multi-vector representation strategy better. Theoretically, we show that DPCML could generalize well to unseen test data by tackling the challenge of the annoying operation that comes from the minimum value. Experiments over a range of benchmark datasets speak to the efficacy of DPCML.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DOMINO: Decomposed Mutual Information Optimization for Generalized Context in Meta-Reinforcement Learning",
        "paper_url": "https://openreview.net/pdf?id=CJGUABT_COm",
        "paper_authors": [
            "Yao Mu",
            "Yuzheng Zhuang",
            "Fei Ni",
            "Bin Wang",
            "Jianyu Chen",
            "Jianye HAO",
            "Ping Luo"
        ],
        "paper_abstract": "Adapting to the changes in transition dynamics is essential in robotic applications. By learning a conditional policy with a compact context, context-aware meta-reinforcement learning provides a flexible way to adjust behavior according to dynamics changes. However, in real-world applications, the agent may encounter complex dynamics changes. Multiple confounders can influence the transition dynamics, making it challenging to infer accurate context for decision-making. This paper addresses such a challenge by decomposed mutual information optimization (DOMINO) for context learning, which explicitly learns a disentangled context to maximize the mutual information between the context and historical trajectories while minimizing the state transition prediction error. Our theoretical analysis shows that DOMINO can overcome the underestimation of the mutual information caused by multi-confounded challenges via learning disentangled context and reduce the demand for the number of samples collected in various environments. Extensive experiments show that the context learned by DOMINO benefits both model-based and model-free reinforcement learning algorithms for dynamics generalization in terms of sample efficiency and performance in unseen environments. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OpenAUC: Towards AUC-Oriented Open-Set Recognition",
        "paper_url": "https://openreview.net/pdf?id=Ddd6FqHXmHA",
        "paper_authors": [
            "Zitai Wang",
            "Qianqian Xu",
            "Zhiyong Yang",
            "Yuan He",
            "Xiaochun Cao",
            "Qingming Huang"
        ],
        "paper_abstract": "Traditional machine learning follows a close-set assumption that the training and test set share the same label space. While in many practical scenarios, it is inevitable that some test samples belong to unknown classes (open-set). To fix this issue, Open-Set Recognition (OSR), whose goal is to make correct predictions on both close-set samples and open-set samples, has attracted rising attention. In this direction, the vast majority of literature focuses on the pattern of open-set samples. However, how to evaluate model performance in this challenging task is still unsolved. In this paper, a systematic analysis reveals that most existing metrics are essentially inconsistent with the aforementioned goal of OSR: (1) For metrics extended from close-set classification, such as Open-set F-score, Youden's index, and Normalized Accuracy, a poor open-set prediction can escape from a low performance score with a superior close-set prediction. (2) Novelty detection AUC, which measures the ranking performance between close-set and open-set samples, ignores the close-set performance. To fix these issues, we propose a novel metric named OpenAUC. Compared with existing metrics, OpenAUC enjoys a concise pairwise formulation that evaluates open-set performance and close-set performance in a coupling manner. Further analysis shows that OpenAUC is free from the aforementioned inconsistency properties. Finally, an end-to-end learning method is proposed to minimize the OpenAUC risk, and the experimental results on popular benchmark datasets speak to its effectiveness.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Exploring the Algorithm-Dependent Generalization of AUPRC Optimization with List Stability",
        "paper_url": "https://openreview.net/pdf?id=csr9uRmTC3f",
        "paper_authors": [
            "Peisong Wen",
            "Qianqian Xu",
            "Zhiyong Yang",
            "Yuan He",
            "Qingming Huang"
        ],
        "paper_abstract": "Stochastic optimization of the Area Under the Precision-Recall Curve (AUPRC) is a crucial problem for machine learning. Although various algorithms have been extensively studied for AUPRC optimization, the generalization is only guaranteed in the multi-query case. In this work, we present the first trial in the single-query generalization of stochastic AUPRC optimization. For sharper generalization bounds, we focus on algorithm-dependent generalization. There are both algorithmic and theoretical obstacles to our destination. From an algorithmic perspective, we notice that the majority of existing stochastic estimators are biased when the sampling strategy is biased, and is leave-one-out unstable due to the non-decomposability. To address these issues, we propose a sampling-rate-invariant unbiased stochastic estimator with superior stability. On top of this, the AUPRC optimization is formulated as a composition optimization problem, and a stochastic algorithm is proposed to solve this problem. From a theoretical perspective, standard techniques of the algorithm-dependent generalization analysis cannot be directly applied to such a listwise compositional optimization problem. To fill this gap, we extend the model stability from instancewise losses to listwise losses and bridge the corresponding generalization and stability. Additionally, we construct state transition matrices to describe the recurrence of the stability, and simplify calculations by matrix spectrum. Practically, experimental results on three image retrieval datasets on speak to the effectiveness and soundness of our framework.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training",
        "paper_url": "https://openreview.net/pdf?id=MbCAOMGsZXC",
        "paper_authors": [
            "Renrui Zhang",
            "Ziyu Guo",
            "Peng Gao",
            "Rongyao Fang",
            "Bin Zhao",
            "Dong Wang",
            "Yu Qiao",
            "Hongsheng Li"
        ],
        "paper_abstract": "Masked Autoencoders (MAE) have shown great potentials in self-supervised pre-training for language and 2D image transformers. However, it still remains an open question on how to exploit masked autoencoding for learning 3D representations of irregular point clouds. In this paper, we propose Point-M2AE, a strong Multi-scale MAE pre-training framework for hierarchical self-supervised learning of 3D point clouds. Unlike the standard transformer in MAE, we modify the encoder and decoder into pyramid architectures to progressively model spatial geometries and capture both fine-grained and high-level semantics of 3D shapes. For the encoder that downsamples point tokens by stages, we design a multi-scale masking strategy to generate consistent visible regions across scales, and adopt a local spatial self-attention mechanism during fine-tuning to focus on neighboring patterns. By multi-scale token propagation, the lightweight decoder gradually upsamples point tokens with complementary skip connections from the encoder, which further promotes the reconstruction from a global-to-local perspective. Extensive experiments demonstrate the state-of-the-art performance of Point-M2AE for 3D representation learning. With a frozen encoder after pre-training, Point-M2AE achieves 92.9% accuracy for linear SVM on ModelNet40, even surpassing some fully trained methods. By fine-tuning on downstream tasks, Point-M2AE achieves 86.43% accuracy on ScanObjectNN, +3.36% to the second-best, and largely benefits the few-shot classification, part segmentation and 3D object detection with the hierarchical pre-training scheme. Code is available at https://github.com/ZrrSkywalker/Point-M2AE.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "OmniVL: One Foundation Model for Image-Language and Video-Language Tasks",
        "paper_url": "https://openreview.net/pdf?id=u4ihlSG240n",
        "paper_authors": [
            "Junke Wang",
            "Dongdong Chen",
            "Zuxuan Wu",
            "Chong Luo",
            "Luowei Zhou",
            "Yucheng Zhao",
            "Yujia Xie",
            "Ce Liu",
            "Yu-Gang Jiang",
            "Lu Yuan"
        ],
        "paper_abstract": "This paper presents OmniVL, a new foundation model to support both image-language and video-language tasks using one universal architecture. It adopts a unified transformer-based visual encoder for both image and video inputs, and thus can perform joint image-language and video-language pretraining. We demonstrate, for the first time, such a paradigm benefits both image and video tasks, as opposed to the conventional one-directional transfer (e.g., use image-language to help video-language). To this end, we propose a \\emph{decoupled} joint pretraining of image-language and video-language to effectively decompose the vision-language modeling into spatial and temporal dimensions and obtain performance boost on both image and video tasks. Moreover, we introduce a novel unified vision-language contrastive (UniVLC) loss to leverage image-text, video-text, image-label (e.g., image classification), video-label (e.g., video action recognition) data together, so that both supervised and noisily supervised pretraining data are utilized as much as possible. Without incurring extra task-specific adaptors, OmniVL can simultaneously support visual only tasks (e.g., image classification, video action recognition), cross-modal alignment tasks (e.g., image/video-text retrieval), and multi-modal understanding and generation tasks (e.g., image/video question answering, captioning). We evaluate OmniVL on a wide range of downstream tasks and achieve state-of-the-art or competitive results with similar model size and data scale.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "EcoFormer: Energy-Saving Attention with Linear Complexity",
        "paper_url": "https://openreview.net/pdf?id=MK_130d4Y0",
        "paper_authors": [
            "Jing Liu",
            "Zizheng Pan",
            "Haoyu He",
            "Jianfei Cai",
            "Bohan Zhuang"
        ],
        "paper_abstract": "Transformer is a transformative framework for deep learning which models sequential data and has achieved remarkable performance on a wide range of tasks, but with high computational and energy cost. To improve its efficiency, a popular choice is to compress the models via binarization which constrains the floating-point values into binary ones to save resource consumption owing to cheap bitwise operations significantly. However, existing binarization methods only aim at minimizing the information loss for the input distribution statistically, while ignoring the pairwise similarity modeling at the core of the attention mechanism. To this end, we propose a new binarization paradigm customized to high-dimensional softmax attention via kernelized hashing, called EcoFormer, to map the original queries and keys into low-dimensional binary codes in Hamming space. The kernelized hash functions are learned to match the ground-truth similarity relations extracted from the attention map in a self-supervised way. Based on the equivalence between the inner product of binary codes and the Hamming distance as well as the associative property of matrix multiplication, we can approximate the attention in linear complexity by expressing it as a dot-product of binary codes. Moreover, the compact binary representations of queries and keys in EcoFormer enable us to replace most of the expensive multiply-accumulate operations in attention with simple accumulations to save considerable on-chip energy footprint on edge devices. Extensive experiments on both vision and language tasks show that EcoFormer consistently achieves comparable performance with standard attentions while consuming much fewer resources. For example, based on PVTv2-B0 and ImageNet-1K, EcoFormer achieves a 73% reduction in on-chip energy footprint with only a slight performance drop of 0.33% compared to the standard attention. Code is available at https://github.com/ziplab/EcoFormer.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Zero-Shot Video Question Answering via Frozen Bidirectional Language Models",
        "paper_url": "https://openreview.net/pdf?id=9uRS5ysgb9",
        "paper_authors": [
            "Antoine Yang",
            "Antoine Miech",
            "Josef Sivic",
            "Ivan Laptev",
            "Cordelia Schmid"
        ],
        "paper_abstract": "Video question answering (VideoQA) is a complex task that requires diverse multi-modal data for training. Manual annotation of question and answers for videos, however, is tedious and prohibits scalability. To tackle this problem, recent methods consider zero-shot settings with no manual annotation of visual question-answer. In particular, a promising approach adapts frozen autoregressive language models pretrained on Web-scale text-only data to multi-modal inputs. In contrast, we here build on frozen bidirectional language models (BiLM) and show that such an approach provides a stronger and cheaper alternative for zero-shot VideoQA. In particular, (i) we combine visual inputs with the frozen BiLM using light trainable modules, (ii) we train such modules using Web-scraped multi-modal data, and finally (iii) we perform zero-shot VideoQA inference through masked language modeling, where the masked text is the answer to a given question. Our proposed approach, FrozenBiLM, outperforms the state of the art in zero-shot VideoQA by a significant margin on a variety of datasets, including LSMDC-FiB, iVQA, MSRVTT-QA, MSVD-QA, ActivityNet-QA, TGIF-FrameQA, How2QA and TVQA. It also demonstrates competitive performance in the few-shot and fully-supervised setting. Our code and models are publicly available at https://github.com/antoyang/FrozenBiLM.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Align then Fusion: Generalized Large-scale Multi-view Clustering with Anchor Matching Correspondences",
        "paper_url": "https://openreview.net/pdf?id=qVtbqSwOxy6",
        "paper_authors": [
            "Siwei Wang",
            "Xinwang Liu",
            "Suyuan Liu",
            "Jiaqi Jin",
            "Wenxuan Tu",
            "Xinzhong Zhu",
            "En Zhu"
        ],
        "paper_abstract": "Multi-view anchor graph clustering selects representative anchors to avoid full pair-wise similarities and therefore reduce the complexity of graph methods. Although widely applied in large-scale applications, existing approaches do not pay sufficient attention to establishing correct correspondences between the anchor sets across views. To be specific, anchor graphs obtained from different views are not aligned column-wisely. Such an Anchor-Unaligned Problem (AUP) would cause inaccurate graph fusion and degrade the clustering performance. Under multi-view scenarios, generating correct correspondences could be extremely difficult since anchors are not consistent in feature dimensions. To solve this challenging issue, we propose the first study of the generalized and flexible anchor graph fusion framework termed Fast Multi-View Anchor-Correspondence Clustering (FMVACC). Specifically, we show how to find anchor correspondence with both feature and structure information, after which anchor graph fusion is performed column-wisely. Moreover, we theoretically show the connection between FMVACC and existing multi-view late fusion and partial view-aligned clustering, which further demonstrates our generality. Extensive experiments on seven benchmark datasets demonstrate the effectiveness and efficiency of our proposed method. Moreover, the proposed alignment module also shows significant performance improvement applying to existing multi-view anchor graph competitors indicating the importance of anchor alignment. Our code is available at \\url{https://github.com/wangsiwei2010/NeurIPS22-FMVACC}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RLIP: Relational Language-Image Pre-training for Human-Object Interaction Detection",
        "paper_url": "https://openreview.net/pdf?id=dozWFpOJcOD",
        "paper_authors": [
            "Hangjie Yuan",
            "Jianwen Jiang",
            "Samuel Albanie",
            "Tao Feng",
            "Ziyuan Huang",
            "Dong Ni",
            "Mingqian Tang"
        ],
        "paper_abstract": "The task of Human-Object Interaction (HOI) detection targets fine-grained visual parsing of humans interacting with their environment, enabling a broad range of applications. Prior work has demonstrated the benefits of effective architecture design and integration of relevant cues for more accurate HOI detection. However, the design of an appropriate pre-training strategy for this task remains underexplored by existing approaches. To address this gap, we propose $\\textit{Relational Language-Image Pre-training}$ (RLIP), a strategy for contrastive pre-training that leverages both entity and relation descriptions. To make effective use of such pre-training, we make three technical contributions: (1) a new $\\textbf{Par}$allel entity detection and $\\textbf{Se}$quential relation inference (ParSe) architecture that enables the use of both entity and relation descriptions during holistically optimized pre-training; (2) a synthetic data generation framework, Label Sequence Extension, that expands the scale of language data available within each minibatch; (3) ambiguity-suppression mechanisms, Relation Quality Labels and Relation Pseudo-Labels, to mitigate the influence of ambiguous/noisy samples in the pre-training data. Through extensive experiments, we demonstrate the benefits of these contributions, collectively termed RLIP-ParSe, for improved zero-shot, few-shot and fine-tuning HOI detection performance as well as increased robustness to learning from noisy annotations. Code will be available at https://github.com/JacobYuan7/RLIP.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Dynamic Graph Neural Networks Under Spatio-Temporal Distribution Shift",
        "paper_url": "https://openreview.net/pdf?id=1tIUqrUuJxx",
        "paper_authors": [
            "Zeyang Zhang",
            "Xin Wang",
            "Ziwei Zhang",
            "Haoyang Li",
            "Zhou Qin",
            "Wenwu Zhu"
        ],
        "paper_abstract": "Dynamic graph neural networks (DyGNNs) have demonstrated powerful predictive abilities by exploiting graph structural and temporal dynamics. However, the existing DyGNNs fail to handle distribution shifts, which naturally exist in dynamic graphs, mainly because the patterns exploited by DyGNNs may be variant with respect to labels under distribution shifts. In this paper, we propose to handle spatio-temporal distribution shifts in dynamic graphs by discovering and utilizing {\\it invariant patterns}, i.e., structures and features whose predictive abilities are stable across distribution shifts, which faces two key challenges: 1) How to discover the complex variant and invariant spatio-temporal patterns in dynamic graphs, which involve both time-varying graph structures and node features. 2) How to handle spatio-temporal distribution shifts with the discovered variant and invariant patterns. To tackle these challenges, we propose the Disentangled Intervention-based Dynamic graph Attention networks (DIDA). Our proposed method can effectively handle spatio-temporal distribution shifts in dynamic graphs by discovering and fully utilizing invariant spatio-temporal patterns. Specifically, we first propose a disentangled spatio-temporal attention network to capture the variant and invariant patterns.  Then, we design a spatio-temporal intervention mechanism to create multiple interventional distributions by sampling and reassembling variant patterns across neighborhoods and time stamps to eliminate the spurious impacts of variant patterns.  Lastly, we propose an invariance regularization term to minimize the variance of predictions in intervened distributions so that our model can make predictions based on invariant patterns with stable predictive abilities and therefore handle distribution shifts. Experiments on three real-world datasets and one synthetic dataset demonstrate the superiority of our method over state-of-the-art baselines under distribution shifts. Our work is the first study of spatio-temporal distribution shifts in dynamic graphs, to the best of our knowledge.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Mix and Reason: Reasoning over Semantic Topology with Data Mixing for Domain Generalization",
        "paper_url": "https://openreview.net/pdf?id=V0GwAmDclY",
        "paper_authors": [
            "Chaoqi Chen",
            "Luyao Tang",
            "Feng Liu",
            "Gangming Zhao",
            "Yue Huang",
            "Yizhou Yu"
        ],
        "paper_abstract": "Domain generalization (DG) enables generalizing a learning machine from multiple seen source domains to an unseen target one. The general objective of DG methods is to learn semantic representations that are independent of domain labels, which is theoretically sound but empirically challenged due to the complex mixture of common and domain-specific factors. Although disentangling the representations into two disjoint parts has been gaining momentum in DG, the strong presumption over the data limits its efficacy in many real-world scenarios. In this paper, we propose Mix and Reason (MiRe), a new DG framework that learns semantic representations via enforcing the structural invariance of semantic topology. MiRe consists of two key components, namely,  Category-aware Data Mixing (CDM) and Adaptive Semantic Topology Refinement (ASTR). CDM mixes two images from different domains in virtue of activation maps generated by two complementary classification losses, making the classifier focus on the representations of semantic objects. ASTR introduces relation graphs to represent semantic topology, which is progressively refined via the interactions between local feature aggregation and global cross-domain relational reasoning. Experiments on multiple DG benchmarks validate the effectiveness and robustness of the proposed MiRe. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Independence Testing-Based Approach to Causal Discovery under Measurement Error and Linear Non-Gaussian Models",
        "paper_url": "https://openreview.net/pdf?id=wOUH1VQ9Rcj",
        "paper_authors": [
            "Haoyue Dai",
            "Peter Spirtes",
            "Kun Zhang"
        ],
        "paper_abstract": "Causal discovery aims to recover causal structures generating the observational data. Despite its success in certain problems, in many real-world scenarios the observed variables are not the target variables of interest, but the imperfect measures of the target variables. Causal discovery under measurement error aims to recover the causal graph among unobserved target variables from observations made with measurement error. We consider a specific formulation of the problem, where the unobserved target variables follow a linear non-Gaussian acyclic model, and the measurement process follows the random measurement error model. Existing methods on this formulation rely on non-scalable over-complete independent component analysis (OICA). In this work, we propose the Transformed Independent Noise (TIN) condition, which checks for independence between a specific linear transformation of some measured variables and certain other measured variables. By leveraging the non-Gaussianity and higher-order statistics of data, TIN is informative about the graph structure among the unobserved target variables. By utilizing TIN, the ordered group decomposition of the causal model is identifiable. In other words, we could achieve what once required OICA to achieve by only conducting independence tests. Experimental results on both synthetic and real-world data demonstrate the effectiveness and reliability of our method.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models",
        "paper_url": "https://openreview.net/pdf?id=AUz5Oig77OS",
        "paper_authors": [
            "Muyang Li",
            "Ji Lin",
            "Chenlin Meng",
            "Stefano Ermon",
            "Song Han",
            "Jun-Yan Zhu"
        ],
        "paper_abstract": "During image editing, existing deep generative models tend to re-synthesize the entire output from scratch, including the unedited regions. This leads to a significant waste of computation, especially for minor editing operations. In this work, we present Spatially Sparse Inference (SSI), a general-purpose technique that selectively performs computation for edited regions and accelerates various generative models, including both conditional GANs and diffusion models. Our key observation is that users tend to make gradual changes to the input image. This motivates us to cache and reuse the feature maps of the original image. Given an edited image, we sparsely apply the convolutional filters to the edited regions while reusing the cached features for the unedited regions. Based on our algorithm, we further propose Sparse Incremental Generative Engine (SIGE) to convert the computation reduction to latency reduction on off-the-shelf hardware. With 1.2%-area edited regions, our method reduces the computation of DDIM by $7.5\\times$ and GauGAN by $18\\times$  while preserving the visual fidelity. With SIGE, we accelerate the inference time of DDIM by $3.0\\times$ on RTX 3090 and $6.6\\times$ on Apple M1 Pro CPU, and GauGAN by $4.2\\times$ on RTX 3090 and $14\\times$ on Apple M1 Pro CPU.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Subsidiary Prototype Alignment for Universal Domain Adaptation",
        "paper_url": "https://openreview.net/pdf?id=5kThooa07pf",
        "paper_authors": [
            "Jogendra Nath Kundu",
            "Suvaansh Bhambri",
            "Akshay Ravindra Kulkarni",
            "Hiran Sarkar",
            "Varun Jampani",
            "Venkatesh Babu Radhakrishnan"
        ],
        "paper_abstract": "Universal Domain Adaptation (UniDA) deals with the problem of knowledge transfer between two datasets with domain-shift as well as category-shift. The goal is to categorize unlabeled target samples, either into one of the \"known\" categories or into a single \"unknown\" category. A major problem in UniDA is negative transfer, i.e. misalignment of \"known\" and \"unknown\" classes. To this end, we first uncover an intriguing tradeoff between negative-transfer-risk and domain-invariance exhibited at different layers of a deep network. It turns out we can strike a balance between these two metrics at a mid-level layer. Towards designing an effective framework based on this insight, we draw motivation from Bag-of-visual-Words (BoW). Word-prototypes in a BoW-like representation of a mid-level layer would represent lower-level visual primitives that are likely to be unaffected by the category-shift in the high-level features. We develop modifications that encourage learning of word-prototypes followed by word-histogram based classification. Following this, subsidiary prototype-space alignment (SPA) can be seen as a closed-set alignment problem, thereby avoiding negative transfer. We realize this with a novel word-histogram-related pretext task to enable closed-set SPA, operating in conjunction with goal task UniDA. We demonstrate the efficacy of our approach on top of existing UniDA techniques, yielding state-of-the-art performance across three standard UniDA and Open-Set DA object recognition benchmarks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Generative Status Estimation and Information Decoupling for Image Rain Removal",
        "paper_url": "https://openreview.net/pdf?id=C2o5DeL_8L1",
        "paper_authors": [
            "Di Lin",
            "Xin WANG",
            "Jia Shen",
            "Renjie Zhang",
            "Ruonan Liu",
            "Miaohui Wang",
            "Wuyuan Xie",
            "Qing Guo",
            "Ping Li"
        ],
        "paper_abstract": "Image rain removal requires the accurate separation between the pixels of the rain streaks and object textures. But the confusing appearances of rains and objects lead to the misunderstanding of pixels, thus remaining the rain streaks or missing the object details in the result. In this paper, we propose SEIDNet equipped with the generative Status Estimation and Information Decoupling for rain removal. In the status estimation, we embed the pixel-wise statuses into the status space, where each status indicates a pixel of the rain or object. The status space allows sampling multiple statuses for a pixel, thus capturing the confusing rain or object. In the information decoupling, we respect the pixel-wise statuses, decoupling the appearance information of rain and object from the pixel. Based on the decoupled information, we construct the kernel space, where multiple kernels are sampled for the pixel to remove the rain and recover the object appearance. We evaluate SEIDNet on the public datasets, achieving state-of-the-art performances of image rain removal. The experimental results also demonstrate the generalization of SEIDNet, which can be easily extended to achieve state-of-the-art performances on other image restoration tasks (e.g., snow, haze, and shadow removal).",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Embodied Scene-aware Human Pose Estimation",
        "paper_url": "https://openreview.net/pdf?id=xl39QEYiB-j",
        "paper_authors": [
            "Zhengyi Luo",
            "Shun Iwase",
            "Ye Yuan",
            "Kris M. Kitani"
        ],
        "paper_abstract": " We propose embodied scene-aware human pose estimation where we estimate 3D poses based on a simulated agent's proprioception and scene awareness, along with external third-person observations. Unlike prior methods that often resort to multistage optimization, non-causal inference, and complex contact modeling to estimate human pose and human scene interactions, our method is one-stage, causal, and recovers global 3D human poses in a simulated environment. Since 2D third-person observations are coupled with the camera pose, we propose to disentangle the camera pose and use a multi-step projection gradient defined in the global coordinate frame as the movement cue for our embodied agent. Leveraging a physics simulation and prescanned scenes (e.g., 3D mesh), we simulate our agent in everyday environments (library, office, bedroom, etc.) and equip our agent with environmental sensors to intelligently navigate and interact with the geometries of the scene. Our method also relies only on 2D keypoints and can be trained on synthetic datasets derived from popular human motion databases. To evaluate, we use the popular H36M and PROX datasets and achieve high quality pose estimation on the challenging PROX dataset without ever using PROX motion sequences for training. Code and videos are available on the project page.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "\"Lossless\" Compression of Deep Neural Networks: A High-dimensional Neural Tangent Kernel Approach",
        "paper_url": "https://openreview.net/pdf?id=NaW6T93F34m",
        "paper_authors": [
            "Lingyu Gu",
            "Yongqi Du",
            "Yuan Zhang",
            "Di Xie",
            "Shiliang Pu",
            "Robert C Qiu",
            "Zhenyu Liao"
        ],
        "paper_abstract": "Modern deep neural networks (DNNs) are extremely powerful; however, this comes at the price of increased depth and having more parameters per layer, making their training and inference more computationally challenging. \nIn an attempt to address this key limitation, efforts have been devoted to the compression (e.g., sparsification and/or quantization) of these large-scale machine learning models, so that they can be deployed on low-power IoT devices.\nIn this paper, building upon recent research advances in the neural tangent kernel (NTK) and random matrix theory, we provide a novel compression approach to wide and fully-connected \\emph{deep} neural nets. \nSpecifically, we demonstrate that in the high-dimensional regime where the number of data points $n$ and their dimension $p$ are both large, and under a Gaussian mixture model for the data, there exists \\emph{asymptotic spectral equivalence} between the NTK matrices for a large family of DNN models. \nThis theoretical result enables ''lossless'' compression of a given DNN to be performed, in the sense that the compressed network yields asymptotically the same NTK as the original (dense and unquantized) network, with its weights and activations taking values \\emph{only} in $\\{ 0, \\pm 1 \\}$ up to scaling. \nExperiments on both synthetic and real-world data are conducted to support the advantages of the proposed compression scheme, with code available at https://github.com/Model-Compression/Lossless_Compression.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DaDA: Distortion-aware Domain Adaptation for Unsupervised Semantic Segmentation",
        "paper_url": "https://openreview.net/pdf?id=6RoAxmwj0L2",
        "paper_authors": [
            "Sujin Jang",
            "Joohan Na",
            "Dokwan Oh"
        ],
        "paper_abstract": "Distributional shifts in photometry and texture have been extensively studied for unsupervised domain adaptation, but their counterparts in optical distortion have been largely neglected. In this work, we tackle the task of unsupervised domain adaptation for semantic image segmentation where unknown optical distortion exists between source and target images. To this end, we propose a distortion-aware domain adaptation (DaDA) framework that boosts the unsupervised segmentation performance. We first present a relative distortion learning (RDL) approach that is capable of modeling domain shifts in fine-grained geometric deformation based on diffeomorphic transformation. Then, we demonstrate that applying additional global affine transformations to the diffeomorphically transformed source images can further improve the segmentation adaptation. Besides, we find that our distortion-aware adaptation method helps to enhance self-supervised learning by providing higher-quality initial models and pseudo labels. To evaluate, we propose new distortion adaptation benchmarks, where rectilinear source images and fisheye target images are used for unsupervised domain adaptation. Extensive experimental results highlight the effectiveness of our approach over state-of-the-art methods under unknown relative distortion across domains. Datasets and more information are available at https://sait-fdd.github.io/.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Coded Residual Transform for Generalizable Deep Metric Learning",
        "paper_url": "https://openreview.net/pdf?id=AlgbeSuE1lx",
        "paper_authors": [
            "SHICHAO KAN",
            "Yixiong Liang",
            "Min Li",
            "Yigang Cen",
            "Jianxin Wang",
            "Zhihai He"
        ],
        "paper_abstract": "A fundamental challenge in deep metric learning is the generalization capability of the  feature embedding network model since the embedding network learned on training classes need to be evaluated on new test classes. To address this challenge, in this paper, we introduce a new method called coded residual transform (CRT) for deep metric learning to significantly improve its generalization capability. Specifically, we learn a set of diversified prototype features, project the feature map onto each prototype, and then encode its features using their projection residuals weighted by their correlation coefficients with each prototype. The proposed CRT method has the following two unique characteristics. First, it represents and encodes the feature map from a set of complimentary perspectives based on projections onto diversified prototypes. Second, unlike existing transformer-based feature representation approaches which encode the original values of features based on global correlation analysis, the proposed coded residual transform encodes the relative differences between the original features and their projected prototypes. Embedding space density and spectral decay analysis show that this multi perspective projection onto diversified prototypes and coded residual representation  are able to achieve significantly improved generalization capability in metric learning. Finally, to further enhance the generalization performance, we propose to enforce the consistency on their feature similarity matrices between  coded residual transforms with different sizes of projection prototypes and embedding dimensions. Our extensive experimental results and ablation studies demonstrate that the proposed CRT method outperform the state-of-the-art deep metric learning methods by large margins and improving upon the current best method by up to 4.28% on the CUB dataset.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "S-Prompts Learning with Pre-trained Transformers: An Occam\u2019s Razor for Domain Incremental Learning",
        "paper_url": "https://openreview.net/pdf?id=ZVe_WeMold",
        "paper_authors": [
            "Yabin Wang",
            "Zhiwu Huang",
            "Xiaopeng Hong"
        ],
        "paper_abstract": "State-of-the-art deep neural networks are still struggling to address the catastrophic forgetting problem in continual learning. In this paper, we propose one simple paradigm (named as S-Prompting) and two concrete approaches to highly reduce the forgetting degree in one of the most typical continual learning scenarios, i.e., domain increment learning (DIL). The key idea of the paradigm is to learn prompts independently across domains with pre-trained transformers, avoiding the use of exemplars that commonly appear in conventional methods. This results in a win-win game where the prompting can achieve the best for each domain. The independent prompting across domains only requests one single cross-entropy loss for training and one simple K-NN operation as a domain identifier for inference. The learning paradigm derives an image prompt learning approach and a novel language-image prompt learning approach. Owning an excellent scalability (0.03% parameter increase per domain), the best of our approaches achieves a remarkable relative improvement (an average of about 30%) over the best of the state-of-the-art exemplar-free methods for three standard DIL tasks, and even surpasses the best of them relatively by about 6% in average when they use exemplars. Source code is available at https://github.com/iamwangyabin/S-Prompts.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fairness Reprogramming",
        "paper_url": "https://openreview.net/pdf?id=Nay_rOB-dZv",
        "paper_authors": [
            "Guanhua Zhang",
            "Yihua Zhang",
            "Yang Zhang",
            "Wenqi Fan",
            "Qing Li",
            "Sijia Liu",
            "Shiyu Chang"
        ],
        "paper_abstract": "Despite a surge of recent advances in promoting machine Learning (ML) fairness, the existing mainstream approaches mostly require training or finetuning the entire weights of the neural network to meet the fairness criteria.  However, this is often infeasible in practice for those large-scale trained models due to large computational and storage costs, low data efficiency, and model privacy issues.  In this paper, we propose a new generic fairness learning paradigm, called FairReprogram, which incorporates the model reprogramming technique.  Specifically, FairReprogram considers the case where models can not be changed and appends to the input a set of perturbations, called the fairness trigger, which is tuned towards the fairness criteria under a min-max formulation.  We further introduce an information-theoretic framework that explains why and under what conditions fairness goals can be achieved using the fairness trigger.  We show both theoretically and empirically that the fairness trigger can effectively obscure demographic biases in the output prediction of fixed ML models by providing false demographic information that hinders the model from utilizing the correct demographic information to make the prediction.  Extensive experiments on both NLP and CV datasets demonstrate that our method can achieve better fairness improvements than retraining-based methods with far less data dependency under two widely-used fairness criteria. Codes are available at https://github.com/UCSB-NLP-Chang/Fairness-Reprogramming.git.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "DeepTOP: Deep Threshold-Optimal Policy for MDPs and RMABs",
        "paper_url": "https://openreview.net/pdf?id=Wk-4Tp-gPpv",
        "paper_authors": [
            "Khaled Nakhleh",
            "I-Hong Hou"
        ],
        "paper_abstract": "We consider the problem of learning the optimal threshold policy for control problems. Threshold policies make control decisions by evaluating whether an element of the system state exceeds a certain threshold, whose value is determined by other elements of the system state. By leveraging the monotone property of threshold policies, we prove that their policy gradients have a surprisingly simple expression. We use this simple expression to build an off-policy actor-critic algorithm for learning the optimal threshold policy. Simulation results show that our policy significantly outperforms other reinforcement learning algorithms due to its ability to exploit the monotone property.\nIn addition, we show that the Whittle index, a powerful tool for restless multi-armed bandit problems, is equivalent to the optimal threshold policy for an alternative problem. This observation leads to a simple algorithm that finds the Whittle index by learning the optimal threshold policy in the alternative problem. Simulation results show that our algorithm learns the Whittle index much faster than several recent studies that learn the Whittle index through indirect means.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "GAMA: Generative Adversarial Multi-Object Scene Attacks",
        "paper_url": "https://openreview.net/pdf?id=DRckHIGk8qw",
        "paper_authors": [
            "Abhishek Aich",
            "Calvin-Khang Ta",
            "Akash A Gupta",
            "Chengyu Song",
            "Srikanth Krishnamurthy",
            "M. Salman Asif",
            "Amit Roy-Chowdhury"
        ],
        "paper_abstract": "The majority of methods for crafting adversarial attacks have focused on scenes with a single dominant object (e.g., images from ImageNet). On the other hand, natural scenes include multiple dominant objects that are semantically related. Thus, it is crucial to explore designing attack strategies that look beyond learning on single-object scenes or attack single-object victim classifiers. Due to their inherent property of strong transferability of perturbations to unknown models, this paper presents the first approach of using generative models for adversarial attacks on multi-object scenes. In order to represent the relationships between different objects in the input scene, we leverage upon the open-sourced pre-trained vision-language model CLIP (Contrastive Language-Image Pre-training), with the motivation to exploit the encoded semantics in the language space along with the visual space. We call this attack approach Generative Adversarial Multi-object Attacks (GAMA). GAMA demonstrates the utility of the CLIP model as an attacker's tool to train formidable perturbation generators for multi-object scenes. Using the joint image-text features to train the generator, we show that GAMA can craft potent transferable perturbations in order to fool victim classifiers in various attack settings. For example, GAMA triggers ~16% more misclassification than state-of-the-art generative approaches in black-box settings where both the classifier architecture and data distribution of the attacker are different from the victim. Our code is available here: https://abhishekaich27.github.io/gama.html",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "RecursiveMix: Mixed Learning with History",
        "paper_url": "https://openreview.net/pdf?id=NjP18IbKKlX",
        "paper_authors": [
            "Lingfeng Yang",
            "Xiang Li",
            "Borui Zhao",
            "Renjie Song",
            "Jian Yang"
        ],
        "paper_abstract": "Mix-based augmentation has been proven fundamental to the generalization of deep vision models. However, current augmentations only mix samples from the current data batch during training, which ignores the possible knowledge accumulated in the learning history. In this paper, we propose a recursive mixed-sample learning paradigm, termed ``RecursiveMix'' (RM), by exploring a novel training strategy that leverages the historical input-prediction-label triplets. More specifically, we iteratively resize the input image batch from the previous iteration and paste it into the current batch while their labels are fused proportionally to the area of the operated patches. Furthermore, a consistency loss is introduced to align the identical image semantics across the iterations, which helps the learning of scale-invariant feature representations. Based on ResNet-50, RM largely improves classification accuracy by $\\sim$3.2% on CIFAR-100 and $\\sim$2.8% on ImageNet with negligible extra computation/storage costs. In the downstream object detection task, the RM-pretrained model outperforms the baseline by 2.1 AP points and surpasses CutMix by 1.4 AP points under the ATSS detector on COCO. In semantic segmentation, RM also surpasses the baseline and CutMix by 1.9 and 1.1 mIoU points under UperNet on ADE20K, respectively. Codes and pretrained models are available at https://github.com/implus/RecursiveMix.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Differentiable Analog Quantum Computing for Optimization and Control",
        "paper_url": "https://openreview.net/pdf?id=gc87Cs_V9qR",
        "paper_authors": [
            "Jiaqi Leng",
            "Yuxiang Peng",
            "Yi-Ling Qiao",
            "Ming Lin",
            "Xiaodi Wu"
        ],
        "paper_abstract": "We formulate the first differentiable analog quantum computing framework with specific parameterization design at the analog signal (pulse) level to better exploit near-term quantum devices via variational methods. We further propose a scalable approach to estimate the gradients of quantum dynamics using a forward pass with Monte Carlo sampling, which leads to a quantum stochastic gradient descent algorithm for scalable gradient-based training in our framework. Applying our framework to quantum optimization and control, we observe a significant advantage of differentiable analog quantum computing against SOTAs based on parameterized digital quantum circuits by {\\em orders of magnitude}. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos",
        "paper_url": "https://openreview.net/pdf?id=QXLue5WoSBE",
        "paper_authors": [
            "Yi-Ling Qiao",
            "Alexander Gao",
            "Ming Lin"
        ],
        "paper_abstract": "We present a method for learning 3D geometry and physics parameters of a dynamic scene from only a monocular RGB video input. To decouple the learning of underlying scene geometry from dynamic motion, we represent the scene as a time-invariant signed distance function (SDF) which serves as a reference frame, along with a time-conditioned deformation field. We further bridge this neural geometry representation with a differentiable physics simulator by designing a two-way conversion between the neural field and its corresponding hexahedral mesh, enabling us to estimate physics parameters from the source video by minimizing a cycle consistency loss. Our method also allows a user to interactively edit 3D objects from the source video by modifying the recovered hexahedral mesh, and propagating the operation back to the neural field representation. Experiments show that our method achieves superior mesh and video reconstruction of dynamic scenes compared to competing Neural Field approaches, and we provide extensive examples which demonstrate its ability to extract useful 3D representations from videos captured with consumer-grade cameras.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "SGAM: Building a Virtual 3D World through Simultaneous Generation and Mapping",
        "paper_url": "https://openreview.net/pdf?id=17KCLTbRymw",
        "paper_authors": [
            "Yuan Shen",
            "Wei-Chiu Ma",
            "Shenlong Wang"
        ],
        "paper_abstract": "We present simultaneous generation and mapping (SGAM), a novel 3D scene generation algorithm. Our goal is to produce a realistic, globally consistent 3D world on a large scale. Achieving this goal is challenging and goes beyond the capacities of existing 3D generation or video generation approaches, which fail to scale up to create large, globally consistent 3D scene structures. Towards tackling the challenges, we take a hybrid approach that integrates generative sensor model- ing with 3D reconstruction. Our proposed approach is an autoregressive generative framework that simultaneously generates sensor data at novel viewpoints and builds a 3D map at each timestamp. Given an arbitrary camera trajectory, our method repeatedly applies this generation-and-mapping process for thousands of steps, allowing us to create a gigantic virtual world. Our model can be trained from RGB-D sequences without having access to the complete 3D scene structure. The generated scenes are readily compatible with various interactive environments and rendering engines. Experiments on CLEVER and GoogleEarth datasets demon- strates ours can generate consistent, realistic, and geometrically-plausible scenes that compare favorably to existing view synthesis methods. Our project page is available at https://yshen47.github.io/sgam.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Learning Substructure Invariance for Out-of-Distribution Molecular Representations",
        "paper_url": "https://openreview.net/pdf?id=2nWUNTnFijm",
        "paper_authors": [
            "Nianzu Yang",
            "Kaipeng Zeng",
            "Qitian Wu",
            "Xiaosong Jia",
            "Junchi Yan"
        ],
        "paper_abstract": "Molecule representation learning (MRL) has been extensively studied and current methods have shown promising power for various tasks, e.g., molecular property prediction and target  identification. However, a common hypothesis of existing methods is that either the model development or experimental evaluation is mostly based on i.i.d. data across training and testing. Such a hypothesis can be violated in real-world applications where testing molecules could come from new environments, bringing about serious performance degradation or unexpected prediction. We propose a new representation learning framework entitled MoleOOD to enhance the robustness of MRL models against such distribution shifts, motivated by an observation that the (bio)chemical properties of molecules are usually invariantly associated with certain privileged molecular substructures across different environments (e.g., scaffolds, sizes, etc.). Specifically, We introduce an environment inference model to identify the latent factors that impact data generation from different distributions in a fully data-driven manner. We also propose a new learning objective to guide the molecule encoder to leverage environment-invariant substructures that more stably relate with the labels across environments. Extensive experiments on ten real-world datasets demonstrate that our model has a stronger generalization ability than existing methods under various out-of-distribution (OOD) settings, despite the absence of manual specifications of environments. Particularly, our method achieves up to 5.9\\% and 3.9\\% improvement over the strongest baselines on OGB and DrugOOD benchmarks in terms of ROC-AUC, respectively. Our source code is publicly available at \\url{https://github.com/yangnianzu0515/MoleOOD}.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Lethal Dose Conjecture on Data Poisoning",
        "paper_url": "https://openreview.net/pdf?id=PYnSpt3jAz",
        "paper_authors": [
            "Wenxiao Wang",
            "Alexander Levine",
            "Soheil Feizi"
        ],
        "paper_abstract": "Data poisoning considers an adversary that distorts the training set of machine learning algorithms for malicious purposes. In this work, we bring to light one conjecture regarding the fundamentals of data poisoning, which we call the Lethal Dose Conjecture. The conjecture states: If $n$ clean training samples are needed for accurate predictions, then in a size-$N$ training set, only $\\Theta(N/n)$ poisoned samples can be tolerated while ensuring accuracy. Theoretically, we verify this conjecture in multiple cases. We also offer a more general perspective of this conjecture through distribution discrimination. Deep Partition Aggregation (DPA) and its extension, Finite Aggregation (FA) are recent approaches for provable defenses against data poisoning, where they predict through the majority vote of many base models trained from different subsets of training set using a given learner. The conjecture implies that both DPA and FA are (asymptotically) optimal---if we have the most data-efficient learner, they can turn it into one of the most robust defenses against data poisoning. This outlines a practical approach to developing stronger defenses against poisoning via finding data-efficient learners. Empirically, as a proof of concept, we show that by simply using different data augmentations for base learners, we can respectively double and triple the certified robustness of DPA on CIFAR-10 and GTSRB without sacrificing accuracy. ",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Unsupervised Causal Generative Understanding of Images",
        "paper_url": "https://openreview.net/pdf?id=VvOcK2DGM7G",
        "paper_authors": [
            "Titas Anciukevi\u010dius",
            "Patrick Fox-Roberts",
            "Edward Rosten",
            "Paul Henderson"
        ],
        "paper_abstract": "We present a novel framework for unsupervised object-centric 3D scene understanding that generalizes robustly to out-of-distribution images. To achieve this, we design a causal generative model reflecting the physical process by which an image is produced, when a camera captures a scene containing multiple objects. This model is trained to reconstruct multi-view images via a latent representation describing the shapes, colours and positions of the 3D objects they show. It explicitly represents object instances as separate neural radiance fields, placed into a 3D scene. We then propose an inference algorithm that can infer this latent representation given a single out-of-distribution image as input -- even when it shows an unseen combination of components, unseen spatial compositions or a radically new viewpoint. We conduct extensive experiments applying our approach to test datasets that have zero probability under the training distribution. These show that it accurately reconstructs a scene's geometry, segments objects and infers their positions, despite not receiving any supervision. Our approach significantly out-performs baselines that do not capture the true causal image generation process.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Don't Pour Cereal into Coffee: Differentiable Temporal Logic for Temporal Action Segmentation",
        "paper_url": "https://openreview.net/pdf?id=PCQyUvAmKs",
        "paper_authors": [
            "Ziwei Xu",
            "Yogesh S Rawat",
            "Yongkang Wong",
            "Mohan Kankanhalli",
            "Mubarak Shah"
        ],
        "paper_abstract": "We propose Differentiable Temporal Logic (DTL), a model-agnostic framework that introduces temporal constraints to deep networks. DTL treats the outputs of a network as a truth assignment of a temporal logic formula, and computes a temporal logic loss reflecting the consistency between the output and the constraints. We propose a comprehensive set of constraints, which are implicit in data annotations, and incorporate them with deep networks via DTL. We evaluate the effectiveness of DTL on the temporal action segmentation task and observe improved performance and reduced logical errors in the output of different task models. Furthermore, we provide an extensive analysis to visualize the desirable effects of DTL.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Rank Diminishing in Deep Neural Networks",
        "paper_url": "https://openreview.net/pdf?id=tIqzLFf3kk",
        "paper_authors": [
            "Ruili Feng",
            "Kecheng Zheng",
            "Yukun Huang",
            "Deli Zhao",
            "Michael Jordan",
            "Zheng-Jun Zha"
        ],
        "paper_abstract": "The rank of neural networks measures information flowing across layers. It is an instance of a key structural condition that applies across broad domains of machine learning. In particular, the assumption of low-rank feature representations led to algorithmic developments in many architectures. For neural networks, however, the intrinsic mechanism that yields low-rank structures remains vague and unclear. To fill this gap, we perform a rigorous study on the behavior of network rank, focusing particularly on the notion of rank deficiency. We theoretically establish a universal monotone decreasing property of network ranks from the basic rules of differential and algebraic composition, and uncover rank deficiency of network blocks and deep function coupling. By virtue of our numerical tools, we provide the first empirical analysis of the per-layer behavior of network ranks in realistic settings, \\ieno, ResNets, deep MLPs, and Transformers on ImageNet. These empirical results are in direct accord with our theory. Furthermore, we reveal a novel phenomenon of independence deficit caused by the rank deficiency of deep networks, where classification confidence of a given category can be linearly decided by the confidence of a handful of other categories. The theoretical results of this work, together with the empirical findings, may advance understanding of the inherent principles of deep neural networks. Code to detect the rank behavior of networks can be found in https://github.com/RuiLiFeng/Rank-Diminishing-in-Deep-Neural-Networks.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "A Lower Bound of Hash Codes' Performance",
        "paper_url": "https://openreview.net/pdf?id=k7xZKpYebXL",
        "paper_authors": [
            "Xiaosu Zhu",
            "Jingkuan Song",
            "Yu Lei",
            "Lianli Gao",
            "Hengtao Shen"
        ],
        "paper_abstract": "As a crucial approach for compact representation learning, hashing has achieved great success in effectiveness and efficiency. Numerous heuristic Hamming space metric learning objectives are designed to obtain high-quality hash codes. Nevertheless, a theoretical analysis of criteria for learning good hash codes remains largely unexploited. In this paper, we prove that inter-class distinctiveness and intra-class compactness among hash codes determine the lower bound of hash codes' performance. Promoting these two characteristics could lift the bound and improve hash learning. We then propose a surrogate model to fully exploit the above objective by estimating the posterior of hash codes and controlling it, which results in a low-bias optimization. Extensive experiments reveal the effectiveness of the proposed method. By testing on a series of hash-models, we obtain performance improvements among all of them, with an up to $26.5\\%$ increase in mean Average Precision and an up to $20.5\\%$ increase in accuracy. Our code is publicly available at https://github.com/VL-Group/LBHash.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Fine-Grained Semantically Aligned Vision-Language Pre-Training",
        "paper_url": "https://openreview.net/pdf?id=yam42JWePu",
        "paper_authors": [
            "Juncheng Li",
            "XIN HE",
            "Longhui Wei",
            "Long Qian",
            "Linchao Zhu",
            "Lingxi Xie",
            "Yueting Zhuang",
            "Qi Tian",
            "Siliang Tang"
        ],
        "paper_abstract": "Large-scale vision-language pre-training has shown impressive advances in a wide range of downstream tasks. Existing methods mainly model the cross-modal alignment by the similarity of the global representations of images and text, or advanced cross-modal attention upon image and text features. However, they fail to explicitly learn the fine-grained semantic alignment between visual regions and textual phrases, as only global image-text alignment information is available. In this paper, we introduce LOUPE, a fine-grained semantically aLigned visiOn-langUage PrE-training framework, which learns fine-grained semantic alignment from the novel perspective of game-theoretic interactions. To efficiently estimate the game-theoretic interactions, we further propose an uncertainty-aware neural Shapley interaction learning module. Experiments show that LOUPE achieves state-of-the-art performance on a variety of  vision-language tasks. Without any object-level human annotations and fine-tuning, LOUPE achieves competitive performance on object detection and visual grounding. More importantly, LOUPE opens a new promising direction of learning fine-grained semantics from large-scale raw image-text pairs.",
        "paper_code": "#",
        "paper_cite": -1
    },
    {
        "paper_name": "Sample Complexity of Learning Heuristic Functions for Greedy-Best-First and A* Search",
        "paper_url": "https://openreview.net/pdf?id=FurHLDnmC5v",
        "paper_authors": [
            "Shinsaku Sakaue",
            "Taihei Oki"
        ],
        "paper_abstract": "Greedy best-first search (GBFS) and A* search (A*) are popular algorithms for path-finding on large graphs. Both use so-called heuristic functions, which estimate how close a vertex is to the goal. While heuristic functions have been handcrafted using domain knowledge, recent studies demonstrate that learning heuristic functions from data is effective in many applications. Motivated by this emerging approach, we study the sample complexity of learning heuristic functions for GBFS and A*. We build on a recent framework called \\textit{data-driven algorithm design} and evaluate the \\textit{pseudo-dimension} of a class of utility functions that measure the performance of parameterized algorithms. Assuming that a vertex set of size $n$ is fixed, we present $\\mathrm{O}(n\\lg n)$ and $\\mathrm{O}(n^2\\lg n)$ upper bounds on the pseudo-dimensions for GBFS and A*, respectively, parameterized by heuristic function values. The upper bound for A* can be improved to $\\mathrm{O}(n^2\\lg d)$ if every vertex has a degree of at most $d$ and to $\\mathrm{O}(n \\lg n)$ if edge weights are integers bounded by $\\mathrm{poly}(n)$. We also give $\\Omega(n)$ lower bounds for GBFS and A*, which imply that our bounds for GBFS and A* under the integer-weight condition are tight up to a $\\lg n$ factor. Finally, we discuss a case where the performance of A* is measured by the suboptimality and show that we can sometimes obtain a better guarantee by combining a parameter-dependent worst-case bound with a sample complexity bound.",
        "paper_code": "#",
        "paper_cite": -1
    }
]